{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RbAFc0gCE1Yf"
      },
      "source": [
        "> ### **OPTIMAL DATA RANGE**\n",
        "---\n",
        "*   ClipLimit: 2-3\n",
        "*   Learning rate: 0.0001 < lr < 0.1\n",
        "*   Batch size: 32, 64, 128\n",
        "*   Dropout rate: 0,5 - 0,8\n",
        "*   Weight: otomatis"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GS2cutmMFf7k"
      },
      "source": [
        "> ### **STRUKTUR**\n",
        "---\n",
        "\n",
        "*   Optimizer: Adam\n",
        "*   Activation function: ReLu (training), Softmax (final)\n",
        "*   Pooling: _Max Pooling_\n",
        "*   Kernel size: 130x242\n",
        "*   Training/testing/validation: 70/10/20\n",
        "*   Epoch: 30-65\n",
        "*   Class: 7\n",
        "*   Weight: ImageNet\n",
        "*   Loss: Cross-Entropy"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RiQq7ALDHNRD"
      },
      "source": [
        " ## **DATA PREPARATION**\n",
        "---\n",
        "menyiapkan data (termasuk penerapan image enhancement)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting opencv-python==4.7.0.72\n",
            "  Downloading opencv_python-4.7.0.72-cp37-abi3-win_amd64.whl (38.2 MB)\n",
            "     ---------------------------------------- 38.2/38.2 MB 2.2 MB/s eta 0:00:00\n",
            "Requirement already satisfied: scikit-image in c:\\users\\user\\anaconda3\\lib\\site-packages (from -r D:\\00 Ardina\\Model Skripsi\\requirements.txt (line 2)) (0.19.3)\n",
            "Collecting graphviz\n",
            "  Downloading graphviz-0.20.1-py3-none-any.whl (47 kB)\n",
            "     -------------------------------------- 47.0/47.0 kB 471.8 kB/s eta 0:00:00\n",
            "Requirement already satisfied: openpyxl in c:\\users\\user\\anaconda3\\lib\\site-packages (from -r D:\\00 Ardina\\Model Skripsi\\requirements.txt (line 4)) (3.0.10)\n",
            "Collecting pydot\n",
            "  Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: pip in c:\\users\\user\\anaconda3\\lib\\site-packages (from -r D:\\00 Ardina\\Model Skripsi\\requirements.txt (line 7)) (22.3.1)\n",
            "  Downloading pydot-1.2.3.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting pydotplus\n",
            "  Downloading pydotplus-2.0.2.tar.gz (278 kB)\n",
            "     -------------------------------------- 278.7/278.7 kB 1.7 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting pydot_ng\n",
            "  Downloading pydot_ng-2.0.0-py2.py3-none-any.whl (20 kB)\n",
            "Collecting plot_model\n",
            "  Downloading plot_model-0.20-py3-none-any.whl (6.9 kB)\n",
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from opencv-python==4.7.0.72->-r D:\\00 Ardina\\Model Skripsi\\requirements.txt (line 1)) (1.23.5)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydot->-r D:\\00 Ardina\\Model Skripsi\\requirements.txt (line 5)) (3.0.9)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-image->-r D:\\00 Ardina\\Model Skripsi\\requirements.txt (line 2)) (22.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-image->-r D:\\00 Ardina\\Model Skripsi\\requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-image->-r D:\\00 Ardina\\Model Skripsi\\requirements.txt (line 2)) (2.26.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-image->-r D:\\00 Ardina\\Model Skripsi\\requirements.txt (line 2)) (2021.7.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-image->-r D:\\00 Ardina\\Model Skripsi\\requirements.txt (line 2)) (1.10.0)\n",
            "Requirement already satisfied: networkx>=2.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-image->-r D:\\00 Ardina\\Model Skripsi\\requirements.txt (line 2)) (2.8.4)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-image->-r D:\\00 Ardina\\Model Skripsi\\requirements.txt (line 2)) (9.4.0)\n",
            "Requirement already satisfied: et_xmlfile in c:\\users\\user\\anaconda3\\lib\\site-packages (from openpyxl->-r D:\\00 Ardina\\Model Skripsi\\requirements.txt (line 4)) (1.1.0)\n",
            "Building wheels for collected packages: pydot, pydotplus\n",
            "  Building wheel for pydot (setup.py): started\n",
            "  Building wheel for pydot (setup.py): finished with status 'done'\n",
            "  Created wheel for pydot: filename=pydot-1.2.3-py3-none-any.whl size=18942 sha256=ad9a32ff87f4e706ea66bac9a2f909c4cc20cd81cf23b97a4d5a796a0fe5f945\n",
            "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\a8\\0a\\63\\6ea0aa7a137559306d1c8886ac43d1f752c9fa90d45e1cbc7b\n",
            "  Building wheel for pydotplus (setup.py): started\n",
            "  Building wheel for pydotplus (setup.py): finished with status 'done'\n",
            "  Created wheel for pydotplus: filename=pydotplus-2.0.2-py3-none-any.whl size=24578 sha256=2b8886bab4765b9a06c8502fd944e664878de35c4f4ca0e06f8e7e7da96aa4c8\n",
            "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\5c\\94\\1f\\953aa60af58ef512e5256e538ff0772c340229e5996ac51fd6\n",
            "Successfully built pydot pydotplus\n",
            "Installing collected packages: plot_model, split-folders, pydotplus, pydot_ng, pydot, opencv-python, graphviz\n",
            "Successfully installed graphviz-0.20.1 opencv-python-4.7.0.72 plot_model-0.20 pydot-1.2.3 pydot_ng-2.0.0 pydotplus-2.0.2 split-folders-0.5.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install -r \"D:\\00 Ardina\\Model Skripsi\\requirements.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rzc4-JxOI9Jj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing, neighbors\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izpw8VI-I9lt",
        "outputId": "9b0ba66a-3bef-4e3f-92cf-89f1426a0490"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Daftar kelas =  ['1000', '10000', '100000', '2000', '20000', '5000', '50000'] \n",
            "\n",
            "Banyak kelas =  7\n"
          ]
        }
      ],
      "source": [
        "path = r\"D:\\UNAIR\\Semester_8\\Skripsi\\deteksi_nominal_vending_machine\\datasetUang\"\n",
        "\n",
        "kelas = os.listdir(path)\n",
        "print(\"Daftar kelas = \",kelas,\"\\n\\nBanyak kelas = \", len(kelas))\n",
        "dataset = path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdSJFwNsKYPU",
        "outputId": "01eda199-75c1-48c0-d593-8fb193175023"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Copying files: 700 files [00:10, 63.86 files/s]\n"
          ]
        }
      ],
      "source": [
        "import splitfolders\n",
        "splitfolders.ratio(dataset, output=\"datasetSplit\", seed=1307, ratio=(0.7, 0.2, 0.1)) #70% : 10% : 20%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvw2D5W_LIuC",
        "outputId": "c9c4ce5e-8677-4860-d9b6-c9978b5941cd"
      },
      "outputs": [],
      "source": [
        "dataset = \"datasetSplit\"\n",
        "#daftar_file(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ToC7O1guLVMc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from keras.utils import plot_model\n",
        "from sklearn.metrics import classification_report\n",
        "from collections import Counter\n",
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "\n",
        "from keras import Model, layers\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.layers import GlobalMaxPooling2D, GlobalAveragePooling2D, Dropout, Dense, Input, Conv2D, MaxPooling2D, Flatten,MaxPooling3D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "25wCmnRGLWAB"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = (130, 242, 3)\n",
        "dataset=\"datasetSplit\"\n",
        "train_pred_test_folders = os.listdir(dataset)\n",
        "train_path = dataset+'/train'\n",
        "test_path = dataset+'/test'\n",
        "val_path = dataset+'/val'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "FiEY_6rHLYKz",
        "outputId": "9d4609ad-b9a0-4390-929a-2c655aa760b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Banyak citra di training set: 490\n",
            "Banyak citra di testing set: 70\n",
            "Banyak citra di prediction set: 140\n",
            "Total citra: 700\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2000x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "quantity_train = {} \n",
        "quantity_test = {}\n",
        "quantity_val = {}\n",
        "for folder in os.listdir(train_path):\n",
        "    quantity_train[folder] = len(os.listdir(train_path+'/'+folder))\n",
        "\n",
        "for folder in os.listdir(test_path):\n",
        "    quantity_test[folder] = len(os.listdir(test_path+'/'+folder))\n",
        "\n",
        "for folder in os.listdir(val_path):\n",
        "    quantity_val[folder] = len(os.listdir(val_path+'/'+folder))\n",
        "\n",
        "quantity_train = pd.DataFrame(list(quantity_train.items()), index=range(0,len(quantity_train)), columns=['class','count'])\n",
        "quantity_test = pd.DataFrame(list(quantity_test.items()), index=range(0,len(quantity_test)), columns=['class','count'])\n",
        "quantity_val = pd.DataFrame(list(quantity_val.items()), index=range(0,len(quantity_val)), columns=['class','count'])\n",
        "\n",
        "figure, ax = plt.subplots(1,2,figsize=(20,5))\n",
        "sns.barplot(x='class',y='count',data=quantity_train,ax=ax[0])\n",
        "sns.barplot(x='class',y='count',data=quantity_test,ax=ax[1])\n",
        "\n",
        "print(\"Banyak citra di training set:\", sum(quantity_train['count'].values))\n",
        "print(\"Banyak citra di testing set:\",sum(quantity_test['count'].values))\n",
        "print(\"Banyak citra di prediction set:\",sum(quantity_val['count'].values))\n",
        "print(\"Total citra:\",sum(quantity_train['count'].values)+sum(quantity_test['count'].values)+sum(quantity_val['count'].values))\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MGtlhk8QLaZh"
      },
      "outputs": [],
      "source": [
        "def save_history(i, history, model_name):\n",
        "    #convert the history.history dict to a pandas DataFrame:     \n",
        "    hist_df = pd.DataFrame(history.history) \n",
        "\n",
        "    # save ke json \n",
        "    hist_json_file = 'percobaan'+str(i)+'_noImgPro/'+model_name+'_history.json' \n",
        "    with open(hist_json_file, mode='w') as f:\n",
        "        hist_df.to_json(f)\n",
        "\n",
        "    # or save ke csv \n",
        "    hist_csv_file = 'percobaan'+str(i)+'_noImgPro/'+model_name+'_history.csv'\n",
        "    with open(hist_csv_file, mode='w') as f:\n",
        "        hist_df.to_csv(f)\n",
        "        \n",
        "def plot_accuracy_from_history(history, isinception=False):\n",
        "  try:\n",
        "    color = sns.color_palette()\n",
        "    if(isinception == False):\n",
        "        acc = history.history['acc']\n",
        "        val_acc = history.history['val_acc']\n",
        "    else:\n",
        "        acc = history.history['accuracy']\n",
        "        val_acc = history.history['val_accuracy']\n",
        "    \n",
        "\n",
        "    epochs = range(len(acc))\n",
        "\n",
        "    sns.lineplot(epochs, acc, label='Training Accuracy')\n",
        "    sns.lineplot(epochs, val_acc,label='Validation Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.legend()\n",
        "    plt.figure()\n",
        "    plt.show()\n",
        "  except TypeError:\n",
        "    pass\n",
        "    \n",
        "def plot_loss_from_history(history):\n",
        "  try:\n",
        "    color = sns.color_palette()\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    \n",
        "    epochs = range(len(loss))\n",
        "    \n",
        "    sns.lineplot(epochs, loss,label='Training Loss')\n",
        "    sns.lineplot(epochs, val_loss, label='Validation Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.figure()\n",
        "    plt.show()\n",
        "  except TypeError:\n",
        "    pass\n",
        "    \n",
        "def do_history_stuff(i, history, history_file_name, isinception=False):\n",
        "    save_history(i, history, history_file_name)\n",
        "    plot_accuracy_from_history(history, isinception)\n",
        "    plot_loss_from_history(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ie_x1Pw9LlHe"
      },
      "outputs": [],
      "source": [
        "def show_few_images(number_of_examples=2, predict_using_model=None):\n",
        "    figure1, ax1 = plt.subplots(number_of_examples,len(os.listdir(train_path)), figsize=(20,4*number_of_examples))\n",
        "    ax1 = ax1.reshape(-1)\n",
        "    axoff_fun = np.vectorize(lambda ax:ax.axis('off'))\n",
        "    axoff_fun(ax1)\n",
        "    axs = 0\n",
        "    for i, folder in enumerate(os.listdir(train_path)):\n",
        "        image_ids = os.listdir(os.path.join(train_path,folder))\n",
        "        for j in [random.randrange(0, len(image_ids)) for i in range(0,number_of_examples)]:\n",
        "            display = plt.imread(os.path.join(train_path,folder,image_ids[j]))\n",
        "            plt.axis('off')\n",
        "            ax1[axs].imshow(display)\n",
        "            title = 'True:'+folder\n",
        "            if(predict_using_model):\n",
        "                predicted_classname = inv_map_classes[np.argmax(vgg16_final_model.predict(np.array([display])))]\n",
        "                title = title+'\\nPredict :'+predicted_classname\n",
        "            ax1[axs].set_title(title)\n",
        "            axs=axs+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xCuQKBilLnS9"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "z8lwG1_kv0gx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "def savePercobaan(i):\n",
        "  try: \n",
        "    os.mkdir(\"percobaan\"+str(i)+\"_noImgPro\") \n",
        "  except OSError as error: \n",
        "    print(error)\n",
        "  saveModel(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4HbaR-kTv3TN"
      },
      "outputs": [],
      "source": [
        "def saveModel(i):\n",
        "  try: \n",
        "    os.mkdir(\"percobaan\"+str(i)+\"_noImgPro/model\") \n",
        "  except OSError as error: \n",
        "    print(error)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TQdkty4ZLt0M"
      },
      "source": [
        " ## **VGG-16**\n",
        "---\n",
        "Visual Geometry Group (16 layers)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jXvi5J4K3j9-"
      },
      "source": [
        "#### **<font color='Pink'>Data Generator</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgkzGvmbnDxg",
        "outputId": "bd49992d-14ec-4a71-81be-02045365a35c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 490 images belonging to 7 classes.\n",
            "Found 70 images belonging to 7 classes.\n",
            "Found 140 images belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "#normalisasi\n",
        "train_datagen = ImageDataGenerator(rescale = 1.0/255.,shear_range=0.2,zoom_range=0.2)\n",
        "train_generator16 = train_datagen.flow_from_directory(train_path,\n",
        "                                                    batch_size=32,\n",
        "                                                    shuffle=True,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    target_size=(130, 242))\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1.0/255.,shear_range=0.2,zoom_range=0.2)\n",
        "test_generator16 = test_datagen.flow_from_directory(test_path, target_size=(130, 242),\n",
        "    batch_size=1,\n",
        "    shuffle=True,\n",
        "    class_mode='categorical')\n",
        "\n",
        "validation_generator16 = validation_datagen.flow_from_directory(val_path, shuffle=True, batch_size=1, class_mode='categorical', target_size=(130, 242))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jr3pfWLTnF8_",
        "outputId": "a6b2bfd0-2659-44f6-8a42-f29101199cda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: '1000', 1: '10000', 2: '100000', 3: '2000', 4: '20000', 5: '5000', 6: '50000'}\n"
          ]
        }
      ],
      "source": [
        "inv_map_classes = {v: k for k, v in validation_generator16.class_indices.items()}\n",
        "#print(validation_generator16.class_indices)\n",
        "print(inv_map_classes)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aActKL9O3mnY"
      },
      "source": [
        "#### **<font color='Pink'>Hyperparameter</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "NjEEV1Mx385B"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "import random\n",
        "\n",
        "array = [['ep1','ep2','ep3','ep4'], ['lr1', 'lr2', 'lr3', 'lr4'], [32, 64, 128], ['dr1', 'dr2', 'dr3', 'dr4']]\n",
        "\n",
        "parameter = []\n",
        "lr_values = array[1][1:]  \n",
        "\n",
        "for _ in range(1):\n",
        "    updated_array = [array[0], ['lr1'] + lr_values, array[2], array[3]]\n",
        "    parameter.extend(list(itertools.product(*updated_array)))\n",
        "\n",
        "parameter = [\n",
        "    [\n",
        "        random.randint(30, 38) if val == 'ep1' else\n",
        "        random.randint(39, 47) if val == 'ep2' else\n",
        "        random.randint(48, 56) if val == 'ep3' else\n",
        "        random.randint(57, 65) if val == 'ep4' else\n",
        "\n",
        "        random.uniform(0.0001, 0.0250249) if val == 'lr1' else\n",
        "        random.uniform(0.025025, 0.050049) if val == 'lr2' else\n",
        "        random.uniform(0.05005, 0.0750749) if val == 'lr3' else\n",
        "        random.uniform(0.075075, 0.1) if val == 'lr4' else\n",
        "\n",
        "        random.uniform(0.5,0.5749) if val == 'dr1' else\n",
        "        random.uniform(0.575,0.649) if val == 'dr2' else\n",
        "        random.uniform(0.65,0.7249) if val == 'dr3' else\n",
        "        random.uniform(0.725,0.8) if val == 'dr4' else\n",
        "\n",
        "        val\n",
        "        for val in kombinasi\n",
        "    ]\n",
        "    for kombinasi in parameter\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3r9T4AumF8JZ",
        "outputId": "f4f89d5d-c0c9-41c7-b0e3-743f28884496"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[36, 0.003373380751101915, 32, 0.5098543477601742]\n",
            "[32, 0.005496665022592807, 32, 0.6080104487879617]\n",
            "[36, 0.004662849646228612, 32, 0.687732078524114]\n",
            "[34, 0.01190268897277744, 32, 0.7389753114194317]\n",
            "[38, 0.015246180491445624, 64, 0.5057734648671738]\n",
            "[33, 0.023653093933468625, 64, 0.5931168335537779]\n",
            "[35, 0.020694432839000187, 64, 0.7035923844540974]\n",
            "[33, 0.021363949619930322, 64, 0.743230126828475]\n",
            "[30, 0.010782093337654343, 128, 0.5260731884539503]\n",
            "[36, 0.016504344312570828, 128, 0.599890573697134]\n",
            "[34, 0.0205449920354826, 128, 0.6915085113618809]\n",
            "[36, 0.024881247532097524, 128, 0.77681798187871]\n",
            "[38, 0.031015623475420754, 32, 0.5166230079897134]\n",
            "[30, 0.03479498747505785, 32, 0.6257901546234617]\n",
            "[34, 0.036836166087951774, 32, 0.7109004843910651]\n",
            "[31, 0.0424535288047127, 32, 0.7535125881771295]\n",
            "[36, 0.03962534179801804, 64, 0.5329734609067738]\n",
            "[33, 0.038345107192264194, 64, 0.5785973290075381]\n",
            "[38, 0.04555272952658948, 64, 0.6869451179212805]\n",
            "[38, 0.03546295958438139, 64, 0.7272027302474687]\n",
            "[38, 0.04279403856092859, 128, 0.54368622637818]\n",
            "[31, 0.04295159791370924, 128, 0.6117120019377673]\n",
            "[38, 0.03470002480251769, 128, 0.6884907205301077]\n",
            "[38, 0.042823880342522734, 128, 0.7883671831672531]\n",
            "[34, 0.054432581975451144, 32, 0.5004984651612646]\n",
            "[38, 0.06660148942189317, 32, 0.6336113685008343]\n",
            "[36, 0.0616952768552278, 32, 0.6954873347776639]\n",
            "[36, 0.07154005613594935, 32, 0.786803322661364]\n",
            "[35, 0.05576155676766237, 64, 0.5516596739007038]\n",
            "[32, 0.058014333984744065, 64, 0.6301342963479828]\n",
            "[31, 0.06558297953745194, 64, 0.6887562261723752]\n",
            "[38, 0.062400038086913454, 64, 0.7850179830960389]\n",
            "[36, 0.0560263479253946, 128, 0.5287316521768917]\n",
            "[33, 0.05028543928484376, 128, 0.5839420757509359]\n",
            "[38, 0.05054556130697726, 128, 0.6831681976218621]\n",
            "[30, 0.055821249892966, 128, 0.7607868515810495]\n",
            "[32, 0.08566278049902719, 32, 0.5122066672303368]\n",
            "[36, 0.09426885857772517, 32, 0.6395285511904477]\n",
            "[32, 0.08758311123272242, 32, 0.7084423543886953]\n",
            "[34, 0.09484235225062093, 32, 0.7676060801032628]\n",
            "[33, 0.08251000725987771, 64, 0.5409538017724222]\n",
            "[35, 0.08249403139146957, 64, 0.625803004219781]\n",
            "[30, 0.09793796720407102, 64, 0.6503977881273599]\n",
            "[37, 0.08458099746385507, 64, 0.7756885995423266]\n",
            "[38, 0.08411898310339605, 128, 0.5310941846458758]\n",
            "[32, 0.0909230508745451, 128, 0.5854906566923935]\n",
            "[34, 0.09523862134452271, 128, 0.6541069841668009]\n",
            "[37, 0.08481573179856466, 128, 0.765595155336293]\n",
            "[40, 0.020170820452382564, 32, 0.5245327410899279]\n",
            "[45, 0.023954023572214718, 32, 0.5859696348437249]\n",
            "[40, 0.022116640587646327, 32, 0.6780292694057619]\n",
            "[44, 0.0027256464038256187, 32, 0.7641779855343074]\n",
            "[47, 0.01911155168723404, 64, 0.5415049029759241]\n",
            "[41, 0.007877041115388115, 64, 0.6003905280318607]\n",
            "[47, 0.00852580696168669, 64, 0.6584232353309146]\n",
            "[45, 0.014759591959429259, 64, 0.7407550846229192]\n",
            "[47, 0.006402427047947042, 128, 0.5056521883518678]\n",
            "[47, 0.013313077658162122, 128, 0.6371334695276855]\n",
            "[41, 0.012489784221785082, 128, 0.6666608350221895]\n",
            "[39, 0.0013929159324779182, 128, 0.794090000573097]\n",
            "[41, 0.028006058735763697, 32, 0.5465884088309968]\n",
            "[46, 0.029634755858398143, 32, 0.6216139194599773]\n",
            "[46, 0.04992838718316221, 32, 0.6873140044830984]\n",
            "[45, 0.0367503841355071, 32, 0.7672356397595242]\n",
            "[44, 0.02622275318635393, 64, 0.531632003365117]\n",
            "[47, 0.04970282186617374, 64, 0.5928066621234753]\n",
            "[47, 0.03078456872386036, 64, 0.7156449185627459]\n",
            "[45, 0.03889556913389968, 64, 0.7627757489391922]\n",
            "[44, 0.02993088992936014, 128, 0.5529803484550162]\n",
            "[47, 0.039848288031838056, 128, 0.6252957366602191]\n",
            "[43, 0.04560678998437291, 128, 0.7050933649504139]\n",
            "[40, 0.028877856561581098, 128, 0.7957817332774954]\n",
            "[44, 0.05032061079785562, 32, 0.5744108521900502]\n",
            "[44, 0.0546955614160564, 32, 0.6161520691424651]\n",
            "[41, 0.0631099876158257, 32, 0.6933487201981056]\n",
            "[47, 0.06685644924408238, 32, 0.7712731704581774]\n",
            "[42, 0.05091025448828542, 64, 0.5115430975059718]\n",
            "[43, 0.05690470405178973, 64, 0.591474805914384]\n",
            "[45, 0.06415396858795326, 64, 0.6625137778815132]\n",
            "[39, 0.06345786256704437, 64, 0.7552177932174494]\n",
            "[39, 0.05210226330082308, 128, 0.5232498664797937]\n",
            "[44, 0.05219897005328457, 128, 0.6256593842172506]\n",
            "[39, 0.06133794235680031, 128, 0.7085516945714122]\n",
            "[47, 0.052817491576969945, 128, 0.7518608229569843]\n",
            "[47, 0.07746164588249607, 32, 0.5562515887307495]\n",
            "[40, 0.08339417587716944, 32, 0.5765387051287557]\n",
            "[39, 0.08943495429555098, 32, 0.6558542684620827]\n",
            "[44, 0.08475950772434501, 32, 0.7601539871445155]\n",
            "[39, 0.08966897437258448, 64, 0.5222472057270325]\n",
            "[42, 0.08872669931709687, 64, 0.5937700920562177]\n",
            "[40, 0.09291243382361616, 64, 0.6783351381713123]\n",
            "[45, 0.07529713692863613, 64, 0.7924792126289628]\n",
            "[41, 0.08239121204331203, 128, 0.530942147693638]\n",
            "[41, 0.09139775628470143, 128, 0.5986281564009589]\n",
            "[40, 0.08523069378545296, 128, 0.6869415973726476]\n",
            "[42, 0.07703926110853163, 128, 0.734022605002796]\n",
            "[50, 0.002300666284755375, 32, 0.5140491754161959]\n",
            "[56, 0.024056461955002946, 32, 0.5844897179570151]\n",
            "[56, 0.010037312707186757, 32, 0.6678597451284813]\n",
            "[53, 0.0007046085447911204, 32, 0.7515226189619136]\n",
            "[49, 0.015150976018065353, 64, 0.5116614560970408]\n",
            "[53, 0.009906581269068192, 64, 0.5909131203912827]\n",
            "[51, 0.0016981849299984343, 64, 0.7086747680757312]\n",
            "[51, 0.011365936686865058, 64, 0.7736342245729819]\n",
            "[50, 0.009306122244754115, 128, 0.5617712128642152]\n",
            "[50, 0.012225713751229293, 128, 0.6406416279912791]\n",
            "[55, 0.022127339749311845, 128, 0.7176465612445233]\n",
            "[49, 0.02127629281430496, 128, 0.7690826223076836]\n",
            "[51, 0.032880229954789404, 32, 0.5058296055881731]\n",
            "[55, 0.03953340605315715, 32, 0.6186829353926961]\n",
            "[51, 0.041053916494419446, 32, 0.7081340175185917]\n",
            "[54, 0.028783802895288403, 32, 0.7482727845658236]\n",
            "[51, 0.0346040144098581, 64, 0.5065614185024915]\n",
            "[54, 0.045193237393864064, 64, 0.5821878323577024]\n",
            "[56, 0.04805036749075145, 64, 0.6818098418960961]\n",
            "[51, 0.02630627162025417, 64, 0.7881312596205636]\n",
            "[52, 0.042130376864080415, 128, 0.5574261636074659]\n",
            "[54, 0.040732238808635524, 128, 0.5796299843319899]\n",
            "[50, 0.041768187810496404, 128, 0.687095266277389]\n",
            "[55, 0.04883880178659393, 128, 0.731031498629046]\n",
            "[54, 0.06311620329209942, 32, 0.5126121229406471]\n",
            "[54, 0.05862506254400038, 32, 0.5914364813599082]\n",
            "[56, 0.0681225167482978, 32, 0.6690522661395223]\n",
            "[52, 0.05274975596772224, 32, 0.7446122912911044]\n",
            "[51, 0.07197188413582659, 64, 0.5705368753629881]\n",
            "[56, 0.054602799744592125, 64, 0.6189756876085774]\n",
            "[50, 0.06283494963471081, 64, 0.7213835141632482]\n",
            "[48, 0.061984462453842704, 64, 0.7547421569913308]\n",
            "[54, 0.05492448170533113, 128, 0.5128626370397874]\n",
            "[51, 0.06077380884079496, 128, 0.6483756832215146]\n",
            "[53, 0.06406748801977996, 128, 0.6623006105447697]\n",
            "[53, 0.053309469729074646, 128, 0.7922816310660458]\n",
            "[49, 0.07856952478558586, 32, 0.5516424474400844]\n",
            "[55, 0.07551561923757853, 32, 0.6102030148010585]\n",
            "[52, 0.09388353388568085, 32, 0.7183233457165972]\n",
            "[49, 0.09883548349458617, 32, 0.7890955763566831]\n",
            "[52, 0.08127317684466412, 64, 0.5251981695386685]\n",
            "[55, 0.08220453587686394, 64, 0.6382139394734726]\n",
            "[53, 0.07792176414478176, 64, 0.717318732354546]\n",
            "[55, 0.09918163017884063, 64, 0.7484331467963614]\n",
            "[53, 0.09870289219381191, 128, 0.5734680319762546]\n",
            "[49, 0.0821826307764866, 128, 0.6275065402357112]\n",
            "[56, 0.09750194558723613, 128, 0.7245994033577801]\n",
            "[48, 0.08833882780477538, 128, 0.7463017998591978]\n",
            "[62, 0.02226534555186678, 32, 0.5275398179665044]\n",
            "[58, 0.003013433331347759, 32, 0.5756358261248318]\n",
            "[62, 0.014097732215003876, 32, 0.6947572896425255]\n",
            "[60, 0.02065371099560054, 32, 0.7311677545059123]\n",
            "[64, 0.011740435976781, 64, 0.5028582586000331]\n",
            "[57, 0.0015137641833101326, 64, 0.6420406198014843]\n",
            "[63, 0.005243565962473723, 64, 0.7167527076497474]\n",
            "[64, 0.003840093700318292, 64, 0.77528203921987]\n",
            "[60, 0.019382211141772274, 128, 0.5647961242172355]\n",
            "[57, 0.006174887164108888, 128, 0.590255701076635]\n",
            "[65, 0.014032250690045545, 128, 0.673696764572981]\n",
            "[65, 0.01603026757103196, 128, 0.7886715985767127]\n",
            "[65, 0.028249580202252166, 32, 0.516828654158117]\n",
            "[63, 0.049527903207109564, 32, 0.6077383331191981]\n",
            "[58, 0.03523194374209868, 32, 0.679976908080077]\n",
            "[63, 0.045983889739746, 32, 0.7485607104441546]\n",
            "[63, 0.03922206833267722, 64, 0.5583603876277693]\n",
            "[65, 0.04363799060069193, 64, 0.621684458199885]\n",
            "[57, 0.03673412697798368, 64, 0.707874000886707]\n",
            "[65, 0.02950992886697853, 64, 0.7500056059901266]\n",
            "[62, 0.0360233902391328, 128, 0.5078598972912546]\n",
            "[62, 0.03633122044720476, 128, 0.6294509382222739]\n",
            "[57, 0.03891530804943628, 128, 0.70537920881031]\n",
            "[59, 0.03230433028707814, 128, 0.7309550480688124]\n",
            "[64, 0.07340851690963911, 32, 0.5208539961719771]\n",
            "[58, 0.062399072997410716, 32, 0.6220244105748218]\n",
            "[61, 0.05958975814658154, 32, 0.7201551199175961]\n",
            "[62, 0.07122486245120926, 32, 0.774373772514576]\n",
            "[60, 0.056049817620307314, 64, 0.5543926959626655]\n",
            "[65, 0.06398558207944315, 64, 0.6237712406355072]\n",
            "[62, 0.07084503698968164, 64, 0.7044202173336617]\n",
            "[65, 0.05084714603152943, 64, 0.7989179543417663]\n",
            "[60, 0.06392791411849452, 128, 0.5363467244197927]\n",
            "[61, 0.05561315672929307, 128, 0.5837450427280789]\n",
            "[57, 0.0535102479136905, 128, 0.6647550703781384]\n",
            "[60, 0.059268955134902185, 128, 0.7265807742988051]\n",
            "[64, 0.07762715594484525, 32, 0.5569277587680848]\n",
            "[59, 0.09074419549380217, 32, 0.5830512622944494]\n",
            "[59, 0.08919333418167515, 32, 0.6929479613781283]\n",
            "[61, 0.09082448794631388, 32, 0.776993276146136]\n",
            "[64, 0.08236363466333851, 64, 0.5471725292211661]\n",
            "[63, 0.0921120495897634, 64, 0.5792522794927635]\n",
            "[60, 0.07709549475177345, 64, 0.6766967718071503]\n",
            "[65, 0.0794938372491056, 64, 0.7476560926687053]\n",
            "[58, 0.08006523675374576, 128, 0.5175069609701619]\n",
            "[61, 0.0824294714365878, 128, 0.5972836024884505]\n",
            "[60, 0.08223146994685424, 128, 0.7233092927345086]\n",
            "[64, 0.08937689634928271, 128, 0.7966102110614598]\n"
          ]
        }
      ],
      "source": [
        "for kombinasi in parameter:\n",
        "    print(kombinasi)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HMKIsY1N6XTH"
      },
      "source": [
        "#### **<font color='Pink'>Model Training</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "oQwWy9EDvRfT"
      },
      "outputs": [],
      "source": [
        "from keras.layers import BatchNormalization\n",
        "def vgg16_training(i, vgg_epoch, learning_rate, batch_size, dropout_rate):\n",
        "  vgg16_model = VGG16(pooling='max', weights='imagenet', include_top=False, input_shape=(130,242,3), classes=7) #defaultnya AVERAGE POOLING\n",
        "  for layers in vgg16_model.layers:\n",
        "              layers.trainable=False\n",
        "\n",
        "  last_output_vgg16 = vgg16_model.layers[-1].output\n",
        "  vgg_16 = Flatten()(last_output_vgg16) #awalnya di bawah last output\n",
        "  vgg_16 = BatchNormalization()(vgg_16)\n",
        "  vgg_16 = Dense(128, activation = 'relu')(vgg_16)\n",
        "  vgg_16 = BatchNormalization()(vgg_16)\n",
        "  vgg_16 = Dropout(dropout_rate)(vgg_16)\n",
        "\n",
        "  #vgg_16 = Dense(64, activation = 'relu')(vgg_16)\n",
        "  #vgg_16 = Dropout(dropout_rate)(vgg_16)\n",
        "  vgg_16 = Dense(7, activation = 'softmax')(vgg_16)\n",
        "  vgg16_final_model = Model(vgg16_model.input, vgg_16)\n",
        "  \n",
        "  opt = Adam(learning_rate=learning_rate)\n",
        "  vgg16_final_model.compile(loss = 'categorical_crossentropy', optimizer= opt, metrics=['acc'])\n",
        "  #vgg16_final_model.summary()\n",
        "\n",
        "  #plot_model(model=vgg16_final_model, show_shapes=True)\n",
        "\n",
        "  train_generator16.batch_size = batch_size\n",
        "\n",
        "  vgg16_filepath = 'percobaan'+str(i)+'_noImgPro/model/vgg_16_'+str(i)+'-saved-model-{epoch:02d}-acc-{val_acc:.2f}.hdf5'\n",
        "  vgg16_checkpoint = tf.keras.callbacks.ModelCheckpoint(vgg16_filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "  vgg16_history = vgg16_final_model.fit(train_generator16, epochs = vgg_epoch, validation_data = validation_generator16,callbacks=[vgg16_checkpoint,early_stopping],verbose=1)\n",
        "\n",
        "  do_history_stuff(i, vgg16_history, 'vgg16_model')\n",
        "  save_vgg16(i, vgg16_final_model)\n",
        "\n",
        "  predictionTest(i, vgg16_final_model)\n",
        "\n",
        "  return(vgg16_final_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "uzyGkyI39Dbv"
      },
      "outputs": [],
      "source": [
        "def save_vgg16(i, vgg16_final_model):\n",
        "  vgg16_final_model.save(('percobaan'+str(i)+'_noImgPro/vgg16-model'+str(i)+'.h5'))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TIFMfEwf8HR8"
      },
      "source": [
        "#### **<font color='Pink'>Evaluation</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "siSMQNcU8oB-"
      },
      "outputs": [],
      "source": [
        "def acc_plot(vgg16_history):\n",
        "  plt.figure(figsize=(10, 8))\n",
        "  plt.plot(vgg16_history.history['acc'], label='train acc')\n",
        "  plt.plot(vgg16_history.history['val_acc'], label='val acc')\n",
        "  plt.legend()\n",
        "  plt.title('Accuracy')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "E7alj36o8w5T"
      },
      "outputs": [],
      "source": [
        "def loss_plot(vgg16_history):\n",
        "  plt.figure(figsize=(10, 8))\n",
        "  plt.plot(vgg16_history.history['loss'], label='train loss')\n",
        "  plt.plot(vgg16_history.history['val_loss'], label='val loss')\n",
        "  plt.legend()\n",
        "  plt.title('Loss')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "hoxqXW5381w9"
      },
      "outputs": [],
      "source": [
        "def predictionTest(i, vgg16_final_model):\n",
        "  true_value = []\n",
        "  vgg_pred = []\n",
        "  for folder in os.listdir(test_path):\n",
        "      test_image_ids = os.listdir(os.path.join(test_path,folder))\n",
        "      \n",
        "      for image_id in test_image_ids[:int(len(test_image_ids))]:\n",
        "          path = os.path.join(test_path,folder,image_id)\n",
        "          #print(path)\n",
        "          true_value.append(test_generator16.class_indices[folder])\n",
        "          img = cv2.resize(cv2.imread(path),(242,130))\n",
        "          img_normalized = img/255\n",
        "          #vgg\n",
        "          vgg16_image_prediction = np.argmax(vgg16_final_model.predict(np.array([img_normalized]), verbose = 0)) #verbose biar gak ngeprint\n",
        "          vgg_pred.append(vgg16_image_prediction)\n",
        "\n",
        "  print(\"\\n\")\n",
        "  clf_report(i, true_value, vgg_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "pJV_qqpT86bD"
      },
      "outputs": [],
      "source": [
        "arr_accuracy16 = []\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "#from mlxtend.plotting import plot_confusion_matrix\n",
        "def clf_report(k, true_value, model_pred):\n",
        "    classes = validation_generator16.class_indices.keys()\n",
        "    TP_count = [true_value[i] == model_pred[i] for i in range(len(true_value))]\n",
        "    model_accuracy = np.sum(TP_count)/len(TP_count)\n",
        "    print('Model Accuracy', model_accuracy)\n",
        "    arr_accuracy16.append(model_accuracy)\n",
        "    plt.figure(figsize=(7,7))\n",
        "    cm = confusion_matrix(true_value,model_pred)\n",
        "    plt.imshow(cm,interpolation='nearest',cmap=plt.cm.viridis)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    thresh = cm.max()*0.8\n",
        "    for i,j in itertools.product(range(cm.shape[0]),range(cm.shape[1])):\n",
        "        plt.text(j,i,cm[i,j],\n",
        "                horizontalalignment=\"center\",\n",
        "                color=\"black\" if cm[i,j] > thresh else \"white\")\n",
        "        pass\n",
        "    \n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    pass\n",
        "    \n",
        "    plt.savefig(\"percobaan\"+str(k)+\"_noImgPro/conf_matrix\"+str(k)+\".png\")\n",
        "    print(classification_report(true_value, model_pred, target_names = list(classes)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Empty DataFrame\n",
            "Columns: [Epoch, Learning Rate, Batch Size, Dropout Rate, Accuracy]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "hasilTabel = pd.DataFrame(columns=['Epoch', 'Learning Rate', 'Batch Size', 'Dropout Rate','Accuracy'])\n",
        "print(hasilTabel)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nr5k_MjPDmTN"
      },
      "source": [
        "#### **<font color='Pink'>Code Running</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percobaan ke- 98 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 56\n",
            "learning rate: 0.024056461955002946\n",
            "batch size: 32\n",
            "dropout rate: 0.5844897179570151\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.4121 - acc: 0.3388\n",
            "Epoch 1: val_acc improved from -inf to 0.29286, saving model to percobaan98_noImgPro/model\\vgg_16_98-saved-model-01-acc-0.29.hdf5\n",
            "16/16 [==============================] - 38s 2s/step - loss: 2.4121 - acc: 0.3388 - val_loss: 3.9458 - val_acc: 0.2929\n",
            "Epoch 2/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.4294 - acc: 0.5000\n",
            "Epoch 2: val_acc did not improve from 0.29286\n",
            "16/16 [==============================] - 33s 2s/step - loss: 1.4294 - acc: 0.5000 - val_loss: 2.7370 - val_acc: 0.2786\n",
            "Epoch 3/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0796 - acc: 0.6429\n",
            "Epoch 3: val_acc improved from 0.29286 to 0.57857, saving model to percobaan98_noImgPro/model\\vgg_16_98-saved-model-03-acc-0.58.hdf5\n",
            "16/16 [==============================] - 36s 2s/step - loss: 1.0796 - acc: 0.6429 - val_loss: 1.3660 - val_acc: 0.5786\n",
            "Epoch 4/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8698 - acc: 0.7143\n",
            "Epoch 4: val_acc did not improve from 0.57857\n",
            "16/16 [==============================] - 52s 3s/step - loss: 0.8698 - acc: 0.7143 - val_loss: 3.0502 - val_acc: 0.2357\n",
            "Epoch 5/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7600 - acc: 0.7469\n",
            "Epoch 5: val_acc did not improve from 0.57857\n",
            "16/16 [==============================] - 53s 3s/step - loss: 0.7600 - acc: 0.7469 - val_loss: 1.2610 - val_acc: 0.5714\n",
            "Epoch 6/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6899 - acc: 0.7714\n",
            "Epoch 6: val_acc did not improve from 0.57857\n",
            "16/16 [==============================] - 49s 3s/step - loss: 0.6899 - acc: 0.7714 - val_loss: 1.8236 - val_acc: 0.3786\n",
            "Epoch 7/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5334 - acc: 0.8184\n",
            "Epoch 7: val_acc improved from 0.57857 to 0.59286, saving model to percobaan98_noImgPro/model\\vgg_16_98-saved-model-07-acc-0.59.hdf5\n",
            "16/16 [==============================] - 58s 4s/step - loss: 0.5334 - acc: 0.8184 - val_loss: 1.2247 - val_acc: 0.5929\n",
            "Epoch 8/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5082 - acc: 0.8265\n",
            "Epoch 8: val_acc did not improve from 0.59286\n",
            "16/16 [==============================] - 55s 3s/step - loss: 0.5082 - acc: 0.8265 - val_loss: 2.3442 - val_acc: 0.3286\n",
            "Epoch 9/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5184 - acc: 0.8306\n",
            "Epoch 9: val_acc did not improve from 0.59286\n",
            "16/16 [==============================] - 52s 3s/step - loss: 0.5184 - acc: 0.8306 - val_loss: 1.2128 - val_acc: 0.5857\n",
            "Epoch 10/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4947 - acc: 0.8490\n",
            "Epoch 10: val_acc improved from 0.59286 to 0.64286, saving model to percobaan98_noImgPro/model\\vgg_16_98-saved-model-10-acc-0.64.hdf5\n",
            "16/16 [==============================] - 51s 3s/step - loss: 0.4947 - acc: 0.8490 - val_loss: 1.2098 - val_acc: 0.6429\n",
            "Epoch 11/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6388 - acc: 0.8000\n",
            "Epoch 11: val_acc did not improve from 0.64286\n",
            "16/16 [==============================] - 51s 3s/step - loss: 0.6388 - acc: 0.8000 - val_loss: 1.5190 - val_acc: 0.5286\n",
            "Epoch 12/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4384 - acc: 0.8388\n",
            "Epoch 12: val_acc did not improve from 0.64286\n",
            "16/16 [==============================] - 50s 3s/step - loss: 0.4384 - acc: 0.8388 - val_loss: 1.2422 - val_acc: 0.6071\n",
            "Epoch 13/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3998 - acc: 0.8714\n",
            "Epoch 13: val_acc improved from 0.64286 to 0.73571, saving model to percobaan98_noImgPro/model\\vgg_16_98-saved-model-13-acc-0.74.hdf5\n",
            "16/16 [==============================] - 51s 3s/step - loss: 0.3998 - acc: 0.8714 - val_loss: 0.8550 - val_acc: 0.7357\n",
            "Epoch 14/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5054 - acc: 0.8184\n",
            "Epoch 14: val_acc did not improve from 0.73571\n",
            "16/16 [==============================] - 52s 3s/step - loss: 0.5054 - acc: 0.8184 - val_loss: 0.8090 - val_acc: 0.7286\n",
            "Epoch 15/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4547 - acc: 0.8469\n",
            "Epoch 15: val_acc did not improve from 0.73571\n",
            "16/16 [==============================] - 51s 3s/step - loss: 0.4547 - acc: 0.8469 - val_loss: 1.0894 - val_acc: 0.6857\n",
            "Epoch 16/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3930 - acc: 0.8633\n",
            "Epoch 16: val_acc improved from 0.73571 to 0.79286, saving model to percobaan98_noImgPro/model\\vgg_16_98-saved-model-16-acc-0.79.hdf5\n",
            "16/16 [==============================] - 51s 3s/step - loss: 0.3930 - acc: 0.8633 - val_loss: 0.6963 - val_acc: 0.7929\n",
            "Epoch 17/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4010 - acc: 0.8673\n",
            "Epoch 17: val_acc improved from 0.79286 to 0.82857, saving model to percobaan98_noImgPro/model\\vgg_16_98-saved-model-17-acc-0.83.hdf5\n",
            "16/16 [==============================] - 49s 3s/step - loss: 0.4010 - acc: 0.8673 - val_loss: 0.6152 - val_acc: 0.8286\n",
            "Epoch 18/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4279 - acc: 0.8571\n",
            "Epoch 18: val_acc did not improve from 0.82857\n",
            "16/16 [==============================] - 50s 3s/step - loss: 0.4279 - acc: 0.8571 - val_loss: 0.7585 - val_acc: 0.8071\n",
            "Epoch 19/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4386 - acc: 0.8449\n",
            "Epoch 19: val_acc did not improve from 0.82857\n",
            "16/16 [==============================] - 51s 3s/step - loss: 0.4386 - acc: 0.8449 - val_loss: 1.0304 - val_acc: 0.7143\n",
            "Epoch 20/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3433 - acc: 0.8816\n",
            "Epoch 20: val_acc did not improve from 0.82857\n",
            "16/16 [==============================] - 49s 3s/step - loss: 0.3433 - acc: 0.8816 - val_loss: 0.8565 - val_acc: 0.8143\n",
            "Epoch 21/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4408 - acc: 0.8633\n",
            "Epoch 21: val_acc did not improve from 0.82857\n",
            "16/16 [==============================] - 47s 3s/step - loss: 0.4408 - acc: 0.8633 - val_loss: 1.0625 - val_acc: 0.7500\n",
            "Epoch 22/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4256 - acc: 0.8490\n",
            "Epoch 22: val_acc did not improve from 0.82857\n",
            "16/16 [==============================] - 55s 3s/step - loss: 0.4256 - acc: 0.8490 - val_loss: 0.6962 - val_acc: 0.8000\n",
            "\n",
            "\n",
            "Model Accuracy 0.7428571428571429\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.70      0.82        10\n",
            "       10000       0.90      0.90      0.90        10\n",
            "      100000       1.00      0.50      0.67        10\n",
            "        2000       0.53      1.00      0.69        10\n",
            "       20000       1.00      0.40      0.57        10\n",
            "        5000       0.60      0.90      0.72        10\n",
            "       50000       0.80      0.80      0.80        10\n",
            "\n",
            "    accuracy                           0.74        70\n",
            "   macro avg       0.83      0.74      0.74        70\n",
            "weighted avg       0.83      0.74      0.74        70\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_53828\\2052248251.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 700x700 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#run ulang percobaan 98\n",
        "j = 97\n",
        "for i in range (j,98):\n",
        "  vgg_epoch = (parameter[i][0])\n",
        "  learning_rate = (parameter[i][1])\n",
        "  batch_size = (parameter[i][2])\n",
        "  dropout_rate = (parameter[i][3])\n",
        "  i=i+1\n",
        "  savePercobaan(i)\n",
        "  print(\"Percobaan ke-\",i,\"↓\")\n",
        "  print(\"HYPERPARAMETER\".center(100,\"─\"))\n",
        "  print(\"vgg epoch:\",vgg_epoch)\n",
        "  print(\"learning rate:\",learning_rate)\n",
        "  print(\"batch size:\",batch_size)\n",
        "  print(\"dropout rate:\",dropout_rate)\n",
        "  print(\"\".center(100,\"─\"))\n",
        "  vgg16_training(i, vgg_epoch, learning_rate, batch_size, dropout_rate)\n",
        "  new_row = {'Epoch': vgg_epoch, 'Learning Rate': learning_rate, 'Batch Size': batch_size,\n",
        "             'Dropout Rate': dropout_rate, 'Accuracy': arr_accuracy16[-1]}\n",
        "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n",
        "  hasilTabel.index = hasilTabel.index + (j+1)\n",
        "  hasilTabel.to_excel(\"hasilTabel.xlsx\")\n",
        "  print(\"\".center(100,\"─\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "j = 0\n",
        "for i in range (j,len(parameter)):\n",
        "  vgg_epoch = (parameter[i][0])\n",
        "  learning_rate = (parameter[i][1])\n",
        "  batch_size = (parameter[i][2])\n",
        "  dropout_rate = (parameter[i][3])\n",
        "  i=i+1\n",
        "  savePercobaan(i)\n",
        "  print(\"Percobaan ke-\",i,\"↓\")\n",
        "  print(\"HYPERPARAMETER\".center(100,\"─\"))\n",
        "  print(\"vgg epoch:\",vgg_epoch)\n",
        "  print(\"learning rate:\",learning_rate)\n",
        "  print(\"batch size:\",batch_size)\n",
        "  print(\"dropout rate:\",dropout_rate)\n",
        "  print(\"\".center(100,\"─\"))\n",
        "  vgg16_training(i, vgg_epoch, learning_rate, batch_size, dropout_rate)\n",
        "  new_row = {'Epoch': vgg_epoch, 'Learning Rate': learning_rate, 'Batch Size': batch_size,\n",
        "             'Dropout Rate': dropout_rate, 'Accuracy': arr_accuracy16[-1]}\n",
        "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n",
        "  hasilTabel.index = hasilTabel.index + (j+1)\n",
        "  hasilTabel.to_excel(\"hasilTabel.xlsx\")\n",
        "  print(\"\".center(100,\"─\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percobaan ke- 1 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 32\n",
            "learning rate: 0.02267326808914284\n",
            "batch size: 32\n",
            "dropout rate: 0.5748920853555588\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/32\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.4950 - acc: 0.3122\n",
            "Epoch 1: val_acc improved from -inf to 0.25000, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-01-acc-0.25.hdf5\n",
            "16/16 [==============================] - 39s 2s/step - loss: 2.4950 - acc: 0.3122 - val_loss: 3.3581 - val_acc: 0.2500\n",
            "Epoch 2/32\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.4351 - acc: 0.5327\n",
            "Epoch 2: val_acc did not improve from 0.25000\n",
            "16/16 [==============================] - 38s 2s/step - loss: 1.4351 - acc: 0.5327 - val_loss: 3.9602 - val_acc: 0.2000\n",
            "Epoch 3/32\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0583 - acc: 0.6082\n",
            "Epoch 3: val_acc did not improve from 0.25000\n",
            "16/16 [==============================] - 38s 2s/step - loss: 1.0583 - acc: 0.6082 - val_loss: 2.9872 - val_acc: 0.1714\n",
            "Epoch 4/32\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8129 - acc: 0.7184\n",
            "Epoch 4: val_acc improved from 0.25000 to 0.47143, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-04-acc-0.47.hdf5\n",
            "16/16 [==============================] - 38s 2s/step - loss: 0.8129 - acc: 0.7184 - val_loss: 1.3590 - val_acc: 0.4714\n",
            "Epoch 5/32\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7969 - acc: 0.7367\n",
            "Epoch 5: val_acc improved from 0.47143 to 0.60000, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-05-acc-0.60.hdf5\n",
            "16/16 [==============================] - 47s 3s/step - loss: 0.7969 - acc: 0.7367 - val_loss: 1.1268 - val_acc: 0.6000\n",
            "Epoch 6/32\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6518 - acc: 0.7694\n",
            "Epoch 6: val_acc did not improve from 0.60000\n",
            "16/16 [==============================] - 41s 3s/step - loss: 0.6518 - acc: 0.7694 - val_loss: 1.5228 - val_acc: 0.4857\n",
            "Epoch 7/32\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5990 - acc: 0.7796\n",
            "Epoch 7: val_acc did not improve from 0.60000\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.5990 - acc: 0.7796 - val_loss: 1.6354 - val_acc: 0.4929\n",
            "Epoch 8/32\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4794 - acc: 0.8388\n",
            "Epoch 8: val_acc improved from 0.60000 to 0.71429, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-08-acc-0.71.hdf5\n",
            "16/16 [==============================] - 41s 3s/step - loss: 0.4794 - acc: 0.8388 - val_loss: 0.8099 - val_acc: 0.7143\n",
            "Epoch 9/32\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4689 - acc: 0.8449\n",
            "Epoch 9: val_acc improved from 0.71429 to 0.78571, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-09-acc-0.79.hdf5\n",
            "16/16 [==============================] - 43s 3s/step - loss: 0.4689 - acc: 0.8449 - val_loss: 0.6559 - val_acc: 0.7857\n",
            "Epoch 10/32\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4295 - acc: 0.8551\n",
            "Epoch 10: val_acc did not improve from 0.78571\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.4295 - acc: 0.8551 - val_loss: 0.9079 - val_acc: 0.6714\n",
            "Epoch 11/32\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4842 - acc: 0.8449\n",
            "Epoch 11: val_acc did not improve from 0.78571\n",
            "16/16 [==============================] - 44s 3s/step - loss: 0.4842 - acc: 0.8449 - val_loss: 0.9410 - val_acc: 0.7286\n",
            "Epoch 12/32\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4787 - acc: 0.8449\n",
            "Epoch 12: val_acc did not improve from 0.78571\n",
            "16/16 [==============================] - 45s 3s/step - loss: 0.4787 - acc: 0.8449 - val_loss: 1.1101 - val_acc: 0.6429\n",
            "Epoch 13/32\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4492 - acc: 0.8469\n",
            "Epoch 13: val_acc did not improve from 0.78571\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.4492 - acc: 0.8469 - val_loss: 0.7899 - val_acc: 0.7571\n",
            "Epoch 14/32\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3965 - acc: 0.8755\n",
            "Epoch 14: val_acc improved from 0.78571 to 0.80714, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-14-acc-0.81.hdf5\n",
            "16/16 [==============================] - 45s 3s/step - loss: 0.3965 - acc: 0.8755 - val_loss: 0.6183 - val_acc: 0.8071\n",
            "Epoch 15/32\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4092 - acc: 0.8571\n",
            "Epoch 15: val_acc improved from 0.80714 to 0.84286, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-15-acc-0.84.hdf5\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.4092 - acc: 0.8571 - val_loss: 0.5104 - val_acc: 0.8429\n",
            "Epoch 16/32\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3747 - acc: 0.8673\n",
            "Epoch 16: val_acc improved from 0.84286 to 0.85000, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-16-acc-0.85.hdf5\n",
            "16/16 [==============================] - 48s 3s/step - loss: 0.3747 - acc: 0.8673 - val_loss: 0.5914 - val_acc: 0.8500\n",
            "Epoch 17/32\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3265 - acc: 0.8837\n",
            "Epoch 17: val_acc improved from 0.85000 to 0.85714, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-17-acc-0.86.hdf5\n",
            "16/16 [==============================] - 47s 3s/step - loss: 0.3265 - acc: 0.8837 - val_loss: 0.4598 - val_acc: 0.8571\n",
            "Epoch 18/32\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4151 - acc: 0.8735\n",
            "Epoch 18: val_acc did not improve from 0.85714\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.4151 - acc: 0.8735 - val_loss: 0.6974 - val_acc: 0.7929\n",
            "Epoch 19/32\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4149 - acc: 0.8653\n",
            "Epoch 19: val_acc did not improve from 0.85714\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.4149 - acc: 0.8653 - val_loss: 0.7566 - val_acc: 0.8000\n",
            "Epoch 20/32\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4311 - acc: 0.8612\n",
            "Epoch 20: val_acc did not improve from 0.85714\n",
            "16/16 [==============================] - 47s 3s/step - loss: 0.4311 - acc: 0.8612 - val_loss: 0.6169 - val_acc: 0.8500\n",
            "Epoch 21/32\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4075 - acc: 0.8571\n",
            "Epoch 21: val_acc did not improve from 0.85714\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.4075 - acc: 0.8571 - val_loss: 0.7115 - val_acc: 0.8357\n",
            "Epoch 22/32\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3281 - acc: 0.8796\n",
            "Epoch 22: val_acc did not improve from 0.85714\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.3281 - acc: 0.8796 - val_loss: 0.9764 - val_acc: 0.7929\n",
            "\n",
            "\n",
            "Model Accuracy 0.7428571428571429\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.73      0.80      0.76        10\n",
            "       10000       1.00      0.50      0.67        10\n",
            "      100000       1.00      0.70      0.82        10\n",
            "        2000       0.73      0.80      0.76        10\n",
            "       20000       0.86      0.60      0.71        10\n",
            "        5000       0.48      1.00      0.65        10\n",
            "       50000       1.00      0.80      0.89        10\n",
            "\n",
            "    accuracy                           0.74        70\n",
            "   macro avg       0.83      0.74      0.75        70\n",
            "weighted avg       0.83      0.74      0.75        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 2 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 31\n",
            "learning rate: 0.012429423480212299\n",
            "batch size: 32\n",
            "dropout rate: 0.6173459557394363\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_54864\\940263153.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.3100 - acc: 0.3612\n",
            "Epoch 1: val_acc improved from -inf to 0.22143, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-01-acc-0.22.hdf5\n",
            "16/16 [==============================] - 44s 3s/step - loss: 2.3100 - acc: 0.3612 - val_loss: 4.2895 - val_acc: 0.2214\n",
            "Epoch 2/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3600 - acc: 0.5245\n",
            "Epoch 2: val_acc improved from 0.22143 to 0.25714, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-02-acc-0.26.hdf5\n",
            "16/16 [==============================] - 44s 3s/step - loss: 1.3600 - acc: 0.5245 - val_loss: 3.5285 - val_acc: 0.2571\n",
            "Epoch 3/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0417 - acc: 0.6408\n",
            "Epoch 3: val_acc improved from 0.25714 to 0.29286, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-03-acc-0.29.hdf5\n",
            "16/16 [==============================] - 43s 3s/step - loss: 1.0417 - acc: 0.6408 - val_loss: 2.4304 - val_acc: 0.2929\n",
            "Epoch 4/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8631 - acc: 0.6959\n",
            "Epoch 4: val_acc improved from 0.29286 to 0.37857, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-04-acc-0.38.hdf5\n",
            "16/16 [==============================] - 44s 3s/step - loss: 0.8631 - acc: 0.6959 - val_loss: 1.8887 - val_acc: 0.3786\n",
            "Epoch 5/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7224 - acc: 0.7592\n",
            "Epoch 5: val_acc did not improve from 0.37857\n",
            "16/16 [==============================] - 44s 3s/step - loss: 0.7224 - acc: 0.7592 - val_loss: 1.4731 - val_acc: 0.3786\n",
            "Epoch 6/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5984 - acc: 0.7755\n",
            "Epoch 6: val_acc improved from 0.37857 to 0.60714, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-06-acc-0.61.hdf5\n",
            "16/16 [==============================] - 43s 3s/step - loss: 0.5984 - acc: 0.7755 - val_loss: 0.9941 - val_acc: 0.6071\n",
            "Epoch 7/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6273 - acc: 0.8020\n",
            "Epoch 7: val_acc improved from 0.60714 to 0.66429, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-07-acc-0.66.hdf5\n",
            "16/16 [==============================] - 43s 3s/step - loss: 0.6273 - acc: 0.8020 - val_loss: 1.0190 - val_acc: 0.6643\n",
            "Epoch 8/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5232 - acc: 0.8347\n",
            "Epoch 8: val_acc improved from 0.66429 to 0.67857, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-08-acc-0.68.hdf5\n",
            "16/16 [==============================] - 44s 3s/step - loss: 0.5232 - acc: 0.8347 - val_loss: 0.9574 - val_acc: 0.6786\n",
            "Epoch 9/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5181 - acc: 0.8082\n",
            "Epoch 9: val_acc improved from 0.67857 to 0.72143, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-09-acc-0.72.hdf5\n",
            "16/16 [==============================] - 44s 3s/step - loss: 0.5181 - acc: 0.8082 - val_loss: 0.8478 - val_acc: 0.7214\n",
            "Epoch 10/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4122 - acc: 0.8531\n",
            "Epoch 10: val_acc improved from 0.72143 to 0.79286, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-10-acc-0.79.hdf5\n",
            "16/16 [==============================] - 43s 3s/step - loss: 0.4122 - acc: 0.8531 - val_loss: 0.6716 - val_acc: 0.7929\n",
            "Epoch 11/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4972 - acc: 0.8388\n",
            "Epoch 11: val_acc improved from 0.79286 to 0.80714, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-11-acc-0.81.hdf5\n",
            "16/16 [==============================] - 44s 3s/step - loss: 0.4972 - acc: 0.8388 - val_loss: 0.6803 - val_acc: 0.8071\n",
            "Epoch 12/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3564 - acc: 0.8673\n",
            "Epoch 12: val_acc improved from 0.80714 to 0.85000, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-12-acc-0.85.hdf5\n",
            "16/16 [==============================] - 43s 3s/step - loss: 0.3564 - acc: 0.8673 - val_loss: 0.5713 - val_acc: 0.8500\n",
            "Epoch 13/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3485 - acc: 0.8816\n",
            "Epoch 13: val_acc did not improve from 0.85000\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.3485 - acc: 0.8816 - val_loss: 0.4820 - val_acc: 0.8429\n",
            "Epoch 14/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3402 - acc: 0.8796\n",
            "Epoch 14: val_acc did not improve from 0.85000\n",
            "16/16 [==============================] - 48s 3s/step - loss: 0.3402 - acc: 0.8796 - val_loss: 0.5278 - val_acc: 0.8429\n",
            "Epoch 15/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3326 - acc: 0.8755\n",
            "Epoch 15: val_acc did not improve from 0.85000\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.3326 - acc: 0.8755 - val_loss: 0.6151 - val_acc: 0.8357\n",
            "Epoch 16/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3287 - acc: 0.8755\n",
            "Epoch 16: val_acc did not improve from 0.85000\n",
            "16/16 [==============================] - 44s 3s/step - loss: 0.3287 - acc: 0.8755 - val_loss: 0.5775 - val_acc: 0.8071\n",
            "Epoch 17/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3141 - acc: 0.8816\n",
            "Epoch 17: val_acc did not improve from 0.85000\n",
            "16/16 [==============================] - 35s 2s/step - loss: 0.3141 - acc: 0.8816 - val_loss: 0.5261 - val_acc: 0.8214\n",
            "Epoch 18/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3624 - acc: 0.8816\n",
            "Epoch 18: val_acc improved from 0.85000 to 0.87857, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-18-acc-0.88.hdf5\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.3624 - acc: 0.8816 - val_loss: 0.4891 - val_acc: 0.8786\n",
            "\n",
            "\n",
            "Model Accuracy 0.7857142857142857\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.67      1.00      0.80        10\n",
            "       10000       1.00      0.80      0.89        10\n",
            "      100000       1.00      0.80      0.89        10\n",
            "        2000       0.71      1.00      0.83        10\n",
            "       20000       1.00      0.30      0.46        10\n",
            "        5000       0.88      0.70      0.78        10\n",
            "       50000       0.64      0.90      0.75        10\n",
            "\n",
            "    accuracy                           0.79        70\n",
            "   macro avg       0.84      0.79      0.77        70\n",
            "weighted avg       0.84      0.79      0.77        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 3 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 31\n",
            "learning rate: 0.0005447297750119896\n",
            "batch size: 32\n",
            "dropout rate: 0.6732446663076203\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_54864\\940263153.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 3.4349 - acc: 0.1673\n",
            "Epoch 1: val_acc improved from -inf to 0.15714, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-01-acc-0.16.hdf5\n",
            "16/16 [==============================] - 52s 3s/step - loss: 3.4349 - acc: 0.1673 - val_loss: 2.2222 - val_acc: 0.1571\n",
            "Epoch 2/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.8505 - acc: 0.2204\n",
            "Epoch 2: val_acc did not improve from 0.15714\n",
            "16/16 [==============================] - 49s 3s/step - loss: 2.8505 - acc: 0.2204 - val_loss: 2.0327 - val_acc: 0.1571\n",
            "Epoch 3/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.5479 - acc: 0.2837\n",
            "Epoch 3: val_acc improved from 0.15714 to 0.19286, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-03-acc-0.19.hdf5\n",
            "16/16 [==============================] - 49s 3s/step - loss: 2.5479 - acc: 0.2837 - val_loss: 1.8834 - val_acc: 0.1929\n",
            "Epoch 4/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.0993 - acc: 0.3735\n",
            "Epoch 4: val_acc improved from 0.19286 to 0.21429, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-04-acc-0.21.hdf5\n",
            "16/16 [==============================] - 49s 3s/step - loss: 2.0993 - acc: 0.3735 - val_loss: 1.7911 - val_acc: 0.2143\n",
            "Epoch 5/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.9712 - acc: 0.3816\n",
            "Epoch 5: val_acc improved from 0.21429 to 0.23571, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-05-acc-0.24.hdf5\n",
            "16/16 [==============================] - 46s 3s/step - loss: 1.9712 - acc: 0.3816 - val_loss: 1.7083 - val_acc: 0.2357\n",
            "Epoch 6/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.8130 - acc: 0.4265\n",
            "Epoch 6: val_acc improved from 0.23571 to 0.30714, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-06-acc-0.31.hdf5\n",
            "16/16 [==============================] - 35s 2s/step - loss: 1.8130 - acc: 0.4265 - val_loss: 1.5731 - val_acc: 0.3071\n",
            "Epoch 7/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.6479 - acc: 0.4735\n",
            "Epoch 7: val_acc improved from 0.30714 to 0.48571, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-07-acc-0.49.hdf5\n",
            "16/16 [==============================] - 42s 3s/step - loss: 1.6479 - acc: 0.4735 - val_loss: 1.3916 - val_acc: 0.4857\n",
            "Epoch 8/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.4413 - acc: 0.5204\n",
            "Epoch 8: val_acc improved from 0.48571 to 0.57857, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-08-acc-0.58.hdf5\n",
            "16/16 [==============================] - 52s 3s/step - loss: 1.4413 - acc: 0.5204 - val_loss: 1.2651 - val_acc: 0.5786\n",
            "Epoch 9/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3694 - acc: 0.5245\n",
            "Epoch 9: val_acc improved from 0.57857 to 0.64286, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-09-acc-0.64.hdf5\n",
            "16/16 [==============================] - 48s 3s/step - loss: 1.3694 - acc: 0.5245 - val_loss: 1.1659 - val_acc: 0.6429\n",
            "Epoch 10/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3793 - acc: 0.5327\n",
            "Epoch 10: val_acc improved from 0.64286 to 0.67857, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-10-acc-0.68.hdf5\n",
            "16/16 [==============================] - 58s 4s/step - loss: 1.3793 - acc: 0.5327 - val_loss: 1.0624 - val_acc: 0.6786\n",
            "Epoch 11/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3299 - acc: 0.5469\n",
            "Epoch 11: val_acc improved from 0.67857 to 0.73571, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-11-acc-0.74.hdf5\n",
            "16/16 [==============================] - 47s 3s/step - loss: 1.3299 - acc: 0.5469 - val_loss: 0.9771 - val_acc: 0.7357\n",
            "Epoch 12/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1979 - acc: 0.6000\n",
            "Epoch 12: val_acc did not improve from 0.73571\n",
            "16/16 [==============================] - 54s 3s/step - loss: 1.1979 - acc: 0.6000 - val_loss: 0.9244 - val_acc: 0.7357\n",
            "Epoch 13/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2538 - acc: 0.5714\n",
            "Epoch 13: val_acc improved from 0.73571 to 0.75714, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-13-acc-0.76.hdf5\n",
            "16/16 [==============================] - 53s 3s/step - loss: 1.2538 - acc: 0.5714 - val_loss: 0.8615 - val_acc: 0.7571\n",
            "Epoch 14/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1628 - acc: 0.6286\n",
            "Epoch 14: val_acc improved from 0.75714 to 0.77143, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-14-acc-0.77.hdf5\n",
            "16/16 [==============================] - 61s 4s/step - loss: 1.1628 - acc: 0.6286 - val_loss: 0.8013 - val_acc: 0.7714\n",
            "Epoch 15/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0677 - acc: 0.6143\n",
            "Epoch 15: val_acc improved from 0.77143 to 0.78571, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-15-acc-0.79.hdf5\n",
            "16/16 [==============================] - 62s 4s/step - loss: 1.0677 - acc: 0.6143 - val_loss: 0.7530 - val_acc: 0.7857\n",
            "Epoch 16/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9429 - acc: 0.6612\n",
            "Epoch 16: val_acc improved from 0.78571 to 0.80000, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-16-acc-0.80.hdf5\n",
            "16/16 [==============================] - 60s 4s/step - loss: 0.9429 - acc: 0.6612 - val_loss: 0.7142 - val_acc: 0.8000\n",
            "Epoch 17/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9868 - acc: 0.6592\n",
            "Epoch 17: val_acc improved from 0.80000 to 0.81429, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-17-acc-0.81.hdf5\n",
            "16/16 [==============================] - 50s 3s/step - loss: 0.9868 - acc: 0.6592 - val_loss: 0.6840 - val_acc: 0.8143\n",
            "Epoch 18/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9501 - acc: 0.6776\n",
            "Epoch 18: val_acc did not improve from 0.81429\n",
            "16/16 [==============================] - 37s 2s/step - loss: 0.9501 - acc: 0.6776 - val_loss: 0.6642 - val_acc: 0.8143\n",
            "Epoch 19/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9254 - acc: 0.6551\n",
            "Epoch 19: val_acc did not improve from 0.81429\n",
            "16/16 [==============================] - 66s 4s/step - loss: 0.9254 - acc: 0.6551 - val_loss: 0.6359 - val_acc: 0.8143\n",
            "Epoch 20/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9333 - acc: 0.6837\n",
            "Epoch 20: val_acc did not improve from 0.81429\n",
            "16/16 [==============================] - 48s 3s/step - loss: 0.9333 - acc: 0.6837 - val_loss: 0.6193 - val_acc: 0.8143\n",
            "Epoch 21/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8714 - acc: 0.6837\n",
            "Epoch 21: val_acc improved from 0.81429 to 0.84286, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-21-acc-0.84.hdf5\n",
            "16/16 [==============================] - 39s 2s/step - loss: 0.8714 - acc: 0.6837 - val_loss: 0.5905 - val_acc: 0.8429\n",
            "Epoch 22/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7670 - acc: 0.7163\n",
            "Epoch 22: val_acc did not improve from 0.84286\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.7670 - acc: 0.7163 - val_loss: 0.5681 - val_acc: 0.8429\n",
            "Epoch 23/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7210 - acc: 0.7469\n",
            "Epoch 23: val_acc did not improve from 0.84286\n",
            "16/16 [==============================] - 43s 3s/step - loss: 0.7210 - acc: 0.7469 - val_loss: 0.5444 - val_acc: 0.8429\n",
            "Epoch 24/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7720 - acc: 0.7327\n",
            "Epoch 24: val_acc did not improve from 0.84286\n",
            "16/16 [==============================] - 45s 3s/step - loss: 0.7720 - acc: 0.7327 - val_loss: 0.5207 - val_acc: 0.8429\n",
            "Epoch 25/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7541 - acc: 0.7347\n",
            "Epoch 25: val_acc improved from 0.84286 to 0.85000, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-25-acc-0.85.hdf5\n",
            "16/16 [==============================] - 57s 4s/step - loss: 0.7541 - acc: 0.7347 - val_loss: 0.5240 - val_acc: 0.8500\n",
            "Epoch 26/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6774 - acc: 0.7633\n",
            "Epoch 26: val_acc improved from 0.85000 to 0.85714, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-26-acc-0.86.hdf5\n",
            "16/16 [==============================] - 52s 3s/step - loss: 0.6774 - acc: 0.7633 - val_loss: 0.5389 - val_acc: 0.8571\n",
            "Epoch 27/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6942 - acc: 0.7592\n",
            "Epoch 27: val_acc did not improve from 0.85714\n",
            "16/16 [==============================] - 50s 3s/step - loss: 0.6942 - acc: 0.7592 - val_loss: 0.5293 - val_acc: 0.8500\n",
            "Epoch 28/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6849 - acc: 0.7633\n",
            "Epoch 28: val_acc did not improve from 0.85714\n",
            "16/16 [==============================] - 49s 3s/step - loss: 0.6849 - acc: 0.7633 - val_loss: 0.5061 - val_acc: 0.8571\n",
            "Epoch 29/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7388 - acc: 0.7510\n",
            "Epoch 29: val_acc improved from 0.85714 to 0.87143, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-29-acc-0.87.hdf5\n",
            "16/16 [==============================] - 48s 3s/step - loss: 0.7388 - acc: 0.7510 - val_loss: 0.4989 - val_acc: 0.8714\n",
            "Epoch 30/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5638 - acc: 0.7959\n",
            "Epoch 30: val_acc did not improve from 0.87143\n",
            "16/16 [==============================] - 47s 3s/step - loss: 0.5638 - acc: 0.7959 - val_loss: 0.4983 - val_acc: 0.8500\n",
            "Epoch 31/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6043 - acc: 0.7857\n",
            "Epoch 31: val_acc did not improve from 0.87143\n",
            "16/16 [==============================] - 35s 2s/step - loss: 0.6043 - acc: 0.7857 - val_loss: 0.4916 - val_acc: 0.8571\n",
            "\n",
            "\n",
            "Model Accuracy 0.8571428571428571\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.82      0.90      0.86        10\n",
            "       10000       0.90      0.90      0.90        10\n",
            "      100000       1.00      1.00      1.00        10\n",
            "        2000       0.67      1.00      0.80        10\n",
            "       20000       0.86      0.60      0.71        10\n",
            "        5000       1.00      0.90      0.95        10\n",
            "       50000       0.88      0.70      0.78        10\n",
            "\n",
            "    accuracy                           0.86        70\n",
            "   macro avg       0.87      0.86      0.86        70\n",
            "weighted avg       0.87      0.86      0.86        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 4 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 31\n",
            "learning rate: 0.0035963600468659532\n",
            "batch size: 32\n",
            "dropout rate: 0.7613655052961976\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_54864\\940263153.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 3.5587 - acc: 0.1898\n",
            "Epoch 1: val_acc improved from -inf to 0.15714, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-01-acc-0.16.hdf5\n",
            "16/16 [==============================] - 34s 2s/step - loss: 3.5587 - acc: 0.1898 - val_loss: 2.5197 - val_acc: 0.1571\n",
            "Epoch 2/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.3049 - acc: 0.3714\n",
            "Epoch 2: val_acc improved from 0.15714 to 0.18571, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-02-acc-0.19.hdf5\n",
            "16/16 [==============================] - 41s 2s/step - loss: 2.3049 - acc: 0.3714 - val_loss: 2.2676 - val_acc: 0.1857\n",
            "Epoch 3/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.8361 - acc: 0.4490\n",
            "Epoch 3: val_acc improved from 0.18571 to 0.31429, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-03-acc-0.31.hdf5\n",
            "16/16 [==============================] - 43s 2s/step - loss: 1.8361 - acc: 0.4490 - val_loss: 1.8831 - val_acc: 0.3143\n",
            "Epoch 4/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.4685 - acc: 0.5429\n",
            "Epoch 4: val_acc improved from 0.31429 to 0.32143, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-04-acc-0.32.hdf5\n",
            "16/16 [==============================] - 39s 2s/step - loss: 1.4685 - acc: 0.5429 - val_loss: 1.5140 - val_acc: 0.3214\n",
            "Epoch 5/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2700 - acc: 0.5714\n",
            "Epoch 5: val_acc improved from 0.32143 to 0.42143, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-05-acc-0.42.hdf5\n",
            "16/16 [==============================] - 39s 3s/step - loss: 1.2700 - acc: 0.5714 - val_loss: 1.3456 - val_acc: 0.4214\n",
            "Epoch 6/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1679 - acc: 0.5735\n",
            "Epoch 6: val_acc improved from 0.42143 to 0.47143, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-06-acc-0.47.hdf5\n",
            "16/16 [==============================] - 43s 3s/step - loss: 1.1679 - acc: 0.5735 - val_loss: 1.2210 - val_acc: 0.4714\n",
            "Epoch 7/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0474 - acc: 0.6429\n",
            "Epoch 7: val_acc improved from 0.47143 to 0.68571, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-07-acc-0.69.hdf5\n",
            "16/16 [==============================] - 40s 2s/step - loss: 1.0474 - acc: 0.6429 - val_loss: 0.9757 - val_acc: 0.6857\n",
            "Epoch 8/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9308 - acc: 0.6714\n",
            "Epoch 8: val_acc improved from 0.68571 to 0.75000, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-08-acc-0.75.hdf5\n",
            "16/16 [==============================] - 39s 2s/step - loss: 0.9308 - acc: 0.6714 - val_loss: 0.8512 - val_acc: 0.7500\n",
            "Epoch 9/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8872 - acc: 0.7020\n",
            "Epoch 9: val_acc improved from 0.75000 to 0.78571, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-09-acc-0.79.hdf5\n",
            "16/16 [==============================] - 39s 2s/step - loss: 0.8872 - acc: 0.7020 - val_loss: 0.7624 - val_acc: 0.7857\n",
            "Epoch 10/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8205 - acc: 0.7041\n",
            "Epoch 10: val_acc improved from 0.78571 to 0.84286, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-10-acc-0.84.hdf5\n",
            "16/16 [==============================] - 44s 3s/step - loss: 0.8205 - acc: 0.7041 - val_loss: 0.7152 - val_acc: 0.8429\n",
            "Epoch 11/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7251 - acc: 0.7388\n",
            "Epoch 11: val_acc did not improve from 0.84286\n",
            "16/16 [==============================] - 39s 2s/step - loss: 0.7251 - acc: 0.7388 - val_loss: 0.7003 - val_acc: 0.8071\n",
            "Epoch 12/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7087 - acc: 0.7367\n",
            "Epoch 12: val_acc improved from 0.84286 to 0.85000, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-12-acc-0.85.hdf5\n",
            "16/16 [==============================] - 40s 3s/step - loss: 0.7087 - acc: 0.7367 - val_loss: 0.6093 - val_acc: 0.8500\n",
            "Epoch 13/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7201 - acc: 0.7265\n",
            "Epoch 13: val_acc improved from 0.85000 to 0.87143, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-13-acc-0.87.hdf5\n",
            "16/16 [==============================] - 43s 2s/step - loss: 0.7201 - acc: 0.7265 - val_loss: 0.5816 - val_acc: 0.8714\n",
            "Epoch 14/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6071 - acc: 0.7878\n",
            "Epoch 14: val_acc did not improve from 0.87143\n",
            "16/16 [==============================] - 38s 3s/step - loss: 0.6071 - acc: 0.7878 - val_loss: 0.5524 - val_acc: 0.8643\n",
            "Epoch 15/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6512 - acc: 0.7694\n",
            "Epoch 15: val_acc did not improve from 0.87143\n",
            "16/16 [==============================] - 44s 3s/step - loss: 0.6512 - acc: 0.7694 - val_loss: 0.5093 - val_acc: 0.8643\n",
            "Epoch 16/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5529 - acc: 0.8082\n",
            "Epoch 16: val_acc improved from 0.87143 to 0.87857, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-16-acc-0.88.hdf5\n",
            "16/16 [==============================] - 39s 2s/step - loss: 0.5529 - acc: 0.8082 - val_loss: 0.4748 - val_acc: 0.8786\n",
            "Epoch 17/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4985 - acc: 0.8122\n",
            "Epoch 17: val_acc improved from 0.87857 to 0.90000, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-17-acc-0.90.hdf5\n",
            "16/16 [==============================] - 39s 2s/step - loss: 0.4985 - acc: 0.8122 - val_loss: 0.4540 - val_acc: 0.9000\n",
            "Epoch 18/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5079 - acc: 0.8163\n",
            "Epoch 18: val_acc improved from 0.90000 to 0.90714, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-18-acc-0.91.hdf5\n",
            "16/16 [==============================] - 45s 3s/step - loss: 0.5079 - acc: 0.8163 - val_loss: 0.4142 - val_acc: 0.9071\n",
            "Epoch 19/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5545 - acc: 0.8102\n",
            "Epoch 19: val_acc did not improve from 0.90714\n",
            "16/16 [==============================] - 39s 2s/step - loss: 0.5545 - acc: 0.8102 - val_loss: 0.4038 - val_acc: 0.8857\n",
            "Epoch 20/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4825 - acc: 0.8429\n",
            "Epoch 20: val_acc did not improve from 0.90714\n",
            "16/16 [==============================] - 39s 2s/step - loss: 0.4825 - acc: 0.8429 - val_loss: 0.3998 - val_acc: 0.8714\n",
            "Epoch 21/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4324 - acc: 0.8449\n",
            "Epoch 21: val_acc did not improve from 0.90714\n",
            "16/16 [==============================] - 44s 3s/step - loss: 0.4324 - acc: 0.8449 - val_loss: 0.3875 - val_acc: 0.8857\n",
            "Epoch 22/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4540 - acc: 0.8347\n",
            "Epoch 22: val_acc did not improve from 0.90714\n",
            "16/16 [==============================] - 38s 2s/step - loss: 0.4540 - acc: 0.8347 - val_loss: 0.3749 - val_acc: 0.8929\n",
            "Epoch 23/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4508 - acc: 0.8224\n",
            "Epoch 23: val_acc did not improve from 0.90714\n",
            "16/16 [==============================] - 39s 2s/step - loss: 0.4508 - acc: 0.8224 - val_loss: 0.3939 - val_acc: 0.8786\n",
            "Epoch 24/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4835 - acc: 0.8449\n",
            "Epoch 24: val_acc did not improve from 0.90714\n",
            "16/16 [==============================] - 44s 3s/step - loss: 0.4835 - acc: 0.8449 - val_loss: 0.3979 - val_acc: 0.8786\n",
            "Epoch 25/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4479 - acc: 0.8408\n",
            "Epoch 25: val_acc did not improve from 0.90714\n",
            "16/16 [==============================] - 39s 2s/step - loss: 0.4479 - acc: 0.8408 - val_loss: 0.3931 - val_acc: 0.8786\n",
            "Epoch 26/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4521 - acc: 0.8490\n",
            "Epoch 26: val_acc did not improve from 0.90714\n",
            "16/16 [==============================] - 39s 2s/step - loss: 0.4521 - acc: 0.8490 - val_loss: 0.4395 - val_acc: 0.8714\n",
            "Epoch 27/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4298 - acc: 0.8612\n",
            "Epoch 27: val_acc did not improve from 0.90714\n",
            "16/16 [==============================] - 44s 3s/step - loss: 0.4298 - acc: 0.8612 - val_loss: 0.4454 - val_acc: 0.8857\n",
            "\n",
            "\n",
            "Model Accuracy 0.8857142857142857\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.89      0.80      0.84        10\n",
            "       10000       0.91      1.00      0.95        10\n",
            "      100000       1.00      0.90      0.95        10\n",
            "        2000       0.71      1.00      0.83        10\n",
            "       20000       1.00      0.60      0.75        10\n",
            "        5000       0.90      0.90      0.90        10\n",
            "       50000       0.91      1.00      0.95        10\n",
            "\n",
            "    accuracy                           0.89        70\n",
            "   macro avg       0.90      0.89      0.88        70\n",
            "weighted avg       0.90      0.89      0.88        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 5 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 31\n",
            "learning rate: 0.01625120570813689\n",
            "batch size: 64\n",
            "dropout rate: 0.5384000577988711\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_54864\\940263153.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.1445 - acc: 0.3449\n",
            "Epoch 1: val_acc improved from -inf to 0.23571, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-01-acc-0.24.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 2.1445 - acc: 0.3449 - val_loss: 4.0885 - val_acc: 0.2357\n",
            "Epoch 2/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.2509 - acc: 0.5878\n",
            "Epoch 2: val_acc improved from 0.23571 to 0.32857, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-02-acc-0.33.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 1.2509 - acc: 0.5878 - val_loss: 3.1191 - val_acc: 0.3286\n",
            "Epoch 3/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8238 - acc: 0.6980\n",
            "Epoch 3: val_acc did not improve from 0.32857\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.8238 - acc: 0.6980 - val_loss: 3.0508 - val_acc: 0.2357\n",
            "Epoch 4/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6456 - acc: 0.7837\n",
            "Epoch 4: val_acc improved from 0.32857 to 0.36429, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-04-acc-0.36.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.6456 - acc: 0.7837 - val_loss: 2.7863 - val_acc: 0.3643\n",
            "Epoch 5/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5230 - acc: 0.8143\n",
            "Epoch 5: val_acc improved from 0.36429 to 0.38571, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-05-acc-0.39.hdf5\n",
            "8/8 [==============================] - 43s 5s/step - loss: 0.5230 - acc: 0.8143 - val_loss: 2.8376 - val_acc: 0.3857\n",
            "Epoch 6/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4391 - acc: 0.8510\n",
            "Epoch 6: val_acc did not improve from 0.38571\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.4391 - acc: 0.8510 - val_loss: 2.7888 - val_acc: 0.3786\n",
            "Epoch 7/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3862 - acc: 0.8592\n",
            "Epoch 7: val_acc did not improve from 0.38571\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.3862 - acc: 0.8592 - val_loss: 2.2409 - val_acc: 0.3786\n",
            "Epoch 8/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3214 - acc: 0.8918\n",
            "Epoch 8: val_acc improved from 0.38571 to 0.54286, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-08-acc-0.54.hdf5\n",
            "8/8 [==============================] - 45s 6s/step - loss: 0.3214 - acc: 0.8918 - val_loss: 1.5627 - val_acc: 0.5429\n",
            "Epoch 9/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3086 - acc: 0.8939\n",
            "Epoch 9: val_acc did not improve from 0.54286\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.3086 - acc: 0.8939 - val_loss: 1.7444 - val_acc: 0.4357\n",
            "Epoch 10/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3193 - acc: 0.8776\n",
            "Epoch 10: val_acc did not improve from 0.54286\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.3193 - acc: 0.8776 - val_loss: 1.7619 - val_acc: 0.3786\n",
            "Epoch 11/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2868 - acc: 0.9061\n",
            "Epoch 11: val_acc did not improve from 0.54286\n",
            "8/8 [==============================] - 44s 5s/step - loss: 0.2868 - acc: 0.9061 - val_loss: 1.8333 - val_acc: 0.3857\n",
            "Epoch 12/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2835 - acc: 0.9061\n",
            "Epoch 12: val_acc did not improve from 0.54286\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.2835 - acc: 0.9061 - val_loss: 1.5202 - val_acc: 0.5000\n",
            "Epoch 13/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2343 - acc: 0.9224\n",
            "Epoch 13: val_acc did not improve from 0.54286\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.2343 - acc: 0.9224 - val_loss: 1.4092 - val_acc: 0.5429\n",
            "Epoch 14/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2508 - acc: 0.9184\n",
            "Epoch 14: val_acc improved from 0.54286 to 0.60714, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-14-acc-0.61.hdf5\n",
            "8/8 [==============================] - 42s 6s/step - loss: 0.2508 - acc: 0.9184 - val_loss: 1.1378 - val_acc: 0.6071\n",
            "Epoch 15/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2622 - acc: 0.9143\n",
            "Epoch 15: val_acc did not improve from 0.60714\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.2622 - acc: 0.9143 - val_loss: 1.0618 - val_acc: 0.5929\n",
            "Epoch 16/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2170 - acc: 0.9204\n",
            "Epoch 16: val_acc improved from 0.60714 to 0.70000, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-16-acc-0.70.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.2170 - acc: 0.9204 - val_loss: 0.9060 - val_acc: 0.7000\n",
            "Epoch 17/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2088 - acc: 0.9306\n",
            "Epoch 17: val_acc did not improve from 0.70000\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.2088 - acc: 0.9306 - val_loss: 0.9213 - val_acc: 0.6929\n",
            "Epoch 18/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2332 - acc: 0.9224\n",
            "Epoch 18: val_acc improved from 0.70000 to 0.72143, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-18-acc-0.72.hdf5\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.2332 - acc: 0.9224 - val_loss: 0.8494 - val_acc: 0.7214\n",
            "Epoch 19/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1527 - acc: 0.9388\n",
            "Epoch 19: val_acc improved from 0.72143 to 0.74286, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-19-acc-0.74.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.1527 - acc: 0.9388 - val_loss: 0.8082 - val_acc: 0.7429\n",
            "Epoch 20/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1462 - acc: 0.9449\n",
            "Epoch 20: val_acc did not improve from 0.74286\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.1462 - acc: 0.9449 - val_loss: 0.8202 - val_acc: 0.7286\n",
            "Epoch 21/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1688 - acc: 0.9429\n",
            "Epoch 21: val_acc did not improve from 0.74286\n",
            "8/8 [==============================] - 42s 6s/step - loss: 0.1688 - acc: 0.9429 - val_loss: 0.8289 - val_acc: 0.7214\n",
            "Epoch 22/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1583 - acc: 0.9490\n",
            "Epoch 22: val_acc did not improve from 0.74286\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.1583 - acc: 0.9490 - val_loss: 0.7951 - val_acc: 0.7429\n",
            "Epoch 23/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1327 - acc: 0.9612\n",
            "Epoch 23: val_acc improved from 0.74286 to 0.77143, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-23-acc-0.77.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.1327 - acc: 0.9612 - val_loss: 0.6271 - val_acc: 0.7714\n",
            "Epoch 24/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1573 - acc: 0.9531\n",
            "Epoch 24: val_acc improved from 0.77143 to 0.78571, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-24-acc-0.79.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.1573 - acc: 0.9531 - val_loss: 0.6171 - val_acc: 0.7857\n",
            "Epoch 25/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1408 - acc: 0.9571\n",
            "Epoch 25: val_acc improved from 0.78571 to 0.82143, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-25-acc-0.82.hdf5\n",
            "8/8 [==============================] - 44s 5s/step - loss: 0.1408 - acc: 0.9571 - val_loss: 0.6649 - val_acc: 0.8214\n",
            "Epoch 26/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1353 - acc: 0.9469\n",
            "Epoch 26: val_acc did not improve from 0.82143\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.1353 - acc: 0.9469 - val_loss: 0.7271 - val_acc: 0.8143\n",
            "Epoch 27/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1757 - acc: 0.9347\n",
            "Epoch 27: val_acc did not improve from 0.82143\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.1757 - acc: 0.9347 - val_loss: 0.6977 - val_acc: 0.8071\n",
            "Epoch 28/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1685 - acc: 0.9306\n",
            "Epoch 28: val_acc did not improve from 0.82143\n",
            "8/8 [==============================] - 44s 5s/step - loss: 0.1685 - acc: 0.9306 - val_loss: 0.6579 - val_acc: 0.8214\n",
            "Epoch 29/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1881 - acc: 0.9347\n",
            "Epoch 29: val_acc did not improve from 0.82143\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.1881 - acc: 0.9347 - val_loss: 0.6710 - val_acc: 0.8143\n",
            "\n",
            "\n",
            "Model Accuracy 0.7428571428571429\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.88      0.70      0.78        10\n",
            "       10000       0.67      1.00      0.80        10\n",
            "      100000       1.00      0.80      0.89        10\n",
            "        2000       1.00      0.60      0.75        10\n",
            "       20000       1.00      0.20      0.33        10\n",
            "        5000       0.90      0.90      0.90        10\n",
            "       50000       0.48      1.00      0.65        10\n",
            "\n",
            "    accuracy                           0.74        70\n",
            "   macro avg       0.85      0.74      0.73        70\n",
            "weighted avg       0.85      0.74      0.73        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 6 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 30\n",
            "learning rate: 0.007237312019711687\n",
            "batch size: 64\n",
            "dropout rate: 0.6171294315001643\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_54864\\940263153.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.5417 - acc: 0.3163\n",
            "Epoch 1: val_acc improved from -inf to 0.25714, saving model to percobaan6_noImgPro/model\\vgg_16_6-saved-model-01-acc-0.26.hdf5\n",
            "8/8 [==============================] - 50s 6s/step - loss: 2.5417 - acc: 0.3163 - val_loss: 2.1425 - val_acc: 0.2571\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1706 - acc: 0.6000\n",
            "Epoch 2: val_acc improved from 0.25714 to 0.27857, saving model to percobaan6_noImgPro/model\\vgg_16_6-saved-model-02-acc-0.28.hdf5\n",
            "8/8 [==============================] - 72s 9s/step - loss: 1.1706 - acc: 0.6000 - val_loss: 2.1077 - val_acc: 0.2786\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9568 - acc: 0.6653\n",
            "Epoch 3: val_acc did not improve from 0.27857\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.9568 - acc: 0.6653 - val_loss: 2.0970 - val_acc: 0.2714\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7880 - acc: 0.7143\n",
            "Epoch 4: val_acc improved from 0.27857 to 0.37857, saving model to percobaan6_noImgPro/model\\vgg_16_6-saved-model-04-acc-0.38.hdf5\n",
            "8/8 [==============================] - 70s 9s/step - loss: 0.7880 - acc: 0.7143 - val_loss: 1.8360 - val_acc: 0.3786\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6539 - acc: 0.7755\n",
            "Epoch 5: val_acc improved from 0.37857 to 0.39286, saving model to percobaan6_noImgPro/model\\vgg_16_6-saved-model-05-acc-0.39.hdf5\n",
            "8/8 [==============================] - 70s 9s/step - loss: 0.6539 - acc: 0.7755 - val_loss: 1.7753 - val_acc: 0.3929\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5478 - acc: 0.8245\n",
            "Epoch 6: val_acc improved from 0.39286 to 0.40714, saving model to percobaan6_noImgPro/model\\vgg_16_6-saved-model-06-acc-0.41.hdf5\n",
            "8/8 [==============================] - 68s 9s/step - loss: 0.5478 - acc: 0.8245 - val_loss: 1.7158 - val_acc: 0.4071\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4790 - acc: 0.8429\n",
            "Epoch 7: val_acc improved from 0.40714 to 0.42143, saving model to percobaan6_noImgPro/model\\vgg_16_6-saved-model-07-acc-0.42.hdf5\n",
            "8/8 [==============================] - 68s 9s/step - loss: 0.4790 - acc: 0.8429 - val_loss: 1.6246 - val_acc: 0.4214\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4078 - acc: 0.8571\n",
            "Epoch 8: val_acc improved from 0.42143 to 0.47857, saving model to percobaan6_noImgPro/model\\vgg_16_6-saved-model-08-acc-0.48.hdf5\n",
            "8/8 [==============================] - 68s 9s/step - loss: 0.4078 - acc: 0.8571 - val_loss: 1.5114 - val_acc: 0.4786\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4018 - acc: 0.8653\n",
            "Epoch 9: val_acc improved from 0.47857 to 0.51429, saving model to percobaan6_noImgPro/model\\vgg_16_6-saved-model-09-acc-0.51.hdf5\n",
            "8/8 [==============================] - 65s 9s/step - loss: 0.4018 - acc: 0.8653 - val_loss: 1.3532 - val_acc: 0.5143\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3449 - acc: 0.8755\n",
            "Epoch 10: val_acc did not improve from 0.51429\n",
            "8/8 [==============================] - 65s 9s/step - loss: 0.3449 - acc: 0.8755 - val_loss: 1.3527 - val_acc: 0.5143\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2900 - acc: 0.8959\n",
            "Epoch 11: val_acc improved from 0.51429 to 0.53571, saving model to percobaan6_noImgPro/model\\vgg_16_6-saved-model-11-acc-0.54.hdf5\n",
            "8/8 [==============================] - 59s 8s/step - loss: 0.2900 - acc: 0.8959 - val_loss: 1.2755 - val_acc: 0.5357\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2755 - acc: 0.9163\n",
            "Epoch 12: val_acc improved from 0.53571 to 0.60714, saving model to percobaan6_noImgPro/model\\vgg_16_6-saved-model-12-acc-0.61.hdf5\n",
            "8/8 [==============================] - 65s 8s/step - loss: 0.2755 - acc: 0.9163 - val_loss: 1.0373 - val_acc: 0.6071\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2350 - acc: 0.9204\n",
            "Epoch 13: val_acc improved from 0.60714 to 0.66429, saving model to percobaan6_noImgPro/model\\vgg_16_6-saved-model-13-acc-0.66.hdf5\n",
            "8/8 [==============================] - 65s 8s/step - loss: 0.2350 - acc: 0.9204 - val_loss: 0.8913 - val_acc: 0.6643\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2391 - acc: 0.9184\n",
            "Epoch 14: val_acc improved from 0.66429 to 0.69286, saving model to percobaan6_noImgPro/model\\vgg_16_6-saved-model-14-acc-0.69.hdf5\n",
            "8/8 [==============================] - 65s 8s/step - loss: 0.2391 - acc: 0.9184 - val_loss: 0.8471 - val_acc: 0.6929\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2389 - acc: 0.9020\n",
            "Epoch 15: val_acc did not improve from 0.69286\n",
            "8/8 [==============================] - 65s 8s/step - loss: 0.2389 - acc: 0.9020 - val_loss: 0.8105 - val_acc: 0.6786\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2752 - acc: 0.9061\n",
            "Epoch 16: val_acc did not improve from 0.69286\n",
            "8/8 [==============================] - 65s 9s/step - loss: 0.2752 - acc: 0.9061 - val_loss: 0.8052 - val_acc: 0.6786\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2250 - acc: 0.9245\n",
            "Epoch 17: val_acc did not improve from 0.69286\n",
            "8/8 [==============================] - 65s 8s/step - loss: 0.2250 - acc: 0.9245 - val_loss: 0.8026 - val_acc: 0.6500\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1887 - acc: 0.9429\n",
            "Epoch 18: val_acc improved from 0.69286 to 0.73571, saving model to percobaan6_noImgPro/model\\vgg_16_6-saved-model-18-acc-0.74.hdf5\n",
            "8/8 [==============================] - 64s 8s/step - loss: 0.1887 - acc: 0.9429 - val_loss: 0.6898 - val_acc: 0.7357\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2303 - acc: 0.9224\n",
            "Epoch 19: val_acc improved from 0.73571 to 0.77143, saving model to percobaan6_noImgPro/model\\vgg_16_6-saved-model-19-acc-0.77.hdf5\n",
            "8/8 [==============================] - 63s 8s/step - loss: 0.2303 - acc: 0.9224 - val_loss: 0.6657 - val_acc: 0.7714\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2237 - acc: 0.9265\n",
            "Epoch 20: val_acc improved from 0.77143 to 0.77857, saving model to percobaan6_noImgPro/model\\vgg_16_6-saved-model-20-acc-0.78.hdf5\n",
            "8/8 [==============================] - 64s 9s/step - loss: 0.2237 - acc: 0.9265 - val_loss: 0.6712 - val_acc: 0.7786\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1857 - acc: 0.9408\n",
            "Epoch 21: val_acc improved from 0.77857 to 0.79286, saving model to percobaan6_noImgPro/model\\vgg_16_6-saved-model-21-acc-0.79.hdf5\n",
            "8/8 [==============================] - 64s 8s/step - loss: 0.1857 - acc: 0.9408 - val_loss: 0.6747 - val_acc: 0.7929\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2126 - acc: 0.9224\n",
            "Epoch 22: val_acc did not improve from 0.79286\n",
            "8/8 [==============================] - 63s 9s/step - loss: 0.2126 - acc: 0.9224 - val_loss: 0.6889 - val_acc: 0.7500\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1882 - acc: 0.9245\n",
            "Epoch 23: val_acc did not improve from 0.79286\n",
            "8/8 [==============================] - 64s 8s/step - loss: 0.1882 - acc: 0.9245 - val_loss: 0.6543 - val_acc: 0.7786\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2085 - acc: 0.9224\n",
            "Epoch 24: val_acc did not improve from 0.79286\n",
            "8/8 [==============================] - 64s 8s/step - loss: 0.2085 - acc: 0.9224 - val_loss: 0.5771 - val_acc: 0.7786\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1873 - acc: 0.9388\n",
            "Epoch 25: val_acc improved from 0.79286 to 0.81429, saving model to percobaan6_noImgPro/model\\vgg_16_6-saved-model-25-acc-0.81.hdf5\n",
            "8/8 [==============================] - 57s 7s/step - loss: 0.1873 - acc: 0.9388 - val_loss: 0.5075 - val_acc: 0.8143\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1786 - acc: 0.9429\n",
            "Epoch 26: val_acc improved from 0.81429 to 0.84286, saving model to percobaan6_noImgPro/model\\vgg_16_6-saved-model-26-acc-0.84.hdf5\n",
            "8/8 [==============================] - 63s 7s/step - loss: 0.1786 - acc: 0.9429 - val_loss: 0.4725 - val_acc: 0.8429\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1846 - acc: 0.9429\n",
            "Epoch 27: val_acc improved from 0.84286 to 0.85000, saving model to percobaan6_noImgPro/model\\vgg_16_6-saved-model-27-acc-0.85.hdf5\n",
            "8/8 [==============================] - 63s 8s/step - loss: 0.1846 - acc: 0.9429 - val_loss: 0.4866 - val_acc: 0.8500\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1657 - acc: 0.9551\n",
            "Epoch 28: val_acc improved from 0.85000 to 0.86429, saving model to percobaan6_noImgPro/model\\vgg_16_6-saved-model-28-acc-0.86.hdf5\n",
            "8/8 [==============================] - 68s 9s/step - loss: 0.1657 - acc: 0.9551 - val_loss: 0.4812 - val_acc: 0.8643\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1474 - acc: 0.9449\n",
            "Epoch 29: val_acc did not improve from 0.86429\n",
            "8/8 [==============================] - 57s 7s/step - loss: 0.1474 - acc: 0.9449 - val_loss: 0.5057 - val_acc: 0.8571\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1484 - acc: 0.9388\n",
            "Epoch 30: val_acc did not improve from 0.86429\n",
            "8/8 [==============================] - 63s 8s/step - loss: 0.1484 - acc: 0.9388 - val_loss: 0.5974 - val_acc: 0.8357\n",
            "\n",
            "\n",
            "Model Accuracy 0.8857142857142857\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.91      1.00      0.95        10\n",
            "       10000       1.00      1.00      1.00        10\n",
            "      100000       0.90      0.90      0.90        10\n",
            "        2000       0.90      0.90      0.90        10\n",
            "       20000       0.83      0.50      0.62        10\n",
            "        5000       0.82      0.90      0.86        10\n",
            "       50000       0.83      1.00      0.91        10\n",
            "\n",
            "    accuracy                           0.89        70\n",
            "   macro avg       0.88      0.89      0.88        70\n",
            "weighted avg       0.88      0.89      0.88        70\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_54864\\940263153.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 7 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 31\n",
            "learning rate: 0.012823036611208162\n",
            "batch size: 64\n",
            "dropout rate: 0.6952522796211565\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.6579 - acc: 0.2980\n",
            "Epoch 1: val_acc improved from -inf to 0.20714, saving model to percobaan7_noImgPro/model\\vgg_16_7-saved-model-01-acc-0.21.hdf5\n",
            "8/8 [==============================] - 41s 5s/step - loss: 2.6579 - acc: 0.2980 - val_loss: 3.5181 - val_acc: 0.2071\n",
            "Epoch 2/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4786 - acc: 0.5184\n",
            "Epoch 2: val_acc did not improve from 0.20714\n",
            "8/8 [==============================] - 39s 5s/step - loss: 1.4786 - acc: 0.5184 - val_loss: 3.8721 - val_acc: 0.1714\n",
            "Epoch 3/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1246 - acc: 0.6224\n",
            "Epoch 3: val_acc did not improve from 0.20714\n",
            "8/8 [==============================] - 38s 5s/step - loss: 1.1246 - acc: 0.6224 - val_loss: 3.9789 - val_acc: 0.1857\n",
            "Epoch 4/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9936 - acc: 0.6469\n",
            "Epoch 4: val_acc improved from 0.20714 to 0.25000, saving model to percobaan7_noImgPro/model\\vgg_16_7-saved-model-04-acc-0.25.hdf5\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.9936 - acc: 0.6469 - val_loss: 2.5149 - val_acc: 0.2500\n",
            "Epoch 5/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8513 - acc: 0.7102\n",
            "Epoch 5: val_acc improved from 0.25000 to 0.25714, saving model to percobaan7_noImgPro/model\\vgg_16_7-saved-model-05-acc-0.26.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.8513 - acc: 0.7102 - val_loss: 2.4110 - val_acc: 0.2571\n",
            "Epoch 6/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6963 - acc: 0.7449\n",
            "Epoch 6: val_acc improved from 0.25714 to 0.37143, saving model to percobaan7_noImgPro/model\\vgg_16_7-saved-model-06-acc-0.37.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.6963 - acc: 0.7449 - val_loss: 1.7494 - val_acc: 0.3714\n",
            "Epoch 7/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7372 - acc: 0.7531\n",
            "Epoch 7: val_acc improved from 0.37143 to 0.47143, saving model to percobaan7_noImgPro/model\\vgg_16_7-saved-model-07-acc-0.47.hdf5\n",
            "8/8 [==============================] - 44s 5s/step - loss: 0.7372 - acc: 0.7531 - val_loss: 1.3521 - val_acc: 0.4714\n",
            "Epoch 8/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6228 - acc: 0.7918\n",
            "Epoch 8: val_acc improved from 0.47143 to 0.65714, saving model to percobaan7_noImgPro/model\\vgg_16_7-saved-model-08-acc-0.66.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.6228 - acc: 0.7918 - val_loss: 1.1963 - val_acc: 0.6571\n",
            "Epoch 9/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5207 - acc: 0.8143\n",
            "Epoch 9: val_acc did not improve from 0.65714\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.5207 - acc: 0.8143 - val_loss: 1.1456 - val_acc: 0.6071\n",
            "Epoch 10/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4642 - acc: 0.8327\n",
            "Epoch 10: val_acc did not improve from 0.65714\n",
            "8/8 [==============================] - 44s 5s/step - loss: 0.4642 - acc: 0.8327 - val_loss: 1.1092 - val_acc: 0.5500\n",
            "Epoch 11/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4406 - acc: 0.8408\n",
            "Epoch 11: val_acc did not improve from 0.65714\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.4406 - acc: 0.8408 - val_loss: 1.0478 - val_acc: 0.5786\n",
            "Epoch 12/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3843 - acc: 0.8633\n",
            "Epoch 12: val_acc did not improve from 0.65714\n",
            "8/8 [==============================] - 43s 6s/step - loss: 0.3843 - acc: 0.8633 - val_loss: 1.0500 - val_acc: 0.6143\n",
            "Epoch 13/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3613 - acc: 0.8673\n",
            "Epoch 13: val_acc did not improve from 0.65714\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.3613 - acc: 0.8673 - val_loss: 1.0684 - val_acc: 0.6071\n",
            "Epoch 14/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3868 - acc: 0.8612\n",
            "Epoch 14: val_acc improved from 0.65714 to 0.67857, saving model to percobaan7_noImgPro/model\\vgg_16_7-saved-model-14-acc-0.68.hdf5\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.3868 - acc: 0.8612 - val_loss: 0.9454 - val_acc: 0.6786\n",
            "Epoch 15/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3366 - acc: 0.8980\n",
            "Epoch 15: val_acc did not improve from 0.67857\n",
            "8/8 [==============================] - 40s 5s/step - loss: 0.3366 - acc: 0.8980 - val_loss: 0.8874 - val_acc: 0.6714\n",
            "Epoch 16/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3653 - acc: 0.8776\n",
            "Epoch 16: val_acc did not improve from 0.67857\n",
            "8/8 [==============================] - 41s 5s/step - loss: 0.3653 - acc: 0.8776 - val_loss: 0.9658 - val_acc: 0.6429\n",
            "Epoch 17/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3682 - acc: 0.8571\n",
            "Epoch 17: val_acc improved from 0.67857 to 0.70000, saving model to percobaan7_noImgPro/model\\vgg_16_7-saved-model-17-acc-0.70.hdf5\n",
            "8/8 [==============================] - 47s 6s/step - loss: 0.3682 - acc: 0.8571 - val_loss: 0.9689 - val_acc: 0.7000\n",
            "Epoch 18/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3487 - acc: 0.8796\n",
            "Epoch 18: val_acc improved from 0.70000 to 0.72143, saving model to percobaan7_noImgPro/model\\vgg_16_7-saved-model-18-acc-0.72.hdf5\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.3487 - acc: 0.8796 - val_loss: 0.7907 - val_acc: 0.7214\n",
            "Epoch 19/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3409 - acc: 0.8898\n",
            "Epoch 19: val_acc did not improve from 0.72143\n",
            "8/8 [==============================] - 45s 6s/step - loss: 0.3409 - acc: 0.8898 - val_loss: 0.7959 - val_acc: 0.7214\n",
            "Epoch 20/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3152 - acc: 0.8939\n",
            "Epoch 20: val_acc did not improve from 0.72143\n",
            "8/8 [==============================] - 46s 6s/step - loss: 0.3152 - acc: 0.8939 - val_loss: 0.7940 - val_acc: 0.7214\n",
            "Epoch 21/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2731 - acc: 0.9082\n",
            "Epoch 21: val_acc did not improve from 0.72143\n",
            "8/8 [==============================] - 46s 6s/step - loss: 0.2731 - acc: 0.9082 - val_loss: 0.8421 - val_acc: 0.7071\n",
            "Epoch 22/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3132 - acc: 0.9143\n",
            "Epoch 22: val_acc did not improve from 0.72143\n",
            "8/8 [==============================] - 32s 4s/step - loss: 0.3132 - acc: 0.9143 - val_loss: 0.7816 - val_acc: 0.7214\n",
            "Epoch 23/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3381 - acc: 0.8714\n",
            "Epoch 23: val_acc did not improve from 0.72143\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.3381 - acc: 0.8714 - val_loss: 0.7627 - val_acc: 0.7214\n",
            "Epoch 24/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2497 - acc: 0.9143\n",
            "Epoch 24: val_acc improved from 0.72143 to 0.79286, saving model to percobaan7_noImgPro/model\\vgg_16_7-saved-model-24-acc-0.79.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.2497 - acc: 0.9143 - val_loss: 0.6359 - val_acc: 0.7929\n",
            "Epoch 25/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2485 - acc: 0.9163\n",
            "Epoch 25: val_acc improved from 0.79286 to 0.83571, saving model to percobaan7_noImgPro/model\\vgg_16_7-saved-model-25-acc-0.84.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.2485 - acc: 0.9163 - val_loss: 0.5434 - val_acc: 0.8357\n",
            "Epoch 26/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2447 - acc: 0.9102\n",
            "Epoch 26: val_acc improved from 0.83571 to 0.84286, saving model to percobaan7_noImgPro/model\\vgg_16_7-saved-model-26-acc-0.84.hdf5\n",
            "8/8 [==============================] - 37s 5s/step - loss: 0.2447 - acc: 0.9102 - val_loss: 0.5087 - val_acc: 0.8429\n",
            "Epoch 27/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2180 - acc: 0.9061\n",
            "Epoch 27: val_acc improved from 0.84286 to 0.85714, saving model to percobaan7_noImgPro/model\\vgg_16_7-saved-model-27-acc-0.86.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.2180 - acc: 0.9061 - val_loss: 0.5234 - val_acc: 0.8571\n",
            "Epoch 28/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2406 - acc: 0.9265\n",
            "Epoch 28: val_acc did not improve from 0.85714\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.2406 - acc: 0.9265 - val_loss: 0.5596 - val_acc: 0.8500\n",
            "Epoch 29/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2549 - acc: 0.9122\n",
            "Epoch 29: val_acc did not improve from 0.85714\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.2549 - acc: 0.9122 - val_loss: 0.4892 - val_acc: 0.8500\n",
            "Epoch 30/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1805 - acc: 0.9347\n",
            "Epoch 30: val_acc improved from 0.85714 to 0.86429, saving model to percobaan7_noImgPro/model\\vgg_16_7-saved-model-30-acc-0.86.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.1805 - acc: 0.9347 - val_loss: 0.4317 - val_acc: 0.8643\n",
            "Epoch 31/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2466 - acc: 0.9245\n",
            "Epoch 31: val_acc did not improve from 0.86429\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.2466 - acc: 0.9245 - val_loss: 0.4987 - val_acc: 0.8429\n",
            "\n",
            "\n",
            "Model Accuracy 0.8714285714285714\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.91      1.00      0.95        10\n",
            "       10000       1.00      0.90      0.95        10\n",
            "      100000       1.00      0.90      0.95        10\n",
            "        2000       0.70      0.70      0.70        10\n",
            "       20000       0.88      0.70      0.78        10\n",
            "        5000       0.69      0.90      0.78        10\n",
            "       50000       1.00      1.00      1.00        10\n",
            "\n",
            "    accuracy                           0.87        70\n",
            "   macro avg       0.88      0.87      0.87        70\n",
            "weighted avg       0.88      0.87      0.87        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 8 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 36\n",
            "learning rate: 0.016872038176122543\n",
            "batch size: 64\n",
            "dropout rate: 0.7793047638999318\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_54864\\940263153.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 3.1501 - acc: 0.2408\n",
            "Epoch 1: val_acc improved from -inf to 0.20714, saving model to percobaan8_noImgPro/model\\vgg_16_8-saved-model-01-acc-0.21.hdf5\n",
            "8/8 [==============================] - 40s 5s/step - loss: 3.1501 - acc: 0.2408 - val_loss: 3.2582 - val_acc: 0.2071\n",
            "Epoch 2/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.9627 - acc: 0.4041\n",
            "Epoch 2: val_acc did not improve from 0.20714\n",
            "8/8 [==============================] - 38s 5s/step - loss: 1.9627 - acc: 0.4041 - val_loss: 4.8538 - val_acc: 0.1786\n",
            "Epoch 3/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7975 - acc: 0.4163\n",
            "Epoch 3: val_acc did not improve from 0.20714\n",
            "8/8 [==============================] - 38s 5s/step - loss: 1.7975 - acc: 0.4163 - val_loss: 3.4192 - val_acc: 0.1714\n",
            "Epoch 4/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4154 - acc: 0.4959\n",
            "Epoch 4: val_acc improved from 0.20714 to 0.21429, saving model to percobaan8_noImgPro/model\\vgg_16_8-saved-model-04-acc-0.21.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 1.4154 - acc: 0.4959 - val_loss: 2.7943 - val_acc: 0.2143\n",
            "Epoch 5/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3390 - acc: 0.5265\n",
            "Epoch 5: val_acc improved from 0.21429 to 0.24286, saving model to percobaan8_noImgPro/model\\vgg_16_8-saved-model-05-acc-0.24.hdf5\n",
            "8/8 [==============================] - 43s 6s/step - loss: 1.3390 - acc: 0.5265 - val_loss: 2.3004 - val_acc: 0.2429\n",
            "Epoch 6/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0770 - acc: 0.6000\n",
            "Epoch 6: val_acc did not improve from 0.24286\n",
            "8/8 [==============================] - 38s 5s/step - loss: 1.0770 - acc: 0.6000 - val_loss: 2.0273 - val_acc: 0.2143\n",
            "Epoch 7/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9627 - acc: 0.6571\n",
            "Epoch 7: val_acc improved from 0.24286 to 0.26429, saving model to percobaan8_noImgPro/model\\vgg_16_8-saved-model-07-acc-0.26.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.9627 - acc: 0.6571 - val_loss: 1.7167 - val_acc: 0.2643\n",
            "Epoch 8/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8423 - acc: 0.6918\n",
            "Epoch 8: val_acc improved from 0.26429 to 0.35714, saving model to percobaan8_noImgPro/model\\vgg_16_8-saved-model-08-acc-0.36.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.8423 - acc: 0.6918 - val_loss: 1.5506 - val_acc: 0.3571\n",
            "Epoch 9/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8246 - acc: 0.6959\n",
            "Epoch 9: val_acc improved from 0.35714 to 0.48571, saving model to percobaan8_noImgPro/model\\vgg_16_8-saved-model-09-acc-0.49.hdf5\n",
            "8/8 [==============================] - 44s 5s/step - loss: 0.8246 - acc: 0.6959 - val_loss: 1.2801 - val_acc: 0.4857\n",
            "Epoch 10/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7912 - acc: 0.7184\n",
            "Epoch 10: val_acc improved from 0.48571 to 0.58571, saving model to percobaan8_noImgPro/model\\vgg_16_8-saved-model-10-acc-0.59.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.7912 - acc: 0.7184 - val_loss: 1.1064 - val_acc: 0.5857\n",
            "Epoch 11/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7524 - acc: 0.7429\n",
            "Epoch 11: val_acc improved from 0.58571 to 0.60714, saving model to percobaan8_noImgPro/model\\vgg_16_8-saved-model-11-acc-0.61.hdf5\n",
            "8/8 [==============================] - 43s 6s/step - loss: 0.7524 - acc: 0.7429 - val_loss: 1.0553 - val_acc: 0.6071\n",
            "Epoch 12/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6608 - acc: 0.7673\n",
            "Epoch 12: val_acc improved from 0.60714 to 0.69286, saving model to percobaan8_noImgPro/model\\vgg_16_8-saved-model-12-acc-0.69.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.6608 - acc: 0.7673 - val_loss: 0.9759 - val_acc: 0.6929\n",
            "Epoch 13/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7542 - acc: 0.7367\n",
            "Epoch 13: val_acc did not improve from 0.69286\n",
            "8/8 [==============================] - 37s 5s/step - loss: 0.7542 - acc: 0.7367 - val_loss: 0.9704 - val_acc: 0.6500\n",
            "Epoch 14/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5819 - acc: 0.7918\n",
            "Epoch 14: val_acc did not improve from 0.69286\n",
            "8/8 [==============================] - 43s 6s/step - loss: 0.5819 - acc: 0.7918 - val_loss: 0.8749 - val_acc: 0.6857\n",
            "Epoch 15/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5574 - acc: 0.8224\n",
            "Epoch 15: val_acc improved from 0.69286 to 0.70000, saving model to percobaan8_noImgPro/model\\vgg_16_8-saved-model-15-acc-0.70.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.5574 - acc: 0.8224 - val_loss: 0.8295 - val_acc: 0.7000\n",
            "Epoch 16/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6014 - acc: 0.7776\n",
            "Epoch 16: val_acc did not improve from 0.70000\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.6014 - acc: 0.7776 - val_loss: 0.8272 - val_acc: 0.6714\n",
            "Epoch 17/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4863 - acc: 0.8327\n",
            "Epoch 17: val_acc did not improve from 0.70000\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.4863 - acc: 0.8327 - val_loss: 0.8541 - val_acc: 0.6571\n",
            "Epoch 18/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4800 - acc: 0.8429\n",
            "Epoch 18: val_acc did not improve from 0.70000\n",
            "8/8 [==============================] - 37s 5s/step - loss: 0.4800 - acc: 0.8429 - val_loss: 0.8496 - val_acc: 0.6857\n",
            "Epoch 19/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4756 - acc: 0.8163\n",
            "Epoch 19: val_acc improved from 0.70000 to 0.70714, saving model to percobaan8_noImgPro/model\\vgg_16_8-saved-model-19-acc-0.71.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.4756 - acc: 0.8163 - val_loss: 0.8228 - val_acc: 0.7071\n",
            "Epoch 20/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4716 - acc: 0.8490\n",
            "Epoch 20: val_acc did not improve from 0.70714\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.4716 - acc: 0.8490 - val_loss: 0.7617 - val_acc: 0.7000\n",
            "Epoch 21/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4834 - acc: 0.8449\n",
            "Epoch 21: val_acc improved from 0.70714 to 0.75714, saving model to percobaan8_noImgPro/model\\vgg_16_8-saved-model-21-acc-0.76.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.4834 - acc: 0.8449 - val_loss: 0.6791 - val_acc: 0.7571\n",
            "Epoch 22/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3836 - acc: 0.8571\n",
            "Epoch 22: val_acc improved from 0.75714 to 0.80000, saving model to percobaan8_noImgPro/model\\vgg_16_8-saved-model-22-acc-0.80.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.3836 - acc: 0.8571 - val_loss: 0.6729 - val_acc: 0.8000\n",
            "Epoch 23/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4475 - acc: 0.8286\n",
            "Epoch 23: val_acc improved from 0.80000 to 0.82143, saving model to percobaan8_noImgPro/model\\vgg_16_8-saved-model-23-acc-0.82.hdf5\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.4475 - acc: 0.8286 - val_loss: 0.6006 - val_acc: 0.8214\n",
            "Epoch 24/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4982 - acc: 0.8082\n",
            "Epoch 24: val_acc did not improve from 0.82143\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.4982 - acc: 0.8082 - val_loss: 0.5875 - val_acc: 0.8214\n",
            "Epoch 25/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3980 - acc: 0.8673\n",
            "Epoch 25: val_acc did not improve from 0.82143\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.3980 - acc: 0.8673 - val_loss: 0.5866 - val_acc: 0.8071\n",
            "Epoch 26/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3823 - acc: 0.8531\n",
            "Epoch 26: val_acc did not improve from 0.82143\n",
            "8/8 [==============================] - 43s 6s/step - loss: 0.3823 - acc: 0.8531 - val_loss: 0.6152 - val_acc: 0.7929\n",
            "Epoch 27/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4081 - acc: 0.8510\n",
            "Epoch 27: val_acc did not improve from 0.82143\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.4081 - acc: 0.8510 - val_loss: 0.6291 - val_acc: 0.7714\n",
            "Epoch 28/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4161 - acc: 0.8571\n",
            "Epoch 28: val_acc did not improve from 0.82143\n",
            "8/8 [==============================] - 37s 5s/step - loss: 0.4161 - acc: 0.8571 - val_loss: 0.6001 - val_acc: 0.8000\n",
            "Epoch 29/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3573 - acc: 0.8694\n",
            "Epoch 29: val_acc improved from 0.82143 to 0.83571, saving model to percobaan8_noImgPro/model\\vgg_16_8-saved-model-29-acc-0.84.hdf5\n",
            "8/8 [==============================] - 45s 5s/step - loss: 0.3573 - acc: 0.8694 - val_loss: 0.5295 - val_acc: 0.8357\n",
            "Epoch 30/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4093 - acc: 0.8551\n",
            "Epoch 30: val_acc did not improve from 0.83571\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.4093 - acc: 0.8551 - val_loss: 0.5174 - val_acc: 0.8214\n",
            "Epoch 31/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4038 - acc: 0.8755\n",
            "Epoch 31: val_acc improved from 0.83571 to 0.84286, saving model to percobaan8_noImgPro/model\\vgg_16_8-saved-model-31-acc-0.84.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.4038 - acc: 0.8755 - val_loss: 0.4990 - val_acc: 0.8429\n",
            "Epoch 32/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3755 - acc: 0.8490\n",
            "Epoch 32: val_acc improved from 0.84286 to 0.85714, saving model to percobaan8_noImgPro/model\\vgg_16_8-saved-model-32-acc-0.86.hdf5\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.3755 - acc: 0.8490 - val_loss: 0.5002 - val_acc: 0.8571\n",
            "Epoch 33/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3649 - acc: 0.8633\n",
            "Epoch 33: val_acc did not improve from 0.85714\n",
            "8/8 [==============================] - 37s 5s/step - loss: 0.3649 - acc: 0.8633 - val_loss: 0.5049 - val_acc: 0.8500\n",
            "Epoch 34/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4140 - acc: 0.8571\n",
            "Epoch 34: val_acc did not improve from 0.85714\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.4140 - acc: 0.8571 - val_loss: 0.5456 - val_acc: 0.8500\n",
            "Epoch 35/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4112 - acc: 0.8592\n",
            "Epoch 35: val_acc did not improve from 0.85714\n",
            "8/8 [==============================] - 44s 5s/step - loss: 0.4112 - acc: 0.8592 - val_loss: 0.6411 - val_acc: 0.8000\n",
            "Epoch 36/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3991 - acc: 0.8816\n",
            "Epoch 36: val_acc did not improve from 0.85714\n",
            "8/8 [==============================] - 37s 5s/step - loss: 0.3991 - acc: 0.8816 - val_loss: 0.6302 - val_acc: 0.8000\n",
            "\n",
            "\n",
            "Model Accuracy 0.7714285714285715\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.80      0.80      0.80        10\n",
            "       10000       1.00      0.90      0.95        10\n",
            "      100000       1.00      0.50      0.67        10\n",
            "        2000       0.75      0.90      0.82        10\n",
            "       20000       1.00      0.50      0.67        10\n",
            "        5000       0.47      0.90      0.62        10\n",
            "       50000       0.90      0.90      0.90        10\n",
            "\n",
            "    accuracy                           0.77        70\n",
            "   macro avg       0.85      0.77      0.77        70\n",
            "weighted avg       0.85      0.77      0.77        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_54864\\940263153.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 700x700 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 700x700 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 700x700 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 700x700 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmoAAAJMCAYAAABKJ4pUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB72ElEQVR4nO3deVwU9f8H8NdyLYewcgi4CoamKOKJheCdCplHfq20KNT0q+aNd+bX1FJIM8XUvPK++3098ihCMzUCL4wUDyxFxQTx4BKRY3d+f/BlbQELlN0Zdl7Px2MetbOfnXm/GRw++57PZ0YhCIIAIiIiIpIcM7EDICIiIqLysaNGREREJFHsqBERERFJFDtqRERERBLFjhoRERGRRLGjRkRERCRR7KgRERERSRQ7akREREQSxY4aERERkUSxo0ZEREQkUeyoEREREVXS8ePH0bt3b6jVaigUCuzdu1fvfUEQMHv2bKjVatjY2KBz5864cOFCpffDjhoRERFRJeXm5qJFixZYtmxZue8vWLAAixYtwrJly3D69Gm4u7uje/fuyMnJqdR+FHwoOxEREdGzUygU2LNnD/r27QuguJqmVqsRFhaGadOmAQDy8/Ph5uaG+fPnY8SIERXetoUhAiYiIiKqCo8fP0ZBQYFR9iUIAhQKhd46pVIJpVJZqe0kJycjLS0NQUFBetvp1KkTYmNj2VEjIiKi6u/x48fwqlcDaekao+yvRo0aePjwod66WbNmYfbs2ZXaTlpaGgDAzc1Nb72bmxtu3LhRqW2xo0ZERESSVFBQgLR0DW7EvwAHe8MOq8/O0aKe33WkpKTAwcFBt76y1bS/Kl2dK69i90/YUSMiIiJJq2GvQA37ynVwKkuL4u07ODjoddSehbu7O4Diylrt2rV169PT08tU2f4JZ30SERERVSEvLy+4u7vj0KFDunUFBQU4duwYAgMDK7UtVtSIiIhI0jSCFhoD36NCI2gr1f7hw4f4448/dK+Tk5ORkJAAJycneHp6IiwsDOHh4WjYsCEaNmyI8PBw2NraIiQkpFL7YUeNiIiIqJLOnDmDLl266F5PnDgRADBo0CBs2LABU6dORV5eHkaNGoWMjAz4+/sjOjoa9vb2ldoP76NGREREkpSdnQ2VSoW0JE+jTCZw976JrKys5x6jVpU4Ro2IiIhIonjpk4iIiCRNCy0qN4Ls2fYhRayoEREREUkUK2pEREQkaRpBgMbAQ+oNvf1nxYoaERERkUSxokZERESSpoUALQxb8TL09p8VK2pEREREEsWKGhEREUmaFgI0rKgRERERkZSwo0ZEREQkUbz0SURERJLGyQREREREJDmsqBEREZGk8Ya3RERERCQ5rKgRERGRpGn/txh6H1LEihoRERGRRLGiRkRERJKmMcINbw29/WfFihoRERGRRLGiRkRERJKmEYoXQ+9DilhRIyIiIpIoVtSIiIhI0jjrk4iIiIgkhxU1IiIikjQtFNBAYfB9SBErakREREQSxYoaERERSZpWKF4MvQ8pYkWNiIiISKLYUSMyAefOncP7778PLy8vWFtbo0aNGmjdujUWLFiABw8eGHTfv/76Kzp16gSVSgWFQoHIyMgq34dCocDs2bOrfLv/ZMOGDVAoFFAoFDh69GiZ9wVBwIsvvgiFQoHOnTs/0z6++uorbNiwoVKfOXr06FNjIjJFmv+NUTP0IkW89ElUza1ZswajRo2Ct7c3pkyZAh8fHxQWFuLMmTNYuXIl4uLisGfPHoPtf8iQIcjNzcWOHTvg6OiIF154ocr3ERcXh7p161b5divK3t4ea9euLdMZO3bsGK5evQp7e/tn3vZXX30FFxcXDB48uMKfad26NeLi4uDj4/PM+yWi6oEdNaJqLC4uDiNHjkT37t2xd+9eKJVK3Xvdu3fHpEmTEBUVZdAYEhMTMWzYMPTo0cNg+2jbtq3Btl0RAwYMwNatW7F8+XI4ODjo1q9duxYBAQHIzs42ShyFhYVQKBRwcHAQ/WdCZEzGqHhJtaLGS59E1Vh4eDgUCgVWr16t10krYWVlhT59+uhea7VaLFiwAI0bN4ZSqYSrqysGDhyIW7du6X2uc+fO8PX1xenTp9GhQwfY2tqifv36+Oyzz6DVFt8WsuSyYFFREVasWKG7RAgAs2fP1v3/X5V85vr167p1R44cQefOneHs7AwbGxt4enrijTfewKNHj3Rtyrv0mZiYiNdffx2Ojo6wtrZGy5YtsXHjRr02JZcIt2/fjhkzZkCtVsPBwQHdunVDUlJSxX7IAN555x0AwPbt23XrsrKysGvXLgwZMqTcz8yZMwf+/v5wcnKCg4MDWrdujbVr10IQnoxYfuGFF3DhwgUcO3ZM9/MrqUiWxL5582ZMmjQJderUgVKpxB9//FHm0ue9e/fg4eGBwMBAFBYW6rZ/8eJF2NnZITQ0tMK5EpG0sKNGVE1pNBocOXIEfn5+8PDwqNBnRo4ciWnTpqF79+7Yt28fPv30U0RFRSEwMBD37t3Ta5uWloZ3330X7733Hvbt24cePXpg+vTp2LJlCwCgZ8+eiIuLAwC8+eabiIuL072uqOvXr6Nnz56wsrLCunXrEBUVhc8++wx2dnYoKCh46ueSkpIQGBiICxcu4Msvv8Tu3bvh4+ODwYMHY8GCBWXaf/TRR7hx4wa+/vprrF69Gr///jt69+4NjUZToTgdHBzw5ptvYt26dbp127dvh5mZGQYMGPDU3EaMGIFvvvkGu3fvRr9+/TB27Fh8+umnujZ79uxB/fr10apVK93Pr/Rl6unTp+PmzZtYuXIl9u/fD1dX1zL7cnFxwY4dO3D69GlMmzYNAPDo0SO89dZb8PT0xMqVKyuUJxFJDy99ElVT9+7dw6NHj+Dl5VWh9pcvX8bq1asxatQoLF26VLe+VatW8Pf3x+LFizFv3jzd+vv37+O7777Dyy+/DADo1q0bjh49im3btmHgwIGoVasWatWqBQBwc3N7pktx8fHxePz4MT7//HO0aNFCtz4kJORvPzd79mwUFBTgp59+0nVSX3vtNWRmZmLOnDkYMWIEVCqVrr2Pj4+ugwkA5ubm6N+/P06fPl3huIcMGYIuXbrgwoULaNq0KdatW4e33nrrqePT1q9fr/t/rVaLzp07QxAELFmyBDNnzoRCoUCrVq1gY2Pzt5cyGzRogP/7v//7x/jatWuHefPmYdq0aejYsSP27t2L5ORknDx5EnZ2dhXKkUiqtIICWsHAN7w18PafFStqRDLx008/AUCZQesvv/wymjRpgh9//FFvvbu7u66TVqJ58+a4ceNGlcXUsmVLWFlZYfjw4di4cSOuXbtWoc8dOXIEXbt2LVNJHDx4MB49elSmsvfXy79AcR4AKpVLp06d0KBBA6xbtw7nz5/H6dOnn3rZsyTGbt26QaVSwdzcHJaWlvj4449x//59pKenV3i/b7zxRoXbTpkyBT179sQ777yDjRs3YunSpWjWrFmFP09E0sOOGlE15eLiAltbWyQnJ1eo/f379wEAtWvXLvOeWq3WvV/C2dm5TDulUom8vLxniLZ8DRo0wOHDh+Hq6orRo0ejQYMGaNCgAZYsWfK3n7t///5T8yh5/69K51Iynq8yuSgUCrz//vvYsmULVq5ciUaNGqFDhw7ltj116hSCgoIAFM/K/eWXX3D69GnMmDGj0vstL8+/i3Hw4MF4/Pgx3N3dOTaNTIacb8/BjhpRNWVubo6uXbsiPj6+zGSA8pR0VlJTU8u8d/v2bbi4uFRZbNbW1gCA/Px8vfWlx8EBQIcOHbB//35kZWXhxIkTCAgIQFhYGHbs2PHU7Ts7Oz81DwBVmstfDR48GPfu3cPKlSvx/vvvP7Xdjh07YGlpiQMHDqB///4IDAxEmzZtnmmf5U3KeJrU1FSMHj0aLVu2xP379zF58uRn2icRSQc7akTV2PTp0yEIAoYNG1bu4PvCwkLs378fAPDKK68AgN5YLQA4ffo0Ll26hK5du1ZZXCUzF8+dO6e3viSW8pibm8Pf3x/Lly8HAJw9e/apbbt27YojR47oOmYlNm3aBFtbW4PduqJOnTqYMmUKevfujUGDBj21nUKhgIWFBczNzXXr8vLysHnz5jJtq6pKqdFo8M4770ChUOD7779HREQEli5dit27dz/3tonEpoGZURYp4mQComosICAAK1aswKhRo+Dn54eRI0eiadOmKCwsxK+//orVq1fD19cXvXv3hre3N4YPH46lS5fCzMwMPXr0wPXr1zFz5kx4eHhgwoQJVRbXa6+9BicnJwwdOhSffPIJLCwssGHDBqSkpOi1W7lyJY4cOYKePXvC09MTjx8/1s2s7Nat21O3P2vWLBw4cABdunTBxx9/DCcnJ2zduhUHDx7EggUL9CYSVLXPPvvsH9v07NkTixYtQkhICIYPH4779+9j4cKF5d5CpVmzZtixYwd27tyJ+vXrw9ra+pnGlc2aNQs///wzoqOj4e7ujkmTJuHYsWMYOnQoWrVqVeFJJ0QkLeyoEVVzw4YNw8svv4zFixdj/vz5SEtLg6WlJRo1aoSQkBCMGTNG13bFihVo0KAB1q5di+XLl0OlUuHVV19FREREuWPSnpWDgwOioqIQFhaG9957DzVr1sS///1v9OjRA//+97917Vq2bIno6GjMmjULaWlpqFGjBnx9fbFv3z7dGK/yeHt7IzY2Fh999BFGjx6NvLw8NGnSBOvXr6/UHf4N5ZVXXsG6deswf/589O7dG3Xq1MGwYcPg6uqKoUOH6rWdM2cOUlNTMWzYMOTk5KBevXp695mriEOHDiEiIgIzZ87Uq4xu2LABrVq1woABAxATEwMrK6uqSI/I6AQjzPoUJDrrUyH89e6LRERERBKRnZ0NlUqFH897ws7esJcmc3O06NrsJrKysvSeQCI2VtSIiIhI0vgIKSIiIiKSHFbUiIiISNI0ghk0gmFrSxqJDgRjRY2IiIhIolhRIyIiIknTQgGtgWtLWkizpMaOmpFptVrcvn0b9vb2lbrjOBERkRQIgoCcnByo1WqYmfHCnKGxo2Zkt2/fLvMgaSIiouomJSUFdevWNcq+5Dzrkx01I7O3twcAtN85FBa28rr5ZNFCV7FDEIXFsQSxQyAiA7Lw8hQ7BKMq0hbg6I1Vur9nZFjsqBlZyeVOC1srWNiVfZyMSbOwFjsCUVgoLMUOgYgMyMJMZufy/zHm8B3jzPqU5hg1XlwmIiIikih21IiIiIgkipc+iYiISNKKb89h2Eutht7+s2JFjYiIiEiiWFEjIiIiSdPCDBqZ3vCWFTUiIiIiiWJFjYiIiCSNt+cgIiIiIslhRY2IiIgkTQsz2T6UnRU1IiIiIoliRY2IiIgkTSMooBEM/FB2A2//WbGiRkRERCRRrKgRERGRpGmMcB81DceoEREREVFlsKJGREREkqYVzKA18H3UtLyPGhERERFVBitqREREJGkco0ZEREREksOKGhEREUmaFoa/z5nWoFt/duyombjNbWfC3capzPp9t2Kw9PddIkRkHCHvtEWH9t7w9HBCfn4RLlz8E6vXHEXKrQdih2YUvUcG4a3Jr8O5dk1cv3ALKyasR2LMZbHDMjjmzbxNPW/fl7zw5rDOeLFpHTi7qfDJBxsQd/iC2GGRAfHSp4kbE78I/X/5WLdMTVgBADh2N0HcwAysRXNP7P32LEaP3Ywp03bC3NwMC+YPgLW1pdihGVyn/oEYufh9bA/fhZGtpyIx5hLCv5uBWh4uYodmUMybecshb2sbK1y7dBtfzdkrdihGVfKsT0MvUiTNqKjKZBXmIqMgR7e0dfbBn4/u4lzmVbFDM6hp07/BD9Hncf3GPVy9lo75nx+Eu5sKjRq6ix2awb0xoRei1h3B92uP4OblP7FiwgbcTbmH3iODxA7NoJg385ZD3meOJ2HT4h8QG50odihkJOyoyYiFwhxd3fzwQ9opsUMxOjs7JQAgOydP5EgMy8LSAo386iM++je99fGHzqFpgLdIURke82begOnnTfLEMWoyEujSDDUsbBCdKr+O2qgPuuLc+RRcv35P7FAMSuViD3MLc2TcydRbn3EnE47uNUWJyRiYd6beeuZNpkYjmEFj4BveGnr7z4odNRnpofbHqQeXcb8gW+xQjGr82O5oUN8VY8O2iB2K0ZS+wbZCoYAg0btuVyXmXYx5E5kOaXYfK+n48ePo3bs31Go1FAoF9u7dq/e+IAiYPXs21Go1bGxs0LlzZ1y4oD9LJj8/H2PHjoWLiwvs7OzQp08f3Lp1S69NRkYGQkNDoVKpoFKpEBoaiszMTANnVzVclY5o5dgI36eeEDsUoxo7pjsCAxpiwuRtuHcvR+xwDC7rXg40RRo4laoq1HRVIfNOljhBGQHzrqm3nnmTqdFCYZRFikyio5abm4sWLVpg2bJl5b6/YMECLFq0CMuWLcPp06fh7u6O7t27IyfnyR/usLAw7NmzBzt27EBMTAwePnyIXr16QaPR6NqEhIQgISEBUVFRiIqKQkJCAkJDQw2eX1UIrv0yMgse4uT9i2KHYjTjxnRHh/aNMHHKdqSlyePkXVRYhCvx19C6e3O99a27NceFuCSRojI85s28AdPPm+TJJC599ujRAz169Cj3PUEQEBkZiRkzZqBfv34AgI0bN8LNzQ3btm3DiBEjkJWVhbVr12Lz5s3o1q0bAGDLli3w8PDA4cOHERwcjEuXLiEqKgonTpyAv78/AGDNmjUICAhAUlISvL3LH8Can5+P/Px83evsbONfdlRAgeDaL+NQ2mloBane0q9qhY0LQtdXfPCfj3fh0aMCODraAQByc/NRUFAkcnSGtWvxAUzbNBZXzlzFpbgreG14N7h6uuDAymixQzMo5s285ZC3ta0V1PWe3ILEzcMJ9ZuokZP5CHdTM8ULzMA4Rs2EJScnIy0tDUFBT6ZsK5VKdOrUCbGxsRgxYgTi4+NRWFio10atVsPX1xexsbEIDg5GXFwcVCqVrpMGAG3btoVKpUJsbOxTO2oRERGYM2eO4RKsgNaOjeBm7YSo1JOixmFMr/dpDQCIXPSu3vrPFhzED9HnxQjJaI59EwsH5xp4b+abcKrtiOuJKZjRMxzpN017IgXzZt5yyLths7pYsHWk7vWIGX0AAId2ncGiaTvFCosMyOQ7amlpaQAANzc3vfVubm64ceOGro2VlRUcHR3LtCn5fFpaGlxdXcts39XVVdemPNOnT8fEiRN1r7Ozs+Hh4fFsyTyj+IwkdP9pglH3KbYu3T4TOwRR7V8Rjf0rTLuyUB7mLS9yzPv8yWvo8eIUscMwOuM8lJ0VNVEpFPqDBAVBKLOutNJtymv/T9tRKpVQKpWVjJaIiIjIRCYT/B139+I70ZeueqWnp+uqbO7u7igoKEBGRsbftrlz506Z7d+9e7dMtY6IiIiqjlZQGGWRIpPvqHl5ecHd3R2HDh3SrSsoKMCxY8cQGBgIAPDz84OlpaVem9TUVCQmJuraBAQEICsrC6dOPblZ7MmTJ5GVlaVrQ0RERFSVTOLS58OHD/HHH3/oXicnJyMhIQFOTk7w9PREWFgYwsPD0bBhQzRs2BDh4eGwtbVFSEgIAEClUmHo0KGYNGkSnJ2d4eTkhMmTJ6NZs2a6WaBNmjTBq6++imHDhmHVqlUAgOHDh6NXr15PnUhAREREz09rhDFqUn0ou0l01M6cOYMuXbroXpcM3h80aBA2bNiAqVOnIi8vD6NGjUJGRgb8/f0RHR0Ne3t73WcWL14MCwsL9O/fH3l5eejatSs2bNgAc3NzXZutW7di3Lhxutmhffr0eeq924iIiIiel0Lg8zaMKjs7GyqVCp33j4SFnbwmGRTNk+dYPosj8WKHQEQGZFH/BbFDMKoibT4OJy9FVlYWHBwcDLqvkr+Z4ae6wLqGYWtLjx8W4aOXfzJKXpUhzTofEREREZnGpU8iIiIyXRoooDHwszgNvf1nxYoaERERkUSxokZERESSphXMoDXwszgNvf1nJc2oiIiIiIgdNSIiIiKp4qVPIiIikjQNDD/YX2PQrT87VtSIiIiIJIoVNSIiIpI0TiYgIiIiIslhRY2IiIgkTSOYQWPgipeht/+spBkVEREREbGiRkRERNImQAGtgWd9CnyEFBEREVH1V1RUhP/85z/w8vKCjY0N6tevj08++QRarbbK98WKGhEREUma1MaozZ8/HytXrsTGjRvRtGlTnDlzBu+//z5UKhXGjx9fpXGxo0ZERET0P9nZ2XqvlUollEql3rq4uDi8/vrr6NmzJwDghRdewPbt23HmzJkqj4eXPomIiEjStILCKAsAeHh4QKVS6ZaIiIgy8bRv3x4//vgjrly5AgD47bffEBMTg9dee63Kc2dFjYiIiOh/UlJS4ODgoHtdupoGANOmTUNWVhYaN24Mc3NzaDQazJs3D++8806Vx8OOGhEREUmaBmbQGPgiYMn2HRwc9Dpq5dm5cye2bNmCbdu2oWnTpkhISEBYWBjUajUGDRpUpXGxo0ZERERUCVOmTMGHH36It99+GwDQrFkz3LhxAxEREeyoERERkbz8dQyZIfdRUY8ePYKZmX6Fz9zcnLfnICIiIhJb7969MW/ePHh6eqJp06b49ddfsWjRIgwZMqTK98WOGhEREUmaFmbQGniMWmW2v3TpUsycOROjRo1Ceno61Go1RowYgY8//rjK42JHTSy9bwMKS7GjMKofbx8QOwRRBKtbih0CERlQ0bXrYodgVEVCodghiM7e3h6RkZGIjIw0+L7YUSMiIiJJ0wgKaAw8Rs3Q239WvOEtERERkUSxo0ZEREQkUbz0SURERJImtdtzGBMrakREREQSxYoaERERSZogmEErGLa2JBh4+89KmlEREREREStqREREJG0aKKCBgW/PYeDtPytW1IiIiIgkihU1IiIikjStYPhZmVrBoJt/ZqyoEREREUkUK2pEREQkaVojzPo09PaflTSjIiIiIiJW1IiIiEjatFBAa+BZmYbe/rNiRY2IiIhIolhRIyIiIknTCApoDDzr09Dbf1asqBERERFJFCtqREREJGmc9UlEREREksOKGhEREUmaFgrDP5mAsz6JiIiIqDLYUZOJ3iODsOnqchx8tBXLT8+Hb/vGYodUpY7H5aHPwNuo2zIZ5rX/wN7vH+q9LwgC5iy8j7otk2HndRWv9LuFC0n5IkVreKZ+vJ+GeTNvOZBr3nLFjpoMdOofiJGL38f28F0Y2XoqEmMuIfy7Gajl4SJ2aFUm95EWLXyU+HJerXLf/3x5JhavysSX82rh5Pd14eZqgeABt5HzUGvkSA1PDse7PMybeTNv0yX874a3hlwEXvoksbwxoRei1h3B92uP4OblP7FiwgbcTbmH3iODxA6tyvToaodPP3RGv541yrwnCAKWrMnER+Od0K9nDfg2VmLDEjc8yhOwbXeOCNEalhyOd3mYN/Nm3mSK2FEzcRaWFmjkVx/x0b/prY8/dA5NA7xFisq4km8WIS1dg+6dbHXrlEoFOgbYIO7MYxEjq3pyPd7Mm3kDzNuUaQWFURYpYkfNxKlc7GFuYY6MO5l66zPuZMLRvaYoMRlbWnoRAMCtlrneejcXc917pkKux5t5Z+qtZ96mSa55yx1vzyETgqD/WqFQQCi90sQpSn1ZEoTin4MpkuvxZt7FmLdpk2PevOGthB0/fhy9e/eGWq2GQqHA3r179d4XBAGzZ8+GWq2GjY0NOnfujAsXLui1yc/Px9ixY+Hi4gI7Ozv06dMHt27d0muTkZGB0NBQqFQqqFQqhIaGIjMzU6/NzZs30bt3b9jZ2cHFxQXjxo1DQUGBIdKuMln3cqAp0sCp1Letmq4qZN7JEicoI3N3Lf4+kpau0Vuffl9TpspW3cn1eDPvmnrrmbdpkmvecif5jlpubi5atGiBZcuWlfv+ggULsGjRIixbtgynT5+Gu7s7unfvjpycJ4PEw8LCsGfPHuzYsQMxMTF4+PAhevXqBY3myR/ukJAQJCQkICoqClFRUUhISEBoaKjufY1Gg549eyI3NxcxMTHYsWMHdu3ahUmTJhku+SpQVFiEK/HX0Lp7c731rbs1x4W4JJGiMi4vTwu4u5rj8PFHunUFBQKOx+UhoI21iJFVPbkeb+bNvAHmbcrkPEZN8pc+e/TogR49epT7niAIiIyMxIwZM9CvXz8AwMaNG+Hm5oZt27ZhxIgRyMrKwtq1a7F582Z069YNALBlyxZ4eHjg8OHDCA4OxqVLlxAVFYUTJ07A398fALBmzRoEBAQgKSkJ3t7eiI6OxsWLF5GSkgK1Wg0A+OKLLzB48GDMmzcPDg4O5caYn5+P/Pwn9+vKzs6usp9NRe1afADTNo3FlTNXcSnuCl4b3g2uni44sDLa6LEYysNcLf5ILtS9vn6zCAmJ+XCqaQbPupYYP6wmIr7MwItelmhY3xIRX2bA1kaBkH72IkZtGHI43uVh3sybeZMpknxH7e8kJycjLS0NQUFPpiUrlUp06tQJsbGxGDFiBOLj41FYWKjXRq1Ww9fXF7GxsQgODkZcXBxUKpWukwYAbdu2hUqlQmxsLLy9vREXFwdfX19dJw0AgoODkZ+fj/j4eHTp0qXcGCMiIjBnzhwDZF9xx76JhYNzDbw380041XbE9cQUzOgZjvSb90SNqyqd+e0xur5xW/d60uzi3Ab2t8f6JW6YMrom8h5rMWb6XWRkaeHfSomoHWrY15B8UbnS5HC8y8O8mTfzNl0l9zoz9D6kqFp31NLS0gAAbm5ueuvd3Nxw48YNXRsrKys4OjqWaVPy+bS0NLi6upbZvqurq16b0vtxdHSElZWVrk15pk+fjokTJ+peZ2dnw8PDo6IpVpn9K6Kxf4XpfuPqHGgLTeqLT31foVBg1mRnzJrsbMSoxGPqx/tpmLe8MG+Sg2rdUStReuaeIAj/OJuvdJvy2j9Lm9KUSiWUSuXfxkJERERPZ4wxZFIdo1atr/u4u7sDQJmKVnp6uq765e7ujoKCAmRkZPxtmzt37pTZ/t27d/XalN5PRkYGCgsLy1TaiIiIiKpCte6oeXl5wd3dHYcOHdKtKygowLFjxxAYGAgA8PPzg6WlpV6b1NRUJCYm6toEBAQgKysLp06d0rU5efIksrKy9NokJiYiNTVV1yY6OhpKpRJ+fn4GzZOIiEjOOOtTwh4+fIg//vhD9zo5ORkJCQlwcnKCp6cnwsLCEB4ejoYNG6Jhw4YIDw+Hra0tQkJCAAAqlQpDhw7FpEmT4OzsDCcnJ0yePBnNmjXTzQJt0qQJXn31VQwbNgyrVq0CAAwfPhy9evWCt3fxYzmCgoLg4+OD0NBQfP7553jw4AEmT56MYcOGPXXGJxEREdHzkHxH7cyZM3ozKksG5g8aNAgbNmzA1KlTkZeXh1GjRiEjIwP+/v6Ijo6Gvf2T2y4sXrwYFhYW6N+/P/Ly8tC1a1ds2LAB5uZPbna6detWjBs3Tjc7tE+fPnr3bjM3N8fBgwcxatQotGvXDjY2NggJCcHChQsN/SMgIiKSNTmPUVMIpv7cCYnJzs6GSqVCZ7wOC4Wl2OEY1Q+3E8QOQRTB6pZih0BEVGWKhEIcxbfIysoy+BWlkr+Zwd8Ph6WdlUH3VZhbgB96rDZKXpUh+YoaERERyZucK2rVejIBERERkSljRY2IiIgkTYDhnxwg1XFgrKgRERERSRQ7akREREQSxUufREREJGmcTEBEREREksOKGhEREUkaK2pEREREJDmsqBEREZGksaJGRERERJLDihoRERFJGitqRERERCQ5rKgRERGRpAmCAoKBK16G3v6zYkWNiIiISKJYUSMiIiJJ00Jh8IeyG3r7z4oVNSIiIiKJYkWNiIiIJI2zPomIiIhIclhRIyIiIknjrE8iIiIikhxW1IiIiEjSOEaNiIiIiCSHFTUymmB1S7FDEMVLCRqxQxDF6ZbmYodAZBRFr/iJHYJRFRU9Bo59K3YYssGOGhEREUkaJxMQERERkeSwokZERESSJhhhMgErakRERERUKayoERERkaQJAATB8PuQIlbUiIiIiCSKFTUiIiKSNC0UUMDAN7w18PafFStqRERERBLFihoRERFJGu+jRkRERESSw4oaERERSZpWUEDBh7ITERERkZSwokZERESSJghGuI+aRG+kxooaERERkUSxokZERESSxlmfRERERCQ5rKgRERGRpLGiRkRERESSw4oaERERSRrvo0ZEREREksOOGhEREZFE8dKnTPQeGYS3Jr8O59o1cf3CLayYsB6JMZfFDsvg5Ja3GczQ1W0AWjh2hL1FTeQUZuBsxk/4Kf2/ECDRuzlWIbkd7xLMWx55h7zTFh3ae8PTwwn5+UW4cPFPrF5zFCm3HogdmsHxhrdk0jr1D8TIxe9je/gujGw9FYkxlxD+3QzU8nAROzSDkmPeHV3/hZedg7H/z6+xOGkcotI2o0Otvghwfk3s0AxOjscbYN5yyrtFc0/s/fYsRo/djCnTdsLc3AwL5g+AtbWl2KGRAbGjJgNvTOiFqHVH8P3aI7h5+U+smLABd1PuoffIILFDMyg55u1p641L2aeQlBOPzMK7SMyKw+8PE1DHtoHYoRmcHI83wLzllPe06d/gh+jzuH7jHq5eS8f8zw/C3U2FRg3dxQ7N4IoragoDL2JnWT521EychaUFGvnVR3z0b3rr4w+dQ9MAb5GiMjy55n099xIa1GgOZ6vaAAB36xfwgm0TJOWcFTkyw5Lr8Wbe8sq7NDs7JQAgOydP5EjIkDhGzcSpXOxhbmGOjDuZeusz7mTC0b2mKDEZg1zzPn53D6zNbTHBeykEaKGAGQ6lbcO5zBixQzMouR5v5p2pt97U8y5t1Addce58Cq5fvyd2KAYn5xvesqMmE6VLugqFAoJU67xVSG55N1e1Q8uanfDNzcW4k5+C2tZe6KUeguyiB/g146jY4Rmc3I53CeZdTC55A8D4sd3RoL4rxoZtETsUMjBRL30eP34cvXv3hlqthkKhwN69e/XeFwQBs2fPhlqtho2NDTp37owLFy7otcnPz8fYsWPh4uICOzs79OnTB7du3dJrk5GRgdDQUKhUKqhUKoSGhiIzM1Ovzc2bN9G7d2/Y2dnBxcUF48aNQ0FBgV6b8+fPo1OnTrCxsUGdOnXwySefSP6kkHUvB5oiDZxKfcus6apC5p0scYIyArnm/WrtQTh+dzfOZf2CO49vIiHzGH65tx+da/UTOzSDkuvxZt419dabet4lxo7pjsCAhpgweRvu3csROxyjEIy0SJGoHbXc3Fy0aNECy5YtK/f9BQsWYNGiRVi2bBlOnz4Nd3d3dO/eHTk5T34xw8LCsGfPHuzYsQMxMTF4+PAhevXqBY1Go2sTEhKChIQEREVFISoqCgkJCQgNDdW9r9Fo0LNnT+Tm5iImJgY7duzArl27MGnSJF2b7OxsdO/eHWq1GqdPn8bSpUuxcOFCLFq0yAA/mapTVFiEK/HX0Lp7c731rbs1x4W4JJGiMjy55m1lpizz5UEraKFQmPZwVLkeb+Ytr7wBYNyY7ujQvhEmTtmOtDTT75SSyJc+e/TogR49epT7niAIiIyMxIwZM9CvX3E1YOPGjXBzc8O2bdswYsQIZGVlYe3atdi8eTO6desGANiyZQs8PDxw+PBhBAcH49KlS4iKisKJEyfg7+8PAFizZg0CAgKQlJQEb29vREdH4+LFi0hJSYFarQYAfPHFFxg8eDDmzZsHBwcHbN26FY8fP8aGDRugVCrh6+uLK1euYNGiRZg4cSIUivKvbefn5yM/P1/3Ojs7u8p+fhW1a/EBTNs0FlfOXMWluCt4bXg3uHq64MDKaKPHYkxyzPtS9ml0dn0TmYX3cOfxTaht6qN9rd448+CI2KEZnByPN8C85ZR32LggdH3FB//5eBcePSqAo6MdACA3Nx8FBUUiR2dYHKMmQcnJyUhLS0NQ0JOp1kqlEp06dUJsbCxGjBiB+Ph4FBYW6rVRq9Xw9fVFbGwsgoODERcXB5VKpeukAUDbtm2hUqkQGxsLb29vxMXFwdfXV9dJA4Dg4GDk5+cjPj4eXbp0QVxcHDp16gSlUqnXZvr06bh+/Tq8vLzKzSMiIgJz5sypyh9NpR37JhYOzjXw3sw34VTbEdcTUzCjZzjSb5r2AFQ55r3/9tfo7haCPnWGo4aFA7ILM3DqfjSOpP+f2KEZnByPN8C85ZT3631aAwAiF72rt/6zBQfxQ/R5MUIiI5BsRy0tLQ0A4Obmprfezc0NN27c0LWxsrKCo6NjmTYln09LS4Orq2uZ7bu6uuq1Kb0fR0dHWFlZ6bV54YUXyuyn5L2nddSmT5+OiRMn6l5nZ2fDw8Pj6YkbyP4V0di/wnS/aT6N3PIu0D7GwdR1OJi6TuxQRCG3412CectDl26fiR2CeIwxiEyig9Qk21ErUfqSoiAIT73M+LQ25bWvijYlY4H+Lh6lUqlXhSMiIiKqKMmOMHZ3L77TcklFq0R6erqukuXu7o6CggJkZGT8bZs7d+6U2f7du3f12pTeT0ZGBgoLC/+2TXp6OoCyVT8iIiKqQgZ/KoECkOgYNcl21Ly8vODu7o5Dhw7p1hUUFODYsWMIDAwEAPj5+cHS0lKvTWpqKhITE3VtAgICkJWVhVOnTunanDx5EllZWXptEhMTkZqaqmsTHR0NpVIJPz8/XZvjx4/r3bIjOjoaarW6zCVRIiIioqogakft4cOHSEhIQEJCAoDiCQQJCQm4efMmFAoFwsLCEB4ejj179iAxMRGDBw+Gra0tQkJCAAAqlQpDhw7FpEmT8OOPP+LXX3/Fe++9h2bNmulmgTZp0gSvvvoqhg0bhhMnTuDEiRMYNmwYevXqBW/v4keNBAUFwcfHB6Ghofj111/x448/YvLkyRg2bBgcHBwAFN/iQ6lUYvDgwUhMTMSePXsQHh7+tzM+iYiI6PkVP+vT8Etl/Pnnn3jvvffg7OwMW1tbtGzZEvHx8VWeu6hj1M6cOYMuXbroXpcMuh80aBA2bNiAqVOnIi8vD6NGjUJGRgb8/f0RHR0Ne3t73WcWL14MCwsL9O/fH3l5eejatSs2bNgAc3NzXZutW7di3Lhxutmhffr00bt3m7m5OQ4ePIhRo0ahXbt2sLGxQUhICBYuXKhro1KpcOjQIYwePRpt2rSBo6MjJk6cqDdRgIiIiExfRkYG2rVrhy5duuD777+Hq6srrl69ipo1a1b5vhSC1G+tb2Kys7OhUqnQGa/DQmEpdjhkBC8laP65kQk63dL8nxsRmYCiV/zEDsGoiooeI+bYHGRlZemuOhlKyd/MF9b9B2a21gbdl/bRY1wfMhcpKSl6eZU3KfDDDz/EL7/8gp9//tmgMQESHqNGREREZGweHh66R06qVCpERESUabNv3z60adMGb731FlxdXdGqVSusWbPGIPFI/vYcRERERMZSXkWttGvXrmHFihWYOHEiPvroI5w6dQrjxo2DUqnEwIEDqzQedtSIiIhI2oxx+4z/bd/BweEfL+lqtVq0adMG4eHhAIBWrVrhwoULWLFiRZV31Hjpk4iIiKgSateuDR8fH711TZo0wc2bN6t8X6yoERERkaQ9y+0znmUfFdWuXTskJSXprbty5Qrq1atXxVGxokZERERUKRMmTMCJEycQHh6OP/74A9u2bcPq1asxevToKt8XO2pEREQkbYKRlgp66aWXsGfPHmzfvh2+vr749NNPERkZiXffffe5Uy2Nlz6JiIiIKqlXr17o1auXwffDjhoRERFJmu7B6QbehxTx0icRERGRRLGiRkRERNIn0wdesqJGREREJFGsqBEREZGkcYwaEREREUkOK2pEREQkbZW8z9kz70OCWFEjIiIikihW1IiIiEjiFP9bDL0P6WFFjYiIiEiiWFEjIiIiaeMYNSIiIiKSGlbUiIiISNpkXFGrUEdt3759Fd5gnz59njkYIiIiInqiQh21vn37VmhjCoUCGo3meeIhIiIiov+pUEdNq9UaOg6SgaJX/MQOQRSnW8aLHYIorm1rKXYIoqkfkiB2CESmRVAUL4behwQ912SCx48fV1UcRERERFRKpTtqGo0Gn376KerUqYMaNWrg2rVrAICZM2di7dq1VR4gERERyZsgGGeRokp31ObNm4cNGzZgwYIFsLKy0q1v1qwZvv766yoNjoiIiEjOKt1R27RpE1avXo13330X5ubmuvXNmzfH5cuXqzQ4IiIiIt3tOQy9SFClO2p//vknXnzxxTLrtVotCgsLqyQoIiIiInqGjlrTpk3x888/l1n/f//3f2jVqlWVBEVERESkUzLr09CLBFX6yQSzZs1CaGgo/vzzT2i1WuzevRtJSUnYtGkTDhw4YIgYiYiIiGSp0hW13r17Y+fOnfjuu++gUCjw8ccf49KlS9i/fz+6d+9uiBiJiIhIxhSCcRYpeqZnfQYHByM4OLiqYyEiIiKiv3jmh7KfOXMGly5dgkKhQJMmTeDnJ8+7zhMREZGB8aHsFXfr1i288847+OWXX1CzZk0AQGZmJgIDA7F9+3Z4eHhUdYxEREREslTpMWpDhgxBYWEhLl26hAcPHuDBgwe4dOkSBEHA0KFDDREjERERyRlnfVbczz//jNjYWHh7e+vWeXt7Y+nSpWjXrl2VBkdEREQkZ5XuqHl6epZ7Y9uioiLUqVOnSoIiIiIi0pHxGLVKX/pcsGABxo4dizNnzkD43xNMz5w5g/Hjx2PhwoVVHiARERGRXFWooubo6AiF4sm129zcXPj7+8PCovjjRUVFsLCwwJAhQ9C3b1+DBEpEREQyJeOKWoU6apGRkQYOg4iIiIhKq1BHbdCgQYaOg4iIiIhKeeYb3gJAXl5emYkFDg4OzxUQERERkR4ZX/qs9GSC3NxcjBkzBq6urqhRowYcHR31FiIiIiKqGpXuqE2dOhVHjhzBV199BaVSia+//hpz5syBWq3Gpk2bDBEjERERyRlveFtx+/fvx6ZNm9C5c2cMGTIEHTp0wIsvvoh69eph69atePfddw0RJz2n3iOD8Nbk1+FcuyauX7iFFRPWIzHmsthhGUzIO23Rob03PD2ckJ9fhAsX/8TqNUeRcuuB2KEZhdyONwC42dhjaosu6FS7AazNLZGc8wDTTx1AYkaa2KEZnByPNyC/vOV+XpOrSlfUHjx4AC8vLwDF49EePCj+BWnfvj2OHz9etdFRlejUPxAjF7+P7eG7MLL1VCTGXEL4dzNQy8NF7NAMpkVzT+z99ixGj92MKdN2wtzcDAvmD4C1taXYoRmcHI+3g6U1vuk2EEVaLYYc24ng71chIuEwsgsfix2awcnxeAPyzFvO5zWFYJxFiirdUatfvz6uX78OAPDx8cE333wDoLjSVvKQdpKWNyb0QtS6I/h+7RHcvPwnVkzYgLsp99B7ZJDYoRnMtOnf4Ifo87h+4x6uXkvH/M8Pwt1NhUYN3cUOzeDkeLxHNAlA6qNsTDt1AOce3MafuVmIvXMdNx9mih2awcnxeAPyzFvO5zU5q3RH7f3338dvv/0GAJg+fbpurNqECRMwZcqUKg+Qno+FpQUa+dVHfPRveuvjD51D0wDvp3zK9NjZKQEA2Tl5IkdiWHI93l3rNMT5B6lYGtgPp/qGYV/wUAyo31LssAxOrsdbrnmXJpfzGoAnsz4NvUhQpceoTZgwQff/Xbp0weXLl3HmzBk0aNAALVq0qNLg6PmpXOxhbmGOjDuZeusz7mTC0b2mKDGJYdQHXXHufAquX78ndigGJdfj7VnDEe++6Ie1SSex4uIvaOGsxsetg1Cg1WDP9fNih2cwcj3ecs27NLmc1+Su0hW10jw9PdGvXz84OTlhyJAhVRETGYBQ6puCQqHQPavV1I0f2x0N6rvi03n7xA7FaOR2vBVQ4EJGGr44dxQXM+9g+9VfsfNaAkJebC12aEYht+NdQq55A/I8r8nVc3fUSjx48AAbN26sqs1VWEREBF566SXY29vD1dUVffv2RVJSkl4bQRAwe/ZsqNVq2NjYoHPnzrhw4YJem/z8fIwdOxYuLi6ws7NDnz59cOvWLb02GRkZCA0NhUqlgkqlQmhoKDIzMw2d4nPJupcDTZEGTqW+ZdZ0VSHzTpY4QRnR2DHdERjQEBMmb8O9ezlih2Nwcj3edx8/xO9Z+lWFP7LvQW2rEiki45Dr8ZZr3iXkdl6TuyrrqInl2LFjGD16NE6cOIFDhw6hqKgIQUFByM3N1bVZsGABFi1ahGXLluH06dNwd3dH9+7dkZPz5Bc8LCwMe/bswY4dOxATE4OHDx+iV69e0Gg0ujYhISFISEhAVFQUoqKikJCQgNDQUKPmW1lFhUW4En8Nrbs311vfultzXIhLesqnTMO4Md3RoX0jTJyyHWlppn/yBuR7vOPvpaC+g5PeOi97J9x+ZNrHXa7HW655A/I8rwGAAkaY9Sl2kk/xXI+QkoKoqCi91+vXr4erqyvi4+PRsWNHCIKAyMhIzJgxA/369QMAbNy4EW5ubti2bRtGjBiBrKwsrF27Fps3b0a3bt0AAFu2bIGHhwcOHz6M4OBgXLp0CVFRUThx4gT8/f0BAGvWrEFAQACSkpLg7V3+ANb8/Hzk5+frXmdnZxvix/C3di0+gGmbxuLKmau4FHcFrw3vBldPFxxYGW30WIwlbFwQur7ig/98vAuPHhXA0dEOAJCbm4+CgiKRozMsOR7vdUmn8H/dBmGkTyC+u3kJzZ3VeLtBK8w4/Z3YoRmcHI83IM+85Xxek7Nq31ErLSur+BuGk1Pxt+vk5GSkpaUhKOjJlG2lUolOnTohNjYWI0aMQHx8PAoLC/XaqNVq+Pr6IjY2FsHBwYiLi4NKpdJ10gCgbdu2UKlUiI2NfWpHLSIiAnPmzDFEqhV27JtYODjXwHsz34RTbUdcT0zBjJ7hSL9pugNQX+9TPDYpcpH+DZg/W3AQP0Sb7uByQJ7H+/yDVIyM+S+mNO+CsU07IOVhJuaePYR9Ny7884erOTkeb0Ceecv5vGaUJwdU9ycTlFSjnkYKY7UEQcDEiRPRvn17+Pr6AgDS0orvSu7m5qbX1s3NDTdu3NC1sbKyKvOsUjc3N93n09LS4OrqWmafrq6uujblmT59OiZOnKh7nZ2dDQ8Pj2fI7vnsXxGN/StM95tmaV26fSZ2CKKS2/EGgJ9u/4Gfbv8hdhiikOPxBuSXt9zPa3JV4Y6aSvX3g3JVKhUGDhz43AE9jzFjxuDcuXOIiYkp855Cod9TFgShzLrSSrcpr/0/bUepVEKpVP5T6ERERPQ0xrjPmUQnDFe4o7Z+/XpDxvHcxo4di3379uH48eOoW7eubr27e/Edm9PS0lC7dm3d+vT0dF2Vzd3dHQUFBcjIyNCrqqWnpyMwMFDX5s6dO2X2e/fu3TLVOiIiIqKqUO1nfQqCgDFjxmD37t04cuSI7jmkJby8vODu7o5Dhw7p1hUUFODYsWO6Tpifnx8sLS312qSmpiIxMVHXJiAgAFlZWTh16pSuzcmTJ5GVlaVrQ0RERAbAJxNUX6NHj8a2bdvw7bffwt7eXjdeTKVSwcbGBgqFAmFhYQgPD0fDhg3RsGFDhIeHw9bWFiEhIbq2Q4cOxaRJk+Ds7AwnJydMnjwZzZo1080CbdKkCV599VUMGzYMq1atAgAMHz4cvXr1eupEAiIiIqLnUe07aitWrAAAdO7cWW/9+vXrMXjwYADA1KlTkZeXh1GjRiEjIwP+/v6Ijo6Gvb29rv3ixYthYWGB/v37Iy8vD127dsWGDRtgbm6ua7N161aMGzdONzu0T58+WLZsmWETJCIikrmSe50Zeh9SVO07ahV5XIhCocDs2bMxe/bsp7axtrbG0qVLsXTp0qe2cXJywpYtW54lTCIiIqJKq/Zj1IiIiIhM1TN11DZv3ox27dpBrVbr7kUWGRmJb7/9tkqDIyIiIpLzZIJKd9RWrFiBiRMn4rXXXkNmZqbuWZg1a9ZEZGRkVcdHREREJFuV7qgtXboUa9aswYwZM/QG2rdp0wbnz5v4IyyIiIjI+FhRq7jk5GS0atWqzHqlUonc3NwqCYqIiIiInqGj5uXlhYSEhDLrv//+e/j4+FRFTEREREQ6JbfnMPQiRZW+PceUKVMwevRoPH78GIIg4NSpU9i+fTsiIiLw9ddfGyJGIiIiIlmqdEft/fffR1FREaZOnYpHjx4hJCQEderUwZIlS/D2228bIkYiIiKSM0FRvBh6HxL0TDe8HTZsGIYNG4Z79+5Bq9XC1dW1quMiIiIikr3nejKBi4tLVcVBREREVD5jzMo0lTFqXl5eUCieXh68du3acwVERERERMUq3VELCwvTe11YWIhff/0VUVFRmDJlSlXFRURERASAD2WvlPHjx5e7fvny5Thz5sxzB0RERERExarsoew9evTArl27qmpzRERERMX4ZILn99///hdOTk5VtTkiIiIi2av0pc9WrVrpTSYQBAFpaWm4e/cuvvrqqyoNjoiIiAjGeHKARCtqle6o9e3bV++1mZkZatWqhc6dO6Nx48ZVFRcRERGR7FWqo1ZUVIQXXngBwcHBcHd3N1RMRERERE/I+D5qlRqjZmFhgZEjRyI/P99Q8RARERHR/1R6MoG/vz9+/fVXQ8RCRERERH9R6TFqo0aNwqRJk3Dr1i34+fnBzs5O7/3mzZtXWXBEREREcr70WeGO2pAhQxAZGYkBAwYAAMaNG6d7T6FQQBAEKBQKaDSaqo+SiIiISIYq3FHbuHEjPvvsMyQnJxsyHiIiIiI9fIRUBQhCcQb16tUzWDByYuHlCQszpdhhGNeReLEjICOqH5IgdgiiKXrFT+wQRGF9/b7YIYji2r/ldSVJ+0gDHBM7Cvmo1GSCv97oloiIiIgMq1KTCRo1avSPnbUHDx48V0BEREREVKxSHbU5c+ZApVIZKhYiIiKisjjrs2LefvttuLq6GioWIiIiIvqLCnfUOD6NiIiIxCDnWZ8VnkxQMuuTiIiIiIyjwhU1rVZryDiIiIiInk6m9aJKP+uTiIiIiIyj0s/6JCIiIjIqGc/6ZEWNiIiISKJYUSMiIiJJ46xPIiIiIpIcVtSIiIhI2jhGjYiIiIikhhU1IiIikjSOUSMiIiIiyWFHjYiIiEiieOmTiIiIpI2TCYiIiIjoWUREREChUCAsLKzKt82KGhEREUmbhCtqp0+fxurVq9G8efOqjed/WFEjIiIiegYPHz7Eu+++izVr1sDR0dEg+2BFTQZ8X/LCm8M648WmdeDspsInH2xA3OELYodlFL1HBuGtya/DuXZNXL9wCysmrEdizGWxwzI45i2PvEPeaYsO7b3h6eGE/PwiXLj4J1avOYqUWw/EDs3g5Hpec7Oxx9QWXdCpdgNYm1siOecBpp86gMSMNLFDMyhj3p4jOztbb71SqYRSqSz3M6NHj0bPnj3RrVs3zJ071yBxsaImA9Y2Vrh26Ta+mrNX7FCMqlP/QIxc/D62h+/CyNZTkRhzCeHfzUAtDxexQzMo5i2fvFs098Teb89i9NjNmDJtJ8zNzbBg/gBYW1uKHZrByfG85mBpjW+6DUSRVoshx3Yi+PtViEg4jOzCx2KHZlI8PDygUql0S0RERLntduzYgbNnzz71/arCipoMnDmehDPHk8QOw+jemNALUeuO4Pu1RwAAKyZsQJugFug9MgjrPtomcnSGw7zlk/e06d/ovZ7/+UHs3TUejRq649z5FJGiMg45ntdGNAlA6qNsTDt1QLfuz9wsESMyIiOOUUtJSYGDg4NudXnVtJSUFIwfPx7R0dGwtrY2aFisqJFJsrC0QCO/+oiP/k1vffyhc2ga4C1SVIbHvOWVd2l2dsV/ULJz8kSOhAyha52GOP8gFUsD++FU3zDsCx6KAfVbih2WyXFwcNBbyuuoxcfHIz09HX5+frCwsICFhQWOHTuGL7/8EhYWFtBoNFUWDytqZJJULvYwtzBHxp1MvfUZdzLh6F5TlJiMgXln6q039bxLG/VBV5w7n4Lr1++JHQoZgGcNR7z7oh/WJp3Eiou/oIWzGh+3DkKBVoM918+LHZ5hSWzWZ9euXXH+vP7P/P3330fjxo0xbdo0mJubV1lY7KiRSRNK/cNTKBQQSq80Qcy7mFzyBoDxY7ujQX1XjA3bInYoZCAKKJCYkYovzh0FAFzMvIOGqloIebG16XfUJMbe3h6+vr566+zs7ODs7Fxm/fOS9KXPiIgIvPTSS7C3t4erqyv69u2LpCT9MQmCIGD27NlQq9WwsbFB586dceGC/syf/Px8jB07Fi4uLrCzs0OfPn1w69YtvTYZGRkIDQ3VDR4MDQ1FZmamXpubN2+id+/esLOzg4uLC8aNG4eCggKD5E7PJ+teDjRFGjiVqqbUdFUh847pjulg3jX11pt63iXGjumOwICGmDB5G+7dyxE7HDKQu48f4vcs/WrpH9n3oLZViRSR8ZTM+jT0IkWS7qgdO3YMo0ePxokTJ3Do0CEUFRUhKCgIubm5ujYLFizAokWLsGzZMpw+fRru7u7o3r07cnKenKzCwsKwZ88e7NixAzExMXj48CF69eqldw05JCQECQkJiIqKQlRUFBISEhAaGqp7X6PRoGfPnsjNzUVMTAx27NiBXbt2YdKkScb5YVClFBUW4Ur8NbTurn8DwtbdmuNCnOkOQGbe8sobAMaN6Y4O7Rth4pTtSEsz/U6pnMXfS0F9Bye9dV72Trj9iMddCo4ePYrIyMgq366kL31GRUXpvV6/fj1cXV0RHx+Pjh07QhAEREZGYsaMGejXrx8AYOPGjXBzc8O2bdswYsQIZGVlYe3atdi8eTO6desGANiyZQs8PDxw+PBhBAcH49KlS4iKisKJEyfg7+8PAFizZg0CAgKQlJQEb29vREdH4+LFi0hJSYFarQYAfPHFFxg8eDDmzZunN0Pkr/Lz85Gfn697Xfr+LMZgbWsFdb0ntyhw83BC/SZq5GQ+wt3UTKPHYyy7Fh/AtE1jceXMVVyKu4LXhneDq6cLDqyMFjs0g2Le8sk7bFwQur7ig/98vAuPHhXA0dEOAJCbm4+CgiKRozMsOZ7X1iWdwv91G4SRPoH47uYlNHdW4+0GrTDj9Hdih2Z4EhujZkyS7qiVlpVV/K3Byan4G0VycjLS0tIQFBSka6NUKtGpUyfExsZixIgRiI+PR2FhoV4btVoNX19fxMbGIjg4GHFxcVCpVLpOGgC0bdsWKpUKsbGx8Pb2RlxcHHx9fXWdNAAIDg5Gfn4+4uPj0aVLl3JjjoiIwJw5c6r051BZDZvVxYKtI3WvR8zoAwA4tOsMFk3bKVZYBnfsm1g4ONfAezPfhFNtR1xPTMGMnuFIv2naA62Zt3zyfr1PawBA5KJ39dZ/tuAgfog27TFLcjyvnX+QipEx/8WU5l0wtmkHpDzMxNyzh7Dvhunf6FfOqk1HTRAETJw4Ee3bt9cN1EtLK74Ts5ubm15bNzc33LhxQ9fGysqqzKMd3NzcdJ9PS0uDq6trmX26urrqtSm9H0dHR1hZWenalGf69OmYOHGi7nV2djY8PDwqlHNVOX/yGnq8OMWo+5SK/SuisX+F6VZUnoZ5y0OXbp+JHYJo5Hpe++n2H/jp9h9ih2F0xnwygdRUm47amDFjcO7cOcTExJR5T6FQ6L0WBKHMutJKtymv/bO0Ke3vHj1BRERE9HckPZmgxNixY7Fv3z789NNPqFu3rm69u7s7AJSpaKWnp+uqX+7u7igoKEBGRsbftrlz506Z/d69e1evTen9ZGRkoLCwsEyljYiIiKqQYKRFgiTdURMEAWPGjMHu3btx5MgReHl56b3v5eUFd3d3HDp0SLeuoKAAx44dQ2BgIADAz88PlpaWem1SU1ORmJioaxMQEICsrCycOnVK1+bkyZPIysrSa5OYmIjU1FRdm+joaCiVSvj5+VV98kRERCR7kr70OXr0aGzbtg3ffvst7O3tdRUtlUoFGxsbKBQKhIWFITw8HA0bNkTDhg0RHh4OW1tbhISE6NoOHToUkyZNgrOzM5ycnDB58mQ0a9ZMNwu0SZMmePXVVzFs2DCsWrUKADB8+HD06tUL3t7Fj58JCgqCj48PQkND8fnnn+PBgweYPHkyhg0b9tQZn0RERETPQ9IdtRUrVgAAOnfurLd+/fr1GDx4MABg6tSpyMvLw6hRo5CRkQF/f39ER0fD3t5e137x4sWwsLBA//79kZeXh65du2LDhg16j3jYunUrxo0bp5sd2qdPHyxbtkz3vrm5OQ4ePIhRo0ahXbt2sLGxQUhICBYuXGig7ImIiAiArG/PoRDk8nwVicjOzoZKpUI3r7GwMJPXJIOia9fFDoHIKIpekedwCOvr98UOQRRX5tYUOwSj0j56jOtD5yIrK8vgV5RK/mY2GRUOc6W1QfelyX+MS199ZJS8KkPSFTUiIiIixf8WQ+9DiiQ9mYCIiIhIzlhRIyIiImmT8Rg1VtSIiIiIJIoVNSIiIpI0OT9CihU1IiIiIoliRY2IiIikjWPUiIiIiEhqWFEjIiIi6ZNoxcvQWFEjIiIikihW1IiIiEjSOOuTiIiIiCSHFTUiIiKSNs76JCIiIiKpYUWNiIiIJI1j1IiIiIhIclhRIyIiImnjGDUiIiIikhp21IiIiIgkipc+iYiISNI4mYCIiIiIJIcVNSIiIpI2TiYgIiIiIqlhRU0kRck3AYWl2GEYlUX9F8QOQRRF166LHQIZmcWReLFDEMWUq+fEDkEUEQ2aix2CURUJhbhu7J2yokZEREREUsOKGhEREUkaZ30SERERkeSwokZERETSxjFqRERERCQ1rKgRERGRpCkEAQrBsCUvQ2//WbGiRkRERCRRrKgRERGRtHGMGhERERFJDStqREREJGm8jxoRERERSQ4rakRERCRtHKNGRERERFLDjhoRERGRRPHSJxEREUkaJxMQERERkeSwokZERETSxskERERERCQ1rKgRERGRpHGMGhERERFJDitqREREJG0co0amrvfIIGy6uhwHH23F8tPz4du+sdghGZzvS16Yvfp9bPnlP/j+j88R0K2p2CEZjRyPN8C85ZT3o4daLP8kHe+0v4YeTX7H2Ddv4vJvj8UOyyjkeLzljB01GejUPxAjF7+P7eG7MLL1VCTGXEL4dzNQy8NF7NAMytrGCtcu3cZXc/aKHYpRyfV4M2955f3F9DTE//II0xe54+vv66FNe1tMDb2Fu2mFYodmUHI93sCTcWqGWqSKHTUZeGNCL0StO4Lv1x7Bzct/YsWEDbibcg+9RwaJHZpBnTmehE2Lf0BsdKLYoRiVXI8385ZP3vmPtTge9RDDp7mg+cu2qPOCFQaFucDdwxL7t2aJHZ5ByfF4yx07aibOwtICjfzqIz76N7318YfOoWmAt0hRkaHI9Xgzb3nlrSkCtBrASqn/J8zKWoHEM3kiRWV4cj3eAABBMM4iQeyomTiViz3MLcyRcSdTb33GnUw4utcUJSYyHLkeb+adqbfe1PO2rWEGn9bW2LLsPu7dKYJGI+DQ3mxcTniM++lFYodnMHI93nLHjppMlP6ioFAoIEj02wM9P7keb+ZdTA55T//CHYIADAi4hlcb/449GzLwSh97mJkrxA7N4OR4vA09Pk3K49SqfUdt9uzZUCgUeou7u7vufUEQMHv2bKjVatjY2KBz5864cOGC3jby8/MxduxYuLi4wM7ODn369MGtW7f02mRkZCA0NBQqlQoqlQqhoaHIzMw0RorPJeteDjRFGjiV+rZV01WFzDumPZZDjuR6vJl3Tb31pp43AKjrWWHxDg8cSHwRO36pj6/21oOmSEDtupZih2Ywcj7eclbtO2oA0LRpU6SmpuqW8+fP695bsGABFi1ahGXLluH06dNwd3dH9+7dkZOTo2sTFhaGPXv2YMeOHYiJicHDhw/Rq1cvaDQaXZuQkBAkJCQgKioKUVFRSEhIQGhoqFHzfBZFhUW4En8Nrbs311vfultzXIhLEikqMhS5Hm/mLa+8/8rG1gzOrhbIydLg9PFHCOxuJ3ZIBiPr4y0YaZEgk7jhrYWFhV4VrYQgCIiMjMSMGTPQr18/AMDGjRvh5uaGbdu2YcSIEcjKysLatWuxefNmdOvWDQCwZcsWeHh44PDhwwgODsalS5cQFRWFEydOwN/fHwCwZs0aBAQEICkpCd7eTx/EmZ+fj/z8fN3r7Ozsqky9QnYtPoBpm8biypmruBR3Ba8N7wZXTxccWBlt9FiMydrWCup6T6asu3k4oX4TNXIyH+FuaqZ4gRmYXI8385ZX3qeP50IQAI/6VvjzegFWf3YPHvWt8OqbKrFDMyi5Hm85M4mO2u+//w61Wg2lUgl/f3+Eh4ejfv36SE5ORlpaGoKCnkxbViqV6NSpE2JjYzFixAjEx8ejsLBQr41arYavry9iY2MRHByMuLg4qFQqXScNANq2bQuVSoXY2Ni/7ahFRERgzpw5hkm8go59EwsH5xp4b+abcKrtiOuJKZjRMxzpN++JGpehNWxWFwu2jtS9HjGjDwDg0K4zWDRtp1hhGZxcjzfzllfeuTlafP35PdxLK4K9ygwdXq2BIZNcYGFp2mPU5Hq8FdrixdD7kKJq31Hz9/fHpk2b0KhRI9y5cwdz585FYGAgLly4gLS0NACAm5ub3mfc3Nxw48YNAEBaWhqsrKzg6OhYpk3J59PS0uDq6lpm366urro2TzN9+nRMnDhR9zo7OxseHh6VT/Q57V8Rjf0r5PWN6/zJa+jx4hSxwxCFHI83wLzlpHNPe3TuaS92GKKQ4/GWs2rfUevRo4fu/5s1a4aAgAA0aNAAGzduRNu2bQEUz4j5K0EQyqwrrXSb8tpXZDtKpRJKpfIf8yAiIqKn4LM+TYednR2aNWuG33//XTdurXTVKz09XVdlc3d3R0FBATIyMv62zZ07d8rs6+7du2WqdURERERVxeQ6avn5+bh06RJq164NLy8vuLu749ChQ7r3CwoKcOzYMQQGBgIA/Pz8YGlpqdcmNTUViYmJujYBAQHIysrCqVOndG1OnjyJrKwsXRsiIiKiqlbtL31OnjwZvXv3hqenJ9LT0zF37lxkZ2dj0KBBUCgUCAsLQ3h4OBo2bIiGDRsiPDwctra2CAkJAQCoVCoMHToUkyZNgrOzM5ycnDB58mQ0a9ZMNwu0SZMmePXVVzFs2DCsWrUKADB8+HD06tXrbycSEBER0fMzxg1ppXrD22rfUbt16xbeeecd3Lt3D7Vq1ULbtm1x4sQJ1KtXDwAwdepU5OXlYdSoUcjIyIC/vz+io6Nhb/9kEOrixYthYWGB/v37Iy8vD127dsWGDRtgbm6ua7N161aMGzdONzu0T58+WLZsmXGTJSIiIllRCKb+3AmJyc7OhkqlQme8DguF6d5BuzwW9V8QOwRRFF27LnYIREYx/eo5sUMQRUSD5v/cyIQUCYU4im+RlZUFBwcHg+6r5G/my30+hYWltUH3VVT4GKf2zTRKXpVhcmPUiIiIiExFtb/0SURERKZNzmPUWFEjIiIikihW1IiIiEjaeMNbIiIiIpIaVtSIiIhI0jhGjYiIiIgkhxU1IiIikjZBKF4MvQ8JYkWNiIiISKJYUSMiIiJJ4xg1IiIiIpIcVtSIiIhI2ngfNSIiIiKSGlbUiIiISNI4Ro2IiIiIJIcdNSIiIiKJ4qVPIiIikjatULwYeh8SxIoaERERkUSxokZERETSxttzEBEREZHUsKJGREREkqaAEW7PYdjNPzNW1IiIiIgkihU1IiIikjZBKF4MvQ8JYkeNjKbo2nWxQyAiA4po0FzsEETxw+0EsUMwquwcLRwbiR2FfLCjRkRERJLGR0gRERERkeSwo0ZERETSJhhpqaCIiAi89NJLsLe3h6urK/r27YukpKTnTrM87KgRERERVcKxY8cwevRonDhxAocOHUJRURGCgoKQm5tb5fviGDUiIiKSNIUgQGHgWZmV2X5UVJTe6/Xr18PV1RXx8fHo2LFjlcbFjhoRERHR/2RnZ+u9ViqVUCqVf/uZrKwsAICTk1OVx8NLn0RERCRtWiMtADw8PKBSqXRLRETE34YmCAImTpyI9u3bw9fXt+py/h9W1IiIiIj+JyUlBQ4ODrrX/1RNGzNmDM6dO4eYmBiDxMOOGhEREUmaMceoOTg46HXU/s7YsWOxb98+HD9+HHXr1jVIXOyoEREREVWCIAgYO3Ys9uzZg6NHj8LLy8tg+2JHjYiIiKgSRo8ejW3btuHbb7+Fvb090tLSAAAqlQo2NjZVui9OJiAiIiJpk9gNb1esWIGsrCx07twZtWvX1i07d+587lRLY0WNiIiIqBIEA4+X+yt21IiIiEjaBKF4MfQ+JIiXPomIiIgkihU1IiIikjSFULwYeh9SxIoaERERkUSxokZERETSxjFqRERERCQ1rKgRERGRpCm0xYuh9yFFrKgRERERSRQ7ajLRe2QQNl1djoOPtmL56fnwbd9Y7JCMgnkzbzlg3qaZ9/G4PPQZeBt1WybDvPYf2Pv9Q733BUHAnIX3UbdlMuy8ruKVfrdwISlfpGgNrGSMmqEXCWJHTQY69Q/EyMXvY3v4LoxsPRWJMZcQ/t0M1PJwETs0g2LezJt5my455J37SIsWPkp8Oa9Wue9/vjwTi1dl4st5tXDy+7pwc7VA8IDbyHko0Wt49EzYUZOBNyb0QtS6I/h+7RHcvPwnVkzYgLsp99B7ZJDYoRkU82bezNt0ySHvHl3t8OmHzujXs0aZ9wRBwJI1mfhovBP69awB38ZKbFjihkd5ArbtzhEhWgOT2LM+jYkdNRNnYWmBRn71ER/9m976+EPn0DTAW6SoDI95M2+AeZsqueb9V8k3i5CWrkH3Tra6dUqlAh0DbBB35rGIkVFV46xPE6dysYe5hTky7mTqrc+4kwlH95qixGQMzDtTbz3zNk3MO1Nvvann/Vdp6UUAALda5nrr3VzMceNWoRghGZRCEKAw8BgyQ2//WbGiJhOlf/8UCgUEif5SViXmXYx5mzbmXUwuef+VQqH/WhCKfw5kOiTdUZs9ezYUCoXe4u7urntfEATMnj0barUaNjY26Ny5My5cuKC3jfz8fIwdOxYuLi6ws7NDnz59cOvWLb02GRkZCA0NhUqlgkqlQmhoKDIzM/Xa3Lx5E71794adnR1cXFwwbtw4FBQUGCz3qpJ1LweaIg2cSn3LrOmqQuadLHGCMgLmXVNvPfM2Tcy7pt56U8/7r9xdiy+IpaVr9Nan39eUqbKZBM76lK6mTZsiNTVVt5w/f1733oIFC7Bo0SIsW7YMp0+fhru7O7p3746cnCcDKcPCwrBnzx7s2LEDMTExePjwIXr16gWN5skvd0hICBISEhAVFYWoqCgkJCQgNDRU975Go0HPnj2Rm5uLmJgY7NixA7t27cKkSZOM80N4DkWFRbgSfw2tuzfXW9+6W3NciEsSKSrDY97MG2Depkquef+Vl6cF3F3Ncfj4I926ggIBx+PyENDGWsTIqKpJfoyahYWFXhWthCAIiIyMxIwZM9CvXz8AwMaNG+Hm5oZt27ZhxIgRyMrKwtq1a7F582Z069YNALBlyxZ4eHjg8OHDCA4OxqVLlxAVFYUTJ07A398fALBmzRoEBAQgKSkJ3t7eiI6OxsWLF5GSkgK1Wg0A+OKLLzB48GDMmzcPDg4OT40/Pz8f+flP7muTnZ1dZT+bitq1+ACmbRqLK2eu4lLcFbw2vBtcPV1wYGW00WMxJubNvJm36ZJD3g9ztfgj+cl4s+s3i5CQmA+nmmbwrGuJ8cNqIuLLDLzoZYmG9S0R8WUGbG0UCOlnL2LUBiIAMPRdR6RZUJN+R+3333+HWq2GUqmEv78/wsPDUb9+fSQnJyMtLQ1BQU+mYiuVSnTq1AmxsbEYMWIE4uPjUVhYqNdGrVbD19cXsbGxCA4ORlxcHFQqla6TBgBt27aFSqVCbGwsvL29ERcXB19fX10nDQCCg4ORn5+P+Ph4dOnS5anxR0REYM6cOVX8U6mcY9/EwsG5Bt6b+SacajviemIKZvQMR/rNe6LGZWjMm3kzb9Mlh7zP/PYYXd+4rXs9aXZxbgP722P9EjdMGV0TeY+1GDP9LjKytPBvpUTUDjXsa0j+YhlVgqQ7av7+/ti0aRMaNWqEO3fuYO7cuQgMDMSFCxeQlpYGAHBzc9P7jJubG27cuAEASEtLg5WVFRwdHcu0Kfl8WloaXF1dy+zb1dVVr03p/Tg6OsLKykrX5mmmT5+OiRMn6l5nZ2fDw8OjIulXqf0rorF/hel806wo5i0vzFteTD3vzoG20KS++NT3FQoFZk12xqzJzkaMioxN0h21Hj166P6/WbNmCAgIQIMGDbBx40a0bdsWQNnZLYIg/OOMl9Jtymv/LG3Ko1QqoVQq/7YNERERPR1vz1FN2NnZoVmzZvj9999149ZKV7TS09N11S93d3cUFBQgIyPjb9vcuXOnzL7u3r2r16b0fjIyMlBYWFim0kZERERUVapVRy0/Px+XLl1C7dq14eXlBXd3dxw6dEj3fkFBAY4dO4bAwEAAgJ+fHywtLfXapKamIjExUdcmICAAWVlZOHXqlK7NyZMnkZWVpdcmMTERqampujbR0dFQKpXw8/MzaM5ERESyJ8AIt+cQO8nySfrS5+TJk9G7d294enoiPT0dc+fORXZ2NgYNGgSFQoGwsDCEh4ejYcOGaNiwIcLDw2Fra4uQkBAAgEqlwtChQzFp0iQ4OzvDyckJkydPRrNmzXSzQJs0aYJXX30Vw4YNw6pVqwAAw4cPR69eveDtXfwokqCgIPj4+CA0NBSff/45Hjx4gMmTJ2PYsGF/O+OTiIiI6HlIuqN269YtvPPOO7h37x5q1aqFtm3b4sSJE6hXrx4AYOrUqcjLy8OoUaOQkZEBf39/REdHw97+ydTkxYsXw8LCAv3790deXh66du2KDRs2wNz8yQ0Bt27dinHjxulmh/bp0wfLli3TvW9ubo6DBw9i1KhRaNeuHWxsbBASEoKFCxca6SdBREQkY8a4Ia1Ex6gpBLk9b0Nk2dnZUKlU6IzXYaGwFDscIiJ6Tj/cThA7BKPKztHCsdE1ZGVlGfyqUsnfzFdaTIOFuWEn5hVp8nHkt/lGyasyJF1RIyIiIoIWgKEfYWroG+o+o2o1mYCIiIhITlhRIyIiIknjfdSIiIiISHJYUSMiIiJpk/GsT1bUiIiIiCSKFTUiIiKSNlbUiIiIiEhqWFEjIiIiaWNFjYiIiIikhhU1IiIikjY+mYCIiIiIpIYdNSIiIiKJ4qVPIiIikjQ+QoqIiIiIJIcVNSIiIpI23p6DiIiIiKSGFTUiIiKSNq0AKAxc8dKyokZERERElcCKGhEREUkbx6gRERERkdSwokZEREQSZ4SKGqRZUWNHzciE//2iFaFQqr8TRERUCdk5En1IpIFkPyzOV5DopUJTw46akeXk5AAAYvCdyJEQEVFVcGwkdgTiyMnJgUqlMs7OZDxGjR01I1Or1UhJSYG9vT0UCoVR952dnQ0PDw+kpKTAwcHBqPsWE/Nm3nLAvJm3sQiCgJycHKjVaqPuV67YUTMyMzMz1K1bV9QYHBwcZHVCK8G85YV5ywvzNi6jVdJKaAUYfLwQ76NGRERERJXBihoRERFJm6AtXgy9DwliRU1GlEolZs2aBaVSKXYoRsW8mbccMG/mTaZJIXB+LREREUlQdnY2VCoVunmMhIWZYTulRdp8HE5ZgaysLEmNd2RFjYiIiEiiOEaNiIiIpI2zPomIiIhIathRIyIiIpIoXvokIiIiaZPxI6RYUSMiIiKSKFbUiEiPIAhGfw6tMZl6fpXBnwVVGwKMUFEz7OafFStqpIe31ZOvwsJCAIBGowFger8Lubm50Gg0yMnJETsU0aSnpyM+Ph6nT5/G48ePZdNJ02qlecd5YzO1f9NywYqazKWlpeH27dt4+PAh2rdvDzMz+fXdr127hm+//RaCIKBu3bro37+/2CEZ3cWLFzF//nykpqbC09MT7777Lrp06SJ2WFUmMTER48ePR05ODh49eoRx48bh9ddfh5ubm9ihGc25c+fwxhtvoKioCIWFhbCzs8PKlSvRtm1b2NjYiB1eleJ5rfzzWrXumHOMGsnRuXPn0L59e/Tv3x9vvvkmmjVrhgMHDiArK0vs0IwmMTERbdq0wZ49e7Bx40YMGTIEffv2xYULF8QOzWiSkpIQGBgIKysr1KtXD5mZmejevTs+//xzPH78WOzwntu1a9fQsWNH+Pr6YuDAgejbty/GjRuHqVOn4vTp02KHZxRpaWl4/fXX8dZbb+H777/Hnj170KpVK/Tp0webNm0yqSojz2s8r5kadtRk6s6dO+jXrx8GDBiA/fv345dffoG3tzfGjBmDr7/+Gg8ePBA7RIPLzc3F6NGjERISguPHjyMmJgYxMTFISEjAsGHDcObMGbFDNIpVq1ahQ4cOWLNmDdasWYMtW7ZgyZIl+PDDD/HZZ5+JHd5z27t3L3x8fLBkyRKMGTMGc+fOxb59+3DixAlERkbi/PnzYodocKmpqVAqlRg8eDAaN26Ml156CTt27MDw4cMxadIk7N27F0D1vzTG85oJn9e0WuMsEsSOmkzdvn0bAPDee++hSZMmaNiwIXbv3o2+ffti1apV2LlzJwoKCkSO0rAsLS2Rm5uLNm3aAADs7OzQsmVLnDlzBunp6Zg0aZIsTux//vmn7rl2giDAysoKo0ePxpo1a/DJJ59gw4YNuveqo9zcXBQUFECr1UKj0UCj0SAoKAjLli3D0aNHq31+FXH//n3cuHEDNWrUAABdpfSLL77A4MGDMWbMGNy6dat6XxoDz2tA5c5rpvw7b0rYUZOprKwsZGRkwMKieJjio0ePAACRkZHo0qUL5s6di1u3bgEw3X/MWq0W9+/fx+XLlwEAZmZmKCgogIuLC44fP47ExER8+umnIkdpeK1bt8aPP/6I5ORkvT/UQ4YMwcyZM/HRRx+Vea86ady4Mc6ePYuzZ8/C3NwcgiBAEAR0794dkZGRiIyMxIkTJ6ptfn+n5N9u165d0bhxY4wZMwZarRbW1ta6DsuyZcvg4+OD8PBwvc9URzyvVe68Vq1+50vGqBl6kSB21GSqY8eOcHd3x5QpUwAAtra2yM/PB1B8KczNzQ3z5s0DUM3+MVeCtbU1Jk+ejC1btmDXrl0AACsrK+Tn50OtViM8PByHDh1CamqqyZ7UgeI/4o0aNcJnn32GP//8E2ZmZrpZcq+//joUCoXuj1t19NZbb+Ff//oX3n33XVy+fBkWFha6Ga59+/ZF48aNER8fL3KUVau8Ga6TJk1CcnIypk2bpqucFhUVAQC8vLyQmZkJoHr/e+d5jec1U8SOmkzk5uaisLAQeXl5AIq/ZS1YsABnz57FuHHjAABKpVL3LbtNmzZ4+PChaPEaQlpaGs6ePYvjx4/rOiK9evVChw4dsGjRIhw4cABA8c8BABwcHFBYWAgbGxuTOalfu3YNixcvxqJFi7Bz504Axcf6rbfewqlTp7Bw4UJcv35dN0uuXr16cHBwqDaTCq5cuYJJkyZhyJAh+PTTT5GcnAwA+PDDD+Hh4YH33nsPly9fhpWVFYDiP9Y2NjYmNesxMTERffr0QUBAAAIDA7Fy5Urk5OTgrbfeQp8+fXDkyBGMHTsWAHSVJwsLC9ja2kKj0VSrP948r8novMaKGpmyxMREvPbaa2jXrh2aNm2K5cuX48aNG+jRowfCwsLw/fffY/jw4QCg+wP26NEj2NjYVLsT99OUngnm6+uLgwcPwsPDA1OnTkWtWrUwe/ZsrF+/HgCQl5eHc+fOwcnJqXqdzP5G6ZlgQ4cORe/evXH16lWMHTsW77zzDmJjY/HBBx/gxIkTuHjxIhYuXIicnBz4+PiIHf4/unjxIl566SUkJSXh8ePH+PLLL/Hee+9h/fr18PPzw+zZs+Hs7IzAwECsW7cO//3vfzFz5kwkJyejc+fOYodfJcqb4RoWFobRo0cjOTkZ06dPR//+/XH06FE0bdoUkyZNwjvvvIPdu3djwoQJMDc3rza/7zyv8bwmFwrBFH5b6amSk5Ph5+eHd999F23atEFSUhI2bdqEDh06YMqUKWjevDm+/vprfPLJJ3Bzc8NLL72E3NxcfPvttzh58iSaNm0qdgrP7c6dO2jXrh0GDBiA9957DxYWFpg2bRrOnDmD8ePHY/z48bh8+TJWr16NVatWoX79+rC3t8fVq1dx+PBhtGrVSuwUnltubi5ee+01NGvWDMuWLUNOTg6uXr2Kvn37wtXVFevXr0fTpk2xfft27Ny5E/v27UOTJk3w+PFj/Pe//5X8z6CgoACDBg2CnZ0dvv76awDAvXv3MGrUKFy/fh2DBw/GqFGjkJKSgqVLl2Lr1q2oWbMm7OzssGrVKsnnV1GLFi3C7t27ERMTo1sXHR2NMWPGoHXr1vjss89Qp04dnDt3DsuWLcP9+/dRs2ZNTJ06Fb6+viJGXjk8r8nnvJadnQ2VSoVuTu/DwszKoPsq0hbg8IP1yMrK0k2wkgJ21Ezc4sWLsWfPHhw/fly3bs+ePVi4cCFcXV3x6aefwtfXF9euXcOnn36Khw8fokaNGpg8ebJJnMwA4Ndff8Vbb72F/fv3o0mTJrr1YWFhOHDgACZPnowPPvgAubm5SEpKwqFDh+Dq6oqOHTuiQYMGIkZedQoKChAYGIgxY8Zg8ODB0Gq1MDMzw71799C2bVu4u7vjhx9+gJ2dHQRBwG+//QY7OzuoVCq4urqKHX6F9OjRA/Xr18fy5cuh0Whgbm6OBw8eYMKECbhy5Qo+/vhj9OjRAwBw69Yt3QzImjVrihh11fr000+xf/9+nDhxQlcxMjc3x6FDhzB48GC89dZbiIyM1PtMye9CdcLzmnzOa+yo8ckEJk+r1SIzMxM5OTmws7ODmZkZ/vWvf8HKygqzZs3CqlWrMH/+fNSvX19XHi/5I2cqypsJZmtri8jISOTl5eGTTz5BUFAQ6tevj9atW6N169YiR1z1/mkmWLNmzfDRRx9hyZIlUCgUaNmypbgBV0LJbTdsbW3x559/AijunBQWFsLJyQmLFi1Cnz59sHTpUl1HrU6dOiZ56adx48aYM2cOzp49izZt2qCoqEhvhuvbb7+NAQMGICAgQPeZ6vhz4HlNfuc1QdBCEAx7nzNDb/9ZVa+vUVRpdevWxe+//44rV67o/jgDQM+ePTFu3DisWrUKly5d0vtMdft2/U/+aSaYu7s75s6dK2aIBleRmWA//vhjtZwJZmZmBktLS0yePBn79u3D4sWLARTfT6qgoADOzs5Yvnw5jhw5grNnzwKonp2TiqjIDNeSn0GJ6viz4HmN5zU5Ma3fXCpjwIABCAoKwr/+9S+kp6fr/jgDwMCBA9GwYUP8+OOPep+pjifuv3qWmWC5ubmixWsIpj4T7ObNmzh48CC+/vpr3L59Gzk5OQgICMDcuXMxdepULF++HMCTQeRarRYvvPACVCqVmGFXKTnPcOV5TYbnNUEAtAZeJPollR01E5KUlISJEyfi7bffxmeffaZ7VMjixYuhVqvRtm1bpKSk6P44P378GHZ2dnBxcREz7CrFmWCmPxPs3LlzePnllzFz5kxMmTIFbdu2xSeffIJbt27hww8/xLRp0zB+/Hh89NFH+OOPP5Ceno7du3dDo9HA3t5e7PCrhJxmuPK8xvOa3HEygYm4ePEiAgMD0aFDB9SsWROHDx/Giy++iDfffBPjx4/HhQsXMHLkSJw7dw4RERFwcHDA+fPnsWbNGpw6dapaDS59Gs4EM/2ZYJmZmejWrRteeeUVTJ8+HY6Ojvjkk09w6NAhODs748svv4Snpyc2bNiAsLAw2Nvbw9bWFrm5udi3b1+1H6cDyGuGK89rPK+VTCboWnMgLBQGnkwgFODHzE2Sm0zAjpoJKCwsxL///W9YWlrqTtw3b95EREQETpw4gbfffhvTpk3Do0ePMGPGDERFRUEQBDg5OWH58uXV6sT9dzgTzPRngt28eRMdO3bE6tWrERQUpFu/adMmfP311/Dw8MCiRYvg5uaGP//8E+fPn4eZmRl8fHxQt25dESOvWnKY4crzWjG5n9d0HTVVqHE6almbJddR46xPE2BpaYnU1FR4eHgAKH6GnaenJz7++GMsWLAAu3fvhoeHB0JCQrB48WJMmTIFtra2UCgUJjVmhzPBTH8mmLm5OWxsbHQP3y4qKoKFhQUGDhyIx48fY9myZfjhhx8wcOBA1KlTB3Xq1BE54qolpxmuPK8V43mNOEatmtNoNCgsLETdunWRkZGhe9SPVqtF7dq1MWHCBDg7O+seFwQAtWvXRs2aNU3qZAZwJhhg+jPB6tSpg4YNG2LJkiXIzMyEhYWF7nmVw4cPh7e3N1auXClylIYjhxmuGo0GAJCfn8/zGnhe09FqjbNIkAkeTXkoOZmZm5vD0tISgwYNwr59+7B69WooFArdg7U9PT0xZ84c7N+/HwkJCQCq34m7ojgTzPRmguXm5iInJwfZ2dm6devWrUNWVhb69++PgoICXfUQAIKDgyEIgi5fUyCnGa5nz55Fly5dkJubC6VSyfMa5HleI33sqFVDV65cQWRkJFJTU3XrOnXqhPnz52PChAm68Rwl36pq1KgBHx8f2NraihKvIXAmmOnPBLt48SL69euHTp06oUmTJti6dSu0Wi1cXFywbds2XL58GUFBQbqZjwBw6tQp2NvbSz63ipLTDNfffvsNHTt2xEsvvaR7QkanTp0QERGBCRMmYPXq1QB4XjP189pTyfih7ByjVs388ccfCAgIQEZGBu7fv4+JEyfq/pGOHDkSubm5GD58OK5fv45//etfqFevHjZt2oS8vLxq+Q27PKVngi1ZsgQHDx7UzQRbu3YtRo4ciWbNmunNBLt69So6deokdvhVIjk5GR07dtSbCRYREYGYmBhMmTIF48aNg62tLT755BO0atWqzEwwqY9fuXjxIjp27IiBAwfipZdewpkzZ/D+++/Dx8cHrVq1Qtu2bfHdd98hJCQEPXv2hKOjI2rXro2jR4/i559/1v0hq84yMzMxZMgQDBw4sMwM199//x1ffvkl5s6dixdffBFhYWHYvHmz3gzX6vLoL6C4Q9quXTuMGjUKCxYsAFBcFXr8+DGmTJkCrVaLkSNH4vr163jjjTd4XjPR8xqVj7M+q5Hc3FyMGzcOWq0Wbdq0wdixYzF58mRMmTIFtWrVAlB82WPr1q2YOnUqzMzM4ODggJycHOzfv98kZkFxJlgxU54J9uDBA7zzzjto3LgxlixZolv/yiuvoFmzZliyZAkEQdBd3lm+fDlu3boFGxsbDBgwAN7e3mKFXqXkMsM1LS0NrVq1QosWLRAVFQWNRqObvfr777/j/fffR48ePXDr1i2MHDkSAKBSqXheM8HzWnlKZn2+Yvu2UWZ9Hnm0g7M+6dmZmZnBz88Pzs7OGDBgAGrVqoW3334bAHSdNTMzM4SGhqJDhw64efMm8vLy4OvrazKz3zgTrJgpzwQrLCxEZmYm3nzzTQBPHhpev3593L9/H0BxtaUkn9GjR4sZrsHIaYZrQEAAUlJS8O2332LlypUoKirCyy+/DF9fX3zzzTf47bffsG7dOpw4cQLXr19Hfn4+fHx8qnXOf8XzGv0djlGrRmxsbDBo0CAMGDAAANC/f39s374dCxcuxIIFC3Dv3j0AxSd0MzMzdOzYEcHBwSZzMuMM1ydMeSaYm5sbtmzZgg4dOgB4MnGmTp06ejmYm5sjJydH99rULg7IZYaru7s7li9fDh8fH7z99tvQaDTYuXMn5s2bh4ULF+KTTz7BsWPHcPDgQXh6eqJjx47o3r27SZzXOMO1EmQ8Rq16nLlJx87ODgB0g8EHDBiAbdu24YsvvsCCBQtw+/ZtTJ06FRMmTEBubq5J/PHiDNeyTH0mWMOGDQEU/7GytLQEUPx7cOfOHV2biIgIrFmzRtd5qU75lUfOM1xr166NiIgITJw4ER999BGcnJx0z6jt27cvatWqhZiYGJGjrFqc4UoVxY5aNVVyCUur1eLtt9/G9u3bERkZiVdeeQVLly7FzJkzYWdnV+3/QXOGq7xngpmZmem+bCgUCt3v/ccff4wZM2aga9euep2X6oozXAG1Wo2pU6ciMDAQwJNjn5GRAWdnZ/j5+YkcYdXhDNdnYOgHspcsElT9z3AyVtIJK6msrV69GgkJCTh79iyaNWsmcnTPjzNcORMMgG7igLm5OTw8PHSX+s+cOYMWLVqIHd5z4wzXJ0r/u1UoFFi8eDFSU1PRpUsXkaKqWpzhSpXFWZ8mQKPRYMqUKYiMjERCQgKaN28udkjPjTNcOROstHnz5mHmzJlwcHDA4cOH0aZNG7FDem6c4fp0O3bswNGjR/HNN9/gxx9/NInfZ85wrTzdrE+rt2ChsDTovoqEQhwp+D/O+iTDaNq0Kc6ePWsSnTSAM1wBzgQrLTg4GDNnzkRsbCx8fHzEDqdKcIbr0/n4+GDLli34+eefJX9LmcqQ+wxXqjxW1EzEX791m4rc3Fzd5AkA2LlzJ9555x1MmjQJ06ZNg4uLC4qKinD79m14enqKGGnV02g00Gq1GDFiBDIzM7Ft2zYolUoIggAzMzPcvHkTH3zwASwtLfHtt98CMM3fgdJK/06Ygt9//103eaKwsBCWlpaYNWsWkpOTsWnTJl27nJwc3dMG5HCsAaCgoED3VA1TkZqaig8//BDffPMNOnTogB07dsDJyQkAsHfvXgwfPhxffvml7oup3JVU1LpYvGmUitpPRf+VXEWNkwlMhCmetDnDlTNcSzO1ThogzxmuFWVqnTRAnjNc6fnw0idJnrm5OQRB0M1wVSgUCA0Nxb59+3D16lWcPn3aJP6AX7lyBfv370dISAhq164NQH+Gq62tLf79739zJpiJKpnlqFAoysxwnTt3Ln799VeTmOFKT2a42tjYAHhy7DMzM01uhmuVEbQAtEbYh/TwXz1VC5zhavozXMn0Z7jSE3KY4UpVgx01qjZKBlVPmTIFP/30ExISEkyik5abm4uIiAj06dNHN8O1qKhIN2nC1tYW//nPf+Dl5YWpU6di/fr1ejNc3dzcxE6BqkhJtdTS0hJr1qyBg4MDYmJi0Lp1a5EjI0MqPcP1hRdeEDskyRG0AgSFYYe3SHX4DMeoUbVjqjNcX331VYwePRo7duzAwoUL8fnnn+Pu3bu6NqGhoYiLi9Pd3PjkyZOynK4vB8HBwQCA2NhYk7gNCf09Hx8f3Lp1Cz///DP/TVczX331Fby8vGBtbQ0/Pz/8/PPPVb4PzvqkascUZ7zJeYYrlc8UZ7jS05niDNeqUDLrs7PiX0aZ9XlU2FPhWZ87d+5EaGgovvrqK7Rr1w6rVq3C119/jYsXL1bpeZodNSIJ0Wg0MDMzg0KhwI4dOxASEoLJkycjLCwMCxcuxI0bN7Bp0ybd/dKIiEyZrqOG143TUcO3Fe6o+fv7o3Xr1lixYoVuXZMmTdC3b19ERERUWVwco0YkIXKZ4UpEVBlFKAQMXFYqQiGA4s7hXymVyjKPaisoKEB8fDw+/PBDvfVBQUGIjY2t0rjYUSOSGFOf4UpEVFFWVlZwd3dHTNp3RtlfjRo1dE+DKTFr1izMnj1bb929e/eg0WjKTOZyc3NDWlpalcbEjhqRBJnqDFciosqwtrZGcnIyCgoKjLK/8sZAl66m/VXptoYYQ82OGpGEmdoMVyKiyrK2toa1tbXYYehxcXGBubl5mepZenp6ld8yibfnIJIoc3NzDBkyBC1bthQ7FCIi+gsrKyv4+fnh0KFDeusPHTqEwMDAKt0XK2pEEsaZnURE0jRx4kSEhoaiTZs2CAgIwOrVq3Hz5k188MEHVbofdtSIiIiIKmnAgAG4f/8+PvnkE6SmpsLX1xffffcd6tWrV6X74X3UiIiIiCSKY9SIiIiIJIodNSIiIiKJYkeNiIiISKLYUSMiIiKSKHbUiMhoZs+erXdfuMGDB6Nv375Gj+P69etQKBRISEgw2D5K5/osjBEnEUkbO2pEMjd48GAoFAooFApYWlqifv36mDx5MnJzcw2+7yVLlmDDhg0VamvsTkvnzp0RFhZmlH0RET0N76NGRHj11Vexfv16FBYW4ueff8a///1v5ObmYsWKFWXaFhYWwtLSskr2q1KpqmQ7RESmihU1IoJSqYS7uzs8PDwQEhKCd999F3v37gXw5BLeunXrUL9+fSiVSgiCgKysLAwfPhyurq5wcHDAK6+8gt9++01vu5999hnc3Nxgb2+PoUOH4vHjx3rvl770qdVqMX/+fLz44otQKpXw9PTEvHnzAABeXl4AgFatWkGhUKBz5866z61fvx5NmjSBtbU1GjdujK+++kpvP6dOnUKrVq1gbW2NNm3a4Ndff33un9m0adPQqFEj2Nraon79+pg5cyYKCwvLtFu1ahU8PDxga2uLt956C5mZmXrv/1PsRCRvrKgRURk2NjZ6nY4//vgD33zzDXbt2gVzc3MAQM+ePeHk5ITvvvsOKpUKq1atQteuXXHlyhU4OTnhm2++waxZs7B8+XJ06NABmzdvxpdffon69es/db/Tp0/HmjVrsHjxYrRv3x6pqam4fPkygOLO1ssvv4zDhw+jadOmsLKyAgCsWbMGs2bNwrJly9CqVSv8+uuvGDZsGOzs7DBo0CDk5uaiV69eeOWVV7BlyxYkJydj/Pjxz/0zsre3x4YNG6BWq3H+/HkMGzYM9vb2mDp1apmf2/79+5GdnY2hQ4di9OjR2Lp1a4ViJyKCQESyNmjQIOH111/XvT558qTg7Ows9O/fXxAEQZg1a5ZgaWkppKen69r8+OOPgoODg/D48WO9bTVo0EBYtWqVIAiCEBAQIHzwwQd67/v7+wstWrQod9/Z2dmCUqkU1qxZU26cycnJAgDh119/1Vvv4eEhbNu2TW/dp59+KgQEBAiCIAirVq0SnJychNzcXN37K1asKHdbf9WpUydh/PjxT32/tAULFgh+fn6617NmzRLMzc2FlJQU3brvv/9eMDMzE1JTUysU+9NyJiL5YEWNiHDgwAHUqFEDRUVFKCwsxOuvv46lS5fq3q9Xrx5q1aqlex0fH4+HDx/C2dlZbzt5eXm4evUqAODSpUtlHk4cEBCAn376qdwYLl26hPz8fHTt2rXCcd+9excpKSkYOnQohg0bpltfVFSkG/926dIltGjRAra2tnpxPK///ve/iIyMxB9//IGHDx+iqKgIDg4Oem08PT1Rt25dvf1qtVokJSXB3Nz8H2MnImJHjYjQpUsXrFixApaWllCr1WUmC9jZ2em91mq1qF27No4ePVpmWzVr1nymGGxsbCr9Ga1WC6D4EqK/v7/eeyWXaAUDPM74xIkTePvttzFnzhwEBwdDpVJhx44d+OKLL/72cwqFQvffisRORMSOGhHBzs4OL774YoXbt27dGmlpabCwsMALL7xQbpsmTZrgxIkTGDhwoG7diRMnnrrNhg0bwsbGBj/++CP+/e9/l3m/ZEyaRqPRrXNzc0OdOnVw7do1vPvuu+Vu18fHB5s3b0ZeXp6uM/h3cVTEL7/8gnr16mHGjBm6dTdu3CjT7ubNm7h9+zbUajUAIC4uDmZmZmjUqFGFYiciYkeNiCqtW7duCAgIQN++fTF//nx4e3vj9u3b+O6779C3b1+0adMG48ePx6BBg9CmTRu0b98eW7duxYULF546mcDa2hrTpk3D1KlTYWVlhXbt2uHu3bu4cOEChg4dCldXV9jY2CAqKgp169aFtbU1VCoVZs+ejXHjxsHBwQE9evRAfn4+zpw5g4yMDEycOBEhISGYMWMGhg4div/85z+4fv06Fi5cWKE87969W+a+be7u7njxxRdx8+ZN7NixAy+99BIOHjyIPXv2lJvToEGDsHDhQmRnZ2PcuHHo378/3N3dAeAfYyci4mQCIpkrPZmgtFmzZulNACiRnZ0tjB07VlCr1YKlpaXg4eEhvPvuu8LNmzd1bebNmye4uLgINWrUEAYNGiRMnTr1qZMJBEEQNBqNMHfuXKFevXqCpaWl4OnpKYSHh+veX7NmjeDh4SGYmZkJnTp10q3funWr0LJlS8HKykpwdHQUOnbsKOzevVv3flxcnNCiRQvByspKaNmypbBr164KTSYAUGaZNWuWIAiCMGXKFMHZ2VmoUaOGMGDAAGHx4sWCSqUq83P76quvBLVaLVhbWwv9+vUTHjx4oLefv4udkwmISCEIBhjAQURERETPjTe8JSIiIpIodtSIiIiIJIodNSIiIiKJYkeNiIiISKLYUSMiIiKSKHbUiIiIiCSKHTUiIiIiiWJHjYiIiEii2FEjIiIikih21IiIiIgkih01IiIiIon6f67YOWjdrFDNAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 700x700 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 700x700 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 700x700 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 700x700 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "j = 0\n",
        "for i in range (j,8):\n",
        "#for i in range (0,10): #aslinya in range len(parameter) tapi kalau mau coba per sedikit2 ya gini deh\n",
        "  vgg_epoch = (parameter[i][0])\n",
        "  learning_rate = (parameter[i][1])\n",
        "  batch_size = (parameter[i][2])\n",
        "  dropout_rate = (parameter[i][3])\n",
        "  i=i+1\n",
        "  savePercobaan(i)\n",
        "  print(\"Percobaan ke-\",i,\"↓\")\n",
        "  print(\"HYPERPARAMETER\".center(100,\"─\"))\n",
        "  print(\"vgg epoch:\",vgg_epoch)\n",
        "  print(\"learning rate:\",learning_rate)\n",
        "  print(\"batch size:\",batch_size)\n",
        "  print(\"dropout rate:\",dropout_rate)\n",
        "  print(\"\".center(100,\"─\"))\n",
        "  vgg16_training(i, vgg_epoch, learning_rate, batch_size, dropout_rate)\n",
        "  new_row = {'Epoch': vgg_epoch, 'Learning Rate': learning_rate, 'Batch Size': batch_size, 'Dropout Rate': dropout_rate, 'Accuracy': arr_accuracy16[-1]}\n",
        "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n",
        "  hasilTabel.index = hasilTabel.index + (j+1)\n",
        "  hasilTabel.to_excel(\"hasilTabel.xlsx\")\n",
        "  print(\"\".center(100,\"─\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percobaan ke- 9 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 32\n",
            "learning rate: 0.024096434180242803\n",
            "batch size: 128\n",
            "dropout rate: 0.5155662584872833\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/32\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.3052 - acc: 0.3286 \n",
            "Epoch 1: val_acc improved from -inf to 0.14286, saving model to percobaan9_noImgPro/model\\vgg_16_9-saved-model-01-acc-0.14.hdf5\n",
            "4/4 [==============================] - 75s 20s/step - loss: 2.3052 - acc: 0.3286 - val_loss: 5.7815 - val_acc: 0.1429\n",
            "Epoch 2/32\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1638 - acc: 0.6122 \n",
            "Epoch 2: val_acc improved from 0.14286 to 0.18571, saving model to percobaan9_noImgPro/model\\vgg_16_9-saved-model-02-acc-0.19.hdf5\n",
            "4/4 [==============================] - 74s 19s/step - loss: 1.1638 - acc: 0.6122 - val_loss: 5.9001 - val_acc: 0.1857\n",
            "Epoch 3/32\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8833 - acc: 0.6980 \n",
            "Epoch 3: val_acc did not improve from 0.18571\n",
            "4/4 [==============================] - 75s 19s/step - loss: 0.8833 - acc: 0.6980 - val_loss: 6.0767 - val_acc: 0.1786\n",
            "Epoch 4/32\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7029 - acc: 0.7449 \n",
            "Epoch 4: val_acc did not improve from 0.18571\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.7029 - acc: 0.7449 - val_loss: 8.6360 - val_acc: 0.1500\n",
            "Epoch 5/32\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5807 - acc: 0.7878 \n",
            "Epoch 5: val_acc improved from 0.18571 to 0.23571, saving model to percobaan9_noImgPro/model\\vgg_16_9-saved-model-05-acc-0.24.hdf5\n",
            "4/4 [==============================] - 80s 22s/step - loss: 0.5807 - acc: 0.7878 - val_loss: 5.3147 - val_acc: 0.2357\n",
            "Epoch 6/32\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4799 - acc: 0.8265 \n",
            "Epoch 6: val_acc improved from 0.23571 to 0.30000, saving model to percobaan9_noImgPro/model\\vgg_16_9-saved-model-06-acc-0.30.hdf5\n",
            "4/4 [==============================] - 81s 21s/step - loss: 0.4799 - acc: 0.8265 - val_loss: 3.6970 - val_acc: 0.3000\n",
            "Epoch 7/32\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3730 - acc: 0.8837 \n",
            "Epoch 7: val_acc improved from 0.30000 to 0.34286, saving model to percobaan9_noImgPro/model\\vgg_16_9-saved-model-07-acc-0.34.hdf5\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.3730 - acc: 0.8837 - val_loss: 3.1306 - val_acc: 0.3429\n",
            "Epoch 8/32\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2810 - acc: 0.9041 \n",
            "Epoch 8: val_acc improved from 0.34286 to 0.36429, saving model to percobaan9_noImgPro/model\\vgg_16_9-saved-model-08-acc-0.36.hdf5\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.2810 - acc: 0.9041 - val_loss: 3.1795 - val_acc: 0.3643\n",
            "Epoch 9/32\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2840 - acc: 0.9000 \n",
            "Epoch 9: val_acc did not improve from 0.36429\n",
            "4/4 [==============================] - 80s 22s/step - loss: 0.2840 - acc: 0.9000 - val_loss: 3.7698 - val_acc: 0.2786\n",
            "Epoch 10/32\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2956 - acc: 0.9000 \n",
            "Epoch 10: val_acc did not improve from 0.36429\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.2956 - acc: 0.9000 - val_loss: 3.8394 - val_acc: 0.2429\n",
            "Epoch 11/32\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2360 - acc: 0.9204 \n",
            "Epoch 11: val_acc did not improve from 0.36429\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.2360 - acc: 0.9204 - val_loss: 3.5009 - val_acc: 0.2571\n",
            "Epoch 12/32\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2533 - acc: 0.9061 \n",
            "Epoch 12: val_acc did not improve from 0.36429\n",
            "4/4 [==============================] - 80s 22s/step - loss: 0.2533 - acc: 0.9061 - val_loss: 3.7268 - val_acc: 0.2429\n",
            "\n",
            "\n",
            "Model Accuracy 0.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.67      0.20      0.31        10\n",
            "       10000       0.00      0.00      0.00        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.00      0.00      0.00        10\n",
            "       20000       0.16      1.00      0.27        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       0.67      0.20      0.31        10\n",
            "\n",
            "    accuracy                           0.20        70\n",
            "   macro avg       0.21      0.20      0.13        70\n",
            "weighted avg       0.21      0.20      0.13        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 10 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 35\n",
            "learning rate: 0.0071169807105828185\n",
            "batch size: 128\n",
            "dropout rate: 0.6467938900729733\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.9487 - acc: 0.2510 \n",
            "Epoch 1: val_acc improved from -inf to 0.22857, saving model to percobaan10_noImgPro/model\\vgg_16_10-saved-model-01-acc-0.23.hdf5\n",
            "4/4 [==============================] - 82s 21s/step - loss: 2.9487 - acc: 0.2510 - val_loss: 2.4002 - val_acc: 0.2286\n",
            "Epoch 2/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.5806 - acc: 0.4633 \n",
            "Epoch 2: val_acc did not improve from 0.22857\n",
            "4/4 [==============================] - 79s 21s/step - loss: 1.5806 - acc: 0.4633 - val_loss: 2.6053 - val_acc: 0.2286\n",
            "Epoch 3/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0866 - acc: 0.6490 \n",
            "Epoch 3: val_acc improved from 0.22857 to 0.35714, saving model to percobaan10_noImgPro/model\\vgg_16_10-saved-model-03-acc-0.36.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 1.0866 - acc: 0.6490 - val_loss: 2.2818 - val_acc: 0.3571\n",
            "Epoch 4/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9366 - acc: 0.6796 \n",
            "Epoch 4: val_acc improved from 0.35714 to 0.42143, saving model to percobaan10_noImgPro/model\\vgg_16_10-saved-model-04-acc-0.42.hdf5\n",
            "4/4 [==============================] - 79s 22s/step - loss: 0.9366 - acc: 0.6796 - val_loss: 2.1090 - val_acc: 0.4214\n",
            "Epoch 5/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7931 - acc: 0.7531 \n",
            "Epoch 5: val_acc did not improve from 0.42143\n",
            "4/4 [==============================] - 79s 22s/step - loss: 0.7931 - acc: 0.7531 - val_loss: 2.1549 - val_acc: 0.3714\n",
            "Epoch 6/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6406 - acc: 0.7714 \n",
            "Epoch 6: val_acc did not improve from 0.42143\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.6406 - acc: 0.7714 - val_loss: 2.2375 - val_acc: 0.2786\n",
            "Epoch 7/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6412 - acc: 0.7714 \n",
            "Epoch 7: val_acc did not improve from 0.42143\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.6412 - acc: 0.7714 - val_loss: 2.3123 - val_acc: 0.2286\n",
            "Epoch 8/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5631 - acc: 0.7980 \n",
            "Epoch 8: val_acc did not improve from 0.42143\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.5631 - acc: 0.7980 - val_loss: 2.1600 - val_acc: 0.2786\n",
            "Epoch 9/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5251 - acc: 0.8184 \n",
            "Epoch 9: val_acc did not improve from 0.42143\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.5251 - acc: 0.8184 - val_loss: 1.9438 - val_acc: 0.3786\n",
            "Epoch 10/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3820 - acc: 0.8796 \n",
            "Epoch 10: val_acc improved from 0.42143 to 0.43571, saving model to percobaan10_noImgPro/model\\vgg_16_10-saved-model-10-acc-0.44.hdf5\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.3820 - acc: 0.8796 - val_loss: 1.8080 - val_acc: 0.4357\n",
            "Epoch 11/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3713 - acc: 0.8796 \n",
            "Epoch 11: val_acc did not improve from 0.43571\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.3713 - acc: 0.8796 - val_loss: 1.7836 - val_acc: 0.4357\n",
            "Epoch 12/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3619 - acc: 0.8796 \n",
            "Epoch 12: val_acc did not improve from 0.43571\n",
            "4/4 [==============================] - 79s 22s/step - loss: 0.3619 - acc: 0.8796 - val_loss: 1.6881 - val_acc: 0.4357\n",
            "Epoch 13/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3305 - acc: 0.8816 \n",
            "Epoch 13: val_acc improved from 0.43571 to 0.46429, saving model to percobaan10_noImgPro/model\\vgg_16_10-saved-model-13-acc-0.46.hdf5\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.3305 - acc: 0.8816 - val_loss: 1.5782 - val_acc: 0.4643\n",
            "Epoch 14/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3446 - acc: 0.8837 \n",
            "Epoch 14: val_acc improved from 0.46429 to 0.48571, saving model to percobaan10_noImgPro/model\\vgg_16_10-saved-model-14-acc-0.49.hdf5\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.3446 - acc: 0.8837 - val_loss: 1.4760 - val_acc: 0.4857\n",
            "Epoch 15/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2825 - acc: 0.9020 \n",
            "Epoch 15: val_acc improved from 0.48571 to 0.51429, saving model to percobaan10_noImgPro/model\\vgg_16_10-saved-model-15-acc-0.51.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.2825 - acc: 0.9020 - val_loss: 1.3196 - val_acc: 0.5143\n",
            "Epoch 16/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2744 - acc: 0.9020 \n",
            "Epoch 16: val_acc improved from 0.51429 to 0.55000, saving model to percobaan10_noImgPro/model\\vgg_16_10-saved-model-16-acc-0.55.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.2744 - acc: 0.9020 - val_loss: 1.1883 - val_acc: 0.5500\n",
            "Epoch 17/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2136 - acc: 0.9367 \n",
            "Epoch 17: val_acc improved from 0.55000 to 0.60714, saving model to percobaan10_noImgPro/model\\vgg_16_10-saved-model-17-acc-0.61.hdf5\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.2136 - acc: 0.9367 - val_loss: 1.0735 - val_acc: 0.6071\n",
            "Epoch 18/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2117 - acc: 0.9306 \n",
            "Epoch 18: val_acc improved from 0.60714 to 0.68571, saving model to percobaan10_noImgPro/model\\vgg_16_10-saved-model-18-acc-0.69.hdf5\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.2117 - acc: 0.9306 - val_loss: 0.9986 - val_acc: 0.6857\n",
            "Epoch 19/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2596 - acc: 0.9204 \n",
            "Epoch 19: val_acc did not improve from 0.68571\n",
            "4/4 [==============================] - 79s 22s/step - loss: 0.2596 - acc: 0.9204 - val_loss: 1.0092 - val_acc: 0.6500\n",
            "Epoch 20/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1993 - acc: 0.9224 \n",
            "Epoch 20: val_acc did not improve from 0.68571\n",
            "4/4 [==============================] - 79s 22s/step - loss: 0.1993 - acc: 0.9224 - val_loss: 1.0121 - val_acc: 0.6357\n",
            "Epoch 21/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1842 - acc: 0.9469 \n",
            "Epoch 21: val_acc did not improve from 0.68571\n",
            "4/4 [==============================] - 79s 22s/step - loss: 0.1842 - acc: 0.9469 - val_loss: 0.9557 - val_acc: 0.6857\n",
            "Epoch 22/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2340 - acc: 0.9184 \n",
            "Epoch 22: val_acc improved from 0.68571 to 0.72143, saving model to percobaan10_noImgPro/model\\vgg_16_10-saved-model-22-acc-0.72.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.2340 - acc: 0.9184 - val_loss: 0.8761 - val_acc: 0.7214\n",
            "Epoch 23/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2205 - acc: 0.9347 \n",
            "Epoch 23: val_acc improved from 0.72143 to 0.76429, saving model to percobaan10_noImgPro/model\\vgg_16_10-saved-model-23-acc-0.76.hdf5\n",
            "4/4 [==============================] - 79s 22s/step - loss: 0.2205 - acc: 0.9347 - val_loss: 0.8004 - val_acc: 0.7643\n",
            "Epoch 24/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1587 - acc: 0.9510 \n",
            "Epoch 24: val_acc improved from 0.76429 to 0.77857, saving model to percobaan10_noImgPro/model\\vgg_16_10-saved-model-24-acc-0.78.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.1587 - acc: 0.9510 - val_loss: 0.7488 - val_acc: 0.7786\n",
            "Epoch 25/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1775 - acc: 0.9327 \n",
            "Epoch 25: val_acc improved from 0.77857 to 0.79286, saving model to percobaan10_noImgPro/model\\vgg_16_10-saved-model-25-acc-0.79.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.1775 - acc: 0.9327 - val_loss: 0.7235 - val_acc: 0.7929\n",
            "Epoch 26/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1639 - acc: 0.9449 \n",
            "Epoch 26: val_acc did not improve from 0.79286\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.1639 - acc: 0.9449 - val_loss: 0.7312 - val_acc: 0.7786\n",
            "Epoch 27/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1503 - acc: 0.9531 \n",
            "Epoch 27: val_acc did not improve from 0.79286\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.1503 - acc: 0.9531 - val_loss: 0.7297 - val_acc: 0.7786\n",
            "Epoch 28/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1614 - acc: 0.9429 \n",
            "Epoch 28: val_acc did not improve from 0.79286\n",
            "4/4 [==============================] - 79s 22s/step - loss: 0.1614 - acc: 0.9429 - val_loss: 0.7228 - val_acc: 0.7643\n",
            "Epoch 29/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1412 - acc: 0.9571 \n",
            "Epoch 29: val_acc did not improve from 0.79286\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.1412 - acc: 0.9571 - val_loss: 0.7250 - val_acc: 0.7643\n",
            "Epoch 30/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1556 - acc: 0.9531 \n",
            "Epoch 30: val_acc did not improve from 0.79286\n",
            "4/4 [==============================] - 79s 22s/step - loss: 0.1556 - acc: 0.9531 - val_loss: 0.7356 - val_acc: 0.7571\n",
            "Epoch 31/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1860 - acc: 0.9306 \n",
            "Epoch 31: val_acc did not improve from 0.79286\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.1860 - acc: 0.9306 - val_loss: 0.7317 - val_acc: 0.7643\n",
            "Epoch 32/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1403 - acc: 0.9673 \n",
            "Epoch 32: val_acc did not improve from 0.79286\n",
            "4/4 [==============================] - 79s 22s/step - loss: 0.1403 - acc: 0.9673 - val_loss: 0.7115 - val_acc: 0.7714\n",
            "Epoch 33/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1734 - acc: 0.9367 \n",
            "Epoch 33: val_acc did not improve from 0.79286\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.1734 - acc: 0.9367 - val_loss: 0.6697 - val_acc: 0.7857\n",
            "Epoch 34/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1860 - acc: 0.9286 \n",
            "Epoch 34: val_acc did not improve from 0.79286\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.1860 - acc: 0.9286 - val_loss: 0.6281 - val_acc: 0.7857\n",
            "Epoch 35/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1311 - acc: 0.9551 \n",
            "Epoch 35: val_acc did not improve from 0.79286\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.1311 - acc: 0.9551 - val_loss: 0.6325 - val_acc: 0.7786\n",
            "\n",
            "\n",
            "Model Accuracy 0.7\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.80      0.80      0.80        10\n",
            "       10000       0.77      1.00      0.87        10\n",
            "      100000       1.00      0.40      0.57        10\n",
            "        2000       1.00      0.50      0.67        10\n",
            "       20000       0.67      0.40      0.50        10\n",
            "        5000       0.73      0.80      0.76        10\n",
            "       50000       0.48      1.00      0.65        10\n",
            "\n",
            "    accuracy                           0.70        70\n",
            "   macro avg       0.78      0.70      0.69        70\n",
            "weighted avg       0.78      0.70      0.69        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 11 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 33\n",
            "learning rate: 0.001996562889247976\n",
            "batch size: 128\n",
            "dropout rate: 0.6589295313473581\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 3.2461 - acc: 0.1510 \n",
            "Epoch 1: val_acc improved from -inf to 0.16429, saving model to percobaan11_noImgPro/model\\vgg_16_11-saved-model-01-acc-0.16.hdf5\n",
            "4/4 [==============================] - 80s 21s/step - loss: 3.2461 - acc: 0.1510 - val_loss: 2.4452 - val_acc: 0.1643\n",
            "Epoch 2/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.4056 - acc: 0.2939 \n",
            "Epoch 2: val_acc improved from 0.16429 to 0.17143, saving model to percobaan11_noImgPro/model\\vgg_16_11-saved-model-02-acc-0.17.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 2.4056 - acc: 0.2939 - val_loss: 2.5438 - val_acc: 0.1714\n",
            "Epoch 3/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.0327 - acc: 0.3939 \n",
            "Epoch 3: val_acc improved from 0.17143 to 0.17857, saving model to percobaan11_noImgPro/model\\vgg_16_11-saved-model-03-acc-0.18.hdf5\n",
            "4/4 [==============================] - 79s 22s/step - loss: 2.0327 - acc: 0.3939 - val_loss: 2.5073 - val_acc: 0.1786\n",
            "Epoch 4/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.6587 - acc: 0.4878 \n",
            "Epoch 4: val_acc did not improve from 0.17857\n",
            "4/4 [==============================] - 79s 21s/step - loss: 1.6587 - acc: 0.4878 - val_loss: 2.3909 - val_acc: 0.1714\n",
            "Epoch 5/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2469 - acc: 0.5612 \n",
            "Epoch 5: val_acc improved from 0.17857 to 0.18571, saving model to percobaan11_noImgPro/model\\vgg_16_11-saved-model-05-acc-0.19.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 1.2469 - acc: 0.5612 - val_loss: 2.2617 - val_acc: 0.1857\n",
            "Epoch 6/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2216 - acc: 0.5939 \n",
            "Epoch 6: val_acc improved from 0.18571 to 0.19286, saving model to percobaan11_noImgPro/model\\vgg_16_11-saved-model-06-acc-0.19.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 1.2216 - acc: 0.5939 - val_loss: 2.2191 - val_acc: 0.1929\n",
            "Epoch 7/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0574 - acc: 0.6531 \n",
            "Epoch 7: val_acc improved from 0.19286 to 0.20714, saving model to percobaan11_noImgPro/model\\vgg_16_11-saved-model-07-acc-0.21.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 1.0574 - acc: 0.6531 - val_loss: 2.1024 - val_acc: 0.2071\n",
            "Epoch 8/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9432 - acc: 0.6653 \n",
            "Epoch 8: val_acc improved from 0.20714 to 0.22143, saving model to percobaan11_noImgPro/model\\vgg_16_11-saved-model-08-acc-0.22.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.9432 - acc: 0.6653 - val_loss: 1.9610 - val_acc: 0.2214\n",
            "Epoch 9/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8750 - acc: 0.6939 \n",
            "Epoch 9: val_acc improved from 0.22143 to 0.24286, saving model to percobaan11_noImgPro/model\\vgg_16_11-saved-model-09-acc-0.24.hdf5\n",
            "4/4 [==============================] - 81s 22s/step - loss: 0.8750 - acc: 0.6939 - val_loss: 1.8585 - val_acc: 0.2429\n",
            "Epoch 10/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7585 - acc: 0.7245 \n",
            "Epoch 10: val_acc improved from 0.24286 to 0.27857, saving model to percobaan11_noImgPro/model\\vgg_16_11-saved-model-10-acc-0.28.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.7585 - acc: 0.7245 - val_loss: 1.7542 - val_acc: 0.2786\n",
            "Epoch 11/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7408 - acc: 0.7490 \n",
            "Epoch 11: val_acc improved from 0.27857 to 0.29286, saving model to percobaan11_noImgPro/model\\vgg_16_11-saved-model-11-acc-0.29.hdf5\n",
            "4/4 [==============================] - 79s 22s/step - loss: 0.7408 - acc: 0.7490 - val_loss: 1.6363 - val_acc: 0.2929\n",
            "Epoch 12/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6143 - acc: 0.7939 \n",
            "Epoch 12: val_acc improved from 0.29286 to 0.31429, saving model to percobaan11_noImgPro/model\\vgg_16_11-saved-model-12-acc-0.31.hdf5\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.6143 - acc: 0.7939 - val_loss: 1.5260 - val_acc: 0.3143\n",
            "Epoch 13/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6063 - acc: 0.7878 \n",
            "Epoch 13: val_acc improved from 0.31429 to 0.35000, saving model to percobaan11_noImgPro/model\\vgg_16_11-saved-model-13-acc-0.35.hdf5\n",
            "4/4 [==============================] - 79s 22s/step - loss: 0.6063 - acc: 0.7878 - val_loss: 1.4466 - val_acc: 0.3500\n",
            "Epoch 14/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5044 - acc: 0.8388 \n",
            "Epoch 14: val_acc improved from 0.35000 to 0.37143, saving model to percobaan11_noImgPro/model\\vgg_16_11-saved-model-14-acc-0.37.hdf5\n",
            "4/4 [==============================] - 79s 22s/step - loss: 0.5044 - acc: 0.8388 - val_loss: 1.3837 - val_acc: 0.3714\n",
            "Epoch 15/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5404 - acc: 0.8245 \n",
            "Epoch 15: val_acc improved from 0.37143 to 0.43571, saving model to percobaan11_noImgPro/model\\vgg_16_11-saved-model-15-acc-0.44.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.5404 - acc: 0.8245 - val_loss: 1.3274 - val_acc: 0.4357\n",
            "Epoch 16/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5151 - acc: 0.8122 \n",
            "Epoch 16: val_acc improved from 0.43571 to 0.50000, saving model to percobaan11_noImgPro/model\\vgg_16_11-saved-model-16-acc-0.50.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.5151 - acc: 0.8122 - val_loss: 1.2696 - val_acc: 0.5000\n",
            "Epoch 17/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5081 - acc: 0.8041 \n",
            "Epoch 17: val_acc improved from 0.50000 to 0.57857, saving model to percobaan11_noImgPro/model\\vgg_16_11-saved-model-17-acc-0.58.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.5081 - acc: 0.8041 - val_loss: 1.1979 - val_acc: 0.5786\n",
            "Epoch 18/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4678 - acc: 0.8245 \n",
            "Epoch 18: val_acc improved from 0.57857 to 0.60714, saving model to percobaan11_noImgPro/model\\vgg_16_11-saved-model-18-acc-0.61.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.4678 - acc: 0.8245 - val_loss: 1.1358 - val_acc: 0.6071\n",
            "Epoch 19/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4363 - acc: 0.8612 \n",
            "Epoch 19: val_acc improved from 0.60714 to 0.63571, saving model to percobaan11_noImgPro/model\\vgg_16_11-saved-model-19-acc-0.64.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.4363 - acc: 0.8612 - val_loss: 1.0950 - val_acc: 0.6357\n",
            "Epoch 20/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3462 - acc: 0.8918 \n",
            "Epoch 20: val_acc improved from 0.63571 to 0.66429, saving model to percobaan11_noImgPro/model\\vgg_16_11-saved-model-20-acc-0.66.hdf5\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.3462 - acc: 0.8918 - val_loss: 1.0663 - val_acc: 0.6643\n",
            "Epoch 21/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4368 - acc: 0.8490 \n",
            "Epoch 21: val_acc improved from 0.66429 to 0.68571, saving model to percobaan11_noImgPro/model\\vgg_16_11-saved-model-21-acc-0.69.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.4368 - acc: 0.8490 - val_loss: 1.0337 - val_acc: 0.6857\n",
            "Epoch 22/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4317 - acc: 0.8449 \n",
            "Epoch 22: val_acc improved from 0.68571 to 0.69286, saving model to percobaan11_noImgPro/model\\vgg_16_11-saved-model-22-acc-0.69.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.4317 - acc: 0.8449 - val_loss: 0.9991 - val_acc: 0.6929\n",
            "Epoch 23/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3663 - acc: 0.8837 \n",
            "Epoch 23: val_acc improved from 0.69286 to 0.72143, saving model to percobaan11_noImgPro/model\\vgg_16_11-saved-model-23-acc-0.72.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.3663 - acc: 0.8837 - val_loss: 0.9720 - val_acc: 0.7214\n",
            "Epoch 24/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3537 - acc: 0.8776 \n",
            "Epoch 24: val_acc improved from 0.72143 to 0.74286, saving model to percobaan11_noImgPro/model\\vgg_16_11-saved-model-24-acc-0.74.hdf5\n",
            "4/4 [==============================] - 79s 22s/step - loss: 0.3537 - acc: 0.8776 - val_loss: 0.9495 - val_acc: 0.7429\n",
            "Epoch 25/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3395 - acc: 0.8878 \n",
            "Epoch 25: val_acc improved from 0.74286 to 0.75714, saving model to percobaan11_noImgPro/model\\vgg_16_11-saved-model-25-acc-0.76.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.3395 - acc: 0.8878 - val_loss: 0.9299 - val_acc: 0.7571\n",
            "Epoch 26/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3430 - acc: 0.8694 \n",
            "Epoch 26: val_acc improved from 0.75714 to 0.76429, saving model to percobaan11_noImgPro/model\\vgg_16_11-saved-model-26-acc-0.76.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.3430 - acc: 0.8694 - val_loss: 0.9040 - val_acc: 0.7643\n",
            "Epoch 27/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3650 - acc: 0.8776 \n",
            "Epoch 27: val_acc improved from 0.76429 to 0.78571, saving model to percobaan11_noImgPro/model\\vgg_16_11-saved-model-27-acc-0.79.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.3650 - acc: 0.8776 - val_loss: 0.8735 - val_acc: 0.7857\n",
            "Epoch 28/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3298 - acc: 0.8776 \n",
            "Epoch 28: val_acc did not improve from 0.78571\n",
            "4/4 [==============================] - 79s 22s/step - loss: 0.3298 - acc: 0.8776 - val_loss: 0.8464 - val_acc: 0.7857\n",
            "Epoch 29/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2513 - acc: 0.9204 \n",
            "Epoch 29: val_acc improved from 0.78571 to 0.79286, saving model to percobaan11_noImgPro/model\\vgg_16_11-saved-model-29-acc-0.79.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.2513 - acc: 0.9204 - val_loss: 0.8188 - val_acc: 0.7929\n",
            "Epoch 30/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2618 - acc: 0.9204 \n",
            "Epoch 30: val_acc did not improve from 0.79286\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.2618 - acc: 0.9204 - val_loss: 0.7940 - val_acc: 0.7857\n",
            "Epoch 31/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3056 - acc: 0.8837 \n",
            "Epoch 31: val_acc did not improve from 0.79286\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.3056 - acc: 0.8837 - val_loss: 0.7674 - val_acc: 0.7929\n",
            "Epoch 32/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2940 - acc: 0.9041 \n",
            "Epoch 32: val_acc did not improve from 0.79286\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.2940 - acc: 0.9041 - val_loss: 0.7438 - val_acc: 0.7929\n",
            "Epoch 33/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3561 - acc: 0.8755 \n",
            "Epoch 33: val_acc improved from 0.79286 to 0.80000, saving model to percobaan11_noImgPro/model\\vgg_16_11-saved-model-33-acc-0.80.hdf5\n",
            "4/4 [==============================] - 79s 22s/step - loss: 0.3561 - acc: 0.8755 - val_loss: 0.7278 - val_acc: 0.8000\n",
            "\n",
            "\n",
            "Model Accuracy 0.7428571428571429\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.89      0.80      0.84        10\n",
            "       10000       0.67      0.80      0.73        10\n",
            "      100000       1.00      0.50      0.67        10\n",
            "        2000       0.86      0.60      0.71        10\n",
            "       20000       0.71      0.50      0.59        10\n",
            "        5000       1.00      1.00      1.00        10\n",
            "       50000       0.50      1.00      0.67        10\n",
            "\n",
            "    accuracy                           0.74        70\n",
            "   macro avg       0.80      0.74      0.74        70\n",
            "weighted avg       0.80      0.74      0.74        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 12 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 38\n",
            "learning rate: 0.02114087167177288\n",
            "batch size: 128\n",
            "dropout rate: 0.7449343558430424\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/38\n",
            "4/4 [==============================] - ETA: 0s - loss: 3.1390 - acc: 0.2347 \n",
            "Epoch 1: val_acc improved from -inf to 0.32143, saving model to percobaan12_noImgPro/model\\vgg_16_12-saved-model-01-acc-0.32.hdf5\n",
            "4/4 [==============================] - 80s 22s/step - loss: 3.1390 - acc: 0.2347 - val_loss: 2.6825 - val_acc: 0.3214\n",
            "Epoch 2/38\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.8887 - acc: 0.4204 \n",
            "Epoch 2: val_acc improved from 0.32143 to 0.36429, saving model to percobaan12_noImgPro/model\\vgg_16_12-saved-model-02-acc-0.36.hdf5\n",
            "4/4 [==============================] - 79s 22s/step - loss: 1.8887 - acc: 0.4204 - val_loss: 2.4787 - val_acc: 0.3643\n",
            "Epoch 3/38\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.4096 - acc: 0.4959 \n",
            "Epoch 3: val_acc improved from 0.36429 to 0.41429, saving model to percobaan12_noImgPro/model\\vgg_16_12-saved-model-03-acc-0.41.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 1.4096 - acc: 0.4959 - val_loss: 2.7327 - val_acc: 0.4143\n",
            "Epoch 4/38\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.3701 - acc: 0.5388 \n",
            "Epoch 4: val_acc did not improve from 0.41429\n",
            "4/4 [==============================] - 79s 21s/step - loss: 1.3701 - acc: 0.5388 - val_loss: 2.5499 - val_acc: 0.3000\n",
            "Epoch 5/38\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.3284 - acc: 0.5592 \n",
            "Epoch 5: val_acc did not improve from 0.41429\n",
            "4/4 [==============================] - 79s 21s/step - loss: 1.3284 - acc: 0.5592 - val_loss: 2.4912 - val_acc: 0.2500\n",
            "Epoch 6/38\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1490 - acc: 0.6163 \n",
            "Epoch 6: val_acc did not improve from 0.41429\n",
            "4/4 [==============================] - 79s 21s/step - loss: 1.1490 - acc: 0.6163 - val_loss: 2.1461 - val_acc: 0.2286\n",
            "Epoch 7/38\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9591 - acc: 0.6429 \n",
            "Epoch 7: val_acc did not improve from 0.41429\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.9591 - acc: 0.6429 - val_loss: 2.2858 - val_acc: 0.2071\n",
            "Epoch 8/38\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8704 - acc: 0.6980 \n",
            "Epoch 8: val_acc did not improve from 0.41429\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.8704 - acc: 0.6980 - val_loss: 2.3087 - val_acc: 0.2071\n",
            "Epoch 9/38\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8333 - acc: 0.7286 \n",
            "Epoch 9: val_acc did not improve from 0.41429\n",
            "4/4 [==============================] - 79s 22s/step - loss: 0.8333 - acc: 0.7286 - val_loss: 2.0317 - val_acc: 0.2786\n",
            "Epoch 10/38\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7527 - acc: 0.7408 \n",
            "Epoch 10: val_acc did not improve from 0.41429\n",
            "4/4 [==============================] - 79s 22s/step - loss: 0.7527 - acc: 0.7408 - val_loss: 2.0010 - val_acc: 0.3071\n",
            "Epoch 11/38\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7076 - acc: 0.7510 \n",
            "Epoch 11: val_acc did not improve from 0.41429\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.7076 - acc: 0.7510 - val_loss: 1.9143 - val_acc: 0.3214\n",
            "Epoch 12/38\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6510 - acc: 0.7694 \n",
            "Epoch 12: val_acc did not improve from 0.41429\n",
            "4/4 [==============================] - 79s 22s/step - loss: 0.6510 - acc: 0.7694 - val_loss: 1.8578 - val_acc: 0.3286\n",
            "Epoch 13/38\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5338 - acc: 0.8163 \n",
            "Epoch 13: val_acc did not improve from 0.41429\n",
            "4/4 [==============================] - 79s 22s/step - loss: 0.5338 - acc: 0.8163 - val_loss: 1.8150 - val_acc: 0.3714\n",
            "Epoch 14/38\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6234 - acc: 0.7939 \n",
            "Epoch 14: val_acc improved from 0.41429 to 0.52143, saving model to percobaan12_noImgPro/model\\vgg_16_12-saved-model-14-acc-0.52.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.6234 - acc: 0.7939 - val_loss: 1.6462 - val_acc: 0.5214\n",
            "Epoch 15/38\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5239 - acc: 0.8122 \n",
            "Epoch 15: val_acc improved from 0.52143 to 0.54286, saving model to percobaan12_noImgPro/model\\vgg_16_12-saved-model-15-acc-0.54.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.5239 - acc: 0.8122 - val_loss: 1.5302 - val_acc: 0.5429\n",
            "Epoch 16/38\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4411 - acc: 0.8388 \n",
            "Epoch 16: val_acc improved from 0.54286 to 0.56429, saving model to percobaan12_noImgPro/model\\vgg_16_12-saved-model-16-acc-0.56.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.4411 - acc: 0.8388 - val_loss: 1.3933 - val_acc: 0.5643\n",
            "Epoch 17/38\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4367 - acc: 0.8429 \n",
            "Epoch 17: val_acc did not improve from 0.56429\n",
            "4/4 [==============================] - 79s 22s/step - loss: 0.4367 - acc: 0.8429 - val_loss: 1.2930 - val_acc: 0.5500\n",
            "Epoch 18/38\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4051 - acc: 0.8673 \n",
            "Epoch 18: val_acc improved from 0.56429 to 0.58571, saving model to percobaan12_noImgPro/model\\vgg_16_12-saved-model-18-acc-0.59.hdf5\n",
            "4/4 [==============================] - 79s 22s/step - loss: 0.4051 - acc: 0.8673 - val_loss: 1.1275 - val_acc: 0.5857\n",
            "Epoch 19/38\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3802 - acc: 0.8776 \n",
            "Epoch 19: val_acc improved from 0.58571 to 0.60714, saving model to percobaan12_noImgPro/model\\vgg_16_12-saved-model-19-acc-0.61.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.3802 - acc: 0.8776 - val_loss: 1.0131 - val_acc: 0.6071\n",
            "Epoch 20/38\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4284 - acc: 0.8735 \n",
            "Epoch 20: val_acc improved from 0.60714 to 0.67143, saving model to percobaan12_noImgPro/model\\vgg_16_12-saved-model-20-acc-0.67.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.4284 - acc: 0.8735 - val_loss: 0.8993 - val_acc: 0.6714\n",
            "Epoch 21/38\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3957 - acc: 0.8673 \n",
            "Epoch 21: val_acc improved from 0.67143 to 0.72857, saving model to percobaan12_noImgPro/model\\vgg_16_12-saved-model-21-acc-0.73.hdf5\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.3957 - acc: 0.8673 - val_loss: 0.8331 - val_acc: 0.7286\n",
            "Epoch 22/38\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3849 - acc: 0.8612 \n",
            "Epoch 22: val_acc improved from 0.72857 to 0.74286, saving model to percobaan12_noImgPro/model\\vgg_16_12-saved-model-22-acc-0.74.hdf5\n",
            "4/4 [==============================] - 79s 22s/step - loss: 0.3849 - acc: 0.8612 - val_loss: 0.8003 - val_acc: 0.7429\n",
            "Epoch 23/38\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3781 - acc: 0.8490 \n",
            "Epoch 23: val_acc did not improve from 0.74286\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.3781 - acc: 0.8490 - val_loss: 0.7662 - val_acc: 0.7357\n",
            "Epoch 24/38\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3339 - acc: 0.8939 \n",
            "Epoch 24: val_acc improved from 0.74286 to 0.77143, saving model to percobaan12_noImgPro/model\\vgg_16_12-saved-model-24-acc-0.77.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.3339 - acc: 0.8939 - val_loss: 0.7527 - val_acc: 0.7714\n",
            "Epoch 25/38\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3384 - acc: 0.8755 \n",
            "Epoch 25: val_acc improved from 0.77143 to 0.78571, saving model to percobaan12_noImgPro/model\\vgg_16_12-saved-model-25-acc-0.79.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.3384 - acc: 0.8755 - val_loss: 0.7492 - val_acc: 0.7857\n",
            "Epoch 26/38\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3215 - acc: 0.9020 \n",
            "Epoch 26: val_acc did not improve from 0.78571\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.3215 - acc: 0.9020 - val_loss: 0.7427 - val_acc: 0.7643\n",
            "Epoch 27/38\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3285 - acc: 0.8837 \n",
            "Epoch 27: val_acc did not improve from 0.78571\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.3285 - acc: 0.8837 - val_loss: 0.8557 - val_acc: 0.7214\n",
            "Epoch 28/38\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3561 - acc: 0.8837 \n",
            "Epoch 28: val_acc did not improve from 0.78571\n",
            "4/4 [==============================] - 79s 22s/step - loss: 0.3561 - acc: 0.8837 - val_loss: 0.9890 - val_acc: 0.6929\n",
            "Epoch 29/38\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3068 - acc: 0.8898 \n",
            "Epoch 29: val_acc did not improve from 0.78571\n",
            "4/4 [==============================] - 81s 22s/step - loss: 0.3068 - acc: 0.8898 - val_loss: 1.1498 - val_acc: 0.6500\n",
            "Epoch 30/38\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3041 - acc: 0.9061 \n",
            "Epoch 30: val_acc did not improve from 0.78571\n",
            "4/4 [==============================] - 85s 22s/step - loss: 0.3041 - acc: 0.9061 - val_loss: 1.0916 - val_acc: 0.6571\n",
            "Epoch 31/38\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2831 - acc: 0.9061 \n",
            "Epoch 31: val_acc did not improve from 0.78571\n",
            "4/4 [==============================] - 75s 20s/step - loss: 0.2831 - acc: 0.9061 - val_loss: 0.9564 - val_acc: 0.6857\n",
            "\n",
            "\n",
            "Model Accuracy 0.6\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.60      0.75        10\n",
            "       10000       0.88      0.70      0.78        10\n",
            "      100000       1.00      0.50      0.67        10\n",
            "        2000       0.80      0.40      0.53        10\n",
            "       20000       1.00      0.30      0.46        10\n",
            "        5000       0.88      0.70      0.78        10\n",
            "       50000       0.29      1.00      0.44        10\n",
            "\n",
            "    accuracy                           0.60        70\n",
            "   macro avg       0.83      0.60      0.63        70\n",
            "weighted avg       0.83      0.60      0.63        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 13 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 30\n",
            "learning rate: 0.03981052451715107\n",
            "batch size: 32\n",
            "dropout rate: 0.5643033974724773\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.8832 - acc: 0.3082\n",
            "Epoch 1: val_acc improved from -inf to 0.19286, saving model to percobaan13_noImgPro/model\\vgg_16_13-saved-model-01-acc-0.19.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 2.8832 - acc: 0.3082 - val_loss: 6.3108 - val_acc: 0.1929\n",
            "Epoch 2/30\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.8099 - acc: 0.4755\n",
            "Epoch 2: val_acc improved from 0.19286 to 0.31429, saving model to percobaan13_noImgPro/model\\vgg_16_13-saved-model-02-acc-0.31.hdf5\n",
            "16/16 [==============================] - 75s 5s/step - loss: 1.8099 - acc: 0.4755 - val_loss: 3.3989 - val_acc: 0.3143\n",
            "Epoch 3/30\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3709 - acc: 0.5571\n",
            "Epoch 3: val_acc did not improve from 0.31429\n",
            "16/16 [==============================] - 75s 5s/step - loss: 1.3709 - acc: 0.5571 - val_loss: 2.0417 - val_acc: 0.2714\n",
            "Epoch 4/30\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9661 - acc: 0.6510\n",
            "Epoch 4: val_acc improved from 0.31429 to 0.40714, saving model to percobaan13_noImgPro/model\\vgg_16_13-saved-model-04-acc-0.41.hdf5\n",
            "16/16 [==============================] - 76s 5s/step - loss: 0.9661 - acc: 0.6510 - val_loss: 1.8716 - val_acc: 0.4071\n",
            "Epoch 5/30\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8860 - acc: 0.7122\n",
            "Epoch 5: val_acc improved from 0.40714 to 0.60714, saving model to percobaan13_noImgPro/model\\vgg_16_13-saved-model-05-acc-0.61.hdf5\n",
            "16/16 [==============================] - 76s 5s/step - loss: 0.8860 - acc: 0.7122 - val_loss: 1.1565 - val_acc: 0.6071\n",
            "Epoch 6/30\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7398 - acc: 0.7592\n",
            "Epoch 6: val_acc improved from 0.60714 to 0.74286, saving model to percobaan13_noImgPro/model\\vgg_16_13-saved-model-06-acc-0.74.hdf5\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.7398 - acc: 0.7592 - val_loss: 0.7964 - val_acc: 0.7429\n",
            "Epoch 7/30\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7401 - acc: 0.7469\n",
            "Epoch 7: val_acc did not improve from 0.74286\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.7401 - acc: 0.7469 - val_loss: 0.8322 - val_acc: 0.7214\n",
            "Epoch 8/30\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6590 - acc: 0.7633\n",
            "Epoch 8: val_acc did not improve from 0.74286\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.6590 - acc: 0.7633 - val_loss: 1.7681 - val_acc: 0.4429\n",
            "Epoch 9/30\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5719 - acc: 0.7959\n",
            "Epoch 9: val_acc improved from 0.74286 to 0.75000, saving model to percobaan13_noImgPro/model\\vgg_16_13-saved-model-09-acc-0.75.hdf5\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.5719 - acc: 0.7959 - val_loss: 0.7222 - val_acc: 0.7500\n",
            "Epoch 10/30\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6017 - acc: 0.8020\n",
            "Epoch 10: val_acc did not improve from 0.75000\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.6017 - acc: 0.8020 - val_loss: 1.1696 - val_acc: 0.6357\n",
            "Epoch 11/30\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5385 - acc: 0.8347\n",
            "Epoch 11: val_acc did not improve from 0.75000\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.5385 - acc: 0.8347 - val_loss: 1.0333 - val_acc: 0.6571\n",
            "Epoch 12/30\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6355 - acc: 0.7918\n",
            "Epoch 12: val_acc did not improve from 0.75000\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.6355 - acc: 0.7918 - val_loss: 0.9199 - val_acc: 0.6786\n",
            "Epoch 13/30\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4875 - acc: 0.8490\n",
            "Epoch 13: val_acc improved from 0.75000 to 0.75714, saving model to percobaan13_noImgPro/model\\vgg_16_13-saved-model-13-acc-0.76.hdf5\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.4875 - acc: 0.8490 - val_loss: 0.8173 - val_acc: 0.7571\n",
            "Epoch 14/30\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6069 - acc: 0.7878\n",
            "Epoch 14: val_acc did not improve from 0.75714\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.6069 - acc: 0.7878 - val_loss: 0.9338 - val_acc: 0.7143\n",
            "\n",
            "\n",
            "Model Accuracy 0.6428571428571429\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.83      1.00      0.91        10\n",
            "       10000       1.00      0.50      0.67        10\n",
            "      100000       1.00      0.30      0.46        10\n",
            "        2000       0.73      0.80      0.76        10\n",
            "       20000       0.75      0.30      0.43        10\n",
            "        5000       1.00      0.60      0.75        10\n",
            "       50000       0.34      1.00      0.51        10\n",
            "\n",
            "    accuracy                           0.64        70\n",
            "   macro avg       0.81      0.64      0.64        70\n",
            "weighted avg       0.81      0.64      0.64        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 14 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 35\n",
            "learning rate: 0.03691568578824196\n",
            "batch size: 32\n",
            "dropout rate: 0.5844551224820937\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/35\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.8537 - acc: 0.2653\n",
            "Epoch 1: val_acc improved from -inf to 0.20714, saving model to percobaan14_noImgPro/model\\vgg_16_14-saved-model-01-acc-0.21.hdf5\n",
            "16/16 [==============================] - 75s 5s/step - loss: 2.8537 - acc: 0.2653 - val_loss: 4.4763 - val_acc: 0.2071\n",
            "Epoch 2/35\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.8063 - acc: 0.4469\n",
            "Epoch 2: val_acc improved from 0.20714 to 0.35000, saving model to percobaan14_noImgPro/model\\vgg_16_14-saved-model-02-acc-0.35.hdf5\n",
            "16/16 [==============================] - 75s 5s/step - loss: 1.8063 - acc: 0.4469 - val_loss: 2.1868 - val_acc: 0.3500\n",
            "Epoch 3/35\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.4184 - acc: 0.5571\n",
            "Epoch 3: val_acc did not improve from 0.35000\n",
            "16/16 [==============================] - 75s 5s/step - loss: 1.4184 - acc: 0.5571 - val_loss: 2.5885 - val_acc: 0.2643\n",
            "Epoch 4/35\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1135 - acc: 0.6306\n",
            "Epoch 4: val_acc improved from 0.35000 to 0.38571, saving model to percobaan14_noImgPro/model\\vgg_16_14-saved-model-04-acc-0.39.hdf5\n",
            "16/16 [==============================] - 74s 5s/step - loss: 1.1135 - acc: 0.6306 - val_loss: 1.6127 - val_acc: 0.3857\n",
            "Epoch 5/35\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9367 - acc: 0.6857\n",
            "Epoch 5: val_acc did not improve from 0.38571\n",
            "16/16 [==============================] - 74s 5s/step - loss: 0.9367 - acc: 0.6857 - val_loss: 1.8860 - val_acc: 0.3571\n",
            "Epoch 6/35\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8173 - acc: 0.6878\n",
            "Epoch 6: val_acc did not improve from 0.38571\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.8173 - acc: 0.6878 - val_loss: 1.6329 - val_acc: 0.3857\n",
            "Epoch 7/35\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6922 - acc: 0.7633\n",
            "Epoch 7: val_acc improved from 0.38571 to 0.51429, saving model to percobaan14_noImgPro/model\\vgg_16_14-saved-model-07-acc-0.51.hdf5\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.6922 - acc: 0.7633 - val_loss: 1.5908 - val_acc: 0.5143\n",
            "Epoch 8/35\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6438 - acc: 0.7510\n",
            "Epoch 8: val_acc improved from 0.51429 to 0.61429, saving model to percobaan14_noImgPro/model\\vgg_16_14-saved-model-08-acc-0.61.hdf5\n",
            "16/16 [==============================] - 74s 5s/step - loss: 0.6438 - acc: 0.7510 - val_loss: 1.2506 - val_acc: 0.6143\n",
            "Epoch 9/35\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6565 - acc: 0.7735\n",
            "Epoch 9: val_acc improved from 0.61429 to 0.64286, saving model to percobaan14_noImgPro/model\\vgg_16_14-saved-model-09-acc-0.64.hdf5\n",
            "16/16 [==============================] - 74s 5s/step - loss: 0.6565 - acc: 0.7735 - val_loss: 0.9761 - val_acc: 0.6429\n",
            "Epoch 10/35\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5829 - acc: 0.8061\n",
            "Epoch 10: val_acc improved from 0.64286 to 0.76429, saving model to percobaan14_noImgPro/model\\vgg_16_14-saved-model-10-acc-0.76.hdf5\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.5829 - acc: 0.8061 - val_loss: 0.7741 - val_acc: 0.7643\n",
            "Epoch 11/35\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6927 - acc: 0.7592\n",
            "Epoch 11: val_acc did not improve from 0.76429\n",
            "16/16 [==============================] - 74s 5s/step - loss: 0.6927 - acc: 0.7592 - val_loss: 0.9893 - val_acc: 0.6857\n",
            "Epoch 12/35\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6639 - acc: 0.7735\n",
            "Epoch 12: val_acc did not improve from 0.76429\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.6639 - acc: 0.7735 - val_loss: 0.8548 - val_acc: 0.7286\n",
            "Epoch 13/35\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6777 - acc: 0.7673\n",
            "Epoch 13: val_acc did not improve from 0.76429\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.6777 - acc: 0.7673 - val_loss: 0.9068 - val_acc: 0.7214\n",
            "Epoch 14/35\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5311 - acc: 0.8204\n",
            "Epoch 14: val_acc improved from 0.76429 to 0.79286, saving model to percobaan14_noImgPro/model\\vgg_16_14-saved-model-14-acc-0.79.hdf5\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.5311 - acc: 0.8204 - val_loss: 0.6462 - val_acc: 0.7929\n",
            "Epoch 15/35\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5173 - acc: 0.8224\n",
            "Epoch 15: val_acc did not improve from 0.79286\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.5173 - acc: 0.8224 - val_loss: 0.8417 - val_acc: 0.7357\n",
            "Epoch 16/35\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4376 - acc: 0.8408\n",
            "Epoch 16: val_acc did not improve from 0.79286\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.4376 - acc: 0.8408 - val_loss: 0.7448 - val_acc: 0.7571\n",
            "Epoch 17/35\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5331 - acc: 0.8224\n",
            "Epoch 17: val_acc did not improve from 0.79286\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.5331 - acc: 0.8224 - val_loss: 0.6299 - val_acc: 0.7857\n",
            "Epoch 18/35\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4548 - acc: 0.8408\n",
            "Epoch 18: val_acc did not improve from 0.79286\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.4548 - acc: 0.8408 - val_loss: 0.7498 - val_acc: 0.7714\n",
            "Epoch 19/35\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5869 - acc: 0.8041\n",
            "Epoch 19: val_acc did not improve from 0.79286\n",
            "16/16 [==============================] - 74s 5s/step - loss: 0.5869 - acc: 0.8041 - val_loss: 0.7435 - val_acc: 0.7714\n",
            "Epoch 20/35\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4540 - acc: 0.8531\n",
            "Epoch 20: val_acc improved from 0.79286 to 0.84286, saving model to percobaan14_noImgPro/model\\vgg_16_14-saved-model-20-acc-0.84.hdf5\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.4540 - acc: 0.8531 - val_loss: 0.5399 - val_acc: 0.8429\n",
            "Epoch 21/35\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5559 - acc: 0.8286\n",
            "Epoch 21: val_acc did not improve from 0.84286\n",
            "16/16 [==============================] - 74s 5s/step - loss: 0.5559 - acc: 0.8286 - val_loss: 0.6471 - val_acc: 0.8071\n",
            "Epoch 22/35\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5004 - acc: 0.8449\n",
            "Epoch 22: val_acc did not improve from 0.84286\n",
            "16/16 [==============================] - 74s 5s/step - loss: 0.5004 - acc: 0.8449 - val_loss: 0.7699 - val_acc: 0.7786\n",
            "Epoch 23/35\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5661 - acc: 0.8265\n",
            "Epoch 23: val_acc did not improve from 0.84286\n",
            "16/16 [==============================] - 74s 5s/step - loss: 0.5661 - acc: 0.8265 - val_loss: 0.8907 - val_acc: 0.7571\n",
            "Epoch 24/35\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4792 - acc: 0.8510\n",
            "Epoch 24: val_acc did not improve from 0.84286\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.4792 - acc: 0.8510 - val_loss: 0.6484 - val_acc: 0.8357\n",
            "Epoch 25/35\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4983 - acc: 0.8367\n",
            "Epoch 25: val_acc improved from 0.84286 to 0.86429, saving model to percobaan14_noImgPro/model\\vgg_16_14-saved-model-25-acc-0.86.hdf5\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.4983 - acc: 0.8367 - val_loss: 0.5968 - val_acc: 0.8643\n",
            "\n",
            "\n",
            "Model Accuracy 0.8428571428571429\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.88      0.70      0.78        10\n",
            "       10000       1.00      0.70      0.82        10\n",
            "      100000       1.00      1.00      1.00        10\n",
            "        2000       0.90      0.90      0.90        10\n",
            "       20000       0.80      0.80      0.80        10\n",
            "        5000       0.56      0.90      0.69        10\n",
            "       50000       1.00      0.90      0.95        10\n",
            "\n",
            "    accuracy                           0.84        70\n",
            "   macro avg       0.88      0.84      0.85        70\n",
            "weighted avg       0.88      0.84      0.85        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 15 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 34\n",
            "learning rate: 0.02733276665773342\n",
            "batch size: 32\n",
            "dropout rate: 0.6818598692455433\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/34\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.7426 - acc: 0.2714\n",
            "Epoch 1: val_acc improved from -inf to 0.22143, saving model to percobaan15_noImgPro/model\\vgg_16_15-saved-model-01-acc-0.22.hdf5\n",
            "16/16 [==============================] - 76s 5s/step - loss: 2.7426 - acc: 0.2714 - val_loss: 6.5940 - val_acc: 0.2214\n",
            "Epoch 2/34\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.8847 - acc: 0.4143\n",
            "Epoch 2: val_acc improved from 0.22143 to 0.23571, saving model to percobaan15_noImgPro/model\\vgg_16_15-saved-model-02-acc-0.24.hdf5\n",
            "16/16 [==============================] - 75s 5s/step - loss: 1.8847 - acc: 0.4143 - val_loss: 4.2643 - val_acc: 0.2357\n",
            "Epoch 3/34\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3738 - acc: 0.5347\n",
            "Epoch 3: val_acc improved from 0.23571 to 0.30000, saving model to percobaan15_noImgPro/model\\vgg_16_15-saved-model-03-acc-0.30.hdf5\n",
            "16/16 [==============================] - 74s 5s/step - loss: 1.3738 - acc: 0.5347 - val_loss: 2.3242 - val_acc: 0.3000\n",
            "Epoch 4/34\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2012 - acc: 0.5959\n",
            "Epoch 4: val_acc improved from 0.30000 to 0.32143, saving model to percobaan15_noImgPro/model\\vgg_16_15-saved-model-04-acc-0.32.hdf5\n",
            "16/16 [==============================] - 75s 5s/step - loss: 1.2012 - acc: 0.5959 - val_loss: 2.1680 - val_acc: 0.3214\n",
            "Epoch 5/34\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9717 - acc: 0.6531\n",
            "Epoch 5: val_acc improved from 0.32143 to 0.55714, saving model to percobaan15_noImgPro/model\\vgg_16_15-saved-model-05-acc-0.56.hdf5\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.9717 - acc: 0.6531 - val_loss: 1.3120 - val_acc: 0.5571\n",
            "Epoch 6/34\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8343 - acc: 0.7184\n",
            "Epoch 6: val_acc did not improve from 0.55714\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.8343 - acc: 0.7184 - val_loss: 1.1819 - val_acc: 0.5429\n",
            "Epoch 7/34\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7240 - acc: 0.7551\n",
            "Epoch 7: val_acc improved from 0.55714 to 0.72857, saving model to percobaan15_noImgPro/model\\vgg_16_15-saved-model-07-acc-0.73.hdf5\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.7240 - acc: 0.7551 - val_loss: 0.9747 - val_acc: 0.7286\n",
            "Epoch 8/34\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7397 - acc: 0.7388\n",
            "Epoch 8: val_acc improved from 0.72857 to 0.74286, saving model to percobaan15_noImgPro/model\\vgg_16_15-saved-model-08-acc-0.74.hdf5\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.7397 - acc: 0.7388 - val_loss: 0.8117 - val_acc: 0.7429\n",
            "Epoch 9/34\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7107 - acc: 0.7612\n",
            "Epoch 9: val_acc did not improve from 0.74286\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.7107 - acc: 0.7612 - val_loss: 0.9904 - val_acc: 0.6214\n",
            "Epoch 10/34\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6015 - acc: 0.8000\n",
            "Epoch 10: val_acc did not improve from 0.74286\n",
            "16/16 [==============================] - 74s 5s/step - loss: 0.6015 - acc: 0.8000 - val_loss: 0.9074 - val_acc: 0.6643\n",
            "Epoch 11/34\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6482 - acc: 0.7857\n",
            "Epoch 11: val_acc did not improve from 0.74286\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.6482 - acc: 0.7857 - val_loss: 0.8601 - val_acc: 0.6714\n",
            "Epoch 12/34\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7261 - acc: 0.7694\n",
            "Epoch 12: val_acc improved from 0.74286 to 0.76429, saving model to percobaan15_noImgPro/model\\vgg_16_15-saved-model-12-acc-0.76.hdf5\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.7261 - acc: 0.7694 - val_loss: 0.6362 - val_acc: 0.7643\n",
            "Epoch 13/34\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6866 - acc: 0.7633\n",
            "Epoch 13: val_acc did not improve from 0.76429\n",
            "16/16 [==============================] - 74s 5s/step - loss: 0.6866 - acc: 0.7633 - val_loss: 0.8183 - val_acc: 0.7143\n",
            "Epoch 14/34\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6236 - acc: 0.7918\n",
            "Epoch 14: val_acc improved from 0.76429 to 0.80714, saving model to percobaan15_noImgPro/model\\vgg_16_15-saved-model-14-acc-0.81.hdf5\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.6236 - acc: 0.7918 - val_loss: 0.5661 - val_acc: 0.8071\n",
            "Epoch 15/34\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5244 - acc: 0.8122\n",
            "Epoch 15: val_acc improved from 0.80714 to 0.82143, saving model to percobaan15_noImgPro/model\\vgg_16_15-saved-model-15-acc-0.82.hdf5\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.5244 - acc: 0.8122 - val_loss: 0.5290 - val_acc: 0.8214\n",
            "Epoch 16/34\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5963 - acc: 0.8122\n",
            "Epoch 16: val_acc did not improve from 0.82143\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.5963 - acc: 0.8122 - val_loss: 0.6714 - val_acc: 0.7714\n",
            "Epoch 17/34\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5939 - acc: 0.8082\n",
            "Epoch 17: val_acc did not improve from 0.82143\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.5939 - acc: 0.8082 - val_loss: 0.5865 - val_acc: 0.8214\n",
            "Epoch 18/34\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6022 - acc: 0.8000\n",
            "Epoch 18: val_acc did not improve from 0.82143\n",
            "16/16 [==============================] - 74s 5s/step - loss: 0.6022 - acc: 0.8000 - val_loss: 0.5647 - val_acc: 0.8214\n",
            "Epoch 19/34\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6077 - acc: 0.8041\n",
            "Epoch 19: val_acc did not improve from 0.82143\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.6077 - acc: 0.8041 - val_loss: 0.5534 - val_acc: 0.8214\n",
            "Epoch 20/34\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6012 - acc: 0.7918\n",
            "Epoch 20: val_acc improved from 0.82143 to 0.86429, saving model to percobaan15_noImgPro/model\\vgg_16_15-saved-model-20-acc-0.86.hdf5\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.6012 - acc: 0.7918 - val_loss: 0.5880 - val_acc: 0.8643\n",
            "\n",
            "\n",
            "Model Accuracy 0.8142857142857143\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.80      0.80      0.80        10\n",
            "       10000       0.77      1.00      0.87        10\n",
            "      100000       0.83      1.00      0.91        10\n",
            "        2000       0.71      0.50      0.59        10\n",
            "       20000       0.78      0.70      0.74        10\n",
            "        5000       0.91      1.00      0.95        10\n",
            "       50000       0.88      0.70      0.78        10\n",
            "\n",
            "    accuracy                           0.81        70\n",
            "   macro avg       0.81      0.81      0.80        70\n",
            "weighted avg       0.81      0.81      0.80        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 16 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 37\n",
            "learning rate: 0.02993468397332672\n",
            "batch size: 32\n",
            "dropout rate: 0.7395676507695375\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/37\n",
            "16/16 [==============================] - ETA: 0s - loss: 3.1379 - acc: 0.2327\n",
            "Epoch 1: val_acc improved from -inf to 0.19286, saving model to percobaan16_noImgPro/model\\vgg_16_16-saved-model-01-acc-0.19.hdf5\n",
            "16/16 [==============================] - 81s 5s/step - loss: 3.1379 - acc: 0.2327 - val_loss: 6.0471 - val_acc: 0.1929\n",
            "Epoch 2/37\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.0591 - acc: 0.3796\n",
            "Epoch 2: val_acc improved from 0.19286 to 0.26429, saving model to percobaan16_noImgPro/model\\vgg_16_16-saved-model-02-acc-0.26.hdf5\n",
            "16/16 [==============================] - 78s 5s/step - loss: 2.0591 - acc: 0.3796 - val_loss: 4.1387 - val_acc: 0.2643\n",
            "Epoch 3/37\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.6866 - acc: 0.4510\n",
            "Epoch 3: val_acc did not improve from 0.26429\n",
            "16/16 [==============================] - 78s 5s/step - loss: 1.6866 - acc: 0.4510 - val_loss: 3.2344 - val_acc: 0.2214\n",
            "Epoch 4/37\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3268 - acc: 0.5265\n",
            "Epoch 4: val_acc improved from 0.26429 to 0.38571, saving model to percobaan16_noImgPro/model\\vgg_16_16-saved-model-04-acc-0.39.hdf5\n",
            "16/16 [==============================] - 79s 5s/step - loss: 1.3268 - acc: 0.5265 - val_loss: 1.9480 - val_acc: 0.3857\n",
            "Epoch 5/37\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1793 - acc: 0.5755\n",
            "Epoch 5: val_acc improved from 0.38571 to 0.61429, saving model to percobaan16_noImgPro/model\\vgg_16_16-saved-model-05-acc-0.61.hdf5\n",
            "16/16 [==============================] - 79s 5s/step - loss: 1.1793 - acc: 0.5755 - val_loss: 1.2312 - val_acc: 0.6143\n",
            "Epoch 6/37\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1340 - acc: 0.6265\n",
            "Epoch 6: val_acc improved from 0.61429 to 0.67857, saving model to percobaan16_noImgPro/model\\vgg_16_16-saved-model-06-acc-0.68.hdf5\n",
            "16/16 [==============================] - 79s 5s/step - loss: 1.1340 - acc: 0.6265 - val_loss: 1.1125 - val_acc: 0.6786\n",
            "Epoch 7/37\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9605 - acc: 0.6510\n",
            "Epoch 7: val_acc did not improve from 0.67857\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.9605 - acc: 0.6510 - val_loss: 1.0189 - val_acc: 0.6357\n",
            "Epoch 8/37\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9340 - acc: 0.6673\n",
            "Epoch 8: val_acc improved from 0.67857 to 0.79286, saving model to percobaan16_noImgPro/model\\vgg_16_16-saved-model-08-acc-0.79.hdf5\n",
            "16/16 [==============================] - 79s 5s/step - loss: 0.9340 - acc: 0.6673 - val_loss: 0.6943 - val_acc: 0.7929\n",
            "Epoch 9/37\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8124 - acc: 0.6918\n",
            "Epoch 9: val_acc did not improve from 0.79286\n",
            "16/16 [==============================] - 79s 5s/step - loss: 0.8124 - acc: 0.6918 - val_loss: 0.7493 - val_acc: 0.7714\n",
            "Epoch 10/37\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8744 - acc: 0.6980\n",
            "Epoch 10: val_acc did not improve from 0.79286\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.8744 - acc: 0.6980 - val_loss: 0.9275 - val_acc: 0.7000\n",
            "Epoch 11/37\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7813 - acc: 0.7265\n",
            "Epoch 11: val_acc did not improve from 0.79286\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.7813 - acc: 0.7265 - val_loss: 0.6717 - val_acc: 0.7857\n",
            "Epoch 12/37\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9635 - acc: 0.6796\n",
            "Epoch 12: val_acc improved from 0.79286 to 0.80000, saving model to percobaan16_noImgPro/model\\vgg_16_16-saved-model-12-acc-0.80.hdf5\n",
            "16/16 [==============================] - 79s 5s/step - loss: 0.9635 - acc: 0.6796 - val_loss: 0.6823 - val_acc: 0.8000\n",
            "Epoch 13/37\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7838 - acc: 0.7265\n",
            "Epoch 13: val_acc did not improve from 0.80000\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.7838 - acc: 0.7265 - val_loss: 0.6546 - val_acc: 0.7786\n",
            "Epoch 14/37\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7565 - acc: 0.7204\n",
            "Epoch 14: val_acc did not improve from 0.80000\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.7565 - acc: 0.7204 - val_loss: 0.7156 - val_acc: 0.7786\n",
            "Epoch 15/37\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7872 - acc: 0.7347\n",
            "Epoch 15: val_acc did not improve from 0.80000\n",
            "16/16 [==============================] - 76s 5s/step - loss: 0.7872 - acc: 0.7347 - val_loss: 0.8580 - val_acc: 0.7571\n",
            "Epoch 16/37\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7824 - acc: 0.7286\n",
            "Epoch 16: val_acc improved from 0.80000 to 0.80714, saving model to percobaan16_noImgPro/model\\vgg_16_16-saved-model-16-acc-0.81.hdf5\n",
            "16/16 [==============================] - 76s 5s/step - loss: 0.7824 - acc: 0.7286 - val_loss: 0.6376 - val_acc: 0.8071\n",
            "Epoch 17/37\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8685 - acc: 0.7061\n",
            "Epoch 17: val_acc did not improve from 0.80714\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.8685 - acc: 0.7061 - val_loss: 0.5725 - val_acc: 0.7857\n",
            "Epoch 18/37\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7024 - acc: 0.7592\n",
            "Epoch 18: val_acc improved from 0.80714 to 0.82857, saving model to percobaan16_noImgPro/model\\vgg_16_16-saved-model-18-acc-0.83.hdf5\n",
            "16/16 [==============================] - 74s 5s/step - loss: 0.7024 - acc: 0.7592 - val_loss: 0.5139 - val_acc: 0.8286\n",
            "Epoch 19/37\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6786 - acc: 0.7776\n",
            "Epoch 19: val_acc improved from 0.82857 to 0.83571, saving model to percobaan16_noImgPro/model\\vgg_16_16-saved-model-19-acc-0.84.hdf5\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.6786 - acc: 0.7776 - val_loss: 0.4788 - val_acc: 0.8357\n",
            "Epoch 20/37\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6979 - acc: 0.7796\n",
            "Epoch 20: val_acc did not improve from 0.83571\n",
            "16/16 [==============================] - 76s 5s/step - loss: 0.6979 - acc: 0.7796 - val_loss: 0.5297 - val_acc: 0.8214\n",
            "Epoch 21/37\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6448 - acc: 0.7837\n",
            "Epoch 21: val_acc did not improve from 0.83571\n",
            "16/16 [==============================] - 74s 5s/step - loss: 0.6448 - acc: 0.7837 - val_loss: 0.5774 - val_acc: 0.8071\n",
            "Epoch 22/37\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7354 - acc: 0.7816\n",
            "Epoch 22: val_acc did not improve from 0.83571\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.7354 - acc: 0.7816 - val_loss: 0.6091 - val_acc: 0.7786\n",
            "Epoch 23/37\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6025 - acc: 0.8041\n",
            "Epoch 23: val_acc did not improve from 0.83571\n",
            "16/16 [==============================] - 74s 5s/step - loss: 0.6025 - acc: 0.8041 - val_loss: 0.8116 - val_acc: 0.7286\n",
            "Epoch 24/37\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6590 - acc: 0.7878\n",
            "Epoch 24: val_acc did not improve from 0.83571\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.6590 - acc: 0.7878 - val_loss: 0.5998 - val_acc: 0.8214\n",
            "\n",
            "\n",
            "Model Accuracy 0.8285714285714286\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.83      1.00      0.91        10\n",
            "       10000       1.00      1.00      1.00        10\n",
            "      100000       1.00      0.90      0.95        10\n",
            "        2000       0.82      0.90      0.86        10\n",
            "       20000       1.00      0.20      0.33        10\n",
            "        5000       1.00      0.80      0.89        10\n",
            "       50000       0.56      1.00      0.71        10\n",
            "\n",
            "    accuracy                           0.83        70\n",
            "   macro avg       0.89      0.83      0.81        70\n",
            "weighted avg       0.89      0.83      0.81        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 17 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 36\n",
            "learning rate: 0.03216274831088306\n",
            "batch size: 64\n",
            "dropout rate: 0.5299316685128863\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.3439 - acc: 0.3735\n",
            "Epoch 1: val_acc improved from -inf to 0.22857, saving model to percobaan17_noImgPro/model\\vgg_16_17-saved-model-01-acc-0.23.hdf5\n",
            "8/8 [==============================] - 73s 9s/step - loss: 2.3439 - acc: 0.3735 - val_loss: 4.3006 - val_acc: 0.2286\n",
            "Epoch 2/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1668 - acc: 0.5939\n",
            "Epoch 2: val_acc improved from 0.22857 to 0.31429, saving model to percobaan17_noImgPro/model\\vgg_16_17-saved-model-02-acc-0.31.hdf5\n",
            "8/8 [==============================] - 73s 9s/step - loss: 1.1668 - acc: 0.5939 - val_loss: 4.2674 - val_acc: 0.3143\n",
            "Epoch 3/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0322 - acc: 0.6347\n",
            "Epoch 3: val_acc improved from 0.31429 to 0.33571, saving model to percobaan17_noImgPro/model\\vgg_16_17-saved-model-03-acc-0.34.hdf5\n",
            "8/8 [==============================] - 73s 9s/step - loss: 1.0322 - acc: 0.6347 - val_loss: 2.8691 - val_acc: 0.3357\n",
            "Epoch 4/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7193 - acc: 0.7571\n",
            "Epoch 4: val_acc did not improve from 0.33571\n",
            "8/8 [==============================] - 71s 9s/step - loss: 0.7193 - acc: 0.7571 - val_loss: 2.7949 - val_acc: 0.3143\n",
            "Epoch 5/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6302 - acc: 0.7531\n",
            "Epoch 5: val_acc improved from 0.33571 to 0.34286, saving model to percobaan17_noImgPro/model\\vgg_16_17-saved-model-05-acc-0.34.hdf5\n",
            "8/8 [==============================] - 73s 9s/step - loss: 0.6302 - acc: 0.7531 - val_loss: 2.8475 - val_acc: 0.3429\n",
            "Epoch 6/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4965 - acc: 0.8388\n",
            "Epoch 6: val_acc did not improve from 0.34286\n",
            "8/8 [==============================] - 72s 9s/step - loss: 0.4965 - acc: 0.8388 - val_loss: 2.5248 - val_acc: 0.3000\n",
            "Epoch 7/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4174 - acc: 0.8531\n",
            "Epoch 7: val_acc did not improve from 0.34286\n",
            "8/8 [==============================] - 72s 9s/step - loss: 0.4174 - acc: 0.8531 - val_loss: 3.5112 - val_acc: 0.2286\n",
            "Epoch 8/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5641 - acc: 0.8082\n",
            "Epoch 8: val_acc did not improve from 0.34286\n",
            "8/8 [==============================] - 72s 9s/step - loss: 0.5641 - acc: 0.8082 - val_loss: 3.4502 - val_acc: 0.3429\n",
            "Epoch 9/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3834 - acc: 0.8735\n",
            "Epoch 9: val_acc improved from 0.34286 to 0.40714, saving model to percobaan17_noImgPro/model\\vgg_16_17-saved-model-09-acc-0.41.hdf5\n",
            "8/8 [==============================] - 71s 9s/step - loss: 0.3834 - acc: 0.8735 - val_loss: 2.4787 - val_acc: 0.4071\n",
            "Epoch 10/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3602 - acc: 0.8714\n",
            "Epoch 10: val_acc improved from 0.40714 to 0.50714, saving model to percobaan17_noImgPro/model\\vgg_16_17-saved-model-10-acc-0.51.hdf5\n",
            "8/8 [==============================] - 72s 9s/step - loss: 0.3602 - acc: 0.8714 - val_loss: 1.6095 - val_acc: 0.5071\n",
            "Epoch 11/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3357 - acc: 0.8878\n",
            "Epoch 11: val_acc improved from 0.50714 to 0.62143, saving model to percobaan17_noImgPro/model\\vgg_16_17-saved-model-11-acc-0.62.hdf5\n",
            "8/8 [==============================] - 72s 9s/step - loss: 0.3357 - acc: 0.8878 - val_loss: 1.1204 - val_acc: 0.6214\n",
            "Epoch 12/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2946 - acc: 0.8776\n",
            "Epoch 12: val_acc improved from 0.62143 to 0.65000, saving model to percobaan17_noImgPro/model\\vgg_16_17-saved-model-12-acc-0.65.hdf5\n",
            "8/8 [==============================] - 71s 9s/step - loss: 0.2946 - acc: 0.8776 - val_loss: 0.9923 - val_acc: 0.6500\n",
            "Epoch 13/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2821 - acc: 0.8959\n",
            "Epoch 13: val_acc did not improve from 0.65000\n",
            "8/8 [==============================] - 72s 9s/step - loss: 0.2821 - acc: 0.8959 - val_loss: 1.0618 - val_acc: 0.6214\n",
            "Epoch 14/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2443 - acc: 0.9224\n",
            "Epoch 14: val_acc did not improve from 0.65000\n",
            "8/8 [==============================] - 72s 9s/step - loss: 0.2443 - acc: 0.9224 - val_loss: 1.2053 - val_acc: 0.6500\n",
            "Epoch 15/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2815 - acc: 0.9061\n",
            "Epoch 15: val_acc improved from 0.65000 to 0.67857, saving model to percobaan17_noImgPro/model\\vgg_16_17-saved-model-15-acc-0.68.hdf5\n",
            "8/8 [==============================] - 71s 9s/step - loss: 0.2815 - acc: 0.9061 - val_loss: 1.1209 - val_acc: 0.6786\n",
            "Epoch 16/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2175 - acc: 0.9286\n",
            "Epoch 16: val_acc improved from 0.67857 to 0.74286, saving model to percobaan17_noImgPro/model\\vgg_16_17-saved-model-16-acc-0.74.hdf5\n",
            "8/8 [==============================] - 72s 9s/step - loss: 0.2175 - acc: 0.9286 - val_loss: 0.7997 - val_acc: 0.7429\n",
            "Epoch 17/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2889 - acc: 0.9163\n",
            "Epoch 17: val_acc improved from 0.74286 to 0.81429, saving model to percobaan17_noImgPro/model\\vgg_16_17-saved-model-17-acc-0.81.hdf5\n",
            "8/8 [==============================] - 71s 9s/step - loss: 0.2889 - acc: 0.9163 - val_loss: 0.5886 - val_acc: 0.8143\n",
            "Epoch 18/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2683 - acc: 0.9143\n",
            "Epoch 18: val_acc improved from 0.81429 to 0.82143, saving model to percobaan17_noImgPro/model\\vgg_16_17-saved-model-18-acc-0.82.hdf5\n",
            "8/8 [==============================] - 71s 9s/step - loss: 0.2683 - acc: 0.9143 - val_loss: 0.5427 - val_acc: 0.8214\n",
            "Epoch 19/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2007 - acc: 0.9327\n",
            "Epoch 19: val_acc did not improve from 0.82143\n",
            "8/8 [==============================] - 71s 9s/step - loss: 0.2007 - acc: 0.9327 - val_loss: 0.7219 - val_acc: 0.7857\n",
            "Epoch 20/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2718 - acc: 0.9102\n",
            "Epoch 20: val_acc did not improve from 0.82143\n",
            "8/8 [==============================] - 71s 9s/step - loss: 0.2718 - acc: 0.9102 - val_loss: 1.3450 - val_acc: 0.6071\n",
            "Epoch 21/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2545 - acc: 0.9082\n",
            "Epoch 21: val_acc did not improve from 0.82143\n",
            "8/8 [==============================] - 71s 9s/step - loss: 0.2545 - acc: 0.9082 - val_loss: 0.9904 - val_acc: 0.6929\n",
            "Epoch 22/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2054 - acc: 0.9388\n",
            "Epoch 22: val_acc did not improve from 0.82143\n",
            "8/8 [==============================] - 71s 9s/step - loss: 0.2054 - acc: 0.9388 - val_loss: 0.9354 - val_acc: 0.7000\n",
            "Epoch 23/36\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3031 - acc: 0.8939\n",
            "Epoch 23: val_acc did not improve from 0.82143\n",
            "8/8 [==============================] - 71s 9s/step - loss: 0.3031 - acc: 0.8939 - val_loss: 0.8364 - val_acc: 0.7571\n",
            "\n",
            "\n",
            "Model Accuracy 0.6428571428571429\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.83      0.50      0.62        10\n",
            "       10000       1.00      0.90      0.95        10\n",
            "      100000       1.00      0.20      0.33        10\n",
            "        2000       0.86      0.60      0.71        10\n",
            "       20000       1.00      0.30      0.46        10\n",
            "        5000       0.43      1.00      0.61        10\n",
            "       50000       0.50      1.00      0.67        10\n",
            "\n",
            "    accuracy                           0.64        70\n",
            "   macro avg       0.80      0.64      0.62        70\n",
            "weighted avg       0.80      0.64      0.62        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 18 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 33\n",
            "learning rate: 0.025040656679572875\n",
            "batch size: 64\n",
            "dropout rate: 0.616485022613032\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.2972 - acc: 0.3429\n",
            "Epoch 1: val_acc improved from -inf to 0.17857, saving model to percobaan18_noImgPro/model\\vgg_16_18-saved-model-01-acc-0.18.hdf5\n",
            "8/8 [==============================] - 70s 9s/step - loss: 2.2972 - acc: 0.3429 - val_loss: 8.3109 - val_acc: 0.1786\n",
            "Epoch 2/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4309 - acc: 0.5286\n",
            "Epoch 2: val_acc improved from 0.17857 to 0.21429, saving model to percobaan18_noImgPro/model\\vgg_16_18-saved-model-02-acc-0.21.hdf5\n",
            "8/8 [==============================] - 69s 9s/step - loss: 1.4309 - acc: 0.5286 - val_loss: 7.8088 - val_acc: 0.2143\n",
            "Epoch 3/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0866 - acc: 0.6286\n",
            "Epoch 3: val_acc improved from 0.21429 to 0.22143, saving model to percobaan18_noImgPro/model\\vgg_16_18-saved-model-03-acc-0.22.hdf5\n",
            "8/8 [==============================] - 69s 9s/step - loss: 1.0866 - acc: 0.6286 - val_loss: 6.6012 - val_acc: 0.2214\n",
            "Epoch 4/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8648 - acc: 0.6898\n",
            "Epoch 4: val_acc did not improve from 0.22143\n",
            "8/8 [==============================] - 69s 9s/step - loss: 0.8648 - acc: 0.6898 - val_loss: 5.8132 - val_acc: 0.2214\n",
            "Epoch 5/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7424 - acc: 0.7469\n",
            "Epoch 5: val_acc did not improve from 0.22143\n",
            "8/8 [==============================] - 69s 9s/step - loss: 0.7424 - acc: 0.7469 - val_loss: 4.6107 - val_acc: 0.2000\n",
            "Epoch 6/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7112 - acc: 0.7429\n",
            "Epoch 6: val_acc did not improve from 0.22143\n",
            "8/8 [==============================] - 78s 10s/step - loss: 0.7112 - acc: 0.7429 - val_loss: 4.1810 - val_acc: 0.1429\n",
            "Epoch 7/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5232 - acc: 0.8163\n",
            "Epoch 7: val_acc did not improve from 0.22143\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.5232 - acc: 0.8163 - val_loss: 3.1425 - val_acc: 0.2214\n",
            "Epoch 8/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4501 - acc: 0.8327\n",
            "Epoch 8: val_acc improved from 0.22143 to 0.32143, saving model to percobaan18_noImgPro/model\\vgg_16_18-saved-model-08-acc-0.32.hdf5\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.4501 - acc: 0.8327 - val_loss: 2.4249 - val_acc: 0.3214\n",
            "Epoch 9/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4349 - acc: 0.8490\n",
            "Epoch 9: val_acc improved from 0.32143 to 0.45000, saving model to percobaan18_noImgPro/model\\vgg_16_18-saved-model-09-acc-0.45.hdf5\n",
            "8/8 [==============================] - 78s 10s/step - loss: 0.4349 - acc: 0.8490 - val_loss: 1.9463 - val_acc: 0.4500\n",
            "Epoch 10/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4353 - acc: 0.8571\n",
            "Epoch 10: val_acc did not improve from 0.45000\n",
            "8/8 [==============================] - 78s 10s/step - loss: 0.4353 - acc: 0.8571 - val_loss: 1.7396 - val_acc: 0.4429\n",
            "Epoch 11/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4530 - acc: 0.8612\n",
            "Epoch 11: val_acc improved from 0.45000 to 0.59286, saving model to percobaan18_noImgPro/model\\vgg_16_18-saved-model-11-acc-0.59.hdf5\n",
            "8/8 [==============================] - 78s 10s/step - loss: 0.4530 - acc: 0.8612 - val_loss: 1.2181 - val_acc: 0.5929\n",
            "Epoch 12/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3372 - acc: 0.8796\n",
            "Epoch 12: val_acc did not improve from 0.59286\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.3372 - acc: 0.8796 - val_loss: 1.2355 - val_acc: 0.5714\n",
            "Epoch 13/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3702 - acc: 0.8633\n",
            "Epoch 13: val_acc improved from 0.59286 to 0.62857, saving model to percobaan18_noImgPro/model\\vgg_16_18-saved-model-13-acc-0.63.hdf5\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.3702 - acc: 0.8633 - val_loss: 1.0213 - val_acc: 0.6286\n",
            "Epoch 14/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3427 - acc: 0.8939\n",
            "Epoch 14: val_acc improved from 0.62857 to 0.63571, saving model to percobaan18_noImgPro/model\\vgg_16_18-saved-model-14-acc-0.64.hdf5\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.3427 - acc: 0.8939 - val_loss: 1.1267 - val_acc: 0.6357\n",
            "Epoch 15/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3307 - acc: 0.8959\n",
            "Epoch 15: val_acc did not improve from 0.63571\n",
            "8/8 [==============================] - 78s 10s/step - loss: 0.3307 - acc: 0.8959 - val_loss: 1.3304 - val_acc: 0.6000\n",
            "Epoch 16/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3542 - acc: 0.8653\n",
            "Epoch 16: val_acc did not improve from 0.63571\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.3542 - acc: 0.8653 - val_loss: 1.4050 - val_acc: 0.5500\n",
            "Epoch 17/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2320 - acc: 0.9143\n",
            "Epoch 17: val_acc did not improve from 0.63571\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.2320 - acc: 0.9143 - val_loss: 1.1146 - val_acc: 0.5786\n",
            "Epoch 18/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3013 - acc: 0.8898\n",
            "Epoch 18: val_acc improved from 0.63571 to 0.64286, saving model to percobaan18_noImgPro/model\\vgg_16_18-saved-model-18-acc-0.64.hdf5\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.3013 - acc: 0.8898 - val_loss: 1.0183 - val_acc: 0.6429\n",
            "Epoch 19/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3207 - acc: 0.8939\n",
            "Epoch 19: val_acc improved from 0.64286 to 0.65714, saving model to percobaan18_noImgPro/model\\vgg_16_18-saved-model-19-acc-0.66.hdf5\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.3207 - acc: 0.8939 - val_loss: 1.1108 - val_acc: 0.6571\n",
            "Epoch 20/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3098 - acc: 0.8898\n",
            "Epoch 20: val_acc improved from 0.65714 to 0.70714, saving model to percobaan18_noImgPro/model\\vgg_16_18-saved-model-20-acc-0.71.hdf5\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.3098 - acc: 0.8898 - val_loss: 0.8726 - val_acc: 0.7071\n",
            "Epoch 21/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2930 - acc: 0.9020\n",
            "Epoch 21: val_acc improved from 0.70714 to 0.82143, saving model to percobaan18_noImgPro/model\\vgg_16_18-saved-model-21-acc-0.82.hdf5\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.2930 - acc: 0.9020 - val_loss: 0.5839 - val_acc: 0.8214\n",
            "Epoch 22/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2838 - acc: 0.9102\n",
            "Epoch 22: val_acc improved from 0.82143 to 0.84286, saving model to percobaan18_noImgPro/model\\vgg_16_18-saved-model-22-acc-0.84.hdf5\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.2838 - acc: 0.9102 - val_loss: 0.5127 - val_acc: 0.8429\n",
            "Epoch 23/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2964 - acc: 0.8918\n",
            "Epoch 23: val_acc did not improve from 0.84286\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.2964 - acc: 0.8918 - val_loss: 0.7325 - val_acc: 0.7571\n",
            "Epoch 24/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2819 - acc: 0.9184\n",
            "Epoch 24: val_acc did not improve from 0.84286\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.2819 - acc: 0.9184 - val_loss: 0.7112 - val_acc: 0.7571\n",
            "Epoch 25/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2036 - acc: 0.9327\n",
            "Epoch 25: val_acc did not improve from 0.84286\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.2036 - acc: 0.9327 - val_loss: 0.5821 - val_acc: 0.8143\n",
            "Epoch 26/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2309 - acc: 0.9265\n",
            "Epoch 26: val_acc did not improve from 0.84286\n",
            "8/8 [==============================] - 78s 10s/step - loss: 0.2309 - acc: 0.9265 - val_loss: 0.5754 - val_acc: 0.8143\n",
            "Epoch 27/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2618 - acc: 0.9204\n",
            "Epoch 27: val_acc did not improve from 0.84286\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.2618 - acc: 0.9204 - val_loss: 0.6342 - val_acc: 0.8286\n",
            "\n",
            "\n",
            "Model Accuracy 0.7571428571428571\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.78      0.70      0.74        10\n",
            "       10000       0.77      1.00      0.87        10\n",
            "      100000       1.00      0.70      0.82        10\n",
            "        2000       0.73      0.80      0.76        10\n",
            "       20000       0.54      0.70      0.61        10\n",
            "        5000       1.00      0.60      0.75        10\n",
            "       50000       0.73      0.80      0.76        10\n",
            "\n",
            "    accuracy                           0.76        70\n",
            "   macro avg       0.79      0.76      0.76        70\n",
            "weighted avg       0.79      0.76      0.76        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 19 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 32\n",
            "learning rate: 0.04719770155465297\n",
            "batch size: 64\n",
            "dropout rate: 0.6839797079485888\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 3.0111 - acc: 0.2633\n",
            "Epoch 1: val_acc improved from -inf to 0.25714, saving model to percobaan19_noImgPro/model\\vgg_16_19-saved-model-01-acc-0.26.hdf5\n",
            "8/8 [==============================] - 78s 10s/step - loss: 3.0111 - acc: 0.2633 - val_loss: 6.5781 - val_acc: 0.2571\n",
            "Epoch 2/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.2288 - acc: 0.3673\n",
            "Epoch 2: val_acc improved from 0.25714 to 0.27143, saving model to percobaan19_noImgPro/model\\vgg_16_19-saved-model-02-acc-0.27.hdf5\n",
            "8/8 [==============================] - 77s 10s/step - loss: 2.2288 - acc: 0.3673 - val_loss: 5.0959 - val_acc: 0.2714\n",
            "Epoch 3/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7248 - acc: 0.4408\n",
            "Epoch 3: val_acc improved from 0.27143 to 0.42143, saving model to percobaan19_noImgPro/model\\vgg_16_19-saved-model-03-acc-0.42.hdf5\n",
            "8/8 [==============================] - 77s 10s/step - loss: 1.7248 - acc: 0.4408 - val_loss: 2.0299 - val_acc: 0.4214\n",
            "Epoch 4/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.2984 - acc: 0.5429\n",
            "Epoch 4: val_acc did not improve from 0.42143\n",
            "8/8 [==============================] - 77s 10s/step - loss: 1.2984 - acc: 0.5429 - val_loss: 2.7656 - val_acc: 0.2643\n",
            "Epoch 5/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0744 - acc: 0.6265\n",
            "Epoch 5: val_acc did not improve from 0.42143\n",
            "8/8 [==============================] - 77s 10s/step - loss: 1.0744 - acc: 0.6265 - val_loss: 2.0450 - val_acc: 0.3357\n",
            "Epoch 6/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9863 - acc: 0.6592\n",
            "Epoch 6: val_acc did not improve from 0.42143\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.9863 - acc: 0.6592 - val_loss: 2.0550 - val_acc: 0.3143\n",
            "Epoch 7/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8869 - acc: 0.6837\n",
            "Epoch 7: val_acc did not improve from 0.42143\n",
            "8/8 [==============================] - 76s 10s/step - loss: 0.8869 - acc: 0.6837 - val_loss: 2.2465 - val_acc: 0.3429\n",
            "Epoch 8/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8539 - acc: 0.7061\n",
            "Epoch 8: val_acc did not improve from 0.42143\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.8539 - acc: 0.7061 - val_loss: 1.7297 - val_acc: 0.4071\n",
            "Epoch 9/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7187 - acc: 0.7612\n",
            "Epoch 9: val_acc did not improve from 0.42143\n",
            "8/8 [==============================] - 76s 10s/step - loss: 0.7187 - acc: 0.7612 - val_loss: 1.9901 - val_acc: 0.3786\n",
            "Epoch 10/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7019 - acc: 0.7571\n",
            "Epoch 10: val_acc improved from 0.42143 to 0.43571, saving model to percobaan19_noImgPro/model\\vgg_16_19-saved-model-10-acc-0.44.hdf5\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.7019 - acc: 0.7571 - val_loss: 1.8439 - val_acc: 0.4357\n",
            "Epoch 11/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6962 - acc: 0.7612\n",
            "Epoch 11: val_acc did not improve from 0.43571\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.6962 - acc: 0.7612 - val_loss: 1.8533 - val_acc: 0.3929\n",
            "Epoch 12/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6426 - acc: 0.7735\n",
            "Epoch 12: val_acc improved from 0.43571 to 0.52857, saving model to percobaan19_noImgPro/model\\vgg_16_19-saved-model-12-acc-0.53.hdf5\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.6426 - acc: 0.7735 - val_loss: 1.6270 - val_acc: 0.5286\n",
            "Epoch 13/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5421 - acc: 0.8020\n",
            "Epoch 13: val_acc improved from 0.52857 to 0.55714, saving model to percobaan19_noImgPro/model\\vgg_16_19-saved-model-13-acc-0.56.hdf5\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.5421 - acc: 0.8020 - val_loss: 1.4559 - val_acc: 0.5571\n",
            "Epoch 14/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5131 - acc: 0.8286\n",
            "Epoch 14: val_acc improved from 0.55714 to 0.62143, saving model to percobaan19_noImgPro/model\\vgg_16_19-saved-model-14-acc-0.62.hdf5\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.5131 - acc: 0.8286 - val_loss: 1.3468 - val_acc: 0.6214\n",
            "Epoch 15/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5110 - acc: 0.8204\n",
            "Epoch 15: val_acc improved from 0.62143 to 0.73571, saving model to percobaan19_noImgPro/model\\vgg_16_19-saved-model-15-acc-0.74.hdf5\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.5110 - acc: 0.8204 - val_loss: 0.9118 - val_acc: 0.7357\n",
            "Epoch 16/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5000 - acc: 0.7898\n",
            "Epoch 16: val_acc did not improve from 0.73571\n",
            "8/8 [==============================] - 76s 10s/step - loss: 0.5000 - acc: 0.7898 - val_loss: 1.2976 - val_acc: 0.6214\n",
            "Epoch 17/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4948 - acc: 0.8388\n",
            "Epoch 17: val_acc did not improve from 0.73571\n",
            "8/8 [==============================] - 76s 10s/step - loss: 0.4948 - acc: 0.8388 - val_loss: 1.0680 - val_acc: 0.6643\n",
            "Epoch 18/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5529 - acc: 0.8184\n",
            "Epoch 18: val_acc did not improve from 0.73571\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.5529 - acc: 0.8184 - val_loss: 0.8550 - val_acc: 0.7286\n",
            "Epoch 19/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5848 - acc: 0.7980\n",
            "Epoch 19: val_acc did not improve from 0.73571\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.5848 - acc: 0.7980 - val_loss: 1.0734 - val_acc: 0.6500\n",
            "Epoch 20/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5117 - acc: 0.8122\n",
            "Epoch 20: val_acc improved from 0.73571 to 0.80000, saving model to percobaan19_noImgPro/model\\vgg_16_19-saved-model-20-acc-0.80.hdf5\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.5117 - acc: 0.8122 - val_loss: 0.6735 - val_acc: 0.8000\n",
            "Epoch 21/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5917 - acc: 0.7918\n",
            "Epoch 21: val_acc did not improve from 0.80000\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.5917 - acc: 0.7918 - val_loss: 0.7139 - val_acc: 0.7643\n",
            "Epoch 22/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5884 - acc: 0.8163\n",
            "Epoch 22: val_acc did not improve from 0.80000\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.5884 - acc: 0.8163 - val_loss: 1.0605 - val_acc: 0.7000\n",
            "Epoch 23/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4429 - acc: 0.8633\n",
            "Epoch 23: val_acc did not improve from 0.80000\n",
            "8/8 [==============================] - 78s 10s/step - loss: 0.4429 - acc: 0.8633 - val_loss: 1.1338 - val_acc: 0.6429\n",
            "Epoch 24/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3991 - acc: 0.8551\n",
            "Epoch 24: val_acc did not improve from 0.80000\n",
            "8/8 [==============================] - 81s 11s/step - loss: 0.3991 - acc: 0.8551 - val_loss: 1.2421 - val_acc: 0.6571\n",
            "Epoch 25/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4720 - acc: 0.8367\n",
            "Epoch 25: val_acc did not improve from 0.80000\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.4720 - acc: 0.8367 - val_loss: 1.2039 - val_acc: 0.6429\n",
            "\n",
            "\n",
            "Model Accuracy 0.5142857142857142\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.80      0.40      0.53        10\n",
            "       10000       0.70      0.70      0.70        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       1.00      0.40      0.57        10\n",
            "       20000       0.50      0.10      0.17        10\n",
            "        5000       0.38      1.00      0.56        10\n",
            "       50000       0.43      1.00      0.61        10\n",
            "\n",
            "    accuracy                           0.51        70\n",
            "   macro avg       0.55      0.51      0.45        70\n",
            "weighted avg       0.55      0.51      0.45        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 20 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 30\n",
            "learning rate: 0.04755848726110507\n",
            "batch size: 64\n",
            "dropout rate: 0.7734304230040852\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 3.3311 - acc: 0.2510\n",
            "Epoch 1: val_acc improved from -inf to 0.25000, saving model to percobaan20_noImgPro/model\\vgg_16_20-saved-model-01-acc-0.25.hdf5\n",
            "8/8 [==============================] - 86s 11s/step - loss: 3.3311 - acc: 0.2510 - val_loss: 8.4191 - val_acc: 0.2500\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.3541 - acc: 0.3531\n",
            "Epoch 2: val_acc did not improve from 0.25000\n",
            "8/8 [==============================] - 85s 11s/step - loss: 2.3541 - acc: 0.3531 - val_loss: 6.3538 - val_acc: 0.1929\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.9986 - acc: 0.3837\n",
            "Epoch 3: val_acc did not improve from 0.25000\n",
            "8/8 [==============================] - 86s 11s/step - loss: 1.9986 - acc: 0.3837 - val_loss: 4.0327 - val_acc: 0.1929\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5441 - acc: 0.4612\n",
            "Epoch 4: val_acc did not improve from 0.25000\n",
            "8/8 [==============================] - 86s 11s/step - loss: 1.5441 - acc: 0.4612 - val_loss: 4.2094 - val_acc: 0.1786\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4517 - acc: 0.5020\n",
            "Epoch 5: val_acc improved from 0.25000 to 0.27143, saving model to percobaan20_noImgPro/model\\vgg_16_20-saved-model-05-acc-0.27.hdf5\n",
            "8/8 [==============================] - 86s 11s/step - loss: 1.4517 - acc: 0.5020 - val_loss: 2.4273 - val_acc: 0.2714\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4093 - acc: 0.4755\n",
            "Epoch 6: val_acc improved from 0.27143 to 0.29286, saving model to percobaan20_noImgPro/model\\vgg_16_20-saved-model-06-acc-0.29.hdf5\n",
            "8/8 [==============================] - 86s 11s/step - loss: 1.4093 - acc: 0.4755 - val_loss: 1.7027 - val_acc: 0.2929\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1567 - acc: 0.5673\n",
            "Epoch 7: val_acc improved from 0.29286 to 0.35714, saving model to percobaan20_noImgPro/model\\vgg_16_20-saved-model-07-acc-0.36.hdf5\n",
            "8/8 [==============================] - 86s 11s/step - loss: 1.1567 - acc: 0.5673 - val_loss: 1.8918 - val_acc: 0.3571\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1877 - acc: 0.5612\n",
            "Epoch 8: val_acc improved from 0.35714 to 0.41429, saving model to percobaan20_noImgPro/model\\vgg_16_20-saved-model-08-acc-0.41.hdf5\n",
            "8/8 [==============================] - 86s 11s/step - loss: 1.1877 - acc: 0.5612 - val_loss: 1.5886 - val_acc: 0.4143\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0109 - acc: 0.6245\n",
            "Epoch 9: val_acc improved from 0.41429 to 0.43571, saving model to percobaan20_noImgPro/model\\vgg_16_20-saved-model-09-acc-0.44.hdf5\n",
            "8/8 [==============================] - 85s 11s/step - loss: 1.0109 - acc: 0.6245 - val_loss: 1.6523 - val_acc: 0.4357\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0446 - acc: 0.6449\n",
            "Epoch 10: val_acc improved from 0.43571 to 0.47857, saving model to percobaan20_noImgPro/model\\vgg_16_20-saved-model-10-acc-0.48.hdf5\n",
            "8/8 [==============================] - 86s 11s/step - loss: 1.0446 - acc: 0.6449 - val_loss: 1.5153 - val_acc: 0.4786\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9729 - acc: 0.6306\n",
            "Epoch 11: val_acc did not improve from 0.47857\n",
            "8/8 [==============================] - 86s 11s/step - loss: 0.9729 - acc: 0.6306 - val_loss: 1.5212 - val_acc: 0.4143\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8175 - acc: 0.7122\n",
            "Epoch 12: val_acc improved from 0.47857 to 0.53571, saving model to percobaan20_noImgPro/model\\vgg_16_20-saved-model-12-acc-0.54.hdf5\n",
            "8/8 [==============================] - 86s 11s/step - loss: 0.8175 - acc: 0.7122 - val_loss: 1.3221 - val_acc: 0.5357\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8852 - acc: 0.6776\n",
            "Epoch 13: val_acc improved from 0.53571 to 0.65000, saving model to percobaan20_noImgPro/model\\vgg_16_20-saved-model-13-acc-0.65.hdf5\n",
            "8/8 [==============================] - 86s 11s/step - loss: 0.8852 - acc: 0.6776 - val_loss: 1.0461 - val_acc: 0.6500\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8215 - acc: 0.7327\n",
            "Epoch 14: val_acc improved from 0.65000 to 0.65714, saving model to percobaan20_noImgPro/model\\vgg_16_20-saved-model-14-acc-0.66.hdf5\n",
            "8/8 [==============================] - 86s 11s/step - loss: 0.8215 - acc: 0.7327 - val_loss: 1.0013 - val_acc: 0.6571\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7878 - acc: 0.7327\n",
            "Epoch 15: val_acc improved from 0.65714 to 0.76429, saving model to percobaan20_noImgPro/model\\vgg_16_20-saved-model-15-acc-0.76.hdf5\n",
            "8/8 [==============================] - 86s 11s/step - loss: 0.7878 - acc: 0.7327 - val_loss: 0.7892 - val_acc: 0.7643\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7307 - acc: 0.7714\n",
            "Epoch 16: val_acc improved from 0.76429 to 0.77143, saving model to percobaan20_noImgPro/model\\vgg_16_20-saved-model-16-acc-0.77.hdf5\n",
            "8/8 [==============================] - 86s 11s/step - loss: 0.7307 - acc: 0.7714 - val_loss: 0.7934 - val_acc: 0.7714\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7130 - acc: 0.7571\n",
            "Epoch 17: val_acc did not improve from 0.77143\n",
            "8/8 [==============================] - 86s 11s/step - loss: 0.7130 - acc: 0.7571 - val_loss: 0.7674 - val_acc: 0.7429\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7769 - acc: 0.7367\n",
            "Epoch 18: val_acc did not improve from 0.77143\n",
            "8/8 [==============================] - 86s 11s/step - loss: 0.7769 - acc: 0.7367 - val_loss: 0.8567 - val_acc: 0.6786\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6814 - acc: 0.7571\n",
            "Epoch 19: val_acc did not improve from 0.77143\n",
            "8/8 [==============================] - 85s 11s/step - loss: 0.6814 - acc: 0.7571 - val_loss: 0.8543 - val_acc: 0.6786\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6803 - acc: 0.7837\n",
            "Epoch 20: val_acc improved from 0.77143 to 0.85000, saving model to percobaan20_noImgPro/model\\vgg_16_20-saved-model-20-acc-0.85.hdf5\n",
            "8/8 [==============================] - 86s 11s/step - loss: 0.6803 - acc: 0.7837 - val_loss: 0.5908 - val_acc: 0.8500\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6486 - acc: 0.7959\n",
            "Epoch 21: val_acc did not improve from 0.85000\n",
            "8/8 [==============================] - 86s 11s/step - loss: 0.6486 - acc: 0.7959 - val_loss: 0.6197 - val_acc: 0.8071\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7225 - acc: 0.7653\n",
            "Epoch 22: val_acc did not improve from 0.85000\n",
            "8/8 [==============================] - 86s 11s/step - loss: 0.7225 - acc: 0.7653 - val_loss: 0.6017 - val_acc: 0.8143\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6573 - acc: 0.7714\n",
            "Epoch 23: val_acc did not improve from 0.85000\n",
            "8/8 [==============================] - 86s 11s/step - loss: 0.6573 - acc: 0.7714 - val_loss: 0.6667 - val_acc: 0.7429\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6047 - acc: 0.8082\n",
            "Epoch 24: val_acc did not improve from 0.85000\n",
            "8/8 [==============================] - 85s 11s/step - loss: 0.6047 - acc: 0.8082 - val_loss: 1.0281 - val_acc: 0.6357\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6824 - acc: 0.7755\n",
            "Epoch 25: val_acc did not improve from 0.85000\n",
            "8/8 [==============================] - 86s 11s/step - loss: 0.6824 - acc: 0.7755 - val_loss: 0.5715 - val_acc: 0.8214\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7092 - acc: 0.7673\n",
            "Epoch 26: val_acc did not improve from 0.85000\n",
            "8/8 [==============================] - 86s 11s/step - loss: 0.7092 - acc: 0.7673 - val_loss: 0.5651 - val_acc: 0.8214\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7615 - acc: 0.7388\n",
            "Epoch 27: val_acc did not improve from 0.85000\n",
            "8/8 [==============================] - 86s 11s/step - loss: 0.7615 - acc: 0.7388 - val_loss: 0.5569 - val_acc: 0.8143\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6743 - acc: 0.7796\n",
            "Epoch 28: val_acc improved from 0.85000 to 0.85714, saving model to percobaan20_noImgPro/model\\vgg_16_20-saved-model-28-acc-0.86.hdf5\n",
            "8/8 [==============================] - 86s 11s/step - loss: 0.6743 - acc: 0.7796 - val_loss: 0.5170 - val_acc: 0.8571\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6801 - acc: 0.7796\n",
            "Epoch 29: val_acc did not improve from 0.85714\n",
            "8/8 [==============================] - 86s 11s/step - loss: 0.6801 - acc: 0.7796 - val_loss: 0.4948 - val_acc: 0.8429\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6848 - acc: 0.7592\n",
            "Epoch 30: val_acc did not improve from 0.85714\n",
            "8/8 [==============================] - 86s 11s/step - loss: 0.6848 - acc: 0.7592 - val_loss: 0.4649 - val_acc: 0.8429\n",
            "\n",
            "\n",
            "Model Accuracy 0.8857142857142857\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.91      1.00      0.95        10\n",
            "       10000       1.00      0.80      0.89        10\n",
            "      100000       1.00      1.00      1.00        10\n",
            "        2000       0.90      0.90      0.90        10\n",
            "       20000       0.83      0.50      0.62        10\n",
            "        5000       0.91      1.00      0.95        10\n",
            "       50000       0.71      1.00      0.83        10\n",
            "\n",
            "    accuracy                           0.89        70\n",
            "   macro avg       0.90      0.89      0.88        70\n",
            "weighted avg       0.90      0.89      0.88        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 21 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 32\n",
            "learning rate: 0.03197886459946077\n",
            "batch size: 128\n",
            "dropout rate: 0.5352012043981675\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/32\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.3079 - acc: 0.3510 \n",
            "Epoch 1: val_acc improved from -inf to 0.14286, saving model to percobaan21_noImgPro/model\\vgg_16_21-saved-model-01-acc-0.14.hdf5\n",
            "4/4 [==============================] - 87s 24s/step - loss: 2.3079 - acc: 0.3510 - val_loss: 8.2195 - val_acc: 0.1429\n",
            "Epoch 2/32\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2725 - acc: 0.5551 \n",
            "Epoch 2: val_acc improved from 0.14286 to 0.32857, saving model to percobaan21_noImgPro/model\\vgg_16_21-saved-model-02-acc-0.33.hdf5\n",
            "4/4 [==============================] - 85s 22s/step - loss: 1.2725 - acc: 0.5551 - val_loss: 3.9490 - val_acc: 0.3286\n",
            "Epoch 3/32\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9624 - acc: 0.6592 \n",
            "Epoch 3: val_acc did not improve from 0.32857\n",
            "4/4 [==============================] - 86s 23s/step - loss: 0.9624 - acc: 0.6592 - val_loss: 7.7078 - val_acc: 0.1571\n",
            "Epoch 4/32\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8351 - acc: 0.7143 \n",
            "Epoch 4: val_acc did not improve from 0.32857\n",
            "4/4 [==============================] - 85s 22s/step - loss: 0.8351 - acc: 0.7143 - val_loss: 10.1793 - val_acc: 0.2571\n",
            "Epoch 5/32\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7055 - acc: 0.7408 \n",
            "Epoch 5: val_acc did not improve from 0.32857\n",
            "4/4 [==============================] - 86s 24s/step - loss: 0.7055 - acc: 0.7408 - val_loss: 9.2671 - val_acc: 0.2500\n",
            "Epoch 6/32\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5057 - acc: 0.8367 \n",
            "Epoch 6: val_acc did not improve from 0.32857\n",
            "4/4 [==============================] - 85s 22s/step - loss: 0.5057 - acc: 0.8367 - val_loss: 8.1583 - val_acc: 0.2857\n",
            "Epoch 7/32\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5078 - acc: 0.8327 \n",
            "Epoch 7: val_acc did not improve from 0.32857\n",
            "4/4 [==============================] - 85s 23s/step - loss: 0.5078 - acc: 0.8327 - val_loss: 7.5694 - val_acc: 0.1857\n",
            "\n",
            "\n",
            "Model Accuracy 0.15714285714285714\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.00      0.00      0.00        10\n",
            "       10000       0.00      0.00      0.00        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.00      0.00      0.00        10\n",
            "       20000       0.16      1.00      0.27        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       0.17      0.10      0.12        10\n",
            "\n",
            "    accuracy                           0.16        70\n",
            "   macro avg       0.05      0.16      0.06        70\n",
            "weighted avg       0.05      0.16      0.06        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 22 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 30\n",
            "learning rate: 0.03341344754006047\n",
            "batch size: 128\n",
            "dropout rate: 0.6409141666625097\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/30\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.6189 - acc: 0.3163 \n",
            "Epoch 1: val_acc improved from -inf to 0.18571, saving model to percobaan22_noImgPro/model\\vgg_16_22-saved-model-01-acc-0.19.hdf5\n",
            "4/4 [==============================] - 86s 22s/step - loss: 2.6189 - acc: 0.3163 - val_loss: 6.5366 - val_acc: 0.1857\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.4395 - acc: 0.5082 \n",
            "Epoch 2: val_acc improved from 0.18571 to 0.23571, saving model to percobaan22_noImgPro/model\\vgg_16_22-saved-model-02-acc-0.24.hdf5\n",
            "4/4 [==============================] - 84s 22s/step - loss: 1.4395 - acc: 0.5082 - val_loss: 5.4314 - val_acc: 0.2357\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.3033 - acc: 0.5469 \n",
            "Epoch 3: val_acc improved from 0.23571 to 0.24286, saving model to percobaan22_noImgPro/model\\vgg_16_22-saved-model-03-acc-0.24.hdf5\n",
            "4/4 [==============================] - 84s 22s/step - loss: 1.3033 - acc: 0.5469 - val_loss: 4.0312 - val_acc: 0.2429\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0822 - acc: 0.6306 \n",
            "Epoch 4: val_acc did not improve from 0.24286\n",
            "4/4 [==============================] - 84s 22s/step - loss: 1.0822 - acc: 0.6306 - val_loss: 4.9762 - val_acc: 0.2143\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8810 - acc: 0.6633 \n",
            "Epoch 5: val_acc did not improve from 0.24286\n",
            "4/4 [==============================] - 84s 22s/step - loss: 0.8810 - acc: 0.6633 - val_loss: 5.0626 - val_acc: 0.1929\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7992 - acc: 0.7082 \n",
            "Epoch 6: val_acc did not improve from 0.24286\n",
            "4/4 [==============================] - 84s 22s/step - loss: 0.7992 - acc: 0.7082 - val_loss: 4.1183 - val_acc: 0.1857\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7528 - acc: 0.7286 \n",
            "Epoch 7: val_acc improved from 0.24286 to 0.34286, saving model to percobaan22_noImgPro/model\\vgg_16_22-saved-model-07-acc-0.34.hdf5\n",
            "4/4 [==============================] - 84s 23s/step - loss: 0.7528 - acc: 0.7286 - val_loss: 2.1784 - val_acc: 0.3429\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5554 - acc: 0.7980 \n",
            "Epoch 8: val_acc improved from 0.34286 to 0.45000, saving model to percobaan22_noImgPro/model\\vgg_16_22-saved-model-08-acc-0.45.hdf5\n",
            "4/4 [==============================] - 84s 23s/step - loss: 0.5554 - acc: 0.7980 - val_loss: 1.5724 - val_acc: 0.4500\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6039 - acc: 0.7653 \n",
            "Epoch 9: val_acc did not improve from 0.45000\n",
            "4/4 [==============================] - 85s 22s/step - loss: 0.6039 - acc: 0.7653 - val_loss: 1.7837 - val_acc: 0.4071\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4509 - acc: 0.8490 \n",
            "Epoch 10: val_acc did not improve from 0.45000\n",
            "4/4 [==============================] - 84s 22s/step - loss: 0.4509 - acc: 0.8490 - val_loss: 1.7531 - val_acc: 0.4357\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3935 - acc: 0.8612 \n",
            "Epoch 11: val_acc did not improve from 0.45000\n",
            "4/4 [==============================] - 84s 22s/step - loss: 0.3935 - acc: 0.8612 - val_loss: 1.9495 - val_acc: 0.4000\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5077 - acc: 0.8449 \n",
            "Epoch 12: val_acc did not improve from 0.45000\n",
            "4/4 [==============================] - 83s 23s/step - loss: 0.5077 - acc: 0.8449 - val_loss: 2.7025 - val_acc: 0.3143\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4091 - acc: 0.8592 \n",
            "Epoch 13: val_acc did not improve from 0.45000\n",
            "4/4 [==============================] - 84s 23s/step - loss: 0.4091 - acc: 0.8592 - val_loss: 2.6055 - val_acc: 0.3571\n",
            "\n",
            "\n",
            "Model Accuracy 0.3142857142857143\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.30      0.46        10\n",
            "       10000       0.00      0.00      0.00        10\n",
            "      100000       1.00      0.10      0.18        10\n",
            "        2000       0.00      0.00      0.00        10\n",
            "       20000       0.21      0.90      0.35        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       0.38      0.90      0.53        10\n",
            "\n",
            "    accuracy                           0.31        70\n",
            "   macro avg       0.37      0.31      0.22        70\n",
            "weighted avg       0.37      0.31      0.22        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 23 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 30\n",
            "learning rate: 0.03475828415470619\n",
            "batch size: 128\n",
            "dropout rate: 0.655559140376386\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/30\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.5194 - acc: 0.3306 \n",
            "Epoch 1: val_acc improved from -inf to 0.21429, saving model to percobaan23_noImgPro/model\\vgg_16_23-saved-model-01-acc-0.21.hdf5\n",
            "4/4 [==============================] - 85s 22s/step - loss: 2.5194 - acc: 0.3306 - val_loss: 4.9873 - val_acc: 0.2143\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.5120 - acc: 0.4939 \n",
            "Epoch 2: val_acc did not improve from 0.21429\n",
            "4/4 [==============================] - 84s 22s/step - loss: 1.5120 - acc: 0.4939 - val_loss: 5.8066 - val_acc: 0.1500\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2526 - acc: 0.5837 \n",
            "Epoch 3: val_acc improved from 0.21429 to 0.28571, saving model to percobaan23_noImgPro/model\\vgg_16_23-saved-model-03-acc-0.29.hdf5\n",
            "4/4 [==============================] - 84s 22s/step - loss: 1.2526 - acc: 0.5837 - val_loss: 3.7666 - val_acc: 0.2857\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1742 - acc: 0.6163 \n",
            "Epoch 4: val_acc improved from 0.28571 to 0.31429, saving model to percobaan23_noImgPro/model\\vgg_16_23-saved-model-04-acc-0.31.hdf5\n",
            "4/4 [==============================] - 84s 22s/step - loss: 1.1742 - acc: 0.6163 - val_loss: 3.7323 - val_acc: 0.3143\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0704 - acc: 0.6388 \n",
            "Epoch 5: val_acc did not improve from 0.31429\n",
            "4/4 [==============================] - 84s 22s/step - loss: 1.0704 - acc: 0.6388 - val_loss: 4.2674 - val_acc: 0.2357\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8253 - acc: 0.6980 \n",
            "Epoch 6: val_acc did not improve from 0.31429\n",
            "4/4 [==============================] - 84s 22s/step - loss: 0.8253 - acc: 0.6980 - val_loss: 5.1020 - val_acc: 0.2071\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7303 - acc: 0.7327 \n",
            "Epoch 7: val_acc did not improve from 0.31429\n",
            "4/4 [==============================] - 84s 22s/step - loss: 0.7303 - acc: 0.7327 - val_loss: 5.7035 - val_acc: 0.2143\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7006 - acc: 0.7429 \n",
            "Epoch 8: val_acc did not improve from 0.31429\n",
            "4/4 [==============================] - 84s 22s/step - loss: 0.7006 - acc: 0.7429 - val_loss: 5.4107 - val_acc: 0.2000\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6146 - acc: 0.7776 \n",
            "Epoch 9: val_acc did not improve from 0.31429\n",
            "4/4 [==============================] - 84s 22s/step - loss: 0.6146 - acc: 0.7776 - val_loss: 4.4285 - val_acc: 0.2357\n",
            "\n",
            "\n",
            "Model Accuracy 0.24285714285714285\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.80      0.40      0.53        10\n",
            "       10000       1.00      0.10      0.18        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.00      0.00      0.00        10\n",
            "       20000       0.16      1.00      0.28        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       1.00      0.20      0.33        10\n",
            "\n",
            "    accuracy                           0.24        70\n",
            "   macro avg       0.42      0.24      0.19        70\n",
            "weighted avg       0.42      0.24      0.19        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 24 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 37\n",
            "learning rate: 0.045757894416961285\n",
            "batch size: 128\n",
            "dropout rate: 0.7887693764347964\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 3.4563 - acc: 0.2245 \n",
            "Epoch 1: val_acc improved from -inf to 0.21429, saving model to percobaan24_noImgPro/model\\vgg_16_24-saved-model-01-acc-0.21.hdf5\n",
            "4/4 [==============================] - 88s 24s/step - loss: 3.4563 - acc: 0.2245 - val_loss: 7.1097 - val_acc: 0.2143\n",
            "Epoch 2/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.3828 - acc: 0.3592 \n",
            "Epoch 2: val_acc did not improve from 0.21429\n",
            "4/4 [==============================] - 86s 24s/step - loss: 2.3828 - acc: 0.3592 - val_loss: 7.7801 - val_acc: 0.1643\n",
            "Epoch 3/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.1338 - acc: 0.3551 \n",
            "Epoch 3: val_acc improved from 0.21429 to 0.27857, saving model to percobaan24_noImgPro/model\\vgg_16_24-saved-model-03-acc-0.28.hdf5\n",
            "4/4 [==============================] - 88s 23s/step - loss: 2.1338 - acc: 0.3551 - val_loss: 4.3741 - val_acc: 0.2786\n",
            "Epoch 4/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.9953 - acc: 0.3714 \n",
            "Epoch 4: val_acc did not improve from 0.27857\n",
            "4/4 [==============================] - 89s 23s/step - loss: 1.9953 - acc: 0.3714 - val_loss: 4.4224 - val_acc: 0.2071\n",
            "Epoch 5/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.6606 - acc: 0.4510 \n",
            "Epoch 5: val_acc did not improve from 0.27857\n",
            "4/4 [==============================] - 84s 22s/step - loss: 1.6606 - acc: 0.4510 - val_loss: 4.4216 - val_acc: 0.1786\n",
            "Epoch 6/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.5100 - acc: 0.4898 \n",
            "Epoch 6: val_acc did not improve from 0.27857\n",
            "4/4 [==============================] - 84s 22s/step - loss: 1.5100 - acc: 0.4898 - val_loss: 3.6261 - val_acc: 0.2500\n",
            "Epoch 7/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2655 - acc: 0.5388 \n",
            "Epoch 7: val_acc did not improve from 0.27857\n",
            "4/4 [==============================] - 84s 22s/step - loss: 1.2655 - acc: 0.5388 - val_loss: 3.6141 - val_acc: 0.2643\n",
            "Epoch 8/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2203 - acc: 0.5633 \n",
            "Epoch 8: val_acc improved from 0.27857 to 0.30000, saving model to percobaan24_noImgPro/model\\vgg_16_24-saved-model-08-acc-0.30.hdf5\n",
            "4/4 [==============================] - 85s 23s/step - loss: 1.2203 - acc: 0.5633 - val_loss: 2.8750 - val_acc: 0.3000\n",
            "Epoch 9/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1913 - acc: 0.5837 \n",
            "Epoch 9: val_acc improved from 0.30000 to 0.34286, saving model to percobaan24_noImgPro/model\\vgg_16_24-saved-model-09-acc-0.34.hdf5\n",
            "4/4 [==============================] - 84s 22s/step - loss: 1.1913 - acc: 0.5837 - val_loss: 2.4468 - val_acc: 0.3429\n",
            "Epoch 10/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0701 - acc: 0.6204 \n",
            "Epoch 10: val_acc improved from 0.34286 to 0.36429, saving model to percobaan24_noImgPro/model\\vgg_16_24-saved-model-10-acc-0.36.hdf5\n",
            "4/4 [==============================] - 84s 23s/step - loss: 1.0701 - acc: 0.6204 - val_loss: 2.2554 - val_acc: 0.3643\n",
            "Epoch 11/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9526 - acc: 0.6429 \n",
            "Epoch 11: val_acc improved from 0.36429 to 0.39286, saving model to percobaan24_noImgPro/model\\vgg_16_24-saved-model-11-acc-0.39.hdf5\n",
            "4/4 [==============================] - 84s 22s/step - loss: 0.9526 - acc: 0.6429 - val_loss: 2.3232 - val_acc: 0.3929\n",
            "Epoch 12/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0170 - acc: 0.6388 \n",
            "Epoch 12: val_acc did not improve from 0.39286\n",
            "4/4 [==============================] - 84s 22s/step - loss: 1.0170 - acc: 0.6388 - val_loss: 2.4979 - val_acc: 0.3500\n",
            "Epoch 13/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8685 - acc: 0.6918 \n",
            "Epoch 13: val_acc improved from 0.39286 to 0.45714, saving model to percobaan24_noImgPro/model\\vgg_16_24-saved-model-13-acc-0.46.hdf5\n",
            "4/4 [==============================] - 84s 22s/step - loss: 0.8685 - acc: 0.6918 - val_loss: 2.1074 - val_acc: 0.4571\n",
            "Epoch 14/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8594 - acc: 0.6735 \n",
            "Epoch 14: val_acc improved from 0.45714 to 0.50000, saving model to percobaan24_noImgPro/model\\vgg_16_24-saved-model-14-acc-0.50.hdf5\n",
            "4/4 [==============================] - 84s 22s/step - loss: 0.8594 - acc: 0.6735 - val_loss: 1.9251 - val_acc: 0.5000\n",
            "Epoch 15/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8930 - acc: 0.6776 \n",
            "Epoch 15: val_acc did not improve from 0.50000\n",
            "4/4 [==============================] - 84s 23s/step - loss: 0.8930 - acc: 0.6776 - val_loss: 2.0751 - val_acc: 0.4357\n",
            "Epoch 16/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7541 - acc: 0.7429 \n",
            "Epoch 16: val_acc did not improve from 0.50000\n",
            "4/4 [==============================] - 84s 23s/step - loss: 0.7541 - acc: 0.7429 - val_loss: 2.0957 - val_acc: 0.4357\n",
            "Epoch 17/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7240 - acc: 0.7449 \n",
            "Epoch 17: val_acc did not improve from 0.50000\n",
            "4/4 [==============================] - 84s 22s/step - loss: 0.7240 - acc: 0.7449 - val_loss: 1.8766 - val_acc: 0.4500\n",
            "Epoch 18/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6492 - acc: 0.7612 \n",
            "Epoch 18: val_acc improved from 0.50000 to 0.51429, saving model to percobaan24_noImgPro/model\\vgg_16_24-saved-model-18-acc-0.51.hdf5\n",
            "4/4 [==============================] - 84s 22s/step - loss: 0.6492 - acc: 0.7612 - val_loss: 1.6519 - val_acc: 0.5143\n",
            "Epoch 19/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6096 - acc: 0.7816 \n",
            "Epoch 19: val_acc improved from 0.51429 to 0.53571, saving model to percobaan24_noImgPro/model\\vgg_16_24-saved-model-19-acc-0.54.hdf5\n",
            "4/4 [==============================] - 84s 22s/step - loss: 0.6096 - acc: 0.7816 - val_loss: 1.7064 - val_acc: 0.5357\n",
            "Epoch 20/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6368 - acc: 0.7959 \n",
            "Epoch 20: val_acc did not improve from 0.53571\n",
            "4/4 [==============================] - 83s 23s/step - loss: 0.6368 - acc: 0.7959 - val_loss: 1.8890 - val_acc: 0.5000\n",
            "Epoch 21/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6609 - acc: 0.7510 \n",
            "Epoch 21: val_acc did not improve from 0.53571\n",
            "4/4 [==============================] - 84s 22s/step - loss: 0.6609 - acc: 0.7510 - val_loss: 1.7984 - val_acc: 0.4857\n",
            "Epoch 22/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6304 - acc: 0.7796 \n",
            "Epoch 22: val_acc did not improve from 0.53571\n",
            "4/4 [==============================] - 84s 22s/step - loss: 0.6304 - acc: 0.7796 - val_loss: 1.8643 - val_acc: 0.4571\n",
            "Epoch 23/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6593 - acc: 0.7633 \n",
            "Epoch 23: val_acc did not improve from 0.53571\n",
            "4/4 [==============================] - 84s 22s/step - loss: 0.6593 - acc: 0.7633 - val_loss: 1.5107 - val_acc: 0.5143\n",
            "Epoch 24/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5437 - acc: 0.8061 \n",
            "Epoch 24: val_acc did not improve from 0.53571\n",
            "4/4 [==============================] - 84s 23s/step - loss: 0.5437 - acc: 0.8061 - val_loss: 1.3171 - val_acc: 0.5286\n",
            "Epoch 25/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5424 - acc: 0.7816 \n",
            "Epoch 25: val_acc improved from 0.53571 to 0.57143, saving model to percobaan24_noImgPro/model\\vgg_16_24-saved-model-25-acc-0.57.hdf5\n",
            "4/4 [==============================] - 85s 22s/step - loss: 0.5424 - acc: 0.7816 - val_loss: 1.2702 - val_acc: 0.5714\n",
            "Epoch 26/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5623 - acc: 0.7980 \n",
            "Epoch 26: val_acc did not improve from 0.57143\n",
            "4/4 [==============================] - 84s 22s/step - loss: 0.5623 - acc: 0.7980 - val_loss: 1.6096 - val_acc: 0.4357\n",
            "Epoch 27/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5843 - acc: 0.7776 \n",
            "Epoch 27: val_acc improved from 0.57143 to 0.57857, saving model to percobaan24_noImgPro/model\\vgg_16_24-saved-model-27-acc-0.58.hdf5\n",
            "4/4 [==============================] - 84s 23s/step - loss: 0.5843 - acc: 0.7776 - val_loss: 1.2418 - val_acc: 0.5786\n",
            "Epoch 28/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5644 - acc: 0.8000 \n",
            "Epoch 28: val_acc improved from 0.57857 to 0.72857, saving model to percobaan24_noImgPro/model\\vgg_16_24-saved-model-28-acc-0.73.hdf5\n",
            "4/4 [==============================] - 86s 24s/step - loss: 0.5644 - acc: 0.8000 - val_loss: 0.7739 - val_acc: 0.7286\n",
            "Epoch 29/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5164 - acc: 0.8286 \n",
            "Epoch 29: val_acc did not improve from 0.72857\n",
            "4/4 [==============================] - 84s 23s/step - loss: 0.5164 - acc: 0.8286 - val_loss: 0.9173 - val_acc: 0.7071\n",
            "Epoch 30/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5222 - acc: 0.8204 \n",
            "Epoch 30: val_acc did not improve from 0.72857\n",
            "4/4 [==============================] - 84s 22s/step - loss: 0.5222 - acc: 0.8204 - val_loss: 1.2058 - val_acc: 0.6429\n",
            "Epoch 31/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4744 - acc: 0.8224 \n",
            "Epoch 31: val_acc did not improve from 0.72857\n",
            "4/4 [==============================] - 84s 22s/step - loss: 0.4744 - acc: 0.8224 - val_loss: 1.4222 - val_acc: 0.5714\n",
            "Epoch 32/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4963 - acc: 0.8224 \n",
            "Epoch 32: val_acc did not improve from 0.72857\n",
            "4/4 [==============================] - 85s 22s/step - loss: 0.4963 - acc: 0.8224 - val_loss: 1.2737 - val_acc: 0.6143\n",
            "Epoch 33/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4673 - acc: 0.8429 \n",
            "Epoch 33: val_acc did not improve from 0.72857\n",
            "4/4 [==============================] - 84s 23s/step - loss: 0.4673 - acc: 0.8429 - val_loss: 1.2292 - val_acc: 0.6500\n",
            "\n",
            "\n",
            "Model Accuracy 0.5428571428571428\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.40      0.57        10\n",
            "       10000       0.56      1.00      0.71        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.67      0.40      0.50        10\n",
            "       20000       0.57      0.40      0.47        10\n",
            "        5000       0.60      0.60      0.60        10\n",
            "       50000       0.40      1.00      0.57        10\n",
            "\n",
            "    accuracy                           0.54        70\n",
            "   macro avg       0.54      0.54      0.49        70\n",
            "weighted avg       0.54      0.54      0.49        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 25 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 37\n",
            "learning rate: 0.05827483055439125\n",
            "batch size: 32\n",
            "dropout rate: 0.5015267677516464\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/37\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.6584 - acc: 0.3490\n",
            "Epoch 1: val_acc improved from -inf to 0.31429, saving model to percobaan25_noImgPro/model\\vgg_16_25-saved-model-01-acc-0.31.hdf5\n",
            "16/16 [==============================] - 83s 5s/step - loss: 2.6584 - acc: 0.3490 - val_loss: 7.8724 - val_acc: 0.3143\n",
            "Epoch 2/37\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.7622 - acc: 0.4776\n",
            "Epoch 2: val_acc did not improve from 0.31429\n",
            "16/16 [==============================] - 82s 5s/step - loss: 1.7622 - acc: 0.4776 - val_loss: 8.7285 - val_acc: 0.1714\n",
            "Epoch 3/37\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3131 - acc: 0.5857\n",
            "Epoch 3: val_acc improved from 0.31429 to 0.35714, saving model to percobaan25_noImgPro/model\\vgg_16_25-saved-model-03-acc-0.36.hdf5\n",
            "16/16 [==============================] - 82s 5s/step - loss: 1.3131 - acc: 0.5857 - val_loss: 3.0958 - val_acc: 0.3571\n",
            "Epoch 4/37\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0194 - acc: 0.6551\n",
            "Epoch 4: val_acc did not improve from 0.35714\n",
            "16/16 [==============================] - 83s 5s/step - loss: 1.0194 - acc: 0.6551 - val_loss: 3.2998 - val_acc: 0.2714\n",
            "Epoch 5/37\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8200 - acc: 0.7143\n",
            "Epoch 5: val_acc improved from 0.35714 to 0.42143, saving model to percobaan25_noImgPro/model\\vgg_16_25-saved-model-05-acc-0.42.hdf5\n",
            "16/16 [==============================] - 83s 5s/step - loss: 0.8200 - acc: 0.7143 - val_loss: 1.8897 - val_acc: 0.4214\n",
            "Epoch 6/37\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8232 - acc: 0.7102\n",
            "Epoch 6: val_acc did not improve from 0.42143\n",
            "16/16 [==============================] - 82s 5s/step - loss: 0.8232 - acc: 0.7102 - val_loss: 2.5691 - val_acc: 0.3857\n",
            "Epoch 7/37\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7473 - acc: 0.7143\n",
            "Epoch 7: val_acc improved from 0.42143 to 0.55714, saving model to percobaan25_noImgPro/model\\vgg_16_25-saved-model-07-acc-0.56.hdf5\n",
            "16/16 [==============================] - 83s 5s/step - loss: 0.7473 - acc: 0.7143 - val_loss: 1.4613 - val_acc: 0.5571\n",
            "Epoch 8/37\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6244 - acc: 0.7776\n",
            "Epoch 8: val_acc improved from 0.55714 to 0.70714, saving model to percobaan25_noImgPro/model\\vgg_16_25-saved-model-08-acc-0.71.hdf5\n",
            "16/16 [==============================] - 82s 5s/step - loss: 0.6244 - acc: 0.7776 - val_loss: 1.2535 - val_acc: 0.7071\n",
            "Epoch 9/37\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6564 - acc: 0.7918\n",
            "Epoch 9: val_acc improved from 0.70714 to 0.73571, saving model to percobaan25_noImgPro/model\\vgg_16_25-saved-model-09-acc-0.74.hdf5\n",
            "16/16 [==============================] - 82s 5s/step - loss: 0.6564 - acc: 0.7918 - val_loss: 1.0344 - val_acc: 0.7357\n",
            "Epoch 10/37\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6402 - acc: 0.7816\n",
            "Epoch 10: val_acc did not improve from 0.73571\n",
            "16/16 [==============================] - 82s 5s/step - loss: 0.6402 - acc: 0.7816 - val_loss: 1.1194 - val_acc: 0.6643\n",
            "Epoch 11/37\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8150 - acc: 0.7776\n",
            "Epoch 11: val_acc did not improve from 0.73571\n",
            "16/16 [==============================] - 82s 5s/step - loss: 0.8150 - acc: 0.7776 - val_loss: 1.4903 - val_acc: 0.6857\n",
            "Epoch 12/37\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6843 - acc: 0.7837\n",
            "Epoch 12: val_acc did not improve from 0.73571\n",
            "16/16 [==============================] - 82s 5s/step - loss: 0.6843 - acc: 0.7837 - val_loss: 2.2253 - val_acc: 0.4571\n",
            "Epoch 13/37\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7154 - acc: 0.7898\n",
            "Epoch 13: val_acc did not improve from 0.73571\n",
            "16/16 [==============================] - 82s 5s/step - loss: 0.7154 - acc: 0.7898 - val_loss: 1.1563 - val_acc: 0.7214\n",
            "Epoch 14/37\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6568 - acc: 0.7837\n",
            "Epoch 14: val_acc did not improve from 0.73571\n",
            "16/16 [==============================] - 82s 5s/step - loss: 0.6568 - acc: 0.7837 - val_loss: 1.4929 - val_acc: 0.6500\n",
            "\n",
            "\n",
            "Model Accuracy 0.4857142857142857\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.75      0.30      0.43        10\n",
            "       10000       0.43      1.00      0.61        10\n",
            "      100000       1.00      0.20      0.33        10\n",
            "        2000       0.00      0.00      0.00        10\n",
            "       20000       0.45      0.90      0.60        10\n",
            "        5000       0.75      0.30      0.43        10\n",
            "       50000       0.47      0.70      0.56        10\n",
            "\n",
            "    accuracy                           0.49        70\n",
            "   macro avg       0.55      0.49      0.42        70\n",
            "weighted avg       0.55      0.49      0.42        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 26 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 38\n",
            "learning rate: 0.07063293700174911\n",
            "batch size: 32\n",
            "dropout rate: 0.6427231094011517\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 3.7654 - acc: 0.2327\n",
            "Epoch 1: val_acc improved from -inf to 0.27857, saving model to percobaan26_noImgPro/model\\vgg_16_26-saved-model-01-acc-0.28.hdf5\n",
            "16/16 [==============================] - 82s 5s/step - loss: 3.7654 - acc: 0.2327 - val_loss: 6.3996 - val_acc: 0.2786\n",
            "Epoch 2/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.4807 - acc: 0.3469\n",
            "Epoch 2: val_acc improved from 0.27857 to 0.30714, saving model to percobaan26_noImgPro/model\\vgg_16_26-saved-model-02-acc-0.31.hdf5\n",
            "16/16 [==============================] - 82s 5s/step - loss: 2.4807 - acc: 0.3469 - val_loss: 1.7650 - val_acc: 0.3071\n",
            "Epoch 3/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.8380 - acc: 0.3959\n",
            "Epoch 3: val_acc improved from 0.30714 to 0.37857, saving model to percobaan26_noImgPro/model\\vgg_16_26-saved-model-03-acc-0.38.hdf5\n",
            "16/16 [==============================] - 82s 5s/step - loss: 1.8380 - acc: 0.3959 - val_loss: 1.6951 - val_acc: 0.3786\n",
            "Epoch 4/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.4471 - acc: 0.4959\n",
            "Epoch 4: val_acc improved from 0.37857 to 0.50714, saving model to percobaan26_noImgPro/model\\vgg_16_26-saved-model-04-acc-0.51.hdf5\n",
            "16/16 [==============================] - 82s 5s/step - loss: 1.4471 - acc: 0.4959 - val_loss: 1.4927 - val_acc: 0.5071\n",
            "Epoch 5/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3738 - acc: 0.5327\n",
            "Epoch 5: val_acc did not improve from 0.50714\n",
            "16/16 [==============================] - 82s 5s/step - loss: 1.3738 - acc: 0.5327 - val_loss: 1.4902 - val_acc: 0.4714\n",
            "Epoch 6/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2737 - acc: 0.5449\n",
            "Epoch 6: val_acc did not improve from 0.50714\n",
            "16/16 [==============================] - 81s 5s/step - loss: 1.2737 - acc: 0.5449 - val_loss: 1.9608 - val_acc: 0.2929\n",
            "Epoch 7/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1733 - acc: 0.5837\n",
            "Epoch 7: val_acc did not improve from 0.50714\n",
            "16/16 [==============================] - 81s 5s/step - loss: 1.1733 - acc: 0.5837 - val_loss: 1.7009 - val_acc: 0.4429\n",
            "Epoch 8/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0706 - acc: 0.6490\n",
            "Epoch 8: val_acc did not improve from 0.50714\n",
            "16/16 [==============================] - 81s 5s/step - loss: 1.0706 - acc: 0.6490 - val_loss: 2.1433 - val_acc: 0.3429\n",
            "Epoch 9/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9911 - acc: 0.6408\n",
            "Epoch 9: val_acc did not improve from 0.50714\n",
            "16/16 [==============================] - 79s 5s/step - loss: 0.9911 - acc: 0.6408 - val_loss: 2.1745 - val_acc: 0.4714\n",
            "Epoch 10/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0823 - acc: 0.6163\n",
            "Epoch 10: val_acc did not improve from 0.50714\n",
            "16/16 [==============================] - 80s 5s/step - loss: 1.0823 - acc: 0.6163 - val_loss: 1.9486 - val_acc: 0.4429\n",
            "\n",
            "\n",
            "Model Accuracy 0.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.20      0.33        10\n",
            "       10000       0.00      0.00      0.00        10\n",
            "      100000       1.00      0.10      0.18        10\n",
            "        2000       0.18      1.00      0.31        10\n",
            "       20000       0.00      0.00      0.00        10\n",
            "        5000       1.00      0.10      0.18        10\n",
            "       50000       0.70      0.70      0.70        10\n",
            "\n",
            "    accuracy                           0.30        70\n",
            "   macro avg       0.55      0.30      0.24        70\n",
            "weighted avg       0.55      0.30      0.24        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 27 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 33\n",
            "learning rate: 0.051464393031196\n",
            "batch size: 32\n",
            "dropout rate: 0.7143158810350841\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/33\n",
            "16/16 [==============================] - ETA: 0s - loss: 3.6250 - acc: 0.2612\n",
            "Epoch 1: val_acc improved from -inf to 0.14286, saving model to percobaan27_noImgPro/model\\vgg_16_27-saved-model-01-acc-0.14.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 3.6250 - acc: 0.2612 - val_loss: 7.4491 - val_acc: 0.1429\n",
            "Epoch 2/33\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.5185 - acc: 0.3265\n",
            "Epoch 2: val_acc improved from 0.14286 to 0.27143, saving model to percobaan27_noImgPro/model\\vgg_16_27-saved-model-02-acc-0.27.hdf5\n",
            "16/16 [==============================] - 79s 5s/step - loss: 2.5185 - acc: 0.3265 - val_loss: 2.7479 - val_acc: 0.2714\n",
            "Epoch 3/33\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.8125 - acc: 0.4265\n",
            "Epoch 3: val_acc did not improve from 0.27143\n",
            "16/16 [==============================] - 78s 5s/step - loss: 1.8125 - acc: 0.4265 - val_loss: 2.5194 - val_acc: 0.2214\n",
            "Epoch 4/33\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.5130 - acc: 0.4510\n",
            "Epoch 4: val_acc improved from 0.27143 to 0.43571, saving model to percobaan27_noImgPro/model\\vgg_16_27-saved-model-04-acc-0.44.hdf5\n",
            "16/16 [==============================] - 78s 5s/step - loss: 1.5130 - acc: 0.4510 - val_loss: 1.7601 - val_acc: 0.4357\n",
            "Epoch 5/33\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3058 - acc: 0.5245\n",
            "Epoch 5: val_acc did not improve from 0.43571\n",
            "16/16 [==============================] - 76s 5s/step - loss: 1.3058 - acc: 0.5245 - val_loss: 2.0376 - val_acc: 0.3071\n",
            "Epoch 6/33\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2833 - acc: 0.5388\n",
            "Epoch 6: val_acc improved from 0.43571 to 0.52143, saving model to percobaan27_noImgPro/model\\vgg_16_27-saved-model-06-acc-0.52.hdf5\n",
            "16/16 [==============================] - 79s 5s/step - loss: 1.2833 - acc: 0.5388 - val_loss: 1.2062 - val_acc: 0.5214\n",
            "Epoch 7/33\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1881 - acc: 0.5776\n",
            "Epoch 7: val_acc did not improve from 0.52143\n",
            "16/16 [==============================] - 76s 5s/step - loss: 1.1881 - acc: 0.5776 - val_loss: 1.9864 - val_acc: 0.2357\n",
            "Epoch 8/33\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0825 - acc: 0.6102\n",
            "Epoch 8: val_acc did not improve from 0.52143\n",
            "16/16 [==============================] - 77s 5s/step - loss: 1.0825 - acc: 0.6102 - val_loss: 1.3473 - val_acc: 0.4500\n",
            "Epoch 9/33\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9692 - acc: 0.6510\n",
            "Epoch 9: val_acc improved from 0.52143 to 0.72143, saving model to percobaan27_noImgPro/model\\vgg_16_27-saved-model-09-acc-0.72.hdf5\n",
            "16/16 [==============================] - 76s 5s/step - loss: 0.9692 - acc: 0.6510 - val_loss: 0.8778 - val_acc: 0.7214\n",
            "Epoch 10/33\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9986 - acc: 0.6469\n",
            "Epoch 10: val_acc did not improve from 0.72143\n",
            "16/16 [==============================] - 76s 5s/step - loss: 0.9986 - acc: 0.6469 - val_loss: 0.8978 - val_acc: 0.6357\n",
            "Epoch 11/33\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0948 - acc: 0.6612\n",
            "Epoch 11: val_acc did not improve from 0.72143\n",
            "16/16 [==============================] - 77s 5s/step - loss: 1.0948 - acc: 0.6612 - val_loss: 1.2462 - val_acc: 0.5714\n",
            "Epoch 12/33\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1522 - acc: 0.6367\n",
            "Epoch 12: val_acc did not improve from 0.72143\n",
            "16/16 [==============================] - 76s 5s/step - loss: 1.1522 - acc: 0.6367 - val_loss: 1.0611 - val_acc: 0.6571\n",
            "Epoch 13/33\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0067 - acc: 0.7000\n",
            "Epoch 13: val_acc improved from 0.72143 to 0.80000, saving model to percobaan27_noImgPro/model\\vgg_16_27-saved-model-13-acc-0.80.hdf5\n",
            "16/16 [==============================] - 76s 5s/step - loss: 1.0067 - acc: 0.7000 - val_loss: 0.6686 - val_acc: 0.8000\n",
            "Epoch 14/33\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9395 - acc: 0.6796\n",
            "Epoch 14: val_acc improved from 0.80000 to 0.82143, saving model to percobaan27_noImgPro/model\\vgg_16_27-saved-model-14-acc-0.82.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.9395 - acc: 0.6796 - val_loss: 0.6096 - val_acc: 0.8214\n",
            "Epoch 15/33\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8751 - acc: 0.7286\n",
            "Epoch 15: val_acc did not improve from 0.82143\n",
            "16/16 [==============================] - 76s 5s/step - loss: 0.8751 - acc: 0.7286 - val_loss: 0.7801 - val_acc: 0.7714\n",
            "Epoch 16/33\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8836 - acc: 0.7102\n",
            "Epoch 16: val_acc improved from 0.82143 to 0.82857, saving model to percobaan27_noImgPro/model\\vgg_16_27-saved-model-16-acc-0.83.hdf5\n",
            "16/16 [==============================] - 76s 5s/step - loss: 0.8836 - acc: 0.7102 - val_loss: 0.5991 - val_acc: 0.8286\n",
            "Epoch 17/33\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9056 - acc: 0.7041\n",
            "Epoch 17: val_acc did not improve from 0.82857\n",
            "16/16 [==============================] - 76s 5s/step - loss: 0.9056 - acc: 0.7041 - val_loss: 0.6486 - val_acc: 0.8214\n",
            "Epoch 18/33\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9187 - acc: 0.6878\n",
            "Epoch 18: val_acc did not improve from 0.82857\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.9187 - acc: 0.6878 - val_loss: 0.8315 - val_acc: 0.7786\n",
            "Epoch 19/33\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8054 - acc: 0.7429\n",
            "Epoch 19: val_acc did not improve from 0.82857\n",
            "16/16 [==============================] - 76s 5s/step - loss: 0.8054 - acc: 0.7429 - val_loss: 0.8230 - val_acc: 0.8286\n",
            "Epoch 20/33\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8026 - acc: 0.7408\n",
            "Epoch 20: val_acc did not improve from 0.82857\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.8026 - acc: 0.7408 - val_loss: 1.0668 - val_acc: 0.7786\n",
            "Epoch 21/33\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9953 - acc: 0.7143\n",
            "Epoch 21: val_acc did not improve from 0.82857\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.9953 - acc: 0.7143 - val_loss: 0.7618 - val_acc: 0.8071\n",
            "\n",
            "\n",
            "Model Accuracy 0.7\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.40      0.57        10\n",
            "       10000       0.62      1.00      0.77        10\n",
            "      100000       0.90      0.90      0.90        10\n",
            "        2000       1.00      0.50      0.67        10\n",
            "       20000       0.62      0.50      0.56        10\n",
            "        5000       0.88      0.70      0.78        10\n",
            "       50000       0.47      0.90      0.62        10\n",
            "\n",
            "    accuracy                           0.70        70\n",
            "   macro avg       0.79      0.70      0.69        70\n",
            "weighted avg       0.79      0.70      0.69        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 28 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 38\n",
            "learning rate: 0.05768953263683754\n",
            "batch size: 32\n",
            "dropout rate: 0.7610157755692729\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 4.0687 - acc: 0.2490\n",
            "Epoch 1: val_acc improved from -inf to 0.35000, saving model to percobaan28_noImgPro/model\\vgg_16_28-saved-model-01-acc-0.35.hdf5\n",
            "16/16 [==============================] - 76s 5s/step - loss: 4.0687 - acc: 0.2490 - val_loss: 3.9937 - val_acc: 0.3500\n",
            "Epoch 2/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.9521 - acc: 0.2837\n",
            "Epoch 2: val_acc did not improve from 0.35000\n",
            "16/16 [==============================] - 76s 5s/step - loss: 2.9521 - acc: 0.2837 - val_loss: 2.5060 - val_acc: 0.3143\n",
            "Epoch 3/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.0784 - acc: 0.3306\n",
            "Epoch 3: val_acc improved from 0.35000 to 0.35714, saving model to percobaan28_noImgPro/model\\vgg_16_28-saved-model-03-acc-0.36.hdf5\n",
            "16/16 [==============================] - 76s 5s/step - loss: 2.0784 - acc: 0.3306 - val_loss: 1.7166 - val_acc: 0.3571\n",
            "Epoch 4/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.7093 - acc: 0.4286\n",
            "Epoch 4: val_acc improved from 0.35714 to 0.39286, saving model to percobaan28_noImgPro/model\\vgg_16_28-saved-model-04-acc-0.39.hdf5\n",
            "16/16 [==============================] - 76s 5s/step - loss: 1.7093 - acc: 0.4286 - val_loss: 1.4744 - val_acc: 0.3929\n",
            "Epoch 5/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.5140 - acc: 0.4531\n",
            "Epoch 5: val_acc improved from 0.39286 to 0.44286, saving model to percobaan28_noImgPro/model\\vgg_16_28-saved-model-05-acc-0.44.hdf5\n",
            "16/16 [==============================] - 76s 5s/step - loss: 1.5140 - acc: 0.4531 - val_loss: 1.4244 - val_acc: 0.4429\n",
            "Epoch 6/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.4897 - acc: 0.4959\n",
            "Epoch 6: val_acc did not improve from 0.44286\n",
            "16/16 [==============================] - 75s 5s/step - loss: 1.4897 - acc: 0.4959 - val_loss: 1.5690 - val_acc: 0.4143\n",
            "Epoch 7/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3046 - acc: 0.5122\n",
            "Epoch 7: val_acc improved from 0.44286 to 0.52143, saving model to percobaan28_noImgPro/model\\vgg_16_28-saved-model-07-acc-0.52.hdf5\n",
            "16/16 [==============================] - 76s 5s/step - loss: 1.3046 - acc: 0.5122 - val_loss: 1.2775 - val_acc: 0.5214\n",
            "Epoch 8/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2753 - acc: 0.5347\n",
            "Epoch 8: val_acc improved from 0.52143 to 0.66429, saving model to percobaan28_noImgPro/model\\vgg_16_28-saved-model-08-acc-0.66.hdf5\n",
            "16/16 [==============================] - 75s 5s/step - loss: 1.2753 - acc: 0.5347 - val_loss: 1.0759 - val_acc: 0.6643\n",
            "Epoch 9/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3145 - acc: 0.5469\n",
            "Epoch 9: val_acc did not improve from 0.66429\n",
            "16/16 [==============================] - 75s 5s/step - loss: 1.3145 - acc: 0.5469 - val_loss: 1.4403 - val_acc: 0.5286\n",
            "Epoch 10/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1973 - acc: 0.5612\n",
            "Epoch 10: val_acc did not improve from 0.66429\n",
            "16/16 [==============================] - 75s 5s/step - loss: 1.1973 - acc: 0.5612 - val_loss: 1.4619 - val_acc: 0.4857\n",
            "Epoch 11/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1775 - acc: 0.6102\n",
            "Epoch 11: val_acc improved from 0.66429 to 0.76429, saving model to percobaan28_noImgPro/model\\vgg_16_28-saved-model-11-acc-0.76.hdf5\n",
            "16/16 [==============================] - 75s 5s/step - loss: 1.1775 - acc: 0.6102 - val_loss: 0.8362 - val_acc: 0.7643\n",
            "Epoch 12/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0554 - acc: 0.6143\n",
            "Epoch 12: val_acc did not improve from 0.76429\n",
            "16/16 [==============================] - 75s 5s/step - loss: 1.0554 - acc: 0.6143 - val_loss: 1.1926 - val_acc: 0.5214\n",
            "Epoch 13/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2712 - acc: 0.5857\n",
            "Epoch 13: val_acc did not improve from 0.76429\n",
            "16/16 [==============================] - 75s 5s/step - loss: 1.2712 - acc: 0.5857 - val_loss: 1.0412 - val_acc: 0.6429\n",
            "Epoch 14/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2284 - acc: 0.6143\n",
            "Epoch 14: val_acc did not improve from 0.76429\n",
            "16/16 [==============================] - 75s 5s/step - loss: 1.2284 - acc: 0.6143 - val_loss: 1.1373 - val_acc: 0.5786\n",
            "Epoch 15/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1479 - acc: 0.6429\n",
            "Epoch 15: val_acc did not improve from 0.76429\n",
            "16/16 [==============================] - 75s 5s/step - loss: 1.1479 - acc: 0.6429 - val_loss: 0.9660 - val_acc: 0.7357\n",
            "Epoch 16/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1181 - acc: 0.6265\n",
            "Epoch 16: val_acc did not improve from 0.76429\n",
            "16/16 [==============================] - 75s 5s/step - loss: 1.1181 - acc: 0.6265 - val_loss: 1.0338 - val_acc: 0.7143\n",
            "\n",
            "\n",
            "Model Accuracy 0.7\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.20      0.33        10\n",
            "       10000       0.90      0.90      0.90        10\n",
            "      100000       1.00      0.70      0.82        10\n",
            "        2000       0.86      0.60      0.71        10\n",
            "       20000       0.47      0.70      0.56        10\n",
            "        5000       0.53      1.00      0.69        10\n",
            "       50000       0.80      0.80      0.80        10\n",
            "\n",
            "    accuracy                           0.70        70\n",
            "   macro avg       0.79      0.70      0.69        70\n",
            "weighted avg       0.79      0.70      0.69        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 29 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 32\n",
            "learning rate: 0.07197588795574347\n",
            "batch size: 64\n",
            "dropout rate: 0.5053391241439382\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.9343 - acc: 0.2592\n",
            "Epoch 1: val_acc improved from -inf to 0.15000, saving model to percobaan29_noImgPro/model\\vgg_16_29-saved-model-01-acc-0.15.hdf5\n",
            "8/8 [==============================] - 77s 10s/step - loss: 2.9343 - acc: 0.2592 - val_loss: 16.1075 - val_acc: 0.1500\n",
            "Epoch 2/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7636 - acc: 0.4673\n",
            "Epoch 2: val_acc improved from 0.15000 to 0.33571, saving model to percobaan29_noImgPro/model\\vgg_16_29-saved-model-02-acc-0.34.hdf5\n",
            "8/8 [==============================] - 77s 10s/step - loss: 1.7636 - acc: 0.4673 - val_loss: 5.7817 - val_acc: 0.3357\n",
            "Epoch 3/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.2053 - acc: 0.6184\n",
            "Epoch 3: val_acc did not improve from 0.33571\n",
            "8/8 [==============================] - 78s 10s/step - loss: 1.2053 - acc: 0.6184 - val_loss: 5.7200 - val_acc: 0.2714\n",
            "Epoch 4/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9995 - acc: 0.6469\n",
            "Epoch 4: val_acc improved from 0.33571 to 0.50000, saving model to percobaan29_noImgPro/model\\vgg_16_29-saved-model-04-acc-0.50.hdf5\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.9995 - acc: 0.6469 - val_loss: 2.3920 - val_acc: 0.5000\n",
            "Epoch 5/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8168 - acc: 0.7224\n",
            "Epoch 5: val_acc did not improve from 0.50000\n",
            "8/8 [==============================] - 78s 10s/step - loss: 0.8168 - acc: 0.7224 - val_loss: 2.5296 - val_acc: 0.4071\n",
            "Epoch 6/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7715 - acc: 0.7367\n",
            "Epoch 6: val_acc did not improve from 0.50000\n",
            "8/8 [==============================] - 81s 10s/step - loss: 0.7715 - acc: 0.7367 - val_loss: 3.4164 - val_acc: 0.3286\n",
            "Epoch 7/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6535 - acc: 0.7776\n",
            "Epoch 7: val_acc did not improve from 0.50000\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.6535 - acc: 0.7776 - val_loss: 2.7100 - val_acc: 0.4000\n",
            "Epoch 8/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5828 - acc: 0.8061\n",
            "Epoch 8: val_acc did not improve from 0.50000\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.5828 - acc: 0.8061 - val_loss: 2.9621 - val_acc: 0.3214\n",
            "Epoch 9/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5421 - acc: 0.8224\n",
            "Epoch 9: val_acc did not improve from 0.50000\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.5421 - acc: 0.8224 - val_loss: 2.4623 - val_acc: 0.4643\n",
            "\n",
            "\n",
            "Model Accuracy 0.32857142857142857\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\2095710237.py:11: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
            "  plt.figure(figsize=(7,7))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.20      0.33        10\n",
            "       10000       0.58      0.70      0.64        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.50      0.30      0.37        10\n",
            "       20000       1.00      0.10      0.18        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       0.20      1.00      0.34        10\n",
            "\n",
            "    accuracy                           0.33        70\n",
            "   macro avg       0.47      0.33      0.27        70\n",
            "weighted avg       0.47      0.33      0.27        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 30 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 32\n",
            "learning rate: 0.052514880469720165\n",
            "batch size: 64\n",
            "dropout rate: 0.5772702507998597\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.6528 - acc: 0.3061\n",
            "Epoch 1: val_acc improved from -inf to 0.14286, saving model to percobaan30_noImgPro/model\\vgg_16_30-saved-model-01-acc-0.14.hdf5\n",
            "8/8 [==============================] - 77s 10s/step - loss: 2.6528 - acc: 0.3061 - val_loss: 11.2419 - val_acc: 0.1429\n",
            "Epoch 2/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7637 - acc: 0.4510\n",
            "Epoch 2: val_acc improved from 0.14286 to 0.23571, saving model to percobaan30_noImgPro/model\\vgg_16_30-saved-model-02-acc-0.24.hdf5\n",
            "8/8 [==============================] - 80s 10s/step - loss: 1.7637 - acc: 0.4510 - val_loss: 6.5774 - val_acc: 0.2357\n",
            "Epoch 3/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.2822 - acc: 0.5837\n",
            "Epoch 3: val_acc improved from 0.23571 to 0.34286, saving model to percobaan30_noImgPro/model\\vgg_16_30-saved-model-03-acc-0.34.hdf5\n",
            "8/8 [==============================] - 77s 10s/step - loss: 1.2822 - acc: 0.5837 - val_loss: 3.8502 - val_acc: 0.3429\n",
            "Epoch 4/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1097 - acc: 0.6020\n",
            "Epoch 4: val_acc improved from 0.34286 to 0.50000, saving model to percobaan30_noImgPro/model\\vgg_16_30-saved-model-04-acc-0.50.hdf5\n",
            "8/8 [==============================] - 78s 10s/step - loss: 1.1097 - acc: 0.6020 - val_loss: 2.4700 - val_acc: 0.5000\n",
            "Epoch 5/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8576 - acc: 0.6898\n",
            "Epoch 5: val_acc did not improve from 0.50000\n",
            "8/8 [==============================] - 78s 10s/step - loss: 0.8576 - acc: 0.6898 - val_loss: 2.5011 - val_acc: 0.3429\n",
            "Epoch 6/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7845 - acc: 0.6918\n",
            "Epoch 6: val_acc did not improve from 0.50000\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.7845 - acc: 0.6918 - val_loss: 2.2778 - val_acc: 0.3286\n",
            "Epoch 7/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6292 - acc: 0.8020\n",
            "Epoch 7: val_acc improved from 0.50000 to 0.57143, saving model to percobaan30_noImgPro/model\\vgg_16_30-saved-model-07-acc-0.57.hdf5\n",
            "8/8 [==============================] - 79s 11s/step - loss: 0.6292 - acc: 0.8020 - val_loss: 1.6236 - val_acc: 0.5714\n",
            "Epoch 8/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6329 - acc: 0.7776\n",
            "Epoch 8: val_acc did not improve from 0.57143\n",
            "8/8 [==============================] - 78s 10s/step - loss: 0.6329 - acc: 0.7776 - val_loss: 2.0514 - val_acc: 0.4429\n",
            "Epoch 9/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5231 - acc: 0.8245\n",
            "Epoch 9: val_acc did not improve from 0.57143\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.5231 - acc: 0.8245 - val_loss: 1.5356 - val_acc: 0.4786\n",
            "Epoch 10/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5175 - acc: 0.8143\n",
            "Epoch 10: val_acc improved from 0.57143 to 0.64286, saving model to percobaan30_noImgPro/model\\vgg_16_30-saved-model-10-acc-0.64.hdf5\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.5175 - acc: 0.8143 - val_loss: 1.3776 - val_acc: 0.6429\n",
            "Epoch 11/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5343 - acc: 0.8061\n",
            "Epoch 11: val_acc improved from 0.64286 to 0.67143, saving model to percobaan30_noImgPro/model\\vgg_16_30-saved-model-11-acc-0.67.hdf5\n",
            "8/8 [==============================] - 81s 10s/step - loss: 0.5343 - acc: 0.8061 - val_loss: 1.2177 - val_acc: 0.6714\n",
            "Epoch 12/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4316 - acc: 0.8327\n",
            "Epoch 12: val_acc did not improve from 0.67143\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.4316 - acc: 0.8327 - val_loss: 0.9615 - val_acc: 0.6357\n",
            "Epoch 13/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4515 - acc: 0.8449\n",
            "Epoch 13: val_acc did not improve from 0.67143\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.4515 - acc: 0.8449 - val_loss: 0.9235 - val_acc: 0.6643\n",
            "Epoch 14/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3348 - acc: 0.8735\n",
            "Epoch 14: val_acc improved from 0.67143 to 0.71429, saving model to percobaan30_noImgPro/model\\vgg_16_30-saved-model-14-acc-0.71.hdf5\n",
            "8/8 [==============================] - 76s 10s/step - loss: 0.3348 - acc: 0.8735 - val_loss: 0.8983 - val_acc: 0.7143\n",
            "Epoch 15/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4558 - acc: 0.8714\n",
            "Epoch 15: val_acc did not improve from 0.71429\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.4558 - acc: 0.8714 - val_loss: 0.9139 - val_acc: 0.7071\n",
            "Epoch 16/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3302 - acc: 0.9041\n",
            "Epoch 16: val_acc improved from 0.71429 to 0.80000, saving model to percobaan30_noImgPro/model\\vgg_16_30-saved-model-16-acc-0.80.hdf5\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.3302 - acc: 0.9041 - val_loss: 0.7462 - val_acc: 0.8000\n",
            "Epoch 17/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3560 - acc: 0.8755\n",
            "Epoch 17: val_acc did not improve from 0.80000\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.3560 - acc: 0.8755 - val_loss: 1.2840 - val_acc: 0.6429\n",
            "Epoch 18/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3813 - acc: 0.8714\n",
            "Epoch 18: val_acc did not improve from 0.80000\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.3813 - acc: 0.8714 - val_loss: 1.3855 - val_acc: 0.6286\n",
            "Epoch 19/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4153 - acc: 0.8531\n",
            "Epoch 19: val_acc did not improve from 0.80000\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.4153 - acc: 0.8531 - val_loss: 1.1206 - val_acc: 0.7214\n",
            "Epoch 20/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3804 - acc: 0.8673\n",
            "Epoch 20: val_acc improved from 0.80000 to 0.80714, saving model to percobaan30_noImgPro/model\\vgg_16_30-saved-model-20-acc-0.81.hdf5\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.3804 - acc: 0.8673 - val_loss: 0.6796 - val_acc: 0.8071\n",
            "Epoch 21/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4222 - acc: 0.8571\n",
            "Epoch 21: val_acc did not improve from 0.80714\n",
            "8/8 [==============================] - 80s 11s/step - loss: 0.4222 - acc: 0.8571 - val_loss: 1.1189 - val_acc: 0.6857\n",
            "Epoch 22/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4258 - acc: 0.8673\n",
            "Epoch 22: val_acc did not improve from 0.80714\n",
            "8/8 [==============================] - 78s 10s/step - loss: 0.4258 - acc: 0.8673 - val_loss: 1.3762 - val_acc: 0.6071\n",
            "Epoch 23/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3562 - acc: 0.8959\n",
            "Epoch 23: val_acc did not improve from 0.80714\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.3562 - acc: 0.8959 - val_loss: 1.1379 - val_acc: 0.6786\n",
            "Epoch 24/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3584 - acc: 0.8796\n",
            "Epoch 24: val_acc did not improve from 0.80714\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.3584 - acc: 0.8796 - val_loss: 1.3130 - val_acc: 0.6857\n",
            "Epoch 25/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2620 - acc: 0.8898\n",
            "Epoch 25: val_acc did not improve from 0.80714\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.2620 - acc: 0.8898 - val_loss: 0.9507 - val_acc: 0.7357\n",
            "\n",
            "\n",
            "Model Accuracy 0.6571428571428571\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.86      0.60      0.71        10\n",
            "       10000       0.60      0.90      0.72        10\n",
            "      100000       1.00      0.40      0.57        10\n",
            "        2000       0.86      0.60      0.71        10\n",
            "       20000       0.75      0.30      0.43        10\n",
            "        5000       0.45      1.00      0.62        10\n",
            "       50000       0.73      0.80      0.76        10\n",
            "\n",
            "    accuracy                           0.66        70\n",
            "   macro avg       0.75      0.66      0.65        70\n",
            "weighted avg       0.75      0.66      0.65        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 31 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 33\n",
            "learning rate: 0.06687506814172534\n",
            "batch size: 64\n",
            "dropout rate: 0.6825355706083546\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 3.2389 - acc: 0.2531\n",
            "Epoch 1: val_acc improved from -inf to 0.22857, saving model to percobaan31_noImgPro/model\\vgg_16_31-saved-model-01-acc-0.23.hdf5\n",
            "8/8 [==============================] - 76s 10s/step - loss: 3.2389 - acc: 0.2531 - val_loss: 7.9996 - val_acc: 0.2286\n",
            "Epoch 2/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.3242 - acc: 0.3816\n",
            "Epoch 2: val_acc did not improve from 0.22857\n",
            "8/8 [==============================] - 79s 10s/step - loss: 2.3242 - acc: 0.3816 - val_loss: 3.2221 - val_acc: 0.2143\n",
            "Epoch 3/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7486 - acc: 0.4327\n",
            "Epoch 3: val_acc did not improve from 0.22857\n",
            "8/8 [==============================] - 76s 10s/step - loss: 1.7486 - acc: 0.4327 - val_loss: 4.0706 - val_acc: 0.2214\n",
            "Epoch 4/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4788 - acc: 0.4980\n",
            "Epoch 4: val_acc improved from 0.22857 to 0.40000, saving model to percobaan31_noImgPro/model\\vgg_16_31-saved-model-04-acc-0.40.hdf5\n",
            "8/8 [==============================] - 79s 10s/step - loss: 1.4788 - acc: 0.4980 - val_loss: 1.5061 - val_acc: 0.4000\n",
            "Epoch 5/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3828 - acc: 0.5102\n",
            "Epoch 5: val_acc improved from 0.40000 to 0.45000, saving model to percobaan31_noImgPro/model\\vgg_16_31-saved-model-05-acc-0.45.hdf5\n",
            "8/8 [==============================] - 77s 10s/step - loss: 1.3828 - acc: 0.5102 - val_loss: 1.5877 - val_acc: 0.4500\n",
            "Epoch 6/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1363 - acc: 0.6082\n",
            "Epoch 6: val_acc improved from 0.45000 to 0.46429, saving model to percobaan31_noImgPro/model\\vgg_16_31-saved-model-06-acc-0.46.hdf5\n",
            "8/8 [==============================] - 79s 10s/step - loss: 1.1363 - acc: 0.6082 - val_loss: 1.7199 - val_acc: 0.4643\n",
            "Epoch 7/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9824 - acc: 0.6388\n",
            "Epoch 7: val_acc did not improve from 0.46429\n",
            "8/8 [==============================] - 78s 10s/step - loss: 0.9824 - acc: 0.6388 - val_loss: 1.9340 - val_acc: 0.3357\n",
            "Epoch 8/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8862 - acc: 0.6898\n",
            "Epoch 8: val_acc improved from 0.46429 to 0.55714, saving model to percobaan31_noImgPro/model\\vgg_16_31-saved-model-08-acc-0.56.hdf5\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.8862 - acc: 0.6898 - val_loss: 1.1784 - val_acc: 0.5571\n",
            "Epoch 9/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9222 - acc: 0.6878\n",
            "Epoch 9: val_acc did not improve from 0.55714\n",
            "8/8 [==============================] - 78s 10s/step - loss: 0.9222 - acc: 0.6878 - val_loss: 2.7008 - val_acc: 0.2429\n",
            "Epoch 10/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7522 - acc: 0.7163\n",
            "Epoch 10: val_acc did not improve from 0.55714\n",
            "8/8 [==============================] - 75s 10s/step - loss: 0.7522 - acc: 0.7163 - val_loss: 2.3376 - val_acc: 0.3286\n",
            "Epoch 11/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7311 - acc: 0.7265\n",
            "Epoch 11: val_acc did not improve from 0.55714\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.7311 - acc: 0.7265 - val_loss: 2.3886 - val_acc: 0.3786\n",
            "Epoch 12/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6295 - acc: 0.7776\n",
            "Epoch 12: val_acc did not improve from 0.55714\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.6295 - acc: 0.7776 - val_loss: 1.5541 - val_acc: 0.5071\n",
            "Epoch 13/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5693 - acc: 0.7939\n",
            "Epoch 13: val_acc did not improve from 0.55714\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.5693 - acc: 0.7939 - val_loss: 1.5037 - val_acc: 0.4786\n",
            "\n",
            "\n",
            "Model Accuracy 0.44285714285714284\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.00      0.00      0.00        10\n",
            "       10000       0.60      0.60      0.60        10\n",
            "      100000       1.00      0.10      0.18        10\n",
            "        2000       0.50      0.70      0.58        10\n",
            "       20000       0.25      0.90      0.39        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       0.89      0.80      0.84        10\n",
            "\n",
            "    accuracy                           0.44        70\n",
            "   macro avg       0.46      0.44      0.37        70\n",
            "weighted avg       0.46      0.44      0.37        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 32 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 31\n",
            "learning rate: 0.06224209044328398\n",
            "batch size: 64\n",
            "dropout rate: 0.738134795482572\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 3.5791 - acc: 0.2347\n",
            "Epoch 1: val_acc improved from -inf to 0.20714, saving model to percobaan32_noImgPro/model\\vgg_16_32-saved-model-01-acc-0.21.hdf5\n",
            "8/8 [==============================] - 76s 10s/step - loss: 3.5791 - acc: 0.2347 - val_loss: 10.9108 - val_acc: 0.2071\n",
            "Epoch 2/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.5024 - acc: 0.3163\n",
            "Epoch 2: val_acc did not improve from 0.20714\n",
            "8/8 [==============================] - 80s 10s/step - loss: 2.5024 - acc: 0.3163 - val_loss: 5.0832 - val_acc: 0.1929\n",
            "Epoch 3/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.0070 - acc: 0.3735\n",
            "Epoch 3: val_acc did not improve from 0.20714\n",
            "8/8 [==============================] - 77s 10s/step - loss: 2.0070 - acc: 0.3735 - val_loss: 5.1317 - val_acc: 0.1929\n",
            "Epoch 4/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8070 - acc: 0.4000\n",
            "Epoch 4: val_acc improved from 0.20714 to 0.35000, saving model to percobaan32_noImgPro/model\\vgg_16_32-saved-model-04-acc-0.35.hdf5\n",
            "8/8 [==============================] - 78s 10s/step - loss: 1.8070 - acc: 0.4000 - val_loss: 2.4909 - val_acc: 0.3500\n",
            "Epoch 5/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4556 - acc: 0.4673\n",
            "Epoch 5: val_acc improved from 0.35000 to 0.45000, saving model to percobaan32_noImgPro/model\\vgg_16_32-saved-model-05-acc-0.45.hdf5\n",
            "8/8 [==============================] - 79s 10s/step - loss: 1.4556 - acc: 0.4673 - val_loss: 2.0733 - val_acc: 0.4500\n",
            "Epoch 6/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.2814 - acc: 0.5531\n",
            "Epoch 6: val_acc did not improve from 0.45000\n",
            "8/8 [==============================] - 76s 10s/step - loss: 1.2814 - acc: 0.5531 - val_loss: 1.9406 - val_acc: 0.4500\n",
            "Epoch 7/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.2209 - acc: 0.5469\n",
            "Epoch 7: val_acc did not improve from 0.45000\n",
            "8/8 [==============================] - 78s 10s/step - loss: 1.2209 - acc: 0.5469 - val_loss: 2.1570 - val_acc: 0.3000\n",
            "Epoch 8/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1635 - acc: 0.5898\n",
            "Epoch 8: val_acc improved from 0.45000 to 0.49286, saving model to percobaan32_noImgPro/model\\vgg_16_32-saved-model-08-acc-0.49.hdf5\n",
            "8/8 [==============================] - 76s 10s/step - loss: 1.1635 - acc: 0.5898 - val_loss: 1.4098 - val_acc: 0.4929\n",
            "Epoch 9/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0114 - acc: 0.6327\n",
            "Epoch 9: val_acc did not improve from 0.49286\n",
            "8/8 [==============================] - 77s 10s/step - loss: 1.0114 - acc: 0.6327 - val_loss: 1.7131 - val_acc: 0.4286\n",
            "Epoch 10/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0049 - acc: 0.6551\n",
            "Epoch 10: val_acc improved from 0.49286 to 0.65714, saving model to percobaan32_noImgPro/model\\vgg_16_32-saved-model-10-acc-0.66.hdf5\n",
            "8/8 [==============================] - 77s 10s/step - loss: 1.0049 - acc: 0.6551 - val_loss: 1.0570 - val_acc: 0.6571\n",
            "Epoch 11/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9077 - acc: 0.6714\n",
            "Epoch 11: val_acc improved from 0.65714 to 0.72143, saving model to percobaan32_noImgPro/model\\vgg_16_32-saved-model-11-acc-0.72.hdf5\n",
            "8/8 [==============================] - 76s 10s/step - loss: 0.9077 - acc: 0.6714 - val_loss: 0.8039 - val_acc: 0.7214\n",
            "Epoch 12/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8521 - acc: 0.7082\n",
            "Epoch 12: val_acc did not improve from 0.72143\n",
            "8/8 [==============================] - 76s 10s/step - loss: 0.8521 - acc: 0.7082 - val_loss: 1.6390 - val_acc: 0.4286\n",
            "Epoch 13/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8799 - acc: 0.6857\n",
            "Epoch 13: val_acc did not improve from 0.72143\n",
            "8/8 [==============================] - 76s 10s/step - loss: 0.8799 - acc: 0.6857 - val_loss: 1.4650 - val_acc: 0.5357\n",
            "Epoch 14/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8669 - acc: 0.7041\n",
            "Epoch 14: val_acc did not improve from 0.72143\n",
            "8/8 [==============================] - 75s 10s/step - loss: 0.8669 - acc: 0.7041 - val_loss: 2.0527 - val_acc: 0.3857\n",
            "Epoch 15/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8256 - acc: 0.7000\n",
            "Epoch 15: val_acc did not improve from 0.72143\n",
            "8/8 [==============================] - 75s 10s/step - loss: 0.8256 - acc: 0.7000 - val_loss: 1.8297 - val_acc: 0.4357\n",
            "Epoch 16/31\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8039 - acc: 0.7122\n",
            "Epoch 16: val_acc did not improve from 0.72143\n",
            "8/8 [==============================] - 75s 10s/step - loss: 0.8039 - acc: 0.7122 - val_loss: 1.7362 - val_acc: 0.4357\n",
            "\n",
            "\n",
            "Model Accuracy 0.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.60      0.30      0.40        10\n",
            "       10000       1.00      0.20      0.33        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.75      0.30      0.43        10\n",
            "       20000       0.25      0.10      0.14        10\n",
            "        5000       0.67      0.20      0.31        10\n",
            "       50000       0.19      1.00      0.32        10\n",
            "\n",
            "    accuracy                           0.30        70\n",
            "   macro avg       0.49      0.30      0.28        70\n",
            "weighted avg       0.49      0.30      0.28        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 33 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 33\n",
            "learning rate: 0.05149635710961387\n",
            "batch size: 128\n",
            "dropout rate: 0.5702717226932095\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.7938 - acc: 0.2755 \n",
            "Epoch 1: val_acc improved from -inf to 0.16429, saving model to percobaan33_noImgPro/model\\vgg_16_33-saved-model-01-acc-0.16.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 2.7938 - acc: 0.2755 - val_loss: 6.1351 - val_acc: 0.1643\n",
            "Epoch 2/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.6711 - acc: 0.4612 \n",
            "Epoch 2: val_acc improved from 0.16429 to 0.20000, saving model to percobaan33_noImgPro/model\\vgg_16_33-saved-model-02-acc-0.20.hdf5\n",
            "4/4 [==============================] - 78s 22s/step - loss: 1.6711 - acc: 0.4612 - val_loss: 8.2841 - val_acc: 0.2000\n",
            "Epoch 3/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.3213 - acc: 0.5327 \n",
            "Epoch 3: val_acc improved from 0.20000 to 0.20714, saving model to percobaan33_noImgPro/model\\vgg_16_33-saved-model-03-acc-0.21.hdf5\n",
            "4/4 [==============================] - 78s 21s/step - loss: 1.3213 - acc: 0.5327 - val_loss: 5.5061 - val_acc: 0.2071\n",
            "Epoch 4/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0117 - acc: 0.6429 \n",
            "Epoch 4: val_acc improved from 0.20714 to 0.35000, saving model to percobaan33_noImgPro/model\\vgg_16_33-saved-model-04-acc-0.35.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 1.0117 - acc: 0.6429 - val_loss: 3.1956 - val_acc: 0.3500\n",
            "Epoch 5/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8404 - acc: 0.7061 \n",
            "Epoch 5: val_acc improved from 0.35000 to 0.43571, saving model to percobaan33_noImgPro/model\\vgg_16_33-saved-model-05-acc-0.44.hdf5\n",
            "4/4 [==============================] - 78s 21s/step - loss: 0.8404 - acc: 0.7061 - val_loss: 2.6298 - val_acc: 0.4357\n",
            "Epoch 6/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7591 - acc: 0.7204 \n",
            "Epoch 6: val_acc did not improve from 0.43571\n",
            "4/4 [==============================] - 78s 21s/step - loss: 0.7591 - acc: 0.7204 - val_loss: 3.1199 - val_acc: 0.3500\n",
            "Epoch 7/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6934 - acc: 0.7327 \n",
            "Epoch 7: val_acc did not improve from 0.43571\n",
            "4/4 [==============================] - 78s 20s/step - loss: 0.6934 - acc: 0.7327 - val_loss: 3.4414 - val_acc: 0.3643\n",
            "Epoch 8/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5456 - acc: 0.8020 \n",
            "Epoch 8: val_acc did not improve from 0.43571\n",
            "4/4 [==============================] - 80s 22s/step - loss: 0.5456 - acc: 0.8020 - val_loss: 3.5553 - val_acc: 0.3214\n",
            "Epoch 9/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5360 - acc: 0.8204 \n",
            "Epoch 9: val_acc did not improve from 0.43571\n",
            "4/4 [==============================] - 78s 21s/step - loss: 0.5360 - acc: 0.8204 - val_loss: 3.1406 - val_acc: 0.4286\n",
            "Epoch 10/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5476 - acc: 0.8184 \n",
            "Epoch 10: val_acc improved from 0.43571 to 0.47857, saving model to percobaan33_noImgPro/model\\vgg_16_33-saved-model-10-acc-0.48.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.5476 - acc: 0.8184 - val_loss: 3.0646 - val_acc: 0.4786\n",
            "\n",
            "\n",
            "Model Accuracy 0.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.38      0.90      0.53        10\n",
            "       10000       0.37      1.00      0.54        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.00      0.00      0.00        10\n",
            "       20000       0.38      0.60      0.46        10\n",
            "        5000       1.00      0.10      0.18        10\n",
            "       50000       1.00      0.20      0.33        10\n",
            "\n",
            "    accuracy                           0.40        70\n",
            "   macro avg       0.45      0.40      0.29        70\n",
            "weighted avg       0.45      0.40      0.29        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 34 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 36\n",
            "learning rate: 0.06264392145702406\n",
            "batch size: 128\n",
            "dropout rate: 0.5982631681504014\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/36\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.8324 - acc: 0.2612 \n",
            "Epoch 1: val_acc improved from -inf to 0.20714, saving model to percobaan34_noImgPro/model\\vgg_16_34-saved-model-01-acc-0.21.hdf5\n",
            "4/4 [==============================] - 78s 22s/step - loss: 2.8324 - acc: 0.2612 - val_loss: 9.4758 - val_acc: 0.2071\n",
            "Epoch 2/36\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.8675 - acc: 0.4388 \n",
            "Epoch 2: val_acc improved from 0.20714 to 0.27857, saving model to percobaan34_noImgPro/model\\vgg_16_34-saved-model-02-acc-0.28.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 1.8675 - acc: 0.4388 - val_loss: 5.3691 - val_acc: 0.2786\n",
            "Epoch 3/36\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.4105 - acc: 0.5694 \n",
            "Epoch 3: val_acc improved from 0.27857 to 0.30000, saving model to percobaan34_noImgPro/model\\vgg_16_34-saved-model-03-acc-0.30.hdf5\n",
            "4/4 [==============================] - 80s 21s/step - loss: 1.4105 - acc: 0.5694 - val_loss: 6.3505 - val_acc: 0.3000\n",
            "Epoch 4/36\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1169 - acc: 0.6204 \n",
            "Epoch 4: val_acc did not improve from 0.30000\n",
            "4/4 [==============================] - 78s 20s/step - loss: 1.1169 - acc: 0.6204 - val_loss: 6.2954 - val_acc: 0.2929\n",
            "Epoch 5/36\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9743 - acc: 0.6612 \n",
            "Epoch 5: val_acc did not improve from 0.30000\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.9743 - acc: 0.6612 - val_loss: 6.6089 - val_acc: 0.2357\n",
            "Epoch 6/36\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7850 - acc: 0.7020 \n",
            "Epoch 6: val_acc did not improve from 0.30000\n",
            "4/4 [==============================] - 90s 24s/step - loss: 0.7850 - acc: 0.7020 - val_loss: 5.5210 - val_acc: 0.2714\n",
            "Epoch 7/36\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7817 - acc: 0.7327 \n",
            "Epoch 7: val_acc did not improve from 0.30000\n",
            "4/4 [==============================] - 81s 21s/step - loss: 0.7817 - acc: 0.7327 - val_loss: 5.9577 - val_acc: 0.2143\n",
            "\n",
            "\n",
            "Model Accuracy 0.17142857142857143\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.00      0.00      0.00        10\n",
            "       10000       0.00      0.00      0.00        10\n",
            "      100000       0.50      0.20      0.29        10\n",
            "        2000       0.00      0.00      0.00        10\n",
            "       20000       0.00      0.00      0.00        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       0.16      1.00      0.27        10\n",
            "\n",
            "    accuracy                           0.17        70\n",
            "   macro avg       0.09      0.17      0.08        70\n",
            "weighted avg       0.09      0.17      0.08        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 35 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 35\n",
            "learning rate: 0.06393342505698188\n",
            "batch size: 128\n",
            "dropout rate: 0.6523359949511304\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.7866 - acc: 0.2816 \n",
            "Epoch 1: val_acc improved from -inf to 0.26429, saving model to percobaan35_noImgPro/model\\vgg_16_35-saved-model-01-acc-0.26.hdf5\n",
            "4/4 [==============================] - 77s 20s/step - loss: 2.7866 - acc: 0.2816 - val_loss: 5.1572 - val_acc: 0.2643\n",
            "Epoch 2/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.8939 - acc: 0.4571 \n",
            "Epoch 2: val_acc improved from 0.26429 to 0.28571, saving model to percobaan35_noImgPro/model\\vgg_16_35-saved-model-02-acc-0.29.hdf5\n",
            "4/4 [==============================] - 77s 21s/step - loss: 1.8939 - acc: 0.4571 - val_loss: 6.6444 - val_acc: 0.2857\n",
            "Epoch 3/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.6324 - acc: 0.4939 \n",
            "Epoch 3: val_acc did not improve from 0.28571\n",
            "4/4 [==============================] - 77s 20s/step - loss: 1.6324 - acc: 0.4939 - val_loss: 5.2310 - val_acc: 0.2286\n",
            "Epoch 4/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.3575 - acc: 0.5735 \n",
            "Epoch 4: val_acc improved from 0.28571 to 0.30714, saving model to percobaan35_noImgPro/model\\vgg_16_35-saved-model-04-acc-0.31.hdf5\n",
            "4/4 [==============================] - 76s 20s/step - loss: 1.3575 - acc: 0.5735 - val_loss: 3.5755 - val_acc: 0.3071\n",
            "Epoch 5/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1317 - acc: 0.6122 \n",
            "Epoch 5: val_acc improved from 0.30714 to 0.41429, saving model to percobaan35_noImgPro/model\\vgg_16_35-saved-model-05-acc-0.41.hdf5\n",
            "4/4 [==============================] - 74s 20s/step - loss: 1.1317 - acc: 0.6122 - val_loss: 3.3446 - val_acc: 0.4143\n",
            "Epoch 6/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9460 - acc: 0.6653 \n",
            "Epoch 6: val_acc did not improve from 0.41429\n",
            "4/4 [==============================] - 74s 19s/step - loss: 0.9460 - acc: 0.6653 - val_loss: 3.7613 - val_acc: 0.3714\n",
            "Epoch 7/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8774 - acc: 0.6939 \n",
            "Epoch 7: val_acc did not improve from 0.41429\n",
            "4/4 [==============================] - 74s 19s/step - loss: 0.8774 - acc: 0.6939 - val_loss: 3.3356 - val_acc: 0.4000\n",
            "Epoch 8/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7752 - acc: 0.7388 \n",
            "Epoch 8: val_acc improved from 0.41429 to 0.54286, saving model to percobaan35_noImgPro/model\\vgg_16_35-saved-model-08-acc-0.54.hdf5\n",
            "4/4 [==============================] - 76s 20s/step - loss: 0.7752 - acc: 0.7388 - val_loss: 2.3855 - val_acc: 0.5429\n",
            "Epoch 9/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6887 - acc: 0.7510 \n",
            "Epoch 9: val_acc did not improve from 0.54286\n",
            "4/4 [==============================] - 74s 20s/step - loss: 0.6887 - acc: 0.7510 - val_loss: 2.1880 - val_acc: 0.5286\n",
            "Epoch 10/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6966 - acc: 0.7735 \n",
            "Epoch 10: val_acc did not improve from 0.54286\n",
            "4/4 [==============================] - 74s 19s/step - loss: 0.6966 - acc: 0.7735 - val_loss: 2.1333 - val_acc: 0.5429\n",
            "Epoch 11/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6293 - acc: 0.7612 \n",
            "Epoch 11: val_acc did not improve from 0.54286\n",
            "4/4 [==============================] - 74s 20s/step - loss: 0.6293 - acc: 0.7612 - val_loss: 1.9739 - val_acc: 0.5286\n",
            "Epoch 12/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5335 - acc: 0.8143 \n",
            "Epoch 12: val_acc improved from 0.54286 to 0.61429, saving model to percobaan35_noImgPro/model\\vgg_16_35-saved-model-12-acc-0.61.hdf5\n",
            "4/4 [==============================] - 75s 21s/step - loss: 0.5335 - acc: 0.8143 - val_loss: 1.7757 - val_acc: 0.6143\n",
            "Epoch 13/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5364 - acc: 0.8102 \n",
            "Epoch 13: val_acc did not improve from 0.61429\n",
            "4/4 [==============================] - 70s 18s/step - loss: 0.5364 - acc: 0.8102 - val_loss: 1.8439 - val_acc: 0.5786\n",
            "Epoch 14/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4818 - acc: 0.8163 \n",
            "Epoch 14: val_acc did not improve from 0.61429\n",
            "4/4 [==============================] - 71s 19s/step - loss: 0.4818 - acc: 0.8163 - val_loss: 1.8943 - val_acc: 0.5786\n",
            "Epoch 15/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4058 - acc: 0.8571 \n",
            "Epoch 15: val_acc improved from 0.61429 to 0.62143, saving model to percobaan35_noImgPro/model\\vgg_16_35-saved-model-15-acc-0.62.hdf5\n",
            "4/4 [==============================] - 78s 20s/step - loss: 0.4058 - acc: 0.8571 - val_loss: 2.1126 - val_acc: 0.6214\n",
            "Epoch 16/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4277 - acc: 0.8347 \n",
            "Epoch 16: val_acc did not improve from 0.62143\n",
            "4/4 [==============================] - 76s 21s/step - loss: 0.4277 - acc: 0.8347 - val_loss: 2.4530 - val_acc: 0.5714\n",
            "Epoch 17/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4723 - acc: 0.8388 \n",
            "Epoch 17: val_acc did not improve from 0.62143\n",
            "4/4 [==============================] - 76s 20s/step - loss: 0.4723 - acc: 0.8388 - val_loss: 2.3466 - val_acc: 0.5714\n",
            "\n",
            "\n",
            "Model Accuracy 0.4142857142857143\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.67      0.40      0.50        10\n",
            "       10000       0.24      1.00      0.39        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.60      0.30      0.40        10\n",
            "       20000       0.00      0.00      0.00        10\n",
            "        5000       0.62      0.50      0.56        10\n",
            "       50000       0.70      0.70      0.70        10\n",
            "\n",
            "    accuracy                           0.41        70\n",
            "   macro avg       0.41      0.41      0.36        70\n",
            "weighted avg       0.41      0.41      0.36        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 36 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 35\n",
            "learning rate: 0.07478640809020295\n",
            "batch size: 128\n",
            "dropout rate: 0.758477513278394\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 3.4712 - acc: 0.2449 \n",
            "Epoch 1: val_acc improved from -inf to 0.18571, saving model to percobaan36_noImgPro/model\\vgg_16_36-saved-model-01-acc-0.19.hdf5\n",
            "4/4 [==============================] - 78s 20s/step - loss: 3.4712 - acc: 0.2449 - val_loss: 15.9969 - val_acc: 0.1857\n",
            "Epoch 2/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.8444 - acc: 0.3000 \n",
            "Epoch 2: val_acc improved from 0.18571 to 0.23571, saving model to percobaan36_noImgPro/model\\vgg_16_36-saved-model-02-acc-0.24.hdf5\n",
            "4/4 [==============================] - 75s 20s/step - loss: 2.8444 - acc: 0.3000 - val_loss: 8.3201 - val_acc: 0.2357\n",
            "Epoch 3/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.3405 - acc: 0.3510 \n",
            "Epoch 3: val_acc improved from 0.23571 to 0.29286, saving model to percobaan36_noImgPro/model\\vgg_16_36-saved-model-03-acc-0.29.hdf5\n",
            "4/4 [==============================] - 75s 20s/step - loss: 2.3405 - acc: 0.3510 - val_loss: 3.9208 - val_acc: 0.2929\n",
            "Epoch 4/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.8282 - acc: 0.4327 \n",
            "Epoch 4: val_acc improved from 0.29286 to 0.35000, saving model to percobaan36_noImgPro/model\\vgg_16_36-saved-model-04-acc-0.35.hdf5\n",
            "4/4 [==============================] - 75s 21s/step - loss: 1.8282 - acc: 0.4327 - val_loss: 2.3707 - val_acc: 0.3500\n",
            "Epoch 5/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.6134 - acc: 0.4184 \n",
            "Epoch 5: val_acc did not improve from 0.35000\n",
            "4/4 [==============================] - 74s 20s/step - loss: 1.6134 - acc: 0.4184 - val_loss: 2.1558 - val_acc: 0.2357\n",
            "Epoch 6/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.5356 - acc: 0.4388 \n",
            "Epoch 6: val_acc did not improve from 0.35000\n",
            "4/4 [==============================] - 74s 19s/step - loss: 1.5356 - acc: 0.4388 - val_loss: 1.7481 - val_acc: 0.3143\n",
            "Epoch 7/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.4406 - acc: 0.4735 \n",
            "Epoch 7: val_acc improved from 0.35000 to 0.37857, saving model to percobaan36_noImgPro/model\\vgg_16_36-saved-model-07-acc-0.38.hdf5\n",
            "4/4 [==============================] - 74s 19s/step - loss: 1.4406 - acc: 0.4735 - val_loss: 1.4990 - val_acc: 0.3786\n",
            "Epoch 8/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.3217 - acc: 0.5082 \n",
            "Epoch 8: val_acc did not improve from 0.37857\n",
            "4/4 [==============================] - 74s 20s/step - loss: 1.3217 - acc: 0.5082 - val_loss: 2.2425 - val_acc: 0.2143\n",
            "Epoch 9/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2329 - acc: 0.5388 \n",
            "Epoch 9: val_acc did not improve from 0.37857\n",
            "4/4 [==============================] - 74s 20s/step - loss: 1.2329 - acc: 0.5388 - val_loss: 3.2702 - val_acc: 0.2214\n",
            "Epoch 10/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0422 - acc: 0.6102 \n",
            "Epoch 10: val_acc did not improve from 0.37857\n",
            "4/4 [==============================] - 74s 20s/step - loss: 1.0422 - acc: 0.6102 - val_loss: 3.7058 - val_acc: 0.2857\n",
            "Epoch 11/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1476 - acc: 0.6102 \n",
            "Epoch 11: val_acc did not improve from 0.37857\n",
            "4/4 [==============================] - 74s 19s/step - loss: 1.1476 - acc: 0.6102 - val_loss: 3.8752 - val_acc: 0.2429\n",
            "Epoch 12/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0281 - acc: 0.6245 \n",
            "Epoch 12: val_acc did not improve from 0.37857\n",
            "4/4 [==============================] - 74s 19s/step - loss: 1.0281 - acc: 0.6245 - val_loss: 2.8952 - val_acc: 0.2786\n",
            "\n",
            "\n",
            "Model Accuracy 0.2571428571428571\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.40      0.57        10\n",
            "       10000       0.00      0.00      0.00        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.00      0.00      0.00        10\n",
            "       20000       0.18      1.00      0.30        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       0.50      0.40      0.44        10\n",
            "\n",
            "    accuracy                           0.26        70\n",
            "   macro avg       0.24      0.26      0.19        70\n",
            "weighted avg       0.24      0.26      0.19        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 37 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 33\n",
            "learning rate: 0.08456574177123914\n",
            "batch size: 32\n",
            "dropout rate: 0.5637037390571091\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/33\n",
            "16/16 [==============================] - ETA: 0s - loss: 3.5190 - acc: 0.2755\n",
            "Epoch 1: val_acc improved from -inf to 0.19286, saving model to percobaan37_noImgPro/model\\vgg_16_37-saved-model-01-acc-0.19.hdf5\n",
            "16/16 [==============================] - 74s 5s/step - loss: 3.5190 - acc: 0.2755 - val_loss: 8.3930 - val_acc: 0.1929\n",
            "Epoch 2/33\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.6468 - acc: 0.3898\n",
            "Epoch 2: val_acc improved from 0.19286 to 0.21429, saving model to percobaan37_noImgPro/model\\vgg_16_37-saved-model-02-acc-0.21.hdf5\n",
            "16/16 [==============================] - 73s 5s/step - loss: 2.6468 - acc: 0.3898 - val_loss: 9.9458 - val_acc: 0.2143\n",
            "Epoch 3/33\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.8085 - acc: 0.4571\n",
            "Epoch 3: val_acc improved from 0.21429 to 0.45000, saving model to percobaan37_noImgPro/model\\vgg_16_37-saved-model-03-acc-0.45.hdf5\n",
            "16/16 [==============================] - 73s 5s/step - loss: 1.8085 - acc: 0.4571 - val_loss: 1.8507 - val_acc: 0.4500\n",
            "Epoch 4/33\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.4287 - acc: 0.5327\n",
            "Epoch 4: val_acc improved from 0.45000 to 0.54286, saving model to percobaan37_noImgPro/model\\vgg_16_37-saved-model-04-acc-0.54.hdf5\n",
            "16/16 [==============================] - 74s 5s/step - loss: 1.4287 - acc: 0.5327 - val_loss: 1.2996 - val_acc: 0.5429\n",
            "Epoch 5/33\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2686 - acc: 0.5939\n",
            "Epoch 5: val_acc improved from 0.54286 to 0.67143, saving model to percobaan37_noImgPro/model\\vgg_16_37-saved-model-05-acc-0.67.hdf5\n",
            "16/16 [==============================] - 74s 5s/step - loss: 1.2686 - acc: 0.5939 - val_loss: 0.9094 - val_acc: 0.6714\n",
            "Epoch 6/33\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1476 - acc: 0.6306\n",
            "Epoch 6: val_acc did not improve from 0.67143\n",
            "16/16 [==============================] - 74s 5s/step - loss: 1.1476 - acc: 0.6306 - val_loss: 1.8521 - val_acc: 0.4929\n",
            "Epoch 7/33\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0980 - acc: 0.6449\n",
            "Epoch 7: val_acc did not improve from 0.67143\n",
            "16/16 [==============================] - 77s 5s/step - loss: 1.0980 - acc: 0.6449 - val_loss: 1.2146 - val_acc: 0.5929\n",
            "Epoch 8/33\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1998 - acc: 0.6306\n",
            "Epoch 8: val_acc did not improve from 0.67143\n",
            "16/16 [==============================] - 80s 5s/step - loss: 1.1998 - acc: 0.6306 - val_loss: 1.3494 - val_acc: 0.5929\n",
            "Epoch 9/33\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0584 - acc: 0.7122\n",
            "Epoch 9: val_acc did not improve from 0.67143\n",
            "16/16 [==============================] - 94s 6s/step - loss: 1.0584 - acc: 0.7122 - val_loss: 2.1212 - val_acc: 0.5000\n",
            "Epoch 10/33\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8963 - acc: 0.7286\n",
            "Epoch 10: val_acc did not improve from 0.67143\n",
            "16/16 [==============================] - 82s 5s/step - loss: 0.8963 - acc: 0.7286 - val_loss: 1.2615 - val_acc: 0.5643\n",
            "\n",
            "\n",
            "Model Accuracy 0.5142857142857142\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.40      0.57        10\n",
            "       10000       0.80      0.40      0.53        10\n",
            "      100000       0.69      0.90      0.78        10\n",
            "        2000       1.00      0.20      0.33        10\n",
            "       20000       0.25      0.90      0.39        10\n",
            "        5000       0.86      0.60      0.71        10\n",
            "       50000       0.67      0.20      0.31        10\n",
            "\n",
            "    accuracy                           0.51        70\n",
            "   macro avg       0.75      0.51      0.52        70\n",
            "weighted avg       0.75      0.51      0.52        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 38 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 36\n",
            "learning rate: 0.08762026934389985\n",
            "batch size: 32\n",
            "dropout rate: 0.5761082660695714\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/36\n",
            "16/16 [==============================] - ETA: 0s - loss: 3.3158 - acc: 0.2959\n",
            "Epoch 1: val_acc improved from -inf to 0.22857, saving model to percobaan38_noImgPro/model\\vgg_16_38-saved-model-01-acc-0.23.hdf5\n",
            "16/16 [==============================] - 79s 5s/step - loss: 3.3158 - acc: 0.2959 - val_loss: 9.4339 - val_acc: 0.2286\n",
            "Epoch 2/36\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.2204 - acc: 0.4245\n",
            "Epoch 2: val_acc did not improve from 0.22857\n",
            "16/16 [==============================] - 77s 5s/step - loss: 2.2204 - acc: 0.4245 - val_loss: 4.4518 - val_acc: 0.1643\n",
            "Epoch 3/36\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.8204 - acc: 0.4490\n",
            "Epoch 3: val_acc did not improve from 0.22857\n",
            "16/16 [==============================] - 78s 5s/step - loss: 1.8204 - acc: 0.4490 - val_loss: 3.3408 - val_acc: 0.2143\n",
            "Epoch 4/36\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2885 - acc: 0.5735\n",
            "Epoch 4: val_acc improved from 0.22857 to 0.27857, saving model to percobaan38_noImgPro/model\\vgg_16_38-saved-model-04-acc-0.28.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 1.2885 - acc: 0.5735 - val_loss: 2.9411 - val_acc: 0.2786\n",
            "Epoch 5/36\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1482 - acc: 0.6367\n",
            "Epoch 5: val_acc improved from 0.27857 to 0.35714, saving model to percobaan38_noImgPro/model\\vgg_16_38-saved-model-05-acc-0.36.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 1.1482 - acc: 0.6367 - val_loss: 1.8423 - val_acc: 0.3571\n",
            "Epoch 6/36\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1299 - acc: 0.6122\n",
            "Epoch 6: val_acc improved from 0.35714 to 0.59286, saving model to percobaan38_noImgPro/model\\vgg_16_38-saved-model-06-acc-0.59.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 1.1299 - acc: 0.6122 - val_loss: 1.6739 - val_acc: 0.5929\n",
            "Epoch 7/36\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9451 - acc: 0.6959\n",
            "Epoch 7: val_acc did not improve from 0.59286\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.9451 - acc: 0.6959 - val_loss: 3.3942 - val_acc: 0.3571\n",
            "Epoch 8/36\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2801 - acc: 0.6102\n",
            "Epoch 8: val_acc did not improve from 0.59286\n",
            "16/16 [==============================] - 77s 5s/step - loss: 1.2801 - acc: 0.6102 - val_loss: 1.3858 - val_acc: 0.5286\n",
            "Epoch 9/36\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2377 - acc: 0.6531\n",
            "Epoch 9: val_acc did not improve from 0.59286\n",
            "16/16 [==============================] - 77s 5s/step - loss: 1.2377 - acc: 0.6531 - val_loss: 1.7324 - val_acc: 0.4857\n",
            "Epoch 10/36\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3415 - acc: 0.6388\n",
            "Epoch 10: val_acc did not improve from 0.59286\n",
            "16/16 [==============================] - 77s 5s/step - loss: 1.3415 - acc: 0.6388 - val_loss: 2.7749 - val_acc: 0.4357\n",
            "Epoch 11/36\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1458 - acc: 0.6837\n",
            "Epoch 11: val_acc did not improve from 0.59286\n",
            "16/16 [==============================] - 77s 5s/step - loss: 1.1458 - acc: 0.6837 - val_loss: 2.3380 - val_acc: 0.4929\n",
            "Epoch 12/36\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1887 - acc: 0.6612\n",
            "Epoch 12: val_acc improved from 0.59286 to 0.68571, saving model to percobaan38_noImgPro/model\\vgg_16_38-saved-model-12-acc-0.69.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 1.1887 - acc: 0.6612 - val_loss: 1.4343 - val_acc: 0.6857\n",
            "Epoch 13/36\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2066 - acc: 0.7020\n",
            "Epoch 13: val_acc improved from 0.68571 to 0.77143, saving model to percobaan38_noImgPro/model\\vgg_16_38-saved-model-13-acc-0.77.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 1.2066 - acc: 0.7020 - val_loss: 0.8965 - val_acc: 0.7714\n",
            "Epoch 14/36\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0409 - acc: 0.7306\n",
            "Epoch 14: val_acc did not improve from 0.77143\n",
            "16/16 [==============================] - 77s 5s/step - loss: 1.0409 - acc: 0.7306 - val_loss: 1.1786 - val_acc: 0.7143\n",
            "Epoch 15/36\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1849 - acc: 0.7367\n",
            "Epoch 15: val_acc did not improve from 0.77143\n",
            "16/16 [==============================] - 77s 5s/step - loss: 1.1849 - acc: 0.7367 - val_loss: 2.0981 - val_acc: 0.6286\n",
            "Epoch 16/36\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0191 - acc: 0.7469\n",
            "Epoch 16: val_acc did not improve from 0.77143\n",
            "16/16 [==============================] - 77s 5s/step - loss: 1.0191 - acc: 0.7469 - val_loss: 1.4646 - val_acc: 0.6500\n",
            "Epoch 17/36\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2006 - acc: 0.7163\n",
            "Epoch 17: val_acc did not improve from 0.77143\n",
            "16/16 [==============================] - 77s 5s/step - loss: 1.2006 - acc: 0.7163 - val_loss: 2.2833 - val_acc: 0.5214\n",
            "Epoch 18/36\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2533 - acc: 0.6714\n",
            "Epoch 18: val_acc did not improve from 0.77143\n",
            "16/16 [==============================] - 77s 5s/step - loss: 1.2533 - acc: 0.6714 - val_loss: 2.2361 - val_acc: 0.6714\n",
            "\n",
            "\n",
            "Model Accuracy 0.5714285714285714\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.78      0.70      0.74        10\n",
            "       10000       1.00      0.40      0.57        10\n",
            "      100000       1.00      0.30      0.46        10\n",
            "        2000       0.64      0.70      0.67        10\n",
            "       20000       0.00      0.00      0.00        10\n",
            "        5000       0.38      1.00      0.56        10\n",
            "       50000       0.53      0.90      0.67        10\n",
            "\n",
            "    accuracy                           0.57        70\n",
            "   macro avg       0.62      0.57      0.52        70\n",
            "weighted avg       0.62      0.57      0.52        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 39 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 31\n",
            "learning rate: 0.09493047751101746\n",
            "batch size: 32\n",
            "dropout rate: 0.7162267192082791\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 4.6597 - acc: 0.2143\n",
            "Epoch 1: val_acc improved from -inf to 0.17857, saving model to percobaan39_noImgPro/model\\vgg_16_39-saved-model-01-acc-0.18.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 4.6597 - acc: 0.2143 - val_loss: 4.8748 - val_acc: 0.1786\n",
            "Epoch 2/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 3.6503 - acc: 0.2531\n",
            "Epoch 2: val_acc improved from 0.17857 to 0.22143, saving model to percobaan39_noImgPro/model\\vgg_16_39-saved-model-02-acc-0.22.hdf5\n",
            "16/16 [==============================] - 78s 5s/step - loss: 3.6503 - acc: 0.2531 - val_loss: 2.6830 - val_acc: 0.2214\n",
            "Epoch 3/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.4501 - acc: 0.2490\n",
            "Epoch 3: val_acc did not improve from 0.22143\n",
            "16/16 [==============================] - 86s 5s/step - loss: 2.4501 - acc: 0.2490 - val_loss: 2.4457 - val_acc: 0.2143\n",
            "Epoch 4/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.0169 - acc: 0.3184\n",
            "Epoch 4: val_acc improved from 0.22143 to 0.35000, saving model to percobaan39_noImgPro/model\\vgg_16_39-saved-model-04-acc-0.35.hdf5\n",
            "16/16 [==============================] - 79s 5s/step - loss: 2.0169 - acc: 0.3184 - val_loss: 2.0053 - val_acc: 0.3500\n",
            "Epoch 5/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.7314 - acc: 0.3959\n",
            "Epoch 5: val_acc did not improve from 0.35000\n",
            "16/16 [==============================] - 74s 5s/step - loss: 1.7314 - acc: 0.3959 - val_loss: 1.6185 - val_acc: 0.3071\n",
            "Epoch 6/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.6399 - acc: 0.4347\n",
            "Epoch 6: val_acc improved from 0.35000 to 0.35714, saving model to percobaan39_noImgPro/model\\vgg_16_39-saved-model-06-acc-0.36.hdf5\n",
            "16/16 [==============================] - 74s 5s/step - loss: 1.6399 - acc: 0.4347 - val_loss: 1.7866 - val_acc: 0.3571\n",
            "Epoch 7/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.5927 - acc: 0.4592\n",
            "Epoch 7: val_acc improved from 0.35714 to 0.37857, saving model to percobaan39_noImgPro/model\\vgg_16_39-saved-model-07-acc-0.38.hdf5\n",
            "16/16 [==============================] - 75s 5s/step - loss: 1.5927 - acc: 0.4592 - val_loss: 1.9169 - val_acc: 0.3786\n",
            "Epoch 8/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.4427 - acc: 0.5245\n",
            "Epoch 8: val_acc did not improve from 0.37857\n",
            "16/16 [==============================] - 74s 5s/step - loss: 1.4427 - acc: 0.5245 - val_loss: 1.8995 - val_acc: 0.3214\n",
            "Epoch 9/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.6204 - acc: 0.4857\n",
            "Epoch 9: val_acc did not improve from 0.37857\n",
            "16/16 [==============================] - 74s 5s/step - loss: 1.6204 - acc: 0.4857 - val_loss: 2.0726 - val_acc: 0.3643\n",
            "Epoch 10/31\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.5328 - acc: 0.4796\n",
            "Epoch 10: val_acc improved from 0.37857 to 0.45000, saving model to percobaan39_noImgPro/model\\vgg_16_39-saved-model-10-acc-0.45.hdf5\n",
            "16/16 [==============================] - 75s 5s/step - loss: 1.5328 - acc: 0.4796 - val_loss: 2.0961 - val_acc: 0.4500\n",
            "\n",
            "\n",
            "Model Accuracy 0.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.10      0.18        10\n",
            "       10000       0.00      0.00      0.00        10\n",
            "      100000       0.53      1.00      0.69        10\n",
            "        2000       0.00      0.00      0.00        10\n",
            "       20000       0.00      0.00      0.00        10\n",
            "        5000       0.28      0.80      0.41        10\n",
            "       50000       0.47      0.90      0.62        10\n",
            "\n",
            "    accuracy                           0.40        70\n",
            "   macro avg       0.33      0.40      0.27        70\n",
            "weighted avg       0.33      0.40      0.27        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 40 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 38\n",
            "learning rate: 0.09262727628166398\n",
            "batch size: 32\n",
            "dropout rate: 0.79723846300863\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 5.5037 - acc: 0.1857\n",
            "Epoch 1: val_acc improved from -inf to 0.14286, saving model to percobaan40_noImgPro/model\\vgg_16_40-saved-model-01-acc-0.14.hdf5\n",
            "16/16 [==============================] - 75s 5s/step - loss: 5.5037 - acc: 0.1857 - val_loss: 10.7363 - val_acc: 0.1429\n",
            "Epoch 2/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 3.7092 - acc: 0.2898\n",
            "Epoch 2: val_acc improved from 0.14286 to 0.17143, saving model to percobaan40_noImgPro/model\\vgg_16_40-saved-model-02-acc-0.17.hdf5\n",
            "16/16 [==============================] - 75s 5s/step - loss: 3.7092 - acc: 0.2898 - val_loss: 4.2847 - val_acc: 0.1714\n",
            "Epoch 3/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.9306 - acc: 0.2061\n",
            "Epoch 3: val_acc improved from 0.17143 to 0.20714, saving model to percobaan40_noImgPro/model\\vgg_16_40-saved-model-03-acc-0.21.hdf5\n",
            "16/16 [==============================] - 74s 5s/step - loss: 2.9306 - acc: 0.2061 - val_loss: 2.2641 - val_acc: 0.2071\n",
            "Epoch 4/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.2744 - acc: 0.2592\n",
            "Epoch 4: val_acc did not improve from 0.20714\n",
            "16/16 [==============================] - 74s 5s/step - loss: 2.2744 - acc: 0.2592 - val_loss: 2.7265 - val_acc: 0.1429\n",
            "Epoch 5/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.2183 - acc: 0.2469\n",
            "Epoch 5: val_acc did not improve from 0.20714\n",
            "16/16 [==============================] - 74s 5s/step - loss: 2.2183 - acc: 0.2469 - val_loss: 1.8646 - val_acc: 0.2071\n",
            "Epoch 6/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.9508 - acc: 0.3306\n",
            "Epoch 6: val_acc improved from 0.20714 to 0.24286, saving model to percobaan40_noImgPro/model\\vgg_16_40-saved-model-06-acc-0.24.hdf5\n",
            "16/16 [==============================] - 74s 5s/step - loss: 1.9508 - acc: 0.3306 - val_loss: 1.6427 - val_acc: 0.2429\n",
            "Epoch 7/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.8543 - acc: 0.3612\n",
            "Epoch 7: val_acc did not improve from 0.24286\n",
            "16/16 [==============================] - 74s 5s/step - loss: 1.8543 - acc: 0.3612 - val_loss: 2.0310 - val_acc: 0.2143\n",
            "Epoch 8/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.8197 - acc: 0.3694\n",
            "Epoch 8: val_acc did not improve from 0.24286\n",
            "16/16 [==============================] - 73s 5s/step - loss: 1.8197 - acc: 0.3694 - val_loss: 2.2995 - val_acc: 0.1429\n",
            "Epoch 9/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.9720 - acc: 0.3531\n",
            "Epoch 9: val_acc did not improve from 0.24286\n",
            "16/16 [==============================] - 73s 5s/step - loss: 1.9720 - acc: 0.3531 - val_loss: 2.4628 - val_acc: 0.1929\n",
            "Epoch 10/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.9090 - acc: 0.3673\n",
            "Epoch 10: val_acc improved from 0.24286 to 0.54286, saving model to percobaan40_noImgPro/model\\vgg_16_40-saved-model-10-acc-0.54.hdf5\n",
            "16/16 [==============================] - 73s 5s/step - loss: 1.9090 - acc: 0.3673 - val_loss: 1.5897 - val_acc: 0.5429\n",
            "Epoch 11/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.8604 - acc: 0.4143\n",
            "Epoch 11: val_acc did not improve from 0.54286\n",
            "16/16 [==============================] - 73s 5s/step - loss: 1.8604 - acc: 0.4143 - val_loss: 1.5466 - val_acc: 0.3357\n",
            "Epoch 12/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.8515 - acc: 0.3878\n",
            "Epoch 12: val_acc did not improve from 0.54286\n",
            "16/16 [==============================] - 73s 5s/step - loss: 1.8515 - acc: 0.3878 - val_loss: 1.4699 - val_acc: 0.5071\n",
            "Epoch 13/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.8097 - acc: 0.4388\n",
            "Epoch 13: val_acc did not improve from 0.54286\n",
            "16/16 [==============================] - 73s 5s/step - loss: 1.8097 - acc: 0.4388 - val_loss: 1.7389 - val_acc: 0.4786\n",
            "Epoch 14/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.6966 - acc: 0.4429\n",
            "Epoch 14: val_acc did not improve from 0.54286\n",
            "16/16 [==============================] - 73s 5s/step - loss: 1.6966 - acc: 0.4429 - val_loss: 2.8606 - val_acc: 0.2571\n",
            "Epoch 15/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.9781 - acc: 0.4020\n",
            "Epoch 15: val_acc did not improve from 0.54286\n",
            "16/16 [==============================] - 73s 5s/step - loss: 1.9781 - acc: 0.4020 - val_loss: 3.5021 - val_acc: 0.2143\n",
            "Epoch 16/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.8126 - acc: 0.4306\n",
            "Epoch 16: val_acc did not improve from 0.54286\n",
            "16/16 [==============================] - 73s 5s/step - loss: 1.8126 - acc: 0.4306 - val_loss: 3.2065 - val_acc: 0.3000\n",
            "Epoch 17/38\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.8819 - acc: 0.4306\n",
            "Epoch 17: val_acc did not improve from 0.54286\n",
            "16/16 [==============================] - 73s 5s/step - loss: 1.8819 - acc: 0.4306 - val_loss: 3.7830 - val_acc: 0.1429\n",
            "\n",
            "\n",
            "Model Accuracy 0.14285714285714285\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.14      1.00      0.25        10\n",
            "       10000       0.00      0.00      0.00        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.00      0.00      0.00        10\n",
            "       20000       0.00      0.00      0.00        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       0.00      0.00      0.00        10\n",
            "\n",
            "    accuracy                           0.14        70\n",
            "   macro avg       0.02      0.14      0.04        70\n",
            "weighted avg       0.02      0.14      0.04        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 41 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 32\n",
            "learning rate: 0.09341545875707691\n",
            "batch size: 64\n",
            "dropout rate: 0.54414579916867\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 3.2008 - acc: 0.3122\n",
            "Epoch 1: val_acc improved from -inf to 0.14286, saving model to percobaan41_noImgPro/model\\vgg_16_41-saved-model-01-acc-0.14.hdf5\n",
            "8/8 [==============================] - 74s 9s/step - loss: 3.2008 - acc: 0.3122 - val_loss: 15.5462 - val_acc: 0.1429\n",
            "Epoch 2/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.2999 - acc: 0.3816\n",
            "Epoch 2: val_acc improved from 0.14286 to 0.16429, saving model to percobaan41_noImgPro/model\\vgg_16_41-saved-model-02-acc-0.16.hdf5\n",
            "8/8 [==============================] - 73s 10s/step - loss: 2.2999 - acc: 0.3816 - val_loss: 7.9006 - val_acc: 0.1643\n",
            "Epoch 3/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7111 - acc: 0.4653\n",
            "Epoch 3: val_acc improved from 0.16429 to 0.30714, saving model to percobaan41_noImgPro/model\\vgg_16_41-saved-model-03-acc-0.31.hdf5\n",
            "8/8 [==============================] - 73s 9s/step - loss: 1.7111 - acc: 0.4653 - val_loss: 3.4803 - val_acc: 0.3071\n",
            "Epoch 4/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3878 - acc: 0.5286\n",
            "Epoch 4: val_acc did not improve from 0.30714\n",
            "8/8 [==============================] - 73s 9s/step - loss: 1.3878 - acc: 0.5286 - val_loss: 3.9077 - val_acc: 0.2643\n",
            "Epoch 5/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0211 - acc: 0.6531\n",
            "Epoch 5: val_acc improved from 0.30714 to 0.43571, saving model to percobaan41_noImgPro/model\\vgg_16_41-saved-model-05-acc-0.44.hdf5\n",
            "8/8 [==============================] - 73s 9s/step - loss: 1.0211 - acc: 0.6531 - val_loss: 1.8965 - val_acc: 0.4357\n",
            "Epoch 6/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8386 - acc: 0.6939\n",
            "Epoch 6: val_acc did not improve from 0.43571\n",
            "8/8 [==============================] - 73s 10s/step - loss: 0.8386 - acc: 0.6939 - val_loss: 2.5286 - val_acc: 0.3429\n",
            "Epoch 7/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7952 - acc: 0.7449\n",
            "Epoch 7: val_acc did not improve from 0.43571\n",
            "8/8 [==============================] - 73s 9s/step - loss: 0.7952 - acc: 0.7449 - val_loss: 2.2353 - val_acc: 0.4000\n",
            "Epoch 8/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7228 - acc: 0.7592\n",
            "Epoch 8: val_acc improved from 0.43571 to 0.59286, saving model to percobaan41_noImgPro/model\\vgg_16_41-saved-model-08-acc-0.59.hdf5\n",
            "8/8 [==============================] - 73s 9s/step - loss: 0.7228 - acc: 0.7592 - val_loss: 1.1036 - val_acc: 0.5929\n",
            "Epoch 9/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6781 - acc: 0.7612\n",
            "Epoch 9: val_acc did not improve from 0.59286\n",
            "8/8 [==============================] - 73s 9s/step - loss: 0.6781 - acc: 0.7612 - val_loss: 1.7969 - val_acc: 0.4214\n",
            "Epoch 10/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6334 - acc: 0.7776\n",
            "Epoch 10: val_acc did not improve from 0.59286\n",
            "8/8 [==============================] - 73s 9s/step - loss: 0.6334 - acc: 0.7776 - val_loss: 1.3527 - val_acc: 0.5643\n",
            "Epoch 11/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6774 - acc: 0.7735\n",
            "Epoch 11: val_acc did not improve from 0.59286\n",
            "8/8 [==============================] - 73s 9s/step - loss: 0.6774 - acc: 0.7735 - val_loss: 2.9900 - val_acc: 0.3500\n",
            "Epoch 12/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5559 - acc: 0.8245\n",
            "Epoch 12: val_acc did not improve from 0.59286\n",
            "8/8 [==============================] - 73s 9s/step - loss: 0.5559 - acc: 0.8245 - val_loss: 2.0232 - val_acc: 0.5143\n",
            "Epoch 13/32\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6084 - acc: 0.8041\n",
            "Epoch 13: val_acc improved from 0.59286 to 0.62857, saving model to percobaan41_noImgPro/model\\vgg_16_41-saved-model-13-acc-0.63.hdf5\n",
            "8/8 [==============================] - 73s 10s/step - loss: 0.6084 - acc: 0.8041 - val_loss: 1.5550 - val_acc: 0.6286\n",
            "\n",
            "\n",
            "Model Accuracy 0.6428571428571429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.82      0.90      0.86        10\n",
            "       10000       1.00      0.80      0.89        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.64      0.90      0.75        10\n",
            "       20000       0.00      0.00      0.00        10\n",
            "        5000       0.59      1.00      0.74        10\n",
            "       50000       0.45      0.90      0.60        10\n",
            "\n",
            "    accuracy                           0.64        70\n",
            "   macro avg       0.50      0.64      0.55        70\n",
            "weighted avg       0.50      0.64      0.55        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 42 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 33\n",
            "learning rate: 0.08357986191640457\n",
            "batch size: 64\n",
            "dropout rate: 0.6178940993264393\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 3.5159 - acc: 0.2592\n",
            "Epoch 1: val_acc improved from -inf to 0.14286, saving model to percobaan42_noImgPro/model\\vgg_16_42-saved-model-01-acc-0.14.hdf5\n",
            "8/8 [==============================] - 74s 9s/step - loss: 3.5159 - acc: 0.2592 - val_loss: 10.3669 - val_acc: 0.1429\n",
            "Epoch 2/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.2495 - acc: 0.3755\n",
            "Epoch 2: val_acc improved from 0.14286 to 0.15714, saving model to percobaan42_noImgPro/model\\vgg_16_42-saved-model-02-acc-0.16.hdf5\n",
            "8/8 [==============================] - 73s 9s/step - loss: 2.2495 - acc: 0.3755 - val_loss: 8.7120 - val_acc: 0.1571\n",
            "Epoch 3/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8148 - acc: 0.4653\n",
            "Epoch 3: val_acc did not improve from 0.15714\n",
            "8/8 [==============================] - 73s 9s/step - loss: 1.8148 - acc: 0.4653 - val_loss: 9.1992 - val_acc: 0.1429\n",
            "Epoch 4/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4854 - acc: 0.5204\n",
            "Epoch 4: val_acc did not improve from 0.15714\n",
            "8/8 [==============================] - 73s 9s/step - loss: 1.4854 - acc: 0.5204 - val_loss: 7.0159 - val_acc: 0.1429\n",
            "Epoch 5/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.2625 - acc: 0.5612\n",
            "Epoch 5: val_acc did not improve from 0.15714\n",
            "8/8 [==============================] - 72s 9s/step - loss: 1.2625 - acc: 0.5612 - val_loss: 5.8528 - val_acc: 0.1429\n",
            "Epoch 6/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1009 - acc: 0.6122\n",
            "Epoch 6: val_acc did not improve from 0.15714\n",
            "8/8 [==============================] - 73s 9s/step - loss: 1.1009 - acc: 0.6122 - val_loss: 4.6096 - val_acc: 0.1500\n",
            "Epoch 7/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8673 - acc: 0.6878\n",
            "Epoch 7: val_acc improved from 0.15714 to 0.47857, saving model to percobaan42_noImgPro/model\\vgg_16_42-saved-model-07-acc-0.48.hdf5\n",
            "8/8 [==============================] - 73s 9s/step - loss: 0.8673 - acc: 0.6878 - val_loss: 1.2176 - val_acc: 0.4786\n",
            "Epoch 8/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9383 - acc: 0.7020\n",
            "Epoch 8: val_acc improved from 0.47857 to 0.62857, saving model to percobaan42_noImgPro/model\\vgg_16_42-saved-model-08-acc-0.63.hdf5\n",
            "8/8 [==============================] - 73s 9s/step - loss: 0.9383 - acc: 0.7020 - val_loss: 1.2224 - val_acc: 0.6286\n",
            "Epoch 9/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8461 - acc: 0.7265\n",
            "Epoch 9: val_acc did not improve from 0.62857\n",
            "8/8 [==============================] - 72s 9s/step - loss: 0.8461 - acc: 0.7265 - val_loss: 1.1052 - val_acc: 0.5500\n",
            "Epoch 10/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8095 - acc: 0.7429\n",
            "Epoch 10: val_acc did not improve from 0.62857\n",
            "8/8 [==============================] - 73s 9s/step - loss: 0.8095 - acc: 0.7429 - val_loss: 2.6604 - val_acc: 0.3714\n",
            "Epoch 11/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8486 - acc: 0.7327\n",
            "Epoch 11: val_acc did not improve from 0.62857\n",
            "8/8 [==============================] - 72s 9s/step - loss: 0.8486 - acc: 0.7327 - val_loss: 1.7761 - val_acc: 0.4357\n",
            "Epoch 12/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7700 - acc: 0.7347\n",
            "Epoch 12: val_acc did not improve from 0.62857\n",
            "8/8 [==============================] - 73s 9s/step - loss: 0.7700 - acc: 0.7347 - val_loss: 1.3308 - val_acc: 0.5500\n",
            "Epoch 13/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7347 - acc: 0.7653\n",
            "Epoch 13: val_acc did not improve from 0.62857\n",
            "8/8 [==============================] - 72s 9s/step - loss: 0.7347 - acc: 0.7653 - val_loss: 1.3200 - val_acc: 0.6143\n",
            "Epoch 14/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7212 - acc: 0.7816\n",
            "Epoch 14: val_acc improved from 0.62857 to 0.72143, saving model to percobaan42_noImgPro/model\\vgg_16_42-saved-model-14-acc-0.72.hdf5\n",
            "8/8 [==============================] - 73s 9s/step - loss: 0.7212 - acc: 0.7816 - val_loss: 0.8887 - val_acc: 0.7214\n",
            "Epoch 15/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7366 - acc: 0.7796\n",
            "Epoch 15: val_acc did not improve from 0.72143\n",
            "8/8 [==============================] - 73s 9s/step - loss: 0.7366 - acc: 0.7796 - val_loss: 1.3791 - val_acc: 0.5714\n",
            "Epoch 16/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6037 - acc: 0.8041\n",
            "Epoch 16: val_acc did not improve from 0.72143\n",
            "8/8 [==============================] - 74s 9s/step - loss: 0.6037 - acc: 0.8041 - val_loss: 1.5550 - val_acc: 0.5214\n",
            "Epoch 17/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7477 - acc: 0.7633\n",
            "Epoch 17: val_acc did not improve from 0.72143\n",
            "8/8 [==============================] - 74s 9s/step - loss: 0.7477 - acc: 0.7633 - val_loss: 1.8912 - val_acc: 0.4500\n",
            "Epoch 18/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5992 - acc: 0.8000\n",
            "Epoch 18: val_acc did not improve from 0.72143\n",
            "8/8 [==============================] - 74s 9s/step - loss: 0.5992 - acc: 0.8000 - val_loss: 1.9377 - val_acc: 0.5786\n",
            "Epoch 19/33\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7214 - acc: 0.7898\n",
            "Epoch 19: val_acc did not improve from 0.72143\n",
            "8/8 [==============================] - 74s 9s/step - loss: 0.7214 - acc: 0.7898 - val_loss: 1.4854 - val_acc: 0.6071\n",
            "\n",
            "\n",
            "Model Accuracy 0.5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.88      0.70      0.78        10\n",
            "       10000       1.00      0.60      0.75        10\n",
            "      100000       1.00      0.10      0.18        10\n",
            "        2000       1.00      0.10      0.18        10\n",
            "       20000       0.00      0.00      0.00        10\n",
            "        5000       0.36      1.00      0.53        10\n",
            "       50000       0.38      1.00      0.56        10\n",
            "\n",
            "    accuracy                           0.50        70\n",
            "   macro avg       0.66      0.50      0.42        70\n",
            "weighted avg       0.66      0.50      0.42        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 43 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 35\n",
            "learning rate: 0.08801821117022995\n",
            "batch size: 64\n",
            "dropout rate: 0.6837065126645538\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/35\n",
            "8/8 [==============================] - ETA: 0s - loss: 3.6136 - acc: 0.2429\n",
            "Epoch 1: val_acc improved from -inf to 0.19286, saving model to percobaan43_noImgPro/model\\vgg_16_43-saved-model-01-acc-0.19.hdf5\n",
            "8/8 [==============================] - 75s 10s/step - loss: 3.6136 - acc: 0.2429 - val_loss: 18.9336 - val_acc: 0.1929\n",
            "Epoch 2/35\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.5334 - acc: 0.3469\n",
            "Epoch 2: val_acc did not improve from 0.19286\n",
            "8/8 [==============================] - 74s 9s/step - loss: 2.5334 - acc: 0.3469 - val_loss: 12.2356 - val_acc: 0.1429\n",
            "Epoch 3/35\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.9709 - acc: 0.3980\n",
            "Epoch 3: val_acc improved from 0.19286 to 0.23571, saving model to percobaan43_noImgPro/model\\vgg_16_43-saved-model-03-acc-0.24.hdf5\n",
            "8/8 [==============================] - 73s 9s/step - loss: 1.9709 - acc: 0.3980 - val_loss: 4.9429 - val_acc: 0.2357\n",
            "Epoch 4/35\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6469 - acc: 0.4388\n",
            "Epoch 4: val_acc did not improve from 0.23571\n",
            "8/8 [==============================] - 73s 9s/step - loss: 1.6469 - acc: 0.4388 - val_loss: 7.8827 - val_acc: 0.1429\n",
            "Epoch 5/35\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4161 - acc: 0.4857\n",
            "Epoch 5: val_acc did not improve from 0.23571\n",
            "8/8 [==============================] - 73s 9s/step - loss: 1.4161 - acc: 0.4857 - val_loss: 7.7646 - val_acc: 0.1429\n",
            "Epoch 6/35\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3145 - acc: 0.5367\n",
            "Epoch 6: val_acc improved from 0.23571 to 0.25714, saving model to percobaan43_noImgPro/model\\vgg_16_43-saved-model-06-acc-0.26.hdf5\n",
            "8/8 [==============================] - 73s 9s/step - loss: 1.3145 - acc: 0.5367 - val_loss: 5.8517 - val_acc: 0.2571\n",
            "Epoch 7/35\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.2702 - acc: 0.5571\n",
            "Epoch 7: val_acc improved from 0.25714 to 0.28571, saving model to percobaan43_noImgPro/model\\vgg_16_43-saved-model-07-acc-0.29.hdf5\n",
            "8/8 [==============================] - 72s 9s/step - loss: 1.2702 - acc: 0.5571 - val_loss: 5.0125 - val_acc: 0.2857\n",
            "Epoch 8/35\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0014 - acc: 0.6673\n",
            "Epoch 8: val_acc did not improve from 0.28571\n",
            "8/8 [==============================] - 73s 9s/step - loss: 1.0014 - acc: 0.6673 - val_loss: 4.2232 - val_acc: 0.1857\n",
            "Epoch 9/35\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9881 - acc: 0.6592\n",
            "Epoch 9: val_acc improved from 0.28571 to 0.31429, saving model to percobaan43_noImgPro/model\\vgg_16_43-saved-model-09-acc-0.31.hdf5\n",
            "8/8 [==============================] - 73s 9s/step - loss: 0.9881 - acc: 0.6592 - val_loss: 4.1526 - val_acc: 0.3143\n",
            "Epoch 10/35\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9622 - acc: 0.6776\n",
            "Epoch 10: val_acc did not improve from 0.31429\n",
            "8/8 [==============================] - 73s 10s/step - loss: 0.9622 - acc: 0.6776 - val_loss: 4.4034 - val_acc: 0.2857\n",
            "Epoch 11/35\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9311 - acc: 0.6714\n",
            "Epoch 11: val_acc did not improve from 0.31429\n",
            "8/8 [==============================] - 73s 9s/step - loss: 0.9311 - acc: 0.6714 - val_loss: 3.0515 - val_acc: 0.2929\n",
            "Epoch 12/35\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8249 - acc: 0.7143\n",
            "Epoch 12: val_acc did not improve from 0.31429\n",
            "8/8 [==============================] - 73s 9s/step - loss: 0.8249 - acc: 0.7143 - val_loss: 3.4485 - val_acc: 0.2714\n",
            "Epoch 13/35\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7917 - acc: 0.7367\n",
            "Epoch 13: val_acc improved from 0.31429 to 0.33571, saving model to percobaan43_noImgPro/model\\vgg_16_43-saved-model-13-acc-0.34.hdf5\n",
            "8/8 [==============================] - 73s 9s/step - loss: 0.7917 - acc: 0.7367 - val_loss: 3.4067 - val_acc: 0.3357\n",
            "Epoch 14/35\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7795 - acc: 0.7531\n",
            "Epoch 14: val_acc improved from 0.33571 to 0.37857, saving model to percobaan43_noImgPro/model\\vgg_16_43-saved-model-14-acc-0.38.hdf5\n",
            "8/8 [==============================] - 74s 9s/step - loss: 0.7795 - acc: 0.7531 - val_loss: 2.6017 - val_acc: 0.3786\n",
            "Epoch 15/35\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7880 - acc: 0.7551\n",
            "Epoch 15: val_acc did not improve from 0.37857\n",
            "8/8 [==============================] - 73s 10s/step - loss: 0.7880 - acc: 0.7551 - val_loss: 2.6423 - val_acc: 0.3429\n",
            "Epoch 16/35\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9355 - acc: 0.7102\n",
            "Epoch 16: val_acc did not improve from 0.37857\n",
            "8/8 [==============================] - 74s 9s/step - loss: 0.9355 - acc: 0.7102 - val_loss: 2.3124 - val_acc: 0.3357\n",
            "Epoch 17/35\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8101 - acc: 0.7469\n",
            "Epoch 17: val_acc improved from 0.37857 to 0.49286, saving model to percobaan43_noImgPro/model\\vgg_16_43-saved-model-17-acc-0.49.hdf5\n",
            "8/8 [==============================] - 75s 10s/step - loss: 0.8101 - acc: 0.7469 - val_loss: 1.5976 - val_acc: 0.4929\n",
            "Epoch 18/35\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8474 - acc: 0.7347\n",
            "Epoch 18: val_acc did not improve from 0.49286\n",
            "8/8 [==============================] - 73s 9s/step - loss: 0.8474 - acc: 0.7347 - val_loss: 1.8297 - val_acc: 0.4500\n",
            "Epoch 19/35\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8526 - acc: 0.7163\n",
            "Epoch 19: val_acc did not improve from 0.49286\n",
            "8/8 [==============================] - 73s 9s/step - loss: 0.8526 - acc: 0.7163 - val_loss: 2.9260 - val_acc: 0.3071\n",
            "Epoch 20/35\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6594 - acc: 0.7735\n",
            "Epoch 20: val_acc did not improve from 0.49286\n",
            "8/8 [==============================] - 73s 9s/step - loss: 0.6594 - acc: 0.7735 - val_loss: 3.9687 - val_acc: 0.2857\n",
            "Epoch 21/35\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7930 - acc: 0.7490\n",
            "Epoch 21: val_acc improved from 0.49286 to 0.56429, saving model to percobaan43_noImgPro/model\\vgg_16_43-saved-model-21-acc-0.56.hdf5\n",
            "8/8 [==============================] - 73s 9s/step - loss: 0.7930 - acc: 0.7490 - val_loss: 1.6689 - val_acc: 0.5643\n",
            "Epoch 22/35\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8274 - acc: 0.7408\n",
            "Epoch 22: val_acc did not improve from 0.56429\n",
            "8/8 [==============================] - 73s 9s/step - loss: 0.8274 - acc: 0.7408 - val_loss: 1.8062 - val_acc: 0.5143\n",
            "\n",
            "\n",
            "Model Accuracy 0.34285714285714286\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.80      0.40      0.53        10\n",
            "       10000       1.00      0.30      0.46        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.44      0.70      0.54        10\n",
            "       20000       0.00      0.00      0.00        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       0.22      1.00      0.36        10\n",
            "\n",
            "    accuracy                           0.34        70\n",
            "   macro avg       0.35      0.34      0.27        70\n",
            "weighted avg       0.35      0.34      0.27        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 44 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 34\n",
            "learning rate: 0.08502832751877068\n",
            "batch size: 64\n",
            "dropout rate: 0.7557551130442524\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/34\n",
            "8/8 [==============================] - ETA: 0s - loss: 4.0954 - acc: 0.2122\n",
            "Epoch 1: val_acc improved from -inf to 0.14286, saving model to percobaan44_noImgPro/model\\vgg_16_44-saved-model-01-acc-0.14.hdf5\n",
            "8/8 [==============================] - 77s 10s/step - loss: 4.0954 - acc: 0.2122 - val_loss: 22.7424 - val_acc: 0.1429\n",
            "Epoch 2/34\n",
            "8/8 [==============================] - ETA: 0s - loss: 3.0266 - acc: 0.3306\n",
            "Epoch 2: val_acc improved from 0.14286 to 0.23571, saving model to percobaan44_noImgPro/model\\vgg_16_44-saved-model-02-acc-0.24.hdf5\n",
            "8/8 [==============================] - 76s 10s/step - loss: 3.0266 - acc: 0.3306 - val_loss: 6.7896 - val_acc: 0.2357\n",
            "Epoch 3/34\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.3978 - acc: 0.3020\n",
            "Epoch 3: val_acc improved from 0.23571 to 0.25714, saving model to percobaan44_noImgPro/model\\vgg_16_44-saved-model-03-acc-0.26.hdf5\n",
            "8/8 [==============================] - 76s 10s/step - loss: 2.3978 - acc: 0.3020 - val_loss: 3.4473 - val_acc: 0.2571\n",
            "Epoch 4/34\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.9074 - acc: 0.3224\n",
            "Epoch 4: val_acc did not improve from 0.25714\n",
            "8/8 [==============================] - 76s 10s/step - loss: 1.9074 - acc: 0.3224 - val_loss: 3.6753 - val_acc: 0.1429\n",
            "Epoch 5/34\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6990 - acc: 0.3673\n",
            "Epoch 5: val_acc did not improve from 0.25714\n",
            "8/8 [==============================] - 76s 10s/step - loss: 1.6990 - acc: 0.3673 - val_loss: 2.3976 - val_acc: 0.2000\n",
            "Epoch 6/34\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5702 - acc: 0.4531\n",
            "Epoch 6: val_acc did not improve from 0.25714\n",
            "8/8 [==============================] - 76s 10s/step - loss: 1.5702 - acc: 0.4531 - val_loss: 2.6119 - val_acc: 0.1429\n",
            "Epoch 7/34\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3571 - acc: 0.5122\n",
            "Epoch 7: val_acc improved from 0.25714 to 0.28571, saving model to percobaan44_noImgPro/model\\vgg_16_44-saved-model-07-acc-0.29.hdf5\n",
            "8/8 [==============================] - 77s 10s/step - loss: 1.3571 - acc: 0.5122 - val_loss: 2.4069 - val_acc: 0.2857\n",
            "Epoch 8/34\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3084 - acc: 0.5367\n",
            "Epoch 8: val_acc did not improve from 0.28571\n",
            "8/8 [==============================] - 77s 10s/step - loss: 1.3084 - acc: 0.5367 - val_loss: 3.3828 - val_acc: 0.1857\n",
            "Epoch 9/34\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.2427 - acc: 0.5449\n",
            "Epoch 9: val_acc did not improve from 0.28571\n",
            "8/8 [==============================] - 77s 10s/step - loss: 1.2427 - acc: 0.5449 - val_loss: 2.8111 - val_acc: 0.2643\n",
            "Epoch 10/34\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1760 - acc: 0.5592\n",
            "Epoch 10: val_acc improved from 0.28571 to 0.38571, saving model to percobaan44_noImgPro/model\\vgg_16_44-saved-model-10-acc-0.39.hdf5\n",
            "8/8 [==============================] - 77s 10s/step - loss: 1.1760 - acc: 0.5592 - val_loss: 2.1353 - val_acc: 0.3857\n",
            "Epoch 11/34\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1089 - acc: 0.6082\n",
            "Epoch 11: val_acc did not improve from 0.38571\n",
            "8/8 [==============================] - 77s 10s/step - loss: 1.1089 - acc: 0.6082 - val_loss: 2.9590 - val_acc: 0.2000\n",
            "Epoch 12/34\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.2386 - acc: 0.5939\n",
            "Epoch 12: val_acc did not improve from 0.38571\n",
            "8/8 [==============================] - 76s 10s/step - loss: 1.2386 - acc: 0.5939 - val_loss: 2.4979 - val_acc: 0.2643\n",
            "Epoch 13/34\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0083 - acc: 0.6367\n",
            "Epoch 13: val_acc did not improve from 0.38571\n",
            "8/8 [==============================] - 76s 10s/step - loss: 1.0083 - acc: 0.6367 - val_loss: 1.6954 - val_acc: 0.3714\n",
            "Epoch 14/34\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0853 - acc: 0.6265\n",
            "Epoch 14: val_acc did not improve from 0.38571\n",
            "8/8 [==============================] - 76s 10s/step - loss: 1.0853 - acc: 0.6265 - val_loss: 2.0322 - val_acc: 0.3857\n",
            "Epoch 15/34\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9722 - acc: 0.6388\n",
            "Epoch 15: val_acc did not improve from 0.38571\n",
            "8/8 [==============================] - 78s 10s/step - loss: 0.9722 - acc: 0.6388 - val_loss: 3.3819 - val_acc: 0.2429\n",
            "Epoch 16/34\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9510 - acc: 0.6755\n",
            "Epoch 16: val_acc improved from 0.38571 to 0.42857, saving model to percobaan44_noImgPro/model\\vgg_16_44-saved-model-16-acc-0.43.hdf5\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.9510 - acc: 0.6755 - val_loss: 1.8836 - val_acc: 0.4286\n",
            "Epoch 17/34\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9828 - acc: 0.6776\n",
            "Epoch 17: val_acc improved from 0.42857 to 0.54286, saving model to percobaan44_noImgPro/model\\vgg_16_44-saved-model-17-acc-0.54.hdf5\n",
            "8/8 [==============================] - 78s 10s/step - loss: 0.9828 - acc: 0.6776 - val_loss: 1.3862 - val_acc: 0.5429\n",
            "Epoch 18/34\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9998 - acc: 0.6755\n",
            "Epoch 18: val_acc did not improve from 0.54286\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.9998 - acc: 0.6755 - val_loss: 1.4865 - val_acc: 0.5357\n",
            "Epoch 19/34\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8956 - acc: 0.6857\n",
            "Epoch 19: val_acc did not improve from 0.54286\n",
            "8/8 [==============================] - 78s 10s/step - loss: 0.8956 - acc: 0.6857 - val_loss: 1.6471 - val_acc: 0.5143\n",
            "Epoch 20/34\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0047 - acc: 0.6878\n",
            "Epoch 20: val_acc did not improve from 0.54286\n",
            "8/8 [==============================] - 80s 10s/step - loss: 1.0047 - acc: 0.6878 - val_loss: 1.4750 - val_acc: 0.4857\n",
            "Epoch 21/34\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0043 - acc: 0.6959\n",
            "Epoch 21: val_acc did not improve from 0.54286\n",
            "8/8 [==============================] - 78s 10s/step - loss: 1.0043 - acc: 0.6959 - val_loss: 2.0732 - val_acc: 0.5143\n",
            "Epoch 22/34\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0455 - acc: 0.6510\n",
            "Epoch 22: val_acc did not improve from 0.54286\n",
            "8/8 [==============================] - 81s 11s/step - loss: 1.0455 - acc: 0.6510 - val_loss: 1.7340 - val_acc: 0.4929\n",
            "\n",
            "\n",
            "Model Accuracy 0.44285714285714284\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.60      0.75        10\n",
            "       10000       0.24      1.00      0.38        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.67      0.60      0.63        10\n",
            "       20000       0.60      0.60      0.60        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       1.00      0.30      0.46        10\n",
            "\n",
            "    accuracy                           0.44        70\n",
            "   macro avg       0.50      0.44      0.40        70\n",
            "weighted avg       0.50      0.44      0.40        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 45 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 35\n",
            "learning rate: 0.086017275135224\n",
            "batch size: 128\n",
            "dropout rate: 0.5441284754498331\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.9055 - acc: 0.2490 \n",
            "Epoch 1: val_acc improved from -inf to 0.17143, saving model to percobaan45_noImgPro/model\\vgg_16_45-saved-model-01-acc-0.17.hdf5\n",
            "4/4 [==============================] - 77s 20s/step - loss: 2.9055 - acc: 0.2490 - val_loss: 15.2347 - val_acc: 0.1714\n",
            "Epoch 2/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.8749 - acc: 0.4388 \n",
            "Epoch 2: val_acc improved from 0.17143 to 0.22143, saving model to percobaan45_noImgPro/model\\vgg_16_45-saved-model-02-acc-0.22.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 1.8749 - acc: 0.4388 - val_loss: 18.6524 - val_acc: 0.2214\n",
            "Epoch 3/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.3685 - acc: 0.5347 \n",
            "Epoch 3: val_acc did not improve from 0.22143\n",
            "4/4 [==============================] - 79s 21s/step - loss: 1.3685 - acc: 0.5347 - val_loss: 13.5200 - val_acc: 0.2071\n",
            "Epoch 4/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0773 - acc: 0.6510 \n",
            "Epoch 4: val_acc did not improve from 0.22143\n",
            "4/4 [==============================] - 80s 21s/step - loss: 1.0773 - acc: 0.6510 - val_loss: 10.7716 - val_acc: 0.1857\n",
            "Epoch 5/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0334 - acc: 0.6592 \n",
            "Epoch 5: val_acc did not improve from 0.22143\n",
            "4/4 [==============================] - 77s 20s/step - loss: 1.0334 - acc: 0.6592 - val_loss: 9.7064 - val_acc: 0.2143\n",
            "Epoch 6/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9070 - acc: 0.6980 \n",
            "Epoch 6: val_acc did not improve from 0.22143\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.9070 - acc: 0.6980 - val_loss: 8.6805 - val_acc: 0.1714\n",
            "Epoch 7/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7381 - acc: 0.7408 \n",
            "Epoch 7: val_acc improved from 0.22143 to 0.30714, saving model to percobaan45_noImgPro/model\\vgg_16_45-saved-model-07-acc-0.31.hdf5\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.7381 - acc: 0.7408 - val_loss: 4.9435 - val_acc: 0.3071\n",
            "Epoch 8/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6702 - acc: 0.7449 \n",
            "Epoch 8: val_acc did not improve from 0.30714\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.6702 - acc: 0.7449 - val_loss: 5.3204 - val_acc: 0.2571\n",
            "Epoch 9/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5880 - acc: 0.7959 \n",
            "Epoch 9: val_acc improved from 0.30714 to 0.32857, saving model to percobaan45_noImgPro/model\\vgg_16_45-saved-model-09-acc-0.33.hdf5\n",
            "4/4 [==============================] - 79s 22s/step - loss: 0.5880 - acc: 0.7959 - val_loss: 4.7756 - val_acc: 0.3286\n",
            "Epoch 10/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6527 - acc: 0.7980 \n",
            "Epoch 10: val_acc did not improve from 0.32857\n",
            "4/4 [==============================] - 80s 22s/step - loss: 0.6527 - acc: 0.7980 - val_loss: 4.9851 - val_acc: 0.3143\n",
            "Epoch 11/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5381 - acc: 0.8265 \n",
            "Epoch 11: val_acc did not improve from 0.32857\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.5381 - acc: 0.8265 - val_loss: 6.3463 - val_acc: 0.2500\n",
            "Epoch 12/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5291 - acc: 0.8082 \n",
            "Epoch 12: val_acc did not improve from 0.32857\n",
            "4/4 [==============================] - 80s 22s/step - loss: 0.5291 - acc: 0.8082 - val_loss: 4.5725 - val_acc: 0.3214\n",
            "Epoch 13/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4562 - acc: 0.8429 \n",
            "Epoch 13: val_acc improved from 0.32857 to 0.50714, saving model to percobaan45_noImgPro/model\\vgg_16_45-saved-model-13-acc-0.51.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.4562 - acc: 0.8429 - val_loss: 2.6963 - val_acc: 0.5071\n",
            "Epoch 14/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4402 - acc: 0.8306 \n",
            "Epoch 14: val_acc did not improve from 0.50714\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.4402 - acc: 0.8306 - val_loss: 2.0892 - val_acc: 0.4500\n",
            "Epoch 15/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4220 - acc: 0.8510 \n",
            "Epoch 15: val_acc improved from 0.50714 to 0.52143, saving model to percobaan45_noImgPro/model\\vgg_16_45-saved-model-15-acc-0.52.hdf5\n",
            "4/4 [==============================] - 80s 22s/step - loss: 0.4220 - acc: 0.8510 - val_loss: 1.6645 - val_acc: 0.5214\n",
            "Epoch 16/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3996 - acc: 0.8551 \n",
            "Epoch 16: val_acc did not improve from 0.52143\n",
            "4/4 [==============================] - 78s 20s/step - loss: 0.3996 - acc: 0.8551 - val_loss: 2.2975 - val_acc: 0.4286\n",
            "Epoch 17/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3804 - acc: 0.8673 \n",
            "Epoch 17: val_acc did not improve from 0.52143\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.3804 - acc: 0.8673 - val_loss: 2.3997 - val_acc: 0.4000\n",
            "Epoch 18/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3778 - acc: 0.8816 \n",
            "Epoch 18: val_acc did not improve from 0.52143\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.3778 - acc: 0.8816 - val_loss: 1.5015 - val_acc: 0.5214\n",
            "Epoch 19/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3023 - acc: 0.8816 \n",
            "Epoch 19: val_acc did not improve from 0.52143\n",
            "4/4 [==============================] - 81s 22s/step - loss: 0.3023 - acc: 0.8816 - val_loss: 1.9503 - val_acc: 0.5143\n",
            "Epoch 20/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3652 - acc: 0.8694 \n",
            "Epoch 20: val_acc did not improve from 0.52143\n",
            "4/4 [==============================] - 78s 21s/step - loss: 0.3652 - acc: 0.8694 - val_loss: 2.5917 - val_acc: 0.4857\n",
            "Epoch 21/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4432 - acc: 0.8571 \n",
            "Epoch 21: val_acc improved from 0.52143 to 0.53571, saving model to percobaan45_noImgPro/model\\vgg_16_45-saved-model-21-acc-0.54.hdf5\n",
            "4/4 [==============================] - 81s 22s/step - loss: 0.4432 - acc: 0.8571 - val_loss: 2.2410 - val_acc: 0.5357\n",
            "Epoch 22/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2833 - acc: 0.9041 \n",
            "Epoch 22: val_acc improved from 0.53571 to 0.60714, saving model to percobaan45_noImgPro/model\\vgg_16_45-saved-model-22-acc-0.61.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.2833 - acc: 0.9041 - val_loss: 1.8448 - val_acc: 0.6071\n",
            "Epoch 23/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3106 - acc: 0.8918 \n",
            "Epoch 23: val_acc did not improve from 0.60714\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.3106 - acc: 0.8918 - val_loss: 1.3227 - val_acc: 0.6000\n",
            "Epoch 24/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2766 - acc: 0.9041 \n",
            "Epoch 24: val_acc improved from 0.60714 to 0.62857, saving model to percobaan45_noImgPro/model\\vgg_16_45-saved-model-24-acc-0.63.hdf5\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.2766 - acc: 0.9041 - val_loss: 1.3053 - val_acc: 0.6286\n",
            "Epoch 25/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2669 - acc: 0.8980 \n",
            "Epoch 25: val_acc improved from 0.62857 to 0.65000, saving model to percobaan45_noImgPro/model\\vgg_16_45-saved-model-25-acc-0.65.hdf5\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.2669 - acc: 0.8980 - val_loss: 1.3187 - val_acc: 0.6500\n",
            "Epoch 26/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2965 - acc: 0.8939 \n",
            "Epoch 26: val_acc improved from 0.65000 to 0.69286, saving model to percobaan45_noImgPro/model\\vgg_16_45-saved-model-26-acc-0.69.hdf5\n",
            "4/4 [==============================] - 81s 21s/step - loss: 0.2965 - acc: 0.8939 - val_loss: 1.1381 - val_acc: 0.6929\n",
            "Epoch 27/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1917 - acc: 0.9184 \n",
            "Epoch 27: val_acc did not improve from 0.69286\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.1917 - acc: 0.9184 - val_loss: 1.1882 - val_acc: 0.6643\n",
            "Epoch 28/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2410 - acc: 0.9163 \n",
            "Epoch 28: val_acc did not improve from 0.69286\n",
            "4/4 [==============================] - 80s 22s/step - loss: 0.2410 - acc: 0.9163 - val_loss: 1.1692 - val_acc: 0.6571\n",
            "Epoch 29/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3221 - acc: 0.8857 \n",
            "Epoch 29: val_acc improved from 0.69286 to 0.76429, saving model to percobaan45_noImgPro/model\\vgg_16_45-saved-model-29-acc-0.76.hdf5\n",
            "4/4 [==============================] - 81s 21s/step - loss: 0.3221 - acc: 0.8857 - val_loss: 0.9333 - val_acc: 0.7643\n",
            "Epoch 30/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2603 - acc: 0.9061 \n",
            "Epoch 30: val_acc did not improve from 0.76429\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.2603 - acc: 0.9061 - val_loss: 1.2861 - val_acc: 0.7214\n",
            "Epoch 31/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3815 - acc: 0.8755 \n",
            "Epoch 31: val_acc did not improve from 0.76429\n",
            "4/4 [==============================] - 81s 21s/step - loss: 0.3815 - acc: 0.8755 - val_loss: 1.5655 - val_acc: 0.6786\n",
            "Epoch 32/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2577 - acc: 0.9082 \n",
            "Epoch 32: val_acc did not improve from 0.76429\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.2577 - acc: 0.9082 - val_loss: 1.1787 - val_acc: 0.6929\n",
            "Epoch 33/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3942 - acc: 0.8918 \n",
            "Epoch 33: val_acc did not improve from 0.76429\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.3942 - acc: 0.8918 - val_loss: 0.9675 - val_acc: 0.7643\n",
            "Epoch 34/35\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3148 - acc: 0.8959 \n",
            "Epoch 34: val_acc did not improve from 0.76429\n",
            "4/4 [==============================] - 81s 21s/step - loss: 0.3148 - acc: 0.8959 - val_loss: 1.0010 - val_acc: 0.7643\n",
            "\n",
            "\n",
            "Model Accuracy 0.7142857142857143\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.70      0.82        10\n",
            "       10000       1.00      0.90      0.95        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.67      1.00      0.80        10\n",
            "       20000       0.75      0.60      0.67        10\n",
            "        5000       0.56      1.00      0.71        10\n",
            "       50000       0.62      0.80      0.70        10\n",
            "\n",
            "    accuracy                           0.71        70\n",
            "   macro avg       0.66      0.71      0.66        70\n",
            "weighted avg       0.66      0.71      0.66        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 46 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 37\n",
            "learning rate: 0.07845587489952437\n",
            "batch size: 128\n",
            "dropout rate: 0.6446680957669143\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 3.1029 - acc: 0.2612 \n",
            "Epoch 1: val_acc improved from -inf to 0.14286, saving model to percobaan46_noImgPro/model\\vgg_16_46-saved-model-01-acc-0.14.hdf5\n",
            "4/4 [==============================] - 81s 22s/step - loss: 3.1029 - acc: 0.2612 - val_loss: 21.7435 - val_acc: 0.1429\n",
            "Epoch 2/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.2278 - acc: 0.3980 \n",
            "Epoch 2: val_acc improved from 0.14286 to 0.17857, saving model to percobaan46_noImgPro/model\\vgg_16_46-saved-model-02-acc-0.18.hdf5\n",
            "4/4 [==============================] - 80s 21s/step - loss: 2.2278 - acc: 0.3980 - val_loss: 10.6042 - val_acc: 0.1786\n",
            "Epoch 3/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.8781 - acc: 0.4449 \n",
            "Epoch 3: val_acc improved from 0.17857 to 0.21429, saving model to percobaan46_noImgPro/model\\vgg_16_46-saved-model-03-acc-0.21.hdf5\n",
            "4/4 [==============================] - 80s 21s/step - loss: 1.8781 - acc: 0.4449 - val_loss: 6.9384 - val_acc: 0.2143\n",
            "Epoch 4/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.3977 - acc: 0.5551 \n",
            "Epoch 4: val_acc improved from 0.21429 to 0.23571, saving model to percobaan46_noImgPro/model\\vgg_16_46-saved-model-04-acc-0.24.hdf5\n",
            "4/4 [==============================] - 80s 21s/step - loss: 1.3977 - acc: 0.5551 - val_loss: 6.8179 - val_acc: 0.2357\n",
            "Epoch 5/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1979 - acc: 0.5980 \n",
            "Epoch 5: val_acc improved from 0.23571 to 0.25000, saving model to percobaan46_noImgPro/model\\vgg_16_46-saved-model-05-acc-0.25.hdf5\n",
            "4/4 [==============================] - 80s 21s/step - loss: 1.1979 - acc: 0.5980 - val_loss: 5.6004 - val_acc: 0.2500\n",
            "Epoch 6/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0126 - acc: 0.6204 \n",
            "Epoch 6: val_acc improved from 0.25000 to 0.25714, saving model to percobaan46_noImgPro/model\\vgg_16_46-saved-model-06-acc-0.26.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 1.0126 - acc: 0.6204 - val_loss: 4.9054 - val_acc: 0.2571\n",
            "Epoch 7/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9559 - acc: 0.6429 \n",
            "Epoch 7: val_acc did not improve from 0.25714\n",
            "4/4 [==============================] - 79s 22s/step - loss: 0.9559 - acc: 0.6429 - val_loss: 4.3589 - val_acc: 0.2357\n",
            "Epoch 8/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9178 - acc: 0.6551 \n",
            "Epoch 8: val_acc improved from 0.25714 to 0.30714, saving model to percobaan46_noImgPro/model\\vgg_16_46-saved-model-08-acc-0.31.hdf5\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.9178 - acc: 0.6551 - val_loss: 3.4988 - val_acc: 0.3071\n",
            "Epoch 9/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7705 - acc: 0.7143 \n",
            "Epoch 9: val_acc improved from 0.30714 to 0.33571, saving model to percobaan46_noImgPro/model\\vgg_16_46-saved-model-09-acc-0.34.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.7705 - acc: 0.7143 - val_loss: 3.4986 - val_acc: 0.3357\n",
            "Epoch 10/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7366 - acc: 0.7204 \n",
            "Epoch 10: val_acc did not improve from 0.33571\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.7366 - acc: 0.7204 - val_loss: 4.2736 - val_acc: 0.2786\n",
            "Epoch 11/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6418 - acc: 0.7714 \n",
            "Epoch 11: val_acc did not improve from 0.33571\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.6418 - acc: 0.7714 - val_loss: 4.2471 - val_acc: 0.2714\n",
            "Epoch 12/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6044 - acc: 0.7816 \n",
            "Epoch 12: val_acc improved from 0.33571 to 0.37857, saving model to percobaan46_noImgPro/model\\vgg_16_46-saved-model-12-acc-0.38.hdf5\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.6044 - acc: 0.7816 - val_loss: 3.5672 - val_acc: 0.3786\n",
            "Epoch 13/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5784 - acc: 0.8102 \n",
            "Epoch 13: val_acc improved from 0.37857 to 0.46429, saving model to percobaan46_noImgPro/model\\vgg_16_46-saved-model-13-acc-0.46.hdf5\n",
            "4/4 [==============================] - 80s 22s/step - loss: 0.5784 - acc: 0.8102 - val_loss: 2.2441 - val_acc: 0.4643\n",
            "Epoch 14/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6144 - acc: 0.7857 \n",
            "Epoch 14: val_acc improved from 0.46429 to 0.53571, saving model to percobaan46_noImgPro/model\\vgg_16_46-saved-model-14-acc-0.54.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.6144 - acc: 0.7857 - val_loss: 1.7346 - val_acc: 0.5357\n",
            "Epoch 15/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5517 - acc: 0.8102 \n",
            "Epoch 15: val_acc improved from 0.53571 to 0.59286, saving model to percobaan46_noImgPro/model\\vgg_16_46-saved-model-15-acc-0.59.hdf5\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.5517 - acc: 0.8102 - val_loss: 1.6653 - val_acc: 0.5929\n",
            "Epoch 16/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5358 - acc: 0.8347 \n",
            "Epoch 16: val_acc did not improve from 0.59286\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.5358 - acc: 0.8347 - val_loss: 1.4978 - val_acc: 0.5929\n",
            "Epoch 17/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4213 - acc: 0.8510 \n",
            "Epoch 17: val_acc improved from 0.59286 to 0.61429, saving model to percobaan46_noImgPro/model\\vgg_16_46-saved-model-17-acc-0.61.hdf5\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.4213 - acc: 0.8510 - val_loss: 1.6688 - val_acc: 0.6143\n",
            "Epoch 18/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5436 - acc: 0.7980 \n",
            "Epoch 18: val_acc did not improve from 0.61429\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.5436 - acc: 0.7980 - val_loss: 1.5203 - val_acc: 0.6000\n",
            "Epoch 19/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4745 - acc: 0.8490 \n",
            "Epoch 19: val_acc did not improve from 0.61429\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.4745 - acc: 0.8490 - val_loss: 1.4192 - val_acc: 0.6071\n",
            "Epoch 20/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4479 - acc: 0.8490 \n",
            "Epoch 20: val_acc did not improve from 0.61429\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.4479 - acc: 0.8490 - val_loss: 1.6272 - val_acc: 0.5571\n",
            "Epoch 21/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4192 - acc: 0.8633 \n",
            "Epoch 21: val_acc did not improve from 0.61429\n",
            "4/4 [==============================] - 79s 22s/step - loss: 0.4192 - acc: 0.8633 - val_loss: 1.9159 - val_acc: 0.5071\n",
            "Epoch 22/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5306 - acc: 0.8367 \n",
            "Epoch 22: val_acc did not improve from 0.61429\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.5306 - acc: 0.8367 - val_loss: 1.5208 - val_acc: 0.6000\n",
            "Epoch 23/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3621 - acc: 0.8735 \n",
            "Epoch 23: val_acc did not improve from 0.61429\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.3621 - acc: 0.8735 - val_loss: 1.5873 - val_acc: 0.5571\n",
            "Epoch 24/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4097 - acc: 0.8408 \n",
            "Epoch 24: val_acc improved from 0.61429 to 0.67143, saving model to percobaan46_noImgPro/model\\vgg_16_46-saved-model-24-acc-0.67.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.4097 - acc: 0.8408 - val_loss: 1.3416 - val_acc: 0.6714\n",
            "Epoch 25/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4390 - acc: 0.8510 \n",
            "Epoch 25: val_acc improved from 0.67143 to 0.69286, saving model to percobaan46_noImgPro/model\\vgg_16_46-saved-model-25-acc-0.69.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.4390 - acc: 0.8510 - val_loss: 1.1055 - val_acc: 0.6929\n",
            "Epoch 26/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3687 - acc: 0.8878 \n",
            "Epoch 26: val_acc did not improve from 0.69286\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.3687 - acc: 0.8878 - val_loss: 1.1018 - val_acc: 0.6714\n",
            "Epoch 27/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4251 - acc: 0.8694 \n",
            "Epoch 27: val_acc did not improve from 0.69286\n",
            "4/4 [==============================] - 83s 22s/step - loss: 0.4251 - acc: 0.8694 - val_loss: 1.6673 - val_acc: 0.6071\n",
            "Epoch 28/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3827 - acc: 0.8653 \n",
            "Epoch 28: val_acc did not improve from 0.69286\n",
            "4/4 [==============================] - 80s 22s/step - loss: 0.3827 - acc: 0.8653 - val_loss: 1.8488 - val_acc: 0.6143\n",
            "Epoch 29/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3036 - acc: 0.8898 \n",
            "Epoch 29: val_acc did not improve from 0.69286\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.3036 - acc: 0.8898 - val_loss: 2.0290 - val_acc: 0.5857\n",
            "Epoch 30/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3484 - acc: 0.8633 \n",
            "Epoch 30: val_acc did not improve from 0.69286\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.3484 - acc: 0.8633 - val_loss: 3.1923 - val_acc: 0.4357\n",
            "Epoch 31/37\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4156 - acc: 0.8735 \n",
            "Epoch 31: val_acc did not improve from 0.69286\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.4156 - acc: 0.8735 - val_loss: 2.8581 - val_acc: 0.4571\n",
            "\n",
            "\n",
            "Model Accuracy 0.3142857142857143\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.20      0.33        10\n",
            "       10000       1.00      0.20      0.33        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.38      0.60      0.46        10\n",
            "       20000       0.00      0.00      0.00        10\n",
            "        5000       1.00      0.20      0.33        10\n",
            "       50000       0.21      1.00      0.34        10\n",
            "\n",
            "    accuracy                           0.31        70\n",
            "   macro avg       0.51      0.31      0.26        70\n",
            "weighted avg       0.51      0.31      0.26        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 47 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 33\n",
            "learning rate: 0.09356215504020778\n",
            "batch size: 128\n",
            "dropout rate: 0.6581876155822749\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 3.3981 - acc: 0.2327 \n",
            "Epoch 1: val_acc improved from -inf to 0.20000, saving model to percobaan47_noImgPro/model\\vgg_16_47-saved-model-01-acc-0.20.hdf5\n",
            "4/4 [==============================] - 81s 22s/step - loss: 3.3981 - acc: 0.2327 - val_loss: 23.7381 - val_acc: 0.2000\n",
            "Epoch 2/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.6380 - acc: 0.3551 \n",
            "Epoch 2: val_acc did not improve from 0.20000\n",
            "4/4 [==============================] - 80s 21s/step - loss: 2.6380 - acc: 0.3551 - val_loss: 14.6180 - val_acc: 0.1643\n",
            "Epoch 3/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.9946 - acc: 0.4429 \n",
            "Epoch 3: val_acc improved from 0.20000 to 0.30714, saving model to percobaan47_noImgPro/model\\vgg_16_47-saved-model-03-acc-0.31.hdf5\n",
            "4/4 [==============================] - 80s 22s/step - loss: 1.9946 - acc: 0.4429 - val_loss: 7.7386 - val_acc: 0.3071\n",
            "Epoch 4/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.4607 - acc: 0.5245 \n",
            "Epoch 4: val_acc did not improve from 0.30714\n",
            "4/4 [==============================] - 80s 21s/step - loss: 1.4607 - acc: 0.5245 - val_loss: 6.0638 - val_acc: 0.2357\n",
            "Epoch 5/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.4553 - acc: 0.5102 \n",
            "Epoch 5: val_acc did not improve from 0.30714\n",
            "4/4 [==============================] - 79s 21s/step - loss: 1.4553 - acc: 0.5102 - val_loss: 4.7437 - val_acc: 0.2571\n",
            "Epoch 6/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2363 - acc: 0.5265 \n",
            "Epoch 6: val_acc did not improve from 0.30714\n",
            "4/4 [==============================] - 80s 22s/step - loss: 1.2363 - acc: 0.5265 - val_loss: 3.2888 - val_acc: 0.3071\n",
            "Epoch 7/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1940 - acc: 0.6082 \n",
            "Epoch 7: val_acc improved from 0.30714 to 0.32857, saving model to percobaan47_noImgPro/model\\vgg_16_47-saved-model-07-acc-0.33.hdf5\n",
            "4/4 [==============================] - 80s 21s/step - loss: 1.1940 - acc: 0.6082 - val_loss: 3.0527 - val_acc: 0.3286\n",
            "Epoch 8/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9654 - acc: 0.6388 \n",
            "Epoch 8: val_acc did not improve from 0.32857\n",
            "4/4 [==============================] - 79s 22s/step - loss: 0.9654 - acc: 0.6388 - val_loss: 3.0991 - val_acc: 0.3286\n",
            "Epoch 9/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8699 - acc: 0.6939 \n",
            "Epoch 9: val_acc improved from 0.32857 to 0.40714, saving model to percobaan47_noImgPro/model\\vgg_16_47-saved-model-09-acc-0.41.hdf5\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.8699 - acc: 0.6939 - val_loss: 3.1133 - val_acc: 0.4071\n",
            "Epoch 10/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8528 - acc: 0.7041 \n",
            "Epoch 10: val_acc did not improve from 0.40714\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.8528 - acc: 0.7041 - val_loss: 3.1927 - val_acc: 0.3929\n",
            "Epoch 11/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7536 - acc: 0.7388 \n",
            "Epoch 11: val_acc did not improve from 0.40714\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.7536 - acc: 0.7388 - val_loss: 3.4187 - val_acc: 0.3571\n",
            "Epoch 12/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6624 - acc: 0.7816 \n",
            "Epoch 12: val_acc did not improve from 0.40714\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.6624 - acc: 0.7816 - val_loss: 4.0085 - val_acc: 0.2714\n",
            "\n",
            "\n",
            "Model Accuracy 0.22857142857142856\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.00      0.00      0.00        10\n",
            "       10000       0.00      0.00      0.00        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.17      0.90      0.29        10\n",
            "       20000       0.00      0.00      0.00        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       0.41      0.70      0.52        10\n",
            "\n",
            "    accuracy                           0.23        70\n",
            "   macro avg       0.08      0.23      0.11        70\n",
            "weighted avg       0.08      0.23      0.11        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 48 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 33\n",
            "learning rate: 0.09477885747205307\n",
            "batch size: 128\n",
            "dropout rate: 0.765374298742985\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 3.8342 - acc: 0.1796 \n",
            "Epoch 1: val_acc improved from -inf to 0.15714, saving model to percobaan48_noImgPro/model\\vgg_16_48-saved-model-01-acc-0.16.hdf5\n",
            "4/4 [==============================] - 81s 21s/step - loss: 3.8342 - acc: 0.1796 - val_loss: 21.4361 - val_acc: 0.1571\n",
            "Epoch 2/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 3.1956 - acc: 0.2959 \n",
            "Epoch 2: val_acc did not improve from 0.15714\n",
            "4/4 [==============================] - 79s 22s/step - loss: 3.1956 - acc: 0.2959 - val_loss: 11.6445 - val_acc: 0.1500\n",
            "Epoch 3/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.6326 - acc: 0.3367 \n",
            "Epoch 3: val_acc did not improve from 0.15714\n",
            "4/4 [==============================] - 80s 21s/step - loss: 2.6326 - acc: 0.3367 - val_loss: 9.2693 - val_acc: 0.1429\n",
            "Epoch 4/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.1591 - acc: 0.3449 \n",
            "Epoch 4: val_acc did not improve from 0.15714\n",
            "4/4 [==============================] - 79s 21s/step - loss: 2.1591 - acc: 0.3449 - val_loss: 5.5668 - val_acc: 0.1429\n",
            "Epoch 5/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.8078 - acc: 0.3673 \n",
            "Epoch 5: val_acc improved from 0.15714 to 0.21429, saving model to percobaan48_noImgPro/model\\vgg_16_48-saved-model-05-acc-0.21.hdf5\n",
            "4/4 [==============================] - 80s 22s/step - loss: 1.8078 - acc: 0.3673 - val_loss: 2.8427 - val_acc: 0.2143\n",
            "Epoch 6/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.5063 - acc: 0.4082 \n",
            "Epoch 6: val_acc improved from 0.21429 to 0.36429, saving model to percobaan48_noImgPro/model\\vgg_16_48-saved-model-06-acc-0.36.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 1.5063 - acc: 0.4082 - val_loss: 2.2114 - val_acc: 0.3643\n",
            "Epoch 7/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.5758 - acc: 0.4327 \n",
            "Epoch 7: val_acc did not improve from 0.36429\n",
            "4/4 [==============================] - 79s 21s/step - loss: 1.5758 - acc: 0.4327 - val_loss: 2.6863 - val_acc: 0.2214\n",
            "Epoch 8/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.5696 - acc: 0.4429 \n",
            "Epoch 8: val_acc did not improve from 0.36429\n",
            "4/4 [==============================] - 79s 21s/step - loss: 1.5696 - acc: 0.4429 - val_loss: 2.9848 - val_acc: 0.2214\n",
            "Epoch 9/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.4940 - acc: 0.4673 \n",
            "Epoch 9: val_acc did not improve from 0.36429\n",
            "4/4 [==============================] - 80s 22s/step - loss: 1.4940 - acc: 0.4673 - val_loss: 2.5035 - val_acc: 0.3214\n",
            "Epoch 10/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.3130 - acc: 0.5286 \n",
            "Epoch 10: val_acc improved from 0.36429 to 0.40714, saving model to percobaan48_noImgPro/model\\vgg_16_48-saved-model-10-acc-0.41.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 1.3130 - acc: 0.5286 - val_loss: 1.9789 - val_acc: 0.4071\n",
            "Epoch 11/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.3330 - acc: 0.5102 \n",
            "Epoch 11: val_acc did not improve from 0.40714\n",
            "4/4 [==============================] - 79s 22s/step - loss: 1.3330 - acc: 0.5102 - val_loss: 2.6067 - val_acc: 0.2929\n",
            "Epoch 12/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2331 - acc: 0.5306 \n",
            "Epoch 12: val_acc did not improve from 0.40714\n",
            "4/4 [==============================] - 79s 22s/step - loss: 1.2331 - acc: 0.5306 - val_loss: 2.7725 - val_acc: 0.2286\n",
            "Epoch 13/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1281 - acc: 0.5755 \n",
            "Epoch 13: val_acc did not improve from 0.40714\n",
            "4/4 [==============================] - 79s 22s/step - loss: 1.1281 - acc: 0.5755 - val_loss: 2.8775 - val_acc: 0.2500\n",
            "Epoch 14/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1356 - acc: 0.5980 \n",
            "Epoch 14: val_acc did not improve from 0.40714\n",
            "4/4 [==============================] - 79s 21s/step - loss: 1.1356 - acc: 0.5980 - val_loss: 2.3374 - val_acc: 0.3857\n",
            "Epoch 15/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1148 - acc: 0.6020 \n",
            "Epoch 15: val_acc did not improve from 0.40714\n",
            "4/4 [==============================] - 79s 21s/step - loss: 1.1148 - acc: 0.6020 - val_loss: 1.9011 - val_acc: 0.3857\n",
            "Epoch 16/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9943 - acc: 0.6306 \n",
            "Epoch 16: val_acc did not improve from 0.40714\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.9943 - acc: 0.6306 - val_loss: 2.3385 - val_acc: 0.3214\n",
            "Epoch 17/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0227 - acc: 0.6449 \n",
            "Epoch 17: val_acc did not improve from 0.40714\n",
            "4/4 [==============================] - 80s 21s/step - loss: 1.0227 - acc: 0.6449 - val_loss: 2.0984 - val_acc: 0.4000\n",
            "Epoch 18/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0038 - acc: 0.6429 \n",
            "Epoch 18: val_acc improved from 0.40714 to 0.43571, saving model to percobaan48_noImgPro/model\\vgg_16_48-saved-model-18-acc-0.44.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 1.0038 - acc: 0.6429 - val_loss: 2.1267 - val_acc: 0.4357\n",
            "Epoch 19/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9287 - acc: 0.6735 \n",
            "Epoch 19: val_acc did not improve from 0.43571\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.9287 - acc: 0.6735 - val_loss: 1.8051 - val_acc: 0.4000\n",
            "Epoch 20/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9273 - acc: 0.6694 \n",
            "Epoch 20: val_acc improved from 0.43571 to 0.48571, saving model to percobaan48_noImgPro/model\\vgg_16_48-saved-model-20-acc-0.49.hdf5\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.9273 - acc: 0.6694 - val_loss: 1.5023 - val_acc: 0.4857\n",
            "Epoch 21/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0213 - acc: 0.6306 \n",
            "Epoch 21: val_acc improved from 0.48571 to 0.62143, saving model to percobaan48_noImgPro/model\\vgg_16_48-saved-model-21-acc-0.62.hdf5\n",
            "4/4 [==============================] - 80s 21s/step - loss: 1.0213 - acc: 0.6306 - val_loss: 1.0967 - val_acc: 0.6214\n",
            "Epoch 22/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8875 - acc: 0.6939 \n",
            "Epoch 22: val_acc improved from 0.62143 to 0.65714, saving model to percobaan48_noImgPro/model\\vgg_16_48-saved-model-22-acc-0.66.hdf5\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.8875 - acc: 0.6939 - val_loss: 0.9655 - val_acc: 0.6571\n",
            "Epoch 23/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8438 - acc: 0.7306 \n",
            "Epoch 23: val_acc improved from 0.65714 to 0.74286, saving model to percobaan48_noImgPro/model\\vgg_16_48-saved-model-23-acc-0.74.hdf5\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.8438 - acc: 0.7306 - val_loss: 0.7939 - val_acc: 0.7429\n",
            "Epoch 24/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7871 - acc: 0.7265 \n",
            "Epoch 24: val_acc improved from 0.74286 to 0.77143, saving model to percobaan48_noImgPro/model\\vgg_16_48-saved-model-24-acc-0.77.hdf5\n",
            "4/4 [==============================] - 79s 22s/step - loss: 0.7871 - acc: 0.7265 - val_loss: 0.8118 - val_acc: 0.7714\n",
            "Epoch 25/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7814 - acc: 0.7367 \n",
            "Epoch 25: val_acc did not improve from 0.77143\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.7814 - acc: 0.7367 - val_loss: 0.8359 - val_acc: 0.7286\n",
            "Epoch 26/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7277 - acc: 0.7163 \n",
            "Epoch 26: val_acc did not improve from 0.77143\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.7277 - acc: 0.7163 - val_loss: 0.8883 - val_acc: 0.6643\n",
            "Epoch 27/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7638 - acc: 0.7347 \n",
            "Epoch 27: val_acc did not improve from 0.77143\n",
            "4/4 [==============================] - 79s 21s/step - loss: 0.7638 - acc: 0.7347 - val_loss: 0.8578 - val_acc: 0.7214\n",
            "Epoch 28/33\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6944 - acc: 0.7551 \n",
            "Epoch 28: val_acc did not improve from 0.77143\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.6944 - acc: 0.7551 - val_loss: 1.0762 - val_acc: 0.6214\n",
            "\n",
            "\n",
            "Model Accuracy 0.4857142857142857\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.26      1.00      0.41        10\n",
            "       10000       0.71      0.50      0.59        10\n",
            "      100000       1.00      0.40      0.57        10\n",
            "        2000       0.75      0.60      0.67        10\n",
            "       20000       0.75      0.30      0.43        10\n",
            "        5000       0.60      0.30      0.40        10\n",
            "       50000       1.00      0.30      0.46        10\n",
            "\n",
            "    accuracy                           0.49        70\n",
            "   macro avg       0.72      0.49      0.50        70\n",
            "weighted avg       0.72      0.49      0.50        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 49 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 40\n",
            "learning rate: 0.006630764855828032\n",
            "batch size: 32\n",
            "dropout rate: 0.5491140547725072\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.2005 - acc: 0.3571\n",
            "Epoch 1: val_acc improved from -inf to 0.22143, saving model to percobaan49_noImgPro/model\\vgg_16_49-saved-model-01-acc-0.22.hdf5\n",
            "16/16 [==============================] - 82s 5s/step - loss: 2.2005 - acc: 0.3571 - val_loss: 2.6643 - val_acc: 0.2214\n",
            "Epoch 2/40\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0928 - acc: 0.6204\n",
            "Epoch 2: val_acc improved from 0.22143 to 0.23571, saving model to percobaan49_noImgPro/model\\vgg_16_49-saved-model-02-acc-0.24.hdf5\n",
            "16/16 [==============================] - 79s 5s/step - loss: 1.0928 - acc: 0.6204 - val_loss: 2.3389 - val_acc: 0.2357\n",
            "Epoch 3/40\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8150 - acc: 0.7000\n",
            "Epoch 3: val_acc improved from 0.23571 to 0.42143, saving model to percobaan49_noImgPro/model\\vgg_16_49-saved-model-03-acc-0.42.hdf5\n",
            "16/16 [==============================] - 80s 5s/step - loss: 0.8150 - acc: 0.7000 - val_loss: 1.6569 - val_acc: 0.4214\n",
            "Epoch 4/40\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7154 - acc: 0.7306\n",
            "Epoch 4: val_acc improved from 0.42143 to 0.47857, saving model to percobaan49_noImgPro/model\\vgg_16_49-saved-model-04-acc-0.48.hdf5\n",
            "16/16 [==============================] - 80s 5s/step - loss: 0.7154 - acc: 0.7306 - val_loss: 1.5392 - val_acc: 0.4786\n",
            "Epoch 5/40\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5495 - acc: 0.8122\n",
            "Epoch 5: val_acc improved from 0.47857 to 0.60714, saving model to percobaan49_noImgPro/model\\vgg_16_49-saved-model-05-acc-0.61.hdf5\n",
            "16/16 [==============================] - 85s 5s/step - loss: 0.5495 - acc: 0.8122 - val_loss: 1.2251 - val_acc: 0.6071\n",
            "Epoch 6/40\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4522 - acc: 0.8551\n",
            "Epoch 6: val_acc improved from 0.60714 to 0.75000, saving model to percobaan49_noImgPro/model\\vgg_16_49-saved-model-06-acc-0.75.hdf5\n",
            "16/16 [==============================] - 85s 5s/step - loss: 0.4522 - acc: 0.8551 - val_loss: 0.8509 - val_acc: 0.7500\n",
            "Epoch 7/40\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3899 - acc: 0.8714\n",
            "Epoch 7: val_acc did not improve from 0.75000\n",
            "16/16 [==============================] - 85s 5s/step - loss: 0.3899 - acc: 0.8714 - val_loss: 0.8317 - val_acc: 0.7071\n",
            "Epoch 8/40\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4600 - acc: 0.8429\n",
            "Epoch 8: val_acc did not improve from 0.75000\n",
            "16/16 [==============================] - 85s 5s/step - loss: 0.4600 - acc: 0.8429 - val_loss: 0.6886 - val_acc: 0.7286\n",
            "Epoch 9/40\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3987 - acc: 0.8367\n",
            "Epoch 9: val_acc improved from 0.75000 to 0.78571, saving model to percobaan49_noImgPro/model\\vgg_16_49-saved-model-09-acc-0.79.hdf5\n",
            "16/16 [==============================] - 85s 5s/step - loss: 0.3987 - acc: 0.8367 - val_loss: 0.6521 - val_acc: 0.7857\n",
            "Epoch 10/40\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2721 - acc: 0.9102\n",
            "Epoch 10: val_acc did not improve from 0.78571\n",
            "16/16 [==============================] - 85s 5s/step - loss: 0.2721 - acc: 0.9102 - val_loss: 0.7281 - val_acc: 0.7571\n",
            "Epoch 11/40\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3326 - acc: 0.8837\n",
            "Epoch 11: val_acc improved from 0.78571 to 0.82857, saving model to percobaan49_noImgPro/model\\vgg_16_49-saved-model-11-acc-0.83.hdf5\n",
            "16/16 [==============================] - 85s 5s/step - loss: 0.3326 - acc: 0.8837 - val_loss: 0.6043 - val_acc: 0.8286\n",
            "Epoch 12/40\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3154 - acc: 0.8959\n",
            "Epoch 12: val_acc did not improve from 0.82857\n",
            "16/16 [==============================] - 85s 5s/step - loss: 0.3154 - acc: 0.8959 - val_loss: 0.5717 - val_acc: 0.8214\n",
            "Epoch 13/40\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3075 - acc: 0.8918\n",
            "Epoch 13: val_acc did not improve from 0.82857\n",
            "16/16 [==============================] - 85s 5s/step - loss: 0.3075 - acc: 0.8918 - val_loss: 0.5735 - val_acc: 0.8000\n",
            "Epoch 14/40\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2847 - acc: 0.9000\n",
            "Epoch 14: val_acc did not improve from 0.82857\n",
            "16/16 [==============================] - 85s 5s/step - loss: 0.2847 - acc: 0.9000 - val_loss: 0.5864 - val_acc: 0.8286\n",
            "Epoch 15/40\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3052 - acc: 0.8878\n",
            "Epoch 15: val_acc improved from 0.82857 to 0.85000, saving model to percobaan49_noImgPro/model\\vgg_16_49-saved-model-15-acc-0.85.hdf5\n",
            "16/16 [==============================] - 85s 5s/step - loss: 0.3052 - acc: 0.8878 - val_loss: 0.5092 - val_acc: 0.8500\n",
            "Epoch 16/40\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2229 - acc: 0.9163\n",
            "Epoch 16: val_acc improved from 0.85000 to 0.86429, saving model to percobaan49_noImgPro/model\\vgg_16_49-saved-model-16-acc-0.86.hdf5\n",
            "16/16 [==============================] - 85s 5s/step - loss: 0.2229 - acc: 0.9163 - val_loss: 0.5459 - val_acc: 0.8643\n",
            "Epoch 17/40\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2369 - acc: 0.9245\n",
            "Epoch 17: val_acc did not improve from 0.86429\n",
            "16/16 [==============================] - 85s 5s/step - loss: 0.2369 - acc: 0.9245 - val_loss: 0.5862 - val_acc: 0.8286\n",
            "Epoch 18/40\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2553 - acc: 0.9143\n",
            "Epoch 18: val_acc did not improve from 0.86429\n",
            "16/16 [==============================] - 85s 5s/step - loss: 0.2553 - acc: 0.9143 - val_loss: 0.5679 - val_acc: 0.8429\n",
            "Epoch 19/40\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2281 - acc: 0.9245\n",
            "Epoch 19: val_acc did not improve from 0.86429\n",
            "16/16 [==============================] - 85s 5s/step - loss: 0.2281 - acc: 0.9245 - val_loss: 0.5462 - val_acc: 0.8500\n",
            "Epoch 20/40\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.1673 - acc: 0.9469\n",
            "Epoch 20: val_acc did not improve from 0.86429\n",
            "16/16 [==============================] - 85s 5s/step - loss: 0.1673 - acc: 0.9469 - val_loss: 0.5418 - val_acc: 0.8357\n",
            "\n",
            "\n",
            "Model Accuracy 0.8571428571428571\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.91      1.00      0.95        10\n",
            "       10000       0.90      0.90      0.90        10\n",
            "      100000       1.00      0.80      0.89        10\n",
            "        2000       0.90      0.90      0.90        10\n",
            "       20000       1.00      0.60      0.75        10\n",
            "        5000       0.64      0.90      0.75        10\n",
            "       50000       0.82      0.90      0.86        10\n",
            "\n",
            "    accuracy                           0.86        70\n",
            "   macro avg       0.88      0.86      0.86        70\n",
            "weighted avg       0.88      0.86      0.86        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 50 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 45\n",
            "learning rate: 0.004336028997259138\n",
            "batch size: 32\n",
            "dropout rate: 0.6389167096001418\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.4726 - acc: 0.3000\n",
            "Epoch 1: val_acc improved from -inf to 0.18571, saving model to percobaan50_noImgPro/model\\vgg_16_50-saved-model-01-acc-0.19.hdf5\n",
            "16/16 [==============================] - 85s 5s/step - loss: 2.4726 - acc: 0.3000 - val_loss: 2.2891 - val_acc: 0.1857\n",
            "Epoch 2/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.5176 - acc: 0.5265\n",
            "Epoch 2: val_acc improved from 0.18571 to 0.27143, saving model to percobaan50_noImgPro/model\\vgg_16_50-saved-model-02-acc-0.27.hdf5\n",
            "16/16 [==============================] - 83s 5s/step - loss: 1.5176 - acc: 0.5265 - val_loss: 2.0564 - val_acc: 0.2714\n",
            "Epoch 3/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0992 - acc: 0.6204\n",
            "Epoch 3: val_acc improved from 0.27143 to 0.47857, saving model to percobaan50_noImgPro/model\\vgg_16_50-saved-model-03-acc-0.48.hdf5\n",
            "16/16 [==============================] - 83s 5s/step - loss: 1.0992 - acc: 0.6204 - val_loss: 1.5938 - val_acc: 0.4786\n",
            "Epoch 4/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9382 - acc: 0.6898\n",
            "Epoch 4: val_acc improved from 0.47857 to 0.50000, saving model to percobaan50_noImgPro/model\\vgg_16_50-saved-model-04-acc-0.50.hdf5\n",
            "16/16 [==============================] - 83s 5s/step - loss: 0.9382 - acc: 0.6898 - val_loss: 1.4779 - val_acc: 0.5000\n",
            "Epoch 5/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8390 - acc: 0.7184\n",
            "Epoch 5: val_acc improved from 0.50000 to 0.61429, saving model to percobaan50_noImgPro/model\\vgg_16_50-saved-model-05-acc-0.61.hdf5\n",
            "16/16 [==============================] - 83s 5s/step - loss: 0.8390 - acc: 0.7184 - val_loss: 1.1469 - val_acc: 0.6143\n",
            "Epoch 6/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6190 - acc: 0.7837\n",
            "Epoch 6: val_acc improved from 0.61429 to 0.64286, saving model to percobaan50_noImgPro/model\\vgg_16_50-saved-model-06-acc-0.64.hdf5\n",
            "16/16 [==============================] - 83s 5s/step - loss: 0.6190 - acc: 0.7837 - val_loss: 1.0465 - val_acc: 0.6429\n",
            "Epoch 7/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6352 - acc: 0.8000\n",
            "Epoch 7: val_acc improved from 0.64286 to 0.67857, saving model to percobaan50_noImgPro/model\\vgg_16_50-saved-model-07-acc-0.68.hdf5\n",
            "16/16 [==============================] - 83s 5s/step - loss: 0.6352 - acc: 0.8000 - val_loss: 0.9303 - val_acc: 0.6786\n",
            "Epoch 8/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5858 - acc: 0.8102\n",
            "Epoch 8: val_acc improved from 0.67857 to 0.74286, saving model to percobaan50_noImgPro/model\\vgg_16_50-saved-model-08-acc-0.74.hdf5\n",
            "16/16 [==============================] - 83s 5s/step - loss: 0.5858 - acc: 0.8102 - val_loss: 0.7925 - val_acc: 0.7429\n",
            "Epoch 9/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4837 - acc: 0.8490\n",
            "Epoch 9: val_acc did not improve from 0.74286\n",
            "16/16 [==============================] - 83s 5s/step - loss: 0.4837 - acc: 0.8490 - val_loss: 0.7693 - val_acc: 0.7143\n",
            "Epoch 10/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4197 - acc: 0.8694\n",
            "Epoch 10: val_acc improved from 0.74286 to 0.81429, saving model to percobaan50_noImgPro/model\\vgg_16_50-saved-model-10-acc-0.81.hdf5\n",
            "16/16 [==============================] - 83s 5s/step - loss: 0.4197 - acc: 0.8694 - val_loss: 0.6527 - val_acc: 0.8143\n",
            "Epoch 11/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4265 - acc: 0.8510\n",
            "Epoch 11: val_acc improved from 0.81429 to 0.85714, saving model to percobaan50_noImgPro/model\\vgg_16_50-saved-model-11-acc-0.86.hdf5\n",
            "16/16 [==============================] - 83s 5s/step - loss: 0.4265 - acc: 0.8510 - val_loss: 0.5776 - val_acc: 0.8571\n",
            "Epoch 12/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4349 - acc: 0.8592\n",
            "Epoch 12: val_acc did not improve from 0.85714\n",
            "16/16 [==============================] - 83s 5s/step - loss: 0.4349 - acc: 0.8592 - val_loss: 0.5225 - val_acc: 0.8571\n",
            "Epoch 13/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3919 - acc: 0.8673\n",
            "Epoch 13: val_acc did not improve from 0.85714\n",
            "16/16 [==============================] - 83s 5s/step - loss: 0.3919 - acc: 0.8673 - val_loss: 0.5223 - val_acc: 0.8429\n",
            "Epoch 14/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3779 - acc: 0.8837\n",
            "Epoch 14: val_acc improved from 0.85714 to 0.87143, saving model to percobaan50_noImgPro/model\\vgg_16_50-saved-model-14-acc-0.87.hdf5\n",
            "16/16 [==============================] - 83s 5s/step - loss: 0.3779 - acc: 0.8837 - val_loss: 0.4886 - val_acc: 0.8714\n",
            "Epoch 15/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3416 - acc: 0.8837\n",
            "Epoch 15: val_acc did not improve from 0.87143\n",
            "16/16 [==============================] - 83s 5s/step - loss: 0.3416 - acc: 0.8837 - val_loss: 0.4759 - val_acc: 0.8714\n",
            "Epoch 16/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3256 - acc: 0.8816\n",
            "Epoch 16: val_acc did not improve from 0.87143\n",
            "16/16 [==============================] - 83s 5s/step - loss: 0.3256 - acc: 0.8816 - val_loss: 0.4587 - val_acc: 0.8714\n",
            "Epoch 17/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3297 - acc: 0.8735\n",
            "Epoch 17: val_acc did not improve from 0.87143\n",
            "16/16 [==============================] - 83s 5s/step - loss: 0.3297 - acc: 0.8735 - val_loss: 0.4681 - val_acc: 0.8714\n",
            "Epoch 18/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3348 - acc: 0.8857\n",
            "Epoch 18: val_acc did not improve from 0.87143\n",
            "16/16 [==============================] - 83s 5s/step - loss: 0.3348 - acc: 0.8857 - val_loss: 0.4715 - val_acc: 0.8643\n",
            "Epoch 19/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3426 - acc: 0.8776\n",
            "Epoch 19: val_acc improved from 0.87143 to 0.89286, saving model to percobaan50_noImgPro/model\\vgg_16_50-saved-model-19-acc-0.89.hdf5\n",
            "16/16 [==============================] - 83s 5s/step - loss: 0.3426 - acc: 0.8776 - val_loss: 0.4564 - val_acc: 0.8929\n",
            "Epoch 20/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3106 - acc: 0.8959\n",
            "Epoch 20: val_acc did not improve from 0.89286\n",
            "16/16 [==============================] - 83s 5s/step - loss: 0.3106 - acc: 0.8959 - val_loss: 0.4398 - val_acc: 0.8929\n",
            "Epoch 21/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2737 - acc: 0.9102\n",
            "Epoch 21: val_acc did not improve from 0.89286\n",
            "16/16 [==============================] - 83s 5s/step - loss: 0.2737 - acc: 0.9102 - val_loss: 0.4495 - val_acc: 0.8857\n",
            "Epoch 22/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2357 - acc: 0.9265\n",
            "Epoch 22: val_acc did not improve from 0.89286\n",
            "16/16 [==============================] - 83s 5s/step - loss: 0.2357 - acc: 0.9265 - val_loss: 0.4733 - val_acc: 0.8857\n",
            "Epoch 23/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2520 - acc: 0.9245\n",
            "Epoch 23: val_acc did not improve from 0.89286\n",
            "16/16 [==============================] - 83s 5s/step - loss: 0.2520 - acc: 0.9245 - val_loss: 0.5074 - val_acc: 0.8643\n",
            "Epoch 24/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2593 - acc: 0.9122\n",
            "Epoch 24: val_acc did not improve from 0.89286\n",
            "16/16 [==============================] - 83s 5s/step - loss: 0.2593 - acc: 0.9122 - val_loss: 0.5702 - val_acc: 0.8500\n",
            "Epoch 25/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3031 - acc: 0.8837\n",
            "Epoch 25: val_acc did not improve from 0.89286\n",
            "16/16 [==============================] - 83s 5s/step - loss: 0.3031 - acc: 0.8837 - val_loss: 0.5021 - val_acc: 0.8714\n",
            "\n",
            "\n",
            "Model Accuracy 0.8714285714285714\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.71      1.00      0.83        10\n",
            "       10000       1.00      0.90      0.95        10\n",
            "      100000       1.00      0.80      0.89        10\n",
            "        2000       0.77      1.00      0.87        10\n",
            "       20000       1.00      0.60      0.75        10\n",
            "        5000       0.80      0.80      0.80        10\n",
            "       50000       1.00      1.00      1.00        10\n",
            "\n",
            "    accuracy                           0.87        70\n",
            "   macro avg       0.90      0.87      0.87        70\n",
            "weighted avg       0.90      0.87      0.87        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 51 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 42\n",
            "learning rate: 0.00678439267908189\n",
            "batch size: 32\n",
            "dropout rate: 0.7072885350830834\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/42\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.8308 - acc: 0.2980\n",
            "Epoch 1: val_acc improved from -inf to 0.30000, saving model to percobaan51_noImgPro/model\\vgg_16_51-saved-model-01-acc-0.30.hdf5\n",
            "16/16 [==============================] - 84s 5s/step - loss: 2.8308 - acc: 0.2980 - val_loss: 2.6987 - val_acc: 0.3000\n",
            "Epoch 2/42\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.6391 - acc: 0.4531\n",
            "Epoch 2: val_acc improved from 0.30000 to 0.35000, saving model to percobaan51_noImgPro/model\\vgg_16_51-saved-model-02-acc-0.35.hdf5\n",
            "16/16 [==============================] - 82s 5s/step - loss: 1.6391 - acc: 0.4531 - val_loss: 2.3572 - val_acc: 0.3500\n",
            "Epoch 3/42\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2555 - acc: 0.5918\n",
            "Epoch 3: val_acc did not improve from 0.35000\n",
            "16/16 [==============================] - 82s 5s/step - loss: 1.2555 - acc: 0.5918 - val_loss: 2.2720 - val_acc: 0.2429\n",
            "Epoch 4/42\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1050 - acc: 0.6265\n",
            "Epoch 4: val_acc improved from 0.35000 to 0.42857, saving model to percobaan51_noImgPro/model\\vgg_16_51-saved-model-04-acc-0.43.hdf5\n",
            "16/16 [==============================] - 82s 5s/step - loss: 1.1050 - acc: 0.6265 - val_loss: 1.6321 - val_acc: 0.4286\n",
            "Epoch 5/42\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9117 - acc: 0.6612\n",
            "Epoch 5: val_acc improved from 0.42857 to 0.52143, saving model to percobaan51_noImgPro/model\\vgg_16_51-saved-model-05-acc-0.52.hdf5\n",
            "16/16 [==============================] - 82s 5s/step - loss: 0.9117 - acc: 0.6612 - val_loss: 1.3916 - val_acc: 0.5214\n",
            "Epoch 6/42\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8784 - acc: 0.6878\n",
            "Epoch 6: val_acc improved from 0.52143 to 0.56429, saving model to percobaan51_noImgPro/model\\vgg_16_51-saved-model-06-acc-0.56.hdf5\n",
            "16/16 [==============================] - 82s 5s/step - loss: 0.8784 - acc: 0.6878 - val_loss: 1.2055 - val_acc: 0.5643\n",
            "Epoch 7/42\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6911 - acc: 0.7612\n",
            "Epoch 7: val_acc improved from 0.56429 to 0.66429, saving model to percobaan51_noImgPro/model\\vgg_16_51-saved-model-07-acc-0.66.hdf5\n",
            "16/16 [==============================] - 82s 5s/step - loss: 0.6911 - acc: 0.7612 - val_loss: 1.0120 - val_acc: 0.6643\n",
            "Epoch 8/42\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6544 - acc: 0.7653\n",
            "Epoch 8: val_acc improved from 0.66429 to 0.72857, saving model to percobaan51_noImgPro/model\\vgg_16_51-saved-model-08-acc-0.73.hdf5\n",
            "16/16 [==============================] - 82s 5s/step - loss: 0.6544 - acc: 0.7653 - val_loss: 0.8693 - val_acc: 0.7286\n",
            "Epoch 9/42\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6266 - acc: 0.7633\n",
            "Epoch 9: val_acc improved from 0.72857 to 0.77143, saving model to percobaan51_noImgPro/model\\vgg_16_51-saved-model-09-acc-0.77.hdf5\n",
            "16/16 [==============================] - 82s 5s/step - loss: 0.6266 - acc: 0.7633 - val_loss: 0.7644 - val_acc: 0.7714\n",
            "Epoch 10/42\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6119 - acc: 0.7612\n",
            "Epoch 10: val_acc improved from 0.77143 to 0.78571, saving model to percobaan51_noImgPro/model\\vgg_16_51-saved-model-10-acc-0.79.hdf5\n",
            "16/16 [==============================] - 83s 5s/step - loss: 0.6119 - acc: 0.7612 - val_loss: 0.6736 - val_acc: 0.7857\n",
            "Epoch 11/42\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5464 - acc: 0.8102\n",
            "Epoch 11: val_acc improved from 0.78571 to 0.83571, saving model to percobaan51_noImgPro/model\\vgg_16_51-saved-model-11-acc-0.84.hdf5\n",
            "16/16 [==============================] - 82s 5s/step - loss: 0.5464 - acc: 0.8102 - val_loss: 0.6120 - val_acc: 0.8357\n",
            "Epoch 12/42\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5322 - acc: 0.8000\n",
            "Epoch 12: val_acc improved from 0.83571 to 0.85000, saving model to percobaan51_noImgPro/model\\vgg_16_51-saved-model-12-acc-0.85.hdf5\n",
            "16/16 [==============================] - 83s 5s/step - loss: 0.5322 - acc: 0.8000 - val_loss: 0.6083 - val_acc: 0.8500\n",
            "Epoch 13/42\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5012 - acc: 0.8286\n",
            "Epoch 13: val_acc improved from 0.85000 to 0.86429, saving model to percobaan51_noImgPro/model\\vgg_16_51-saved-model-13-acc-0.86.hdf5\n",
            "16/16 [==============================] - 83s 5s/step - loss: 0.5012 - acc: 0.8286 - val_loss: 0.5699 - val_acc: 0.8643\n",
            "Epoch 14/42\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4851 - acc: 0.8286\n",
            "Epoch 14: val_acc did not improve from 0.86429\n",
            "16/16 [==============================] - 83s 5s/step - loss: 0.4851 - acc: 0.8286 - val_loss: 0.5490 - val_acc: 0.8643\n",
            "Epoch 15/42\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4640 - acc: 0.8245\n",
            "Epoch 15: val_acc did not improve from 0.86429\n",
            "16/16 [==============================] - 82s 5s/step - loss: 0.4640 - acc: 0.8245 - val_loss: 0.5346 - val_acc: 0.8571\n",
            "Epoch 16/42\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4519 - acc: 0.8653\n",
            "Epoch 16: val_acc improved from 0.86429 to 0.87143, saving model to percobaan51_noImgPro/model\\vgg_16_51-saved-model-16-acc-0.87.hdf5\n",
            "16/16 [==============================] - 82s 5s/step - loss: 0.4519 - acc: 0.8653 - val_loss: 0.5026 - val_acc: 0.8714\n",
            "Epoch 17/42\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3532 - acc: 0.8816\n",
            "Epoch 17: val_acc did not improve from 0.87143\n",
            "16/16 [==============================] - 82s 5s/step - loss: 0.3532 - acc: 0.8816 - val_loss: 0.5075 - val_acc: 0.8429\n",
            "Epoch 18/42\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3660 - acc: 0.8633\n",
            "Epoch 18: val_acc improved from 0.87143 to 0.88571, saving model to percobaan51_noImgPro/model\\vgg_16_51-saved-model-18-acc-0.89.hdf5\n",
            "16/16 [==============================] - 82s 5s/step - loss: 0.3660 - acc: 0.8633 - val_loss: 0.4582 - val_acc: 0.8857\n",
            "Epoch 19/42\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3359 - acc: 0.8898\n",
            "Epoch 19: val_acc did not improve from 0.88571\n",
            "16/16 [==============================] - 82s 5s/step - loss: 0.3359 - acc: 0.8898 - val_loss: 0.4843 - val_acc: 0.8786\n",
            "Epoch 20/42\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3509 - acc: 0.8653\n",
            "Epoch 20: val_acc did not improve from 0.88571\n",
            "16/16 [==============================] - 82s 5s/step - loss: 0.3509 - acc: 0.8653 - val_loss: 0.4823 - val_acc: 0.8786\n",
            "Epoch 21/42\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3388 - acc: 0.8878\n",
            "Epoch 21: val_acc did not improve from 0.88571\n",
            "16/16 [==============================] - 81s 5s/step - loss: 0.3388 - acc: 0.8878 - val_loss: 0.4439 - val_acc: 0.8857\n",
            "Epoch 22/42\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3616 - acc: 0.8755\n",
            "Epoch 22: val_acc did not improve from 0.88571\n",
            "16/16 [==============================] - 82s 5s/step - loss: 0.3616 - acc: 0.8755 - val_loss: 0.4782 - val_acc: 0.8643\n",
            "Epoch 23/42\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3966 - acc: 0.8673\n",
            "Epoch 23: val_acc improved from 0.88571 to 0.89286, saving model to percobaan51_noImgPro/model\\vgg_16_51-saved-model-23-acc-0.89.hdf5\n",
            "16/16 [==============================] - 82s 5s/step - loss: 0.3966 - acc: 0.8673 - val_loss: 0.4151 - val_acc: 0.8929\n",
            "Epoch 24/42\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2836 - acc: 0.9020\n",
            "Epoch 24: val_acc did not improve from 0.89286\n",
            "16/16 [==============================] - 82s 5s/step - loss: 0.2836 - acc: 0.9020 - val_loss: 0.4740 - val_acc: 0.8786\n",
            "Epoch 25/42\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3437 - acc: 0.8980\n",
            "Epoch 25: val_acc did not improve from 0.89286\n",
            "16/16 [==============================] - 82s 5s/step - loss: 0.3437 - acc: 0.8980 - val_loss: 0.4899 - val_acc: 0.8786\n",
            "Epoch 26/42\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3239 - acc: 0.8939\n",
            "Epoch 26: val_acc did not improve from 0.89286\n",
            "16/16 [==============================] - 82s 5s/step - loss: 0.3239 - acc: 0.8939 - val_loss: 0.4976 - val_acc: 0.8786\n",
            "Epoch 27/42\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2516 - acc: 0.9143\n",
            "Epoch 27: val_acc did not improve from 0.89286\n",
            "16/16 [==============================] - 82s 5s/step - loss: 0.2516 - acc: 0.9143 - val_loss: 0.4692 - val_acc: 0.8857\n",
            "Epoch 28/42\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3499 - acc: 0.8959\n",
            "Epoch 28: val_acc did not improve from 0.89286\n",
            "16/16 [==============================] - 82s 5s/step - loss: 0.3499 - acc: 0.8959 - val_loss: 0.4963 - val_acc: 0.8857\n",
            "\n",
            "\n",
            "Model Accuracy 0.8857142857142857\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.80      0.80      0.80        10\n",
            "       10000       1.00      0.90      0.95        10\n",
            "      100000       1.00      1.00      1.00        10\n",
            "        2000       0.62      1.00      0.77        10\n",
            "       20000       1.00      0.50      0.67        10\n",
            "        5000       1.00      1.00      1.00        10\n",
            "       50000       1.00      1.00      1.00        10\n",
            "\n",
            "    accuracy                           0.89        70\n",
            "   macro avg       0.92      0.89      0.88        70\n",
            "weighted avg       0.92      0.89      0.88        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 52 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 43\n",
            "learning rate: 0.01885670628657198\n",
            "batch size: 32\n",
            "dropout rate: 0.72793357804551\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.8122 - acc: 0.2714\n",
            "Epoch 1: val_acc improved from -inf to 0.20714, saving model to percobaan52_noImgPro/model\\vgg_16_52-saved-model-01-acc-0.21.hdf5\n",
            "16/16 [==============================] - 83s 5s/step - loss: 2.8122 - acc: 0.2714 - val_loss: 2.8152 - val_acc: 0.2071\n",
            "Epoch 2/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.0589 - acc: 0.4041\n",
            "Epoch 2: val_acc improved from 0.20714 to 0.35000, saving model to percobaan52_noImgPro/model\\vgg_16_52-saved-model-02-acc-0.35.hdf5\n",
            "16/16 [==============================] - 81s 5s/step - loss: 2.0589 - acc: 0.4041 - val_loss: 2.1099 - val_acc: 0.3500\n",
            "Epoch 3/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.5890 - acc: 0.4857\n",
            "Epoch 3: val_acc improved from 0.35000 to 0.48571, saving model to percobaan52_noImgPro/model\\vgg_16_52-saved-model-03-acc-0.49.hdf5\n",
            "16/16 [==============================] - 81s 5s/step - loss: 1.5890 - acc: 0.4857 - val_loss: 1.3168 - val_acc: 0.4857\n",
            "Epoch 4/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2766 - acc: 0.5286\n",
            "Epoch 4: val_acc improved from 0.48571 to 0.53571, saving model to percobaan52_noImgPro/model\\vgg_16_52-saved-model-04-acc-0.54.hdf5\n",
            "16/16 [==============================] - 81s 5s/step - loss: 1.2766 - acc: 0.5286 - val_loss: 1.3658 - val_acc: 0.5357\n",
            "Epoch 5/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9902 - acc: 0.6408\n",
            "Epoch 5: val_acc improved from 0.53571 to 0.64286, saving model to percobaan52_noImgPro/model\\vgg_16_52-saved-model-05-acc-0.64.hdf5\n",
            "16/16 [==============================] - 81s 5s/step - loss: 0.9902 - acc: 0.6408 - val_loss: 1.1064 - val_acc: 0.6429\n",
            "Epoch 6/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9612 - acc: 0.6531\n",
            "Epoch 6: val_acc improved from 0.64286 to 0.67857, saving model to percobaan52_noImgPro/model\\vgg_16_52-saved-model-06-acc-0.68.hdf5\n",
            "16/16 [==============================] - 81s 5s/step - loss: 0.9612 - acc: 0.6531 - val_loss: 0.9915 - val_acc: 0.6786\n",
            "Epoch 7/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8337 - acc: 0.6898\n",
            "Epoch 7: val_acc improved from 0.67857 to 0.70714, saving model to percobaan52_noImgPro/model\\vgg_16_52-saved-model-07-acc-0.71.hdf5\n",
            "16/16 [==============================] - 81s 5s/step - loss: 0.8337 - acc: 0.6898 - val_loss: 0.8894 - val_acc: 0.7071\n",
            "Epoch 8/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6837 - acc: 0.7531\n",
            "Epoch 8: val_acc improved from 0.70714 to 0.72857, saving model to percobaan52_noImgPro/model\\vgg_16_52-saved-model-08-acc-0.73.hdf5\n",
            "16/16 [==============================] - 81s 5s/step - loss: 0.6837 - acc: 0.7531 - val_loss: 0.8278 - val_acc: 0.7286\n",
            "Epoch 9/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7570 - acc: 0.7592\n",
            "Epoch 9: val_acc did not improve from 0.72857\n",
            "16/16 [==============================] - 80s 5s/step - loss: 0.7570 - acc: 0.7592 - val_loss: 0.8010 - val_acc: 0.7286\n",
            "Epoch 10/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6221 - acc: 0.7592\n",
            "Epoch 10: val_acc improved from 0.72857 to 0.75000, saving model to percobaan52_noImgPro/model\\vgg_16_52-saved-model-10-acc-0.75.hdf5\n",
            "16/16 [==============================] - 81s 5s/step - loss: 0.6221 - acc: 0.7592 - val_loss: 0.7047 - val_acc: 0.7500\n",
            "Epoch 11/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6129 - acc: 0.7837\n",
            "Epoch 11: val_acc improved from 0.75000 to 0.80000, saving model to percobaan52_noImgPro/model\\vgg_16_52-saved-model-11-acc-0.80.hdf5\n",
            "16/16 [==============================] - 81s 5s/step - loss: 0.6129 - acc: 0.7837 - val_loss: 0.6187 - val_acc: 0.8000\n",
            "Epoch 12/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6646 - acc: 0.7673\n",
            "Epoch 12: val_acc improved from 0.80000 to 0.81429, saving model to percobaan52_noImgPro/model\\vgg_16_52-saved-model-12-acc-0.81.hdf5\n",
            "16/16 [==============================] - 81s 5s/step - loss: 0.6646 - acc: 0.7673 - val_loss: 0.6297 - val_acc: 0.8143\n",
            "Epoch 13/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5417 - acc: 0.7918\n",
            "Epoch 13: val_acc did not improve from 0.81429\n",
            "16/16 [==============================] - 80s 5s/step - loss: 0.5417 - acc: 0.7918 - val_loss: 0.6465 - val_acc: 0.8000\n",
            "Epoch 14/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5540 - acc: 0.7918\n",
            "Epoch 14: val_acc improved from 0.81429 to 0.83571, saving model to percobaan52_noImgPro/model\\vgg_16_52-saved-model-14-acc-0.84.hdf5\n",
            "16/16 [==============================] - 81s 5s/step - loss: 0.5540 - acc: 0.7918 - val_loss: 0.5698 - val_acc: 0.8357\n",
            "Epoch 15/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6388 - acc: 0.7776\n",
            "Epoch 15: val_acc did not improve from 0.83571\n",
            "16/16 [==============================] - 81s 5s/step - loss: 0.6388 - acc: 0.7776 - val_loss: 0.5678 - val_acc: 0.8286\n",
            "Epoch 16/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6436 - acc: 0.7776\n",
            "Epoch 16: val_acc did not improve from 0.83571\n",
            "16/16 [==============================] - 80s 5s/step - loss: 0.6436 - acc: 0.7776 - val_loss: 0.5861 - val_acc: 0.8357\n",
            "Epoch 17/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5595 - acc: 0.8204\n",
            "Epoch 17: val_acc improved from 0.83571 to 0.85000, saving model to percobaan52_noImgPro/model\\vgg_16_52-saved-model-17-acc-0.85.hdf5\n",
            "16/16 [==============================] - 82s 5s/step - loss: 0.5595 - acc: 0.8204 - val_loss: 0.5861 - val_acc: 0.8500\n",
            "Epoch 18/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5247 - acc: 0.8224\n",
            "Epoch 18: val_acc did not improve from 0.85000\n",
            "16/16 [==============================] - 80s 5s/step - loss: 0.5247 - acc: 0.8224 - val_loss: 0.5913 - val_acc: 0.8500\n",
            "Epoch 19/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5586 - acc: 0.8122\n",
            "Epoch 19: val_acc did not improve from 0.85000\n",
            "16/16 [==============================] - 81s 5s/step - loss: 0.5586 - acc: 0.8122 - val_loss: 0.7085 - val_acc: 0.8143\n",
            "Epoch 20/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4879 - acc: 0.8306\n",
            "Epoch 20: val_acc did not improve from 0.85000\n",
            "16/16 [==============================] - 80s 5s/step - loss: 0.4879 - acc: 0.8306 - val_loss: 0.5781 - val_acc: 0.8500\n",
            "\n",
            "\n",
            "Model Accuracy 0.8857142857142857\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.90      0.95        10\n",
            "       10000       1.00      1.00      1.00        10\n",
            "      100000       1.00      0.90      0.95        10\n",
            "        2000       0.77      1.00      0.87        10\n",
            "       20000       0.83      0.50      0.62        10\n",
            "        5000       0.75      0.90      0.82        10\n",
            "       50000       0.91      1.00      0.95        10\n",
            "\n",
            "    accuracy                           0.89        70\n",
            "   macro avg       0.89      0.89      0.88        70\n",
            "weighted avg       0.89      0.89      0.88        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 53 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 47\n",
            "learning rate: 0.01319822621337074\n",
            "batch size: 64\n",
            "dropout rate: 0.5330537129389288\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/47\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.4626 - acc: 0.3347\n",
            "Epoch 1: val_acc improved from -inf to 0.19286, saving model to percobaan53_noImgPro/model\\vgg_16_53-saved-model-01-acc-0.19.hdf5\n",
            "8/8 [==============================] - 82s 10s/step - loss: 2.4626 - acc: 0.3347 - val_loss: 4.1532 - val_acc: 0.1929\n",
            "Epoch 2/47\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.2487 - acc: 0.5531\n",
            "Epoch 2: val_acc improved from 0.19286 to 0.20714, saving model to percobaan53_noImgPro/model\\vgg_16_53-saved-model-02-acc-0.21.hdf5\n",
            "8/8 [==============================] - 80s 10s/step - loss: 1.2487 - acc: 0.5531 - val_loss: 4.3500 - val_acc: 0.2071\n",
            "Epoch 3/47\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7805 - acc: 0.7327\n",
            "Epoch 3: val_acc did not improve from 0.20714\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.7805 - acc: 0.7327 - val_loss: 4.9615 - val_acc: 0.1857\n",
            "Epoch 4/47\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6993 - acc: 0.7551\n",
            "Epoch 4: val_acc did not improve from 0.20714\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.6993 - acc: 0.7551 - val_loss: 3.5858 - val_acc: 0.2000\n",
            "Epoch 5/47\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5439 - acc: 0.8163\n",
            "Epoch 5: val_acc did not improve from 0.20714\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.5439 - acc: 0.8163 - val_loss: 3.0170 - val_acc: 0.2000\n",
            "Epoch 6/47\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4677 - acc: 0.8327\n",
            "Epoch 6: val_acc improved from 0.20714 to 0.45714, saving model to percobaan53_noImgPro/model\\vgg_16_53-saved-model-06-acc-0.46.hdf5\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.4677 - acc: 0.8327 - val_loss: 1.6847 - val_acc: 0.4571\n",
            "Epoch 7/47\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4092 - acc: 0.8633\n",
            "Epoch 7: val_acc improved from 0.45714 to 0.52143, saving model to percobaan53_noImgPro/model\\vgg_16_53-saved-model-07-acc-0.52.hdf5\n",
            "8/8 [==============================] - 80s 11s/step - loss: 0.4092 - acc: 0.8633 - val_loss: 1.4387 - val_acc: 0.5214\n",
            "Epoch 8/47\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3305 - acc: 0.8939\n",
            "Epoch 8: val_acc did not improve from 0.52143\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.3305 - acc: 0.8939 - val_loss: 1.4656 - val_acc: 0.4357\n",
            "Epoch 9/47\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2697 - acc: 0.9102\n",
            "Epoch 9: val_acc did not improve from 0.52143\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.2697 - acc: 0.9102 - val_loss: 1.3815 - val_acc: 0.4929\n",
            "Epoch 10/47\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2811 - acc: 0.9041\n",
            "Epoch 10: val_acc improved from 0.52143 to 0.53571, saving model to percobaan53_noImgPro/model\\vgg_16_53-saved-model-10-acc-0.54.hdf5\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.2811 - acc: 0.9041 - val_loss: 1.2870 - val_acc: 0.5357\n",
            "Epoch 11/47\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2290 - acc: 0.9204\n",
            "Epoch 11: val_acc did not improve from 0.53571\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.2290 - acc: 0.9204 - val_loss: 1.2590 - val_acc: 0.5000\n",
            "Epoch 12/47\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2214 - acc: 0.9143\n",
            "Epoch 12: val_acc improved from 0.53571 to 0.69286, saving model to percobaan53_noImgPro/model\\vgg_16_53-saved-model-12-acc-0.69.hdf5\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.2214 - acc: 0.9143 - val_loss: 0.8512 - val_acc: 0.6929\n",
            "Epoch 13/47\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2356 - acc: 0.9163\n",
            "Epoch 13: val_acc improved from 0.69286 to 0.76429, saving model to percobaan53_noImgPro/model\\vgg_16_53-saved-model-13-acc-0.76.hdf5\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.2356 - acc: 0.9163 - val_loss: 0.7297 - val_acc: 0.7643\n",
            "Epoch 14/47\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1677 - acc: 0.9469\n",
            "Epoch 14: val_acc did not improve from 0.76429\n",
            "8/8 [==============================] - 81s 10s/step - loss: 0.1677 - acc: 0.9469 - val_loss: 0.6942 - val_acc: 0.7571\n",
            "Epoch 15/47\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1727 - acc: 0.9408\n",
            "Epoch 15: val_acc did not improve from 0.76429\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.1727 - acc: 0.9408 - val_loss: 0.7428 - val_acc: 0.7286\n",
            "Epoch 16/47\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2063 - acc: 0.9347\n",
            "Epoch 16: val_acc did not improve from 0.76429\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.2063 - acc: 0.9347 - val_loss: 0.7564 - val_acc: 0.7500\n",
            "Epoch 17/47\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1617 - acc: 0.9408\n",
            "Epoch 17: val_acc improved from 0.76429 to 0.77857, saving model to percobaan53_noImgPro/model\\vgg_16_53-saved-model-17-acc-0.78.hdf5\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.1617 - acc: 0.9408 - val_loss: 0.7730 - val_acc: 0.7786\n",
            "Epoch 18/47\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1875 - acc: 0.9388\n",
            "Epoch 18: val_acc did not improve from 0.77857\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.1875 - acc: 0.9388 - val_loss: 0.7261 - val_acc: 0.7643\n",
            "Epoch 19/47\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1522 - acc: 0.9449\n",
            "Epoch 19: val_acc did not improve from 0.77857\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.1522 - acc: 0.9449 - val_loss: 0.6815 - val_acc: 0.7643\n",
            "Epoch 20/47\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1834 - acc: 0.9429\n",
            "Epoch 20: val_acc improved from 0.77857 to 0.80714, saving model to percobaan53_noImgPro/model\\vgg_16_53-saved-model-20-acc-0.81.hdf5\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.1834 - acc: 0.9429 - val_loss: 0.6861 - val_acc: 0.8071\n",
            "Epoch 21/47\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1863 - acc: 0.9306\n",
            "Epoch 21: val_acc improved from 0.80714 to 0.82143, saving model to percobaan53_noImgPro/model\\vgg_16_53-saved-model-21-acc-0.82.hdf5\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.1863 - acc: 0.9306 - val_loss: 0.6042 - val_acc: 0.8214\n",
            "Epoch 22/47\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1423 - acc: 0.9429\n",
            "Epoch 22: val_acc improved from 0.82143 to 0.84286, saving model to percobaan53_noImgPro/model\\vgg_16_53-saved-model-22-acc-0.84.hdf5\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.1423 - acc: 0.9429 - val_loss: 0.5509 - val_acc: 0.8429\n",
            "Epoch 23/47\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1369 - acc: 0.9449\n",
            "Epoch 23: val_acc did not improve from 0.84286\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.1369 - acc: 0.9449 - val_loss: 0.5046 - val_acc: 0.8286\n",
            "Epoch 24/47\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1576 - acc: 0.9449\n",
            "Epoch 24: val_acc did not improve from 0.84286\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.1576 - acc: 0.9449 - val_loss: 0.5418 - val_acc: 0.8071\n",
            "Epoch 25/47\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1411 - acc: 0.9449\n",
            "Epoch 25: val_acc did not improve from 0.84286\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.1411 - acc: 0.9449 - val_loss: 0.6243 - val_acc: 0.8143\n",
            "Epoch 26/47\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1761 - acc: 0.9469\n",
            "Epoch 26: val_acc did not improve from 0.84286\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.1761 - acc: 0.9469 - val_loss: 0.5955 - val_acc: 0.8286\n",
            "Epoch 27/47\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1543 - acc: 0.9429\n",
            "Epoch 27: val_acc did not improve from 0.84286\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.1543 - acc: 0.9429 - val_loss: 0.6198 - val_acc: 0.8357\n",
            "Epoch 28/47\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1522 - acc: 0.9490\n",
            "Epoch 28: val_acc did not improve from 0.84286\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.1522 - acc: 0.9490 - val_loss: 0.6368 - val_acc: 0.8214\n",
            "\n",
            "\n",
            "Model Accuracy 0.8142857142857143\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.91      1.00      0.95        10\n",
            "       10000       1.00      0.90      0.95        10\n",
            "      100000       1.00      0.50      0.67        10\n",
            "        2000       0.83      1.00      0.91        10\n",
            "       20000       1.00      0.40      0.57        10\n",
            "        5000       0.75      0.90      0.82        10\n",
            "       50000       0.59      1.00      0.74        10\n",
            "\n",
            "    accuracy                           0.81        70\n",
            "   macro avg       0.87      0.81      0.80        70\n",
            "weighted avg       0.87      0.81      0.80        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 54 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 45\n",
            "learning rate: 0.023027745775895864\n",
            "batch size: 64\n",
            "dropout rate: 0.5914435428329587\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.3799 - acc: 0.3469\n",
            "Epoch 1: val_acc improved from -inf to 0.14286, saving model to percobaan54_noImgPro/model\\vgg_16_54-saved-model-01-acc-0.14.hdf5\n",
            "8/8 [==============================] - 81s 10s/step - loss: 2.3799 - acc: 0.3469 - val_loss: 7.6465 - val_acc: 0.1429\n",
            "Epoch 2/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5761 - acc: 0.4980\n",
            "Epoch 2: val_acc did not improve from 0.14286\n",
            "8/8 [==============================] - 79s 10s/step - loss: 1.5761 - acc: 0.4980 - val_loss: 7.7545 - val_acc: 0.1429\n",
            "Epoch 3/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1358 - acc: 0.5857\n",
            "Epoch 3: val_acc improved from 0.14286 to 0.16429, saving model to percobaan54_noImgPro/model\\vgg_16_54-saved-model-03-acc-0.16.hdf5\n",
            "8/8 [==============================] - 79s 11s/step - loss: 1.1358 - acc: 0.5857 - val_loss: 6.5852 - val_acc: 0.1643\n",
            "Epoch 4/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8804 - acc: 0.6918\n",
            "Epoch 4: val_acc improved from 0.16429 to 0.19286, saving model to percobaan54_noImgPro/model\\vgg_16_54-saved-model-04-acc-0.19.hdf5\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.8804 - acc: 0.6918 - val_loss: 6.5135 - val_acc: 0.1929\n",
            "Epoch 5/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7029 - acc: 0.7633\n",
            "Epoch 5: val_acc improved from 0.19286 to 0.22143, saving model to percobaan54_noImgPro/model\\vgg_16_54-saved-model-05-acc-0.22.hdf5\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.7029 - acc: 0.7633 - val_loss: 3.8070 - val_acc: 0.2214\n",
            "Epoch 6/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5577 - acc: 0.8061\n",
            "Epoch 6: val_acc improved from 0.22143 to 0.31429, saving model to percobaan54_noImgPro/model\\vgg_16_54-saved-model-06-acc-0.31.hdf5\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.5577 - acc: 0.8061 - val_loss: 2.6346 - val_acc: 0.3143\n",
            "Epoch 7/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4955 - acc: 0.8163\n",
            "Epoch 7: val_acc did not improve from 0.31429\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.4955 - acc: 0.8163 - val_loss: 2.5100 - val_acc: 0.3071\n",
            "Epoch 8/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4208 - acc: 0.8755\n",
            "Epoch 8: val_acc improved from 0.31429 to 0.44286, saving model to percobaan54_noImgPro/model\\vgg_16_54-saved-model-08-acc-0.44.hdf5\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.4208 - acc: 0.8755 - val_loss: 1.6032 - val_acc: 0.4429\n",
            "Epoch 9/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4274 - acc: 0.8408\n",
            "Epoch 9: val_acc improved from 0.44286 to 0.54286, saving model to percobaan54_noImgPro/model\\vgg_16_54-saved-model-09-acc-0.54.hdf5\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.4274 - acc: 0.8408 - val_loss: 1.3721 - val_acc: 0.5429\n",
            "Epoch 10/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3641 - acc: 0.8878\n",
            "Epoch 10: val_acc improved from 0.54286 to 0.59286, saving model to percobaan54_noImgPro/model\\vgg_16_54-saved-model-10-acc-0.59.hdf5\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.3641 - acc: 0.8878 - val_loss: 1.1906 - val_acc: 0.5929\n",
            "Epoch 11/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3186 - acc: 0.8918\n",
            "Epoch 11: val_acc improved from 0.59286 to 0.62143, saving model to percobaan54_noImgPro/model\\vgg_16_54-saved-model-11-acc-0.62.hdf5\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.3186 - acc: 0.8918 - val_loss: 1.2016 - val_acc: 0.6214\n",
            "Epoch 12/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2694 - acc: 0.9041\n",
            "Epoch 12: val_acc improved from 0.62143 to 0.68571, saving model to percobaan54_noImgPro/model\\vgg_16_54-saved-model-12-acc-0.69.hdf5\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.2694 - acc: 0.9041 - val_loss: 0.8471 - val_acc: 0.6857\n",
            "Epoch 13/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3009 - acc: 0.9000\n",
            "Epoch 13: val_acc improved from 0.68571 to 0.70714, saving model to percobaan54_noImgPro/model\\vgg_16_54-saved-model-13-acc-0.71.hdf5\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.3009 - acc: 0.9000 - val_loss: 0.7876 - val_acc: 0.7071\n",
            "Epoch 14/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2437 - acc: 0.9082\n",
            "Epoch 14: val_acc improved from 0.70714 to 0.71429, saving model to percobaan54_noImgPro/model\\vgg_16_54-saved-model-14-acc-0.71.hdf5\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.2437 - acc: 0.9082 - val_loss: 0.8945 - val_acc: 0.7143\n",
            "Epoch 15/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2735 - acc: 0.9184\n",
            "Epoch 15: val_acc did not improve from 0.71429\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.2735 - acc: 0.9184 - val_loss: 0.9428 - val_acc: 0.6929\n",
            "Epoch 16/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2664 - acc: 0.9102\n",
            "Epoch 16: val_acc improved from 0.71429 to 0.72143, saving model to percobaan54_noImgPro/model\\vgg_16_54-saved-model-16-acc-0.72.hdf5\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.2664 - acc: 0.9102 - val_loss: 0.7695 - val_acc: 0.7214\n",
            "Epoch 17/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2784 - acc: 0.9204\n",
            "Epoch 17: val_acc improved from 0.72143 to 0.73571, saving model to percobaan54_noImgPro/model\\vgg_16_54-saved-model-17-acc-0.74.hdf5\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.2784 - acc: 0.9204 - val_loss: 0.7654 - val_acc: 0.7357\n",
            "Epoch 18/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3482 - acc: 0.8837\n",
            "Epoch 18: val_acc did not improve from 0.73571\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.3482 - acc: 0.8837 - val_loss: 0.9070 - val_acc: 0.6500\n",
            "Epoch 19/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2999 - acc: 0.8878\n",
            "Epoch 19: val_acc did not improve from 0.73571\n",
            "8/8 [==============================] - 78s 10s/step - loss: 0.2999 - acc: 0.8878 - val_loss: 0.9851 - val_acc: 0.6429\n",
            "Epoch 20/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2375 - acc: 0.9184\n",
            "Epoch 20: val_acc did not improve from 0.73571\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.2375 - acc: 0.9184 - val_loss: 1.0215 - val_acc: 0.6643\n",
            "Epoch 21/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2639 - acc: 0.9041\n",
            "Epoch 21: val_acc improved from 0.73571 to 0.75000, saving model to percobaan54_noImgPro/model\\vgg_16_54-saved-model-21-acc-0.75.hdf5\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.2639 - acc: 0.9041 - val_loss: 0.8380 - val_acc: 0.7500\n",
            "Epoch 22/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2144 - acc: 0.9204\n",
            "Epoch 22: val_acc improved from 0.75000 to 0.77857, saving model to percobaan54_noImgPro/model\\vgg_16_54-saved-model-22-acc-0.78.hdf5\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.2144 - acc: 0.9204 - val_loss: 0.7553 - val_acc: 0.7786\n",
            "Epoch 23/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2636 - acc: 0.8918\n",
            "Epoch 23: val_acc improved from 0.77857 to 0.80000, saving model to percobaan54_noImgPro/model\\vgg_16_54-saved-model-23-acc-0.80.hdf5\n",
            "8/8 [==============================] - 80s 11s/step - loss: 0.2636 - acc: 0.8918 - val_loss: 0.7681 - val_acc: 0.8000\n",
            "Epoch 24/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2163 - acc: 0.9286\n",
            "Epoch 24: val_acc did not improve from 0.80000\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.2163 - acc: 0.9286 - val_loss: 0.8783 - val_acc: 0.7429\n",
            "Epoch 25/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2059 - acc: 0.9184\n",
            "Epoch 25: val_acc did not improve from 0.80000\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.2059 - acc: 0.9184 - val_loss: 0.8423 - val_acc: 0.7500\n",
            "Epoch 26/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2261 - acc: 0.9122\n",
            "Epoch 26: val_acc did not improve from 0.80000\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.2261 - acc: 0.9122 - val_loss: 0.8913 - val_acc: 0.7429\n",
            "Epoch 27/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2321 - acc: 0.9122\n",
            "Epoch 27: val_acc did not improve from 0.80000\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.2321 - acc: 0.9122 - val_loss: 1.1008 - val_acc: 0.6500\n",
            "\n",
            "\n",
            "Model Accuracy 0.5714285714285714\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.86      0.60      0.71        10\n",
            "       10000       0.89      0.80      0.84        10\n",
            "      100000       1.00      0.50      0.67        10\n",
            "        2000       0.75      0.60      0.67        10\n",
            "       20000       0.00      0.00      0.00        10\n",
            "        5000       1.00      0.50      0.67        10\n",
            "       50000       0.28      1.00      0.43        10\n",
            "\n",
            "    accuracy                           0.57        70\n",
            "   macro avg       0.68      0.57      0.57        70\n",
            "weighted avg       0.68      0.57      0.57        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 55 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 41\n",
            "learning rate: 0.006729553818609509\n",
            "batch size: 64\n",
            "dropout rate: 0.6962827005674291\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 3.1954 - acc: 0.2388\n",
            "Epoch 1: val_acc improved from -inf to 0.14286, saving model to percobaan55_noImgPro/model\\vgg_16_55-saved-model-01-acc-0.14.hdf5\n",
            "8/8 [==============================] - 80s 10s/step - loss: 3.1954 - acc: 0.2388 - val_loss: 3.0294 - val_acc: 0.1429\n",
            "Epoch 2/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6168 - acc: 0.4531\n",
            "Epoch 2: val_acc improved from 0.14286 to 0.20000, saving model to percobaan55_noImgPro/model\\vgg_16_55-saved-model-02-acc-0.20.hdf5\n",
            "8/8 [==============================] - 79s 10s/step - loss: 1.6168 - acc: 0.4531 - val_loss: 1.7702 - val_acc: 0.2000\n",
            "Epoch 3/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1402 - acc: 0.5837\n",
            "Epoch 3: val_acc improved from 0.20000 to 0.21429, saving model to percobaan55_noImgPro/model\\vgg_16_55-saved-model-03-acc-0.21.hdf5\n",
            "8/8 [==============================] - 80s 10s/step - loss: 1.1402 - acc: 0.5837 - val_loss: 2.0016 - val_acc: 0.2143\n",
            "Epoch 4/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9765 - acc: 0.6571\n",
            "Epoch 4: val_acc improved from 0.21429 to 0.25000, saving model to percobaan55_noImgPro/model\\vgg_16_55-saved-model-04-acc-0.25.hdf5\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.9765 - acc: 0.6571 - val_loss: 2.0158 - val_acc: 0.2500\n",
            "Epoch 5/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7950 - acc: 0.7000\n",
            "Epoch 5: val_acc improved from 0.25000 to 0.38571, saving model to percobaan55_noImgPro/model\\vgg_16_55-saved-model-05-acc-0.39.hdf5\n",
            "8/8 [==============================] - 79s 11s/step - loss: 0.7950 - acc: 0.7000 - val_loss: 1.7745 - val_acc: 0.3857\n",
            "Epoch 6/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7672 - acc: 0.7184\n",
            "Epoch 6: val_acc improved from 0.38571 to 0.41429, saving model to percobaan55_noImgPro/model\\vgg_16_55-saved-model-06-acc-0.41.hdf5\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.7672 - acc: 0.7184 - val_loss: 1.6217 - val_acc: 0.4143\n",
            "Epoch 7/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5916 - acc: 0.7939\n",
            "Epoch 7: val_acc improved from 0.41429 to 0.48571, saving model to percobaan55_noImgPro/model\\vgg_16_55-saved-model-07-acc-0.49.hdf5\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.5916 - acc: 0.7939 - val_loss: 1.4120 - val_acc: 0.4857\n",
            "Epoch 8/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5814 - acc: 0.8122\n",
            "Epoch 8: val_acc improved from 0.48571 to 0.50714, saving model to percobaan55_noImgPro/model\\vgg_16_55-saved-model-08-acc-0.51.hdf5\n",
            "8/8 [==============================] - 79s 11s/step - loss: 0.5814 - acc: 0.8122 - val_loss: 1.3223 - val_acc: 0.5071\n",
            "Epoch 9/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5611 - acc: 0.8143\n",
            "Epoch 9: val_acc improved from 0.50714 to 0.56429, saving model to percobaan55_noImgPro/model\\vgg_16_55-saved-model-09-acc-0.56.hdf5\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.5611 - acc: 0.8143 - val_loss: 1.2321 - val_acc: 0.5643\n",
            "Epoch 10/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4605 - acc: 0.8306\n",
            "Epoch 10: val_acc did not improve from 0.56429\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.4605 - acc: 0.8306 - val_loss: 1.2621 - val_acc: 0.5571\n",
            "Epoch 11/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3955 - acc: 0.8673\n",
            "Epoch 11: val_acc did not improve from 0.56429\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.3955 - acc: 0.8673 - val_loss: 1.2559 - val_acc: 0.5571\n",
            "Epoch 12/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4856 - acc: 0.8367\n",
            "Epoch 12: val_acc improved from 0.56429 to 0.64286, saving model to percobaan55_noImgPro/model\\vgg_16_55-saved-model-12-acc-0.64.hdf5\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.4856 - acc: 0.8367 - val_loss: 1.0566 - val_acc: 0.6429\n",
            "Epoch 13/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3823 - acc: 0.8816\n",
            "Epoch 13: val_acc improved from 0.64286 to 0.69286, saving model to percobaan55_noImgPro/model\\vgg_16_55-saved-model-13-acc-0.69.hdf5\n",
            "8/8 [==============================] - 79s 11s/step - loss: 0.3823 - acc: 0.8816 - val_loss: 0.8870 - val_acc: 0.6929\n",
            "Epoch 14/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3811 - acc: 0.8469\n",
            "Epoch 14: val_acc improved from 0.69286 to 0.72143, saving model to percobaan55_noImgPro/model\\vgg_16_55-saved-model-14-acc-0.72.hdf5\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.3811 - acc: 0.8469 - val_loss: 0.8202 - val_acc: 0.7214\n",
            "Epoch 15/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3524 - acc: 0.8776\n",
            "Epoch 15: val_acc did not improve from 0.72143\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.3524 - acc: 0.8776 - val_loss: 0.8071 - val_acc: 0.7000\n",
            "Epoch 16/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3022 - acc: 0.9000\n",
            "Epoch 16: val_acc did not improve from 0.72143\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.3022 - acc: 0.9000 - val_loss: 0.7730 - val_acc: 0.6857\n",
            "Epoch 17/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3520 - acc: 0.8694\n",
            "Epoch 17: val_acc improved from 0.72143 to 0.74286, saving model to percobaan55_noImgPro/model\\vgg_16_55-saved-model-17-acc-0.74.hdf5\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.3520 - acc: 0.8694 - val_loss: 0.6819 - val_acc: 0.7429\n",
            "Epoch 18/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2967 - acc: 0.9041\n",
            "Epoch 18: val_acc did not improve from 0.74286\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.2967 - acc: 0.9041 - val_loss: 0.7030 - val_acc: 0.7214\n",
            "Epoch 19/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2293 - acc: 0.9245\n",
            "Epoch 19: val_acc did not improve from 0.74286\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.2293 - acc: 0.9245 - val_loss: 0.7505 - val_acc: 0.7286\n",
            "Epoch 20/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2983 - acc: 0.9082\n",
            "Epoch 20: val_acc improved from 0.74286 to 0.75714, saving model to percobaan55_noImgPro/model\\vgg_16_55-saved-model-20-acc-0.76.hdf5\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.2983 - acc: 0.9082 - val_loss: 0.7004 - val_acc: 0.7571\n",
            "Epoch 21/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2857 - acc: 0.9000\n",
            "Epoch 21: val_acc improved from 0.75714 to 0.79286, saving model to percobaan55_noImgPro/model\\vgg_16_55-saved-model-21-acc-0.79.hdf5\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.2857 - acc: 0.9000 - val_loss: 0.6395 - val_acc: 0.7929\n",
            "Epoch 22/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2476 - acc: 0.9102\n",
            "Epoch 22: val_acc improved from 0.79286 to 0.80714, saving model to percobaan55_noImgPro/model\\vgg_16_55-saved-model-22-acc-0.81.hdf5\n",
            "8/8 [==============================] - 79s 11s/step - loss: 0.2476 - acc: 0.9102 - val_loss: 0.6047 - val_acc: 0.8071\n",
            "Epoch 23/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2586 - acc: 0.9041\n",
            "Epoch 23: val_acc did not improve from 0.80714\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.2586 - acc: 0.9041 - val_loss: 0.5806 - val_acc: 0.8000\n",
            "Epoch 24/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2412 - acc: 0.9061\n",
            "Epoch 24: val_acc did not improve from 0.80714\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.2412 - acc: 0.9061 - val_loss: 0.5893 - val_acc: 0.8000\n",
            "Epoch 25/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2384 - acc: 0.9224\n",
            "Epoch 25: val_acc did not improve from 0.80714\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.2384 - acc: 0.9224 - val_loss: 0.5718 - val_acc: 0.8000\n",
            "Epoch 26/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2361 - acc: 0.9184\n",
            "Epoch 26: val_acc improved from 0.80714 to 0.84286, saving model to percobaan55_noImgPro/model\\vgg_16_55-saved-model-26-acc-0.84.hdf5\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.2361 - acc: 0.9184 - val_loss: 0.5381 - val_acc: 0.8429\n",
            "Epoch 27/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2399 - acc: 0.9102\n",
            "Epoch 27: val_acc did not improve from 0.84286\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.2399 - acc: 0.9102 - val_loss: 0.5128 - val_acc: 0.8214\n",
            "Epoch 28/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2159 - acc: 0.9204\n",
            "Epoch 28: val_acc did not improve from 0.84286\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.2159 - acc: 0.9204 - val_loss: 0.4710 - val_acc: 0.8429\n",
            "Epoch 29/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2213 - acc: 0.9327\n",
            "Epoch 29: val_acc improved from 0.84286 to 0.85714, saving model to percobaan55_noImgPro/model\\vgg_16_55-saved-model-29-acc-0.86.hdf5\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.2213 - acc: 0.9327 - val_loss: 0.4576 - val_acc: 0.8571\n",
            "Epoch 30/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1761 - acc: 0.9551\n",
            "Epoch 30: val_acc improved from 0.85714 to 0.87143, saving model to percobaan55_noImgPro/model\\vgg_16_55-saved-model-30-acc-0.87.hdf5\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.1761 - acc: 0.9551 - val_loss: 0.4491 - val_acc: 0.8714\n",
            "Epoch 31/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2137 - acc: 0.9388\n",
            "Epoch 31: val_acc improved from 0.87143 to 0.87857, saving model to percobaan55_noImgPro/model\\vgg_16_55-saved-model-31-acc-0.88.hdf5\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.2137 - acc: 0.9388 - val_loss: 0.4374 - val_acc: 0.8786\n",
            "Epoch 32/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2010 - acc: 0.9265\n",
            "Epoch 32: val_acc did not improve from 0.87857\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.2010 - acc: 0.9265 - val_loss: 0.4452 - val_acc: 0.8714\n",
            "Epoch 33/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1853 - acc: 0.9510\n",
            "Epoch 33: val_acc did not improve from 0.87857\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.1853 - acc: 0.9510 - val_loss: 0.4606 - val_acc: 0.8571\n",
            "Epoch 34/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1847 - acc: 0.9347\n",
            "Epoch 34: val_acc did not improve from 0.87857\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.1847 - acc: 0.9347 - val_loss: 0.4715 - val_acc: 0.8714\n",
            "Epoch 35/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2097 - acc: 0.9327\n",
            "Epoch 35: val_acc did not improve from 0.87857\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.2097 - acc: 0.9327 - val_loss: 0.4783 - val_acc: 0.8643\n",
            "Epoch 36/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2337 - acc: 0.9224\n",
            "Epoch 36: val_acc did not improve from 0.87857\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.2337 - acc: 0.9224 - val_loss: 0.4403 - val_acc: 0.8643\n",
            "\n",
            "\n",
            "Model Accuracy 0.8142857142857143\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.82      0.90      0.86        10\n",
            "       10000       0.83      1.00      0.91        10\n",
            "      100000       1.00      0.90      0.95        10\n",
            "        2000       0.71      1.00      0.83        10\n",
            "       20000       1.00      0.30      0.46        10\n",
            "        5000       1.00      0.70      0.82        10\n",
            "       50000       0.64      0.90      0.75        10\n",
            "\n",
            "    accuracy                           0.81        70\n",
            "   macro avg       0.86      0.81      0.80        70\n",
            "weighted avg       0.86      0.81      0.80        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 56 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 45\n",
            "learning rate: 0.013704256139438408\n",
            "batch size: 64\n",
            "dropout rate: 0.798351028811011\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 3.4286 - acc: 0.2286\n",
            "Epoch 1: val_acc improved from -inf to 0.24286, saving model to percobaan56_noImgPro/model\\vgg_16_56-saved-model-01-acc-0.24.hdf5\n",
            "8/8 [==============================] - 85s 11s/step - loss: 3.4286 - acc: 0.2286 - val_loss: 2.7561 - val_acc: 0.2429\n",
            "Epoch 2/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.2585 - acc: 0.3592\n",
            "Epoch 2: val_acc did not improve from 0.24286\n",
            "8/8 [==============================] - 83s 11s/step - loss: 2.2585 - acc: 0.3592 - val_loss: 2.8330 - val_acc: 0.2429\n",
            "Epoch 3/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7196 - acc: 0.4327\n",
            "Epoch 3: val_acc did not improve from 0.24286\n",
            "8/8 [==============================] - 84s 11s/step - loss: 1.7196 - acc: 0.4327 - val_loss: 2.4114 - val_acc: 0.1857\n",
            "Epoch 4/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5333 - acc: 0.4796\n",
            "Epoch 4: val_acc improved from 0.24286 to 0.31429, saving model to percobaan56_noImgPro/model\\vgg_16_56-saved-model-04-acc-0.31.hdf5\n",
            "8/8 [==============================] - 84s 11s/step - loss: 1.5333 - acc: 0.4796 - val_loss: 1.7826 - val_acc: 0.3143\n",
            "Epoch 5/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3810 - acc: 0.4939\n",
            "Epoch 5: val_acc improved from 0.31429 to 0.32857, saving model to percobaan56_noImgPro/model\\vgg_16_56-saved-model-05-acc-0.33.hdf5\n",
            "8/8 [==============================] - 83s 11s/step - loss: 1.3810 - acc: 0.4939 - val_loss: 1.7653 - val_acc: 0.3286\n",
            "Epoch 6/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.2024 - acc: 0.5531\n",
            "Epoch 6: val_acc improved from 0.32857 to 0.39286, saving model to percobaan56_noImgPro/model\\vgg_16_56-saved-model-06-acc-0.39.hdf5\n",
            "8/8 [==============================] - 84s 11s/step - loss: 1.2024 - acc: 0.5531 - val_loss: 1.6344 - val_acc: 0.3929\n",
            "Epoch 7/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0697 - acc: 0.5857\n",
            "Epoch 7: val_acc improved from 0.39286 to 0.47857, saving model to percobaan56_noImgPro/model\\vgg_16_56-saved-model-07-acc-0.48.hdf5\n",
            "8/8 [==============================] - 85s 11s/step - loss: 1.0697 - acc: 0.5857 - val_loss: 1.3157 - val_acc: 0.4786\n",
            "Epoch 8/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0445 - acc: 0.6224\n",
            "Epoch 8: val_acc improved from 0.47857 to 0.57857, saving model to percobaan56_noImgPro/model\\vgg_16_56-saved-model-08-acc-0.58.hdf5\n",
            "8/8 [==============================] - 85s 11s/step - loss: 1.0445 - acc: 0.6224 - val_loss: 1.1769 - val_acc: 0.5786\n",
            "Epoch 9/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9819 - acc: 0.6347\n",
            "Epoch 9: val_acc did not improve from 0.57857\n",
            "8/8 [==============================] - 84s 11s/step - loss: 0.9819 - acc: 0.6347 - val_loss: 1.1516 - val_acc: 0.5500\n",
            "Epoch 10/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8156 - acc: 0.6939\n",
            "Epoch 10: val_acc improved from 0.57857 to 0.63571, saving model to percobaan56_noImgPro/model\\vgg_16_56-saved-model-10-acc-0.64.hdf5\n",
            "8/8 [==============================] - 84s 11s/step - loss: 0.8156 - acc: 0.6939 - val_loss: 1.0184 - val_acc: 0.6357\n",
            "Epoch 11/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7789 - acc: 0.6898\n",
            "Epoch 11: val_acc improved from 0.63571 to 0.70000, saving model to percobaan56_noImgPro/model\\vgg_16_56-saved-model-11-acc-0.70.hdf5\n",
            "8/8 [==============================] - 85s 11s/step - loss: 0.7789 - acc: 0.6898 - val_loss: 0.8947 - val_acc: 0.7000\n",
            "Epoch 12/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6910 - acc: 0.7510\n",
            "Epoch 12: val_acc improved from 0.70000 to 0.72857, saving model to percobaan56_noImgPro/model\\vgg_16_56-saved-model-12-acc-0.73.hdf5\n",
            "8/8 [==============================] - 84s 11s/step - loss: 0.6910 - acc: 0.7510 - val_loss: 0.8713 - val_acc: 0.7286\n",
            "Epoch 13/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7484 - acc: 0.7224\n",
            "Epoch 13: val_acc did not improve from 0.72857\n",
            "8/8 [==============================] - 84s 11s/step - loss: 0.7484 - acc: 0.7224 - val_loss: 0.8216 - val_acc: 0.7286\n",
            "Epoch 14/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6683 - acc: 0.7633\n",
            "Epoch 14: val_acc did not improve from 0.72857\n",
            "8/8 [==============================] - 84s 11s/step - loss: 0.6683 - acc: 0.7633 - val_loss: 0.8160 - val_acc: 0.7143\n",
            "Epoch 15/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6312 - acc: 0.7653\n",
            "Epoch 15: val_acc did not improve from 0.72857\n",
            "8/8 [==============================] - 84s 11s/step - loss: 0.6312 - acc: 0.7653 - val_loss: 0.8380 - val_acc: 0.6857\n",
            "Epoch 16/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5758 - acc: 0.7959\n",
            "Epoch 16: val_acc did not improve from 0.72857\n",
            "8/8 [==============================] - 83s 11s/step - loss: 0.5758 - acc: 0.7959 - val_loss: 0.8284 - val_acc: 0.6929\n",
            "Epoch 17/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6993 - acc: 0.7612\n",
            "Epoch 17: val_acc improved from 0.72857 to 0.73571, saving model to percobaan56_noImgPro/model\\vgg_16_56-saved-model-17-acc-0.74.hdf5\n",
            "8/8 [==============================] - 84s 11s/step - loss: 0.6993 - acc: 0.7612 - val_loss: 0.7776 - val_acc: 0.7357\n",
            "Epoch 18/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5643 - acc: 0.7980\n",
            "Epoch 18: val_acc improved from 0.73571 to 0.77857, saving model to percobaan56_noImgPro/model\\vgg_16_56-saved-model-18-acc-0.78.hdf5\n",
            "8/8 [==============================] - 84s 11s/step - loss: 0.5643 - acc: 0.7980 - val_loss: 0.6662 - val_acc: 0.7786\n",
            "Epoch 19/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5665 - acc: 0.8102\n",
            "Epoch 19: val_acc improved from 0.77857 to 0.79286, saving model to percobaan56_noImgPro/model\\vgg_16_56-saved-model-19-acc-0.79.hdf5\n",
            "8/8 [==============================] - 84s 11s/step - loss: 0.5665 - acc: 0.8102 - val_loss: 0.6005 - val_acc: 0.7929\n",
            "Epoch 20/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5187 - acc: 0.8286\n",
            "Epoch 20: val_acc improved from 0.79286 to 0.82857, saving model to percobaan56_noImgPro/model\\vgg_16_56-saved-model-20-acc-0.83.hdf5\n",
            "8/8 [==============================] - 84s 11s/step - loss: 0.5187 - acc: 0.8286 - val_loss: 0.6025 - val_acc: 0.8286\n",
            "Epoch 21/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5173 - acc: 0.8163\n",
            "Epoch 21: val_acc did not improve from 0.82857\n",
            "8/8 [==============================] - 84s 11s/step - loss: 0.5173 - acc: 0.8163 - val_loss: 0.6166 - val_acc: 0.8214\n",
            "Epoch 22/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5198 - acc: 0.8163\n",
            "Epoch 22: val_acc did not improve from 0.82857\n",
            "8/8 [==============================] - 84s 11s/step - loss: 0.5198 - acc: 0.8163 - val_loss: 0.6862 - val_acc: 0.8000\n",
            "Epoch 23/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5472 - acc: 0.8000\n",
            "Epoch 23: val_acc did not improve from 0.82857\n",
            "8/8 [==============================] - 83s 11s/step - loss: 0.5472 - acc: 0.8000 - val_loss: 0.6023 - val_acc: 0.8214\n",
            "Epoch 24/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4955 - acc: 0.8286\n",
            "Epoch 24: val_acc did not improve from 0.82857\n",
            "8/8 [==============================] - 84s 11s/step - loss: 0.4955 - acc: 0.8286 - val_loss: 0.5733 - val_acc: 0.8071\n",
            "Epoch 25/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4487 - acc: 0.8490\n",
            "Epoch 25: val_acc did not improve from 0.82857\n",
            "8/8 [==============================] - 84s 11s/step - loss: 0.4487 - acc: 0.8490 - val_loss: 0.5533 - val_acc: 0.8143\n",
            "Epoch 26/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4829 - acc: 0.8122\n",
            "Epoch 26: val_acc improved from 0.82857 to 0.83571, saving model to percobaan56_noImgPro/model\\vgg_16_56-saved-model-26-acc-0.84.hdf5\n",
            "8/8 [==============================] - 84s 11s/step - loss: 0.4829 - acc: 0.8122 - val_loss: 0.5451 - val_acc: 0.8357\n",
            "Epoch 27/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4192 - acc: 0.8408\n",
            "Epoch 27: val_acc improved from 0.83571 to 0.85000, saving model to percobaan56_noImgPro/model\\vgg_16_56-saved-model-27-acc-0.85.hdf5\n",
            "8/8 [==============================] - 84s 11s/step - loss: 0.4192 - acc: 0.8408 - val_loss: 0.5070 - val_acc: 0.8500\n",
            "Epoch 28/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3785 - acc: 0.8673\n",
            "Epoch 28: val_acc did not improve from 0.85000\n",
            "8/8 [==============================] - 84s 11s/step - loss: 0.3785 - acc: 0.8673 - val_loss: 0.5974 - val_acc: 0.8071\n",
            "Epoch 29/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4323 - acc: 0.8551\n",
            "Epoch 29: val_acc did not improve from 0.85000\n",
            "8/8 [==============================] - 84s 11s/step - loss: 0.4323 - acc: 0.8551 - val_loss: 0.7441 - val_acc: 0.7714\n",
            "Epoch 30/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4079 - acc: 0.8673\n",
            "Epoch 30: val_acc did not improve from 0.85000\n",
            "8/8 [==============================] - 84s 11s/step - loss: 0.4079 - acc: 0.8673 - val_loss: 0.6588 - val_acc: 0.7857\n",
            "Epoch 31/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4748 - acc: 0.8184\n",
            "Epoch 31: val_acc did not improve from 0.85000\n",
            "8/8 [==============================] - 84s 11s/step - loss: 0.4748 - acc: 0.8184 - val_loss: 0.5000 - val_acc: 0.8357\n",
            "Epoch 32/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4517 - acc: 0.8469\n",
            "Epoch 32: val_acc did not improve from 0.85000\n",
            "8/8 [==============================] - 84s 11s/step - loss: 0.4517 - acc: 0.8469 - val_loss: 0.5204 - val_acc: 0.8429\n",
            "Epoch 33/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4283 - acc: 0.8510\n",
            "Epoch 33: val_acc did not improve from 0.85000\n",
            "8/8 [==============================] - 84s 11s/step - loss: 0.4283 - acc: 0.8510 - val_loss: 0.5521 - val_acc: 0.8143\n",
            "Epoch 34/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3992 - acc: 0.8714\n",
            "Epoch 34: val_acc did not improve from 0.85000\n",
            "8/8 [==============================] - 84s 11s/step - loss: 0.3992 - acc: 0.8714 - val_loss: 0.5334 - val_acc: 0.8143\n",
            "Epoch 35/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4440 - acc: 0.8571\n",
            "Epoch 35: val_acc did not improve from 0.85000\n",
            "8/8 [==============================] - 84s 11s/step - loss: 0.4440 - acc: 0.8571 - val_loss: 0.5035 - val_acc: 0.8357\n",
            "Epoch 36/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4184 - acc: 0.8510\n",
            "Epoch 36: val_acc improved from 0.85000 to 0.88571, saving model to percobaan56_noImgPro/model\\vgg_16_56-saved-model-36-acc-0.89.hdf5\n",
            "8/8 [==============================] - 84s 11s/step - loss: 0.4184 - acc: 0.8510 - val_loss: 0.4429 - val_acc: 0.8857\n",
            "Epoch 37/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4022 - acc: 0.8490\n",
            "Epoch 37: val_acc improved from 0.88571 to 0.89286, saving model to percobaan56_noImgPro/model\\vgg_16_56-saved-model-37-acc-0.89.hdf5\n",
            "8/8 [==============================] - 84s 11s/step - loss: 0.4022 - acc: 0.8490 - val_loss: 0.4137 - val_acc: 0.8929\n",
            "Epoch 38/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3916 - acc: 0.8571\n",
            "Epoch 38: val_acc did not improve from 0.89286\n",
            "8/8 [==============================] - 84s 11s/step - loss: 0.3916 - acc: 0.8571 - val_loss: 0.4168 - val_acc: 0.8714\n",
            "Epoch 39/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3884 - acc: 0.8673\n",
            "Epoch 39: val_acc did not improve from 0.89286\n",
            "8/8 [==============================] - 84s 11s/step - loss: 0.3884 - acc: 0.8673 - val_loss: 0.4563 - val_acc: 0.8429\n",
            "Epoch 40/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3238 - acc: 0.9041\n",
            "Epoch 40: val_acc did not improve from 0.89286\n",
            "8/8 [==============================] - 84s 11s/step - loss: 0.3238 - acc: 0.9041 - val_loss: 0.4705 - val_acc: 0.8571\n",
            "Epoch 41/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3404 - acc: 0.8714\n",
            "Epoch 41: val_acc did not improve from 0.89286\n",
            "8/8 [==============================] - 84s 11s/step - loss: 0.3404 - acc: 0.8714 - val_loss: 0.4475 - val_acc: 0.8714\n",
            "Epoch 42/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3246 - acc: 0.8959\n",
            "Epoch 42: val_acc did not improve from 0.89286\n",
            "8/8 [==============================] - 84s 11s/step - loss: 0.3246 - acc: 0.8959 - val_loss: 0.4354 - val_acc: 0.8571\n",
            "\n",
            "\n",
            "Model Accuracy 0.8714285714285714\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.90      0.90      0.90        10\n",
            "       10000       1.00      0.90      0.95        10\n",
            "      100000       1.00      0.90      0.95        10\n",
            "        2000       0.62      1.00      0.77        10\n",
            "       20000       0.83      0.50      0.62        10\n",
            "        5000       1.00      0.90      0.95        10\n",
            "       50000       0.91      1.00      0.95        10\n",
            "\n",
            "    accuracy                           0.87        70\n",
            "   macro avg       0.90      0.87      0.87        70\n",
            "weighted avg       0.90      0.87      0.87        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 57 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 39\n",
            "learning rate: 0.0051196997541044465\n",
            "batch size: 128\n",
            "dropout rate: 0.5118107256797669\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.5222 - acc: 0.2694 \n",
            "Epoch 1: val_acc improved from -inf to 0.20000, saving model to percobaan57_noImgPro/model\\vgg_16_57-saved-model-01-acc-0.20.hdf5\n",
            "4/4 [==============================] - 84s 22s/step - loss: 2.5222 - acc: 0.2694 - val_loss: 2.3259 - val_acc: 0.2000\n",
            "Epoch 2/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.4085 - acc: 0.5102 \n",
            "Epoch 2: val_acc improved from 0.20000 to 0.22857, saving model to percobaan57_noImgPro/model\\vgg_16_57-saved-model-02-acc-0.23.hdf5\n",
            "4/4 [==============================] - 83s 22s/step - loss: 1.4085 - acc: 0.5102 - val_loss: 2.1836 - val_acc: 0.2286\n",
            "Epoch 3/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8763 - acc: 0.7020 \n",
            "Epoch 3: val_acc improved from 0.22857 to 0.24286, saving model to percobaan57_noImgPro/model\\vgg_16_57-saved-model-03-acc-0.24.hdf5\n",
            "4/4 [==============================] - 82s 23s/step - loss: 0.8763 - acc: 0.7020 - val_loss: 2.0224 - val_acc: 0.2429\n",
            "Epoch 4/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6646 - acc: 0.7776 \n",
            "Epoch 4: val_acc improved from 0.24286 to 0.26429, saving model to percobaan57_noImgPro/model\\vgg_16_57-saved-model-04-acc-0.26.hdf5\n",
            "4/4 [==============================] - 83s 22s/step - loss: 0.6646 - acc: 0.7776 - val_loss: 1.9562 - val_acc: 0.2643\n",
            "Epoch 5/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5544 - acc: 0.8061 \n",
            "Epoch 5: val_acc improved from 0.26429 to 0.29286, saving model to percobaan57_noImgPro/model\\vgg_16_57-saved-model-05-acc-0.29.hdf5\n",
            "4/4 [==============================] - 83s 22s/step - loss: 0.5544 - acc: 0.8061 - val_loss: 1.8699 - val_acc: 0.2929\n",
            "Epoch 6/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5124 - acc: 0.8388 \n",
            "Epoch 6: val_acc did not improve from 0.29286\n",
            "4/4 [==============================] - 82s 22s/step - loss: 0.5124 - acc: 0.8388 - val_loss: 1.8660 - val_acc: 0.2929\n",
            "Epoch 7/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4039 - acc: 0.8633 \n",
            "Epoch 7: val_acc did not improve from 0.29286\n",
            "4/4 [==============================] - 82s 23s/step - loss: 0.4039 - acc: 0.8633 - val_loss: 1.8299 - val_acc: 0.2929\n",
            "Epoch 8/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3693 - acc: 0.8633 \n",
            "Epoch 8: val_acc improved from 0.29286 to 0.30000, saving model to percobaan57_noImgPro/model\\vgg_16_57-saved-model-08-acc-0.30.hdf5\n",
            "4/4 [==============================] - 82s 23s/step - loss: 0.3693 - acc: 0.8633 - val_loss: 1.7096 - val_acc: 0.3000\n",
            "Epoch 9/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3068 - acc: 0.9041 \n",
            "Epoch 9: val_acc improved from 0.30000 to 0.35714, saving model to percobaan57_noImgPro/model\\vgg_16_57-saved-model-09-acc-0.36.hdf5\n",
            "4/4 [==============================] - 82s 22s/step - loss: 0.3068 - acc: 0.9041 - val_loss: 1.5313 - val_acc: 0.3571\n",
            "Epoch 10/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2766 - acc: 0.9122 \n",
            "Epoch 10: val_acc improved from 0.35714 to 0.40000, saving model to percobaan57_noImgPro/model\\vgg_16_57-saved-model-10-acc-0.40.hdf5\n",
            "4/4 [==============================] - 82s 22s/step - loss: 0.2766 - acc: 0.9122 - val_loss: 1.4091 - val_acc: 0.4000\n",
            "Epoch 11/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2489 - acc: 0.9388 \n",
            "Epoch 11: val_acc did not improve from 0.40000\n",
            "4/4 [==============================] - 82s 22s/step - loss: 0.2489 - acc: 0.9388 - val_loss: 1.3945 - val_acc: 0.4000\n",
            "Epoch 12/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2293 - acc: 0.9306 \n",
            "Epoch 12: val_acc did not improve from 0.40000\n",
            "4/4 [==============================] - 82s 23s/step - loss: 0.2293 - acc: 0.9306 - val_loss: 1.4152 - val_acc: 0.3929\n",
            "Epoch 13/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2104 - acc: 0.9367 \n",
            "Epoch 13: val_acc improved from 0.40000 to 0.40714, saving model to percobaan57_noImgPro/model\\vgg_16_57-saved-model-13-acc-0.41.hdf5\n",
            "4/4 [==============================] - 83s 22s/step - loss: 0.2104 - acc: 0.9367 - val_loss: 1.4003 - val_acc: 0.4071\n",
            "Epoch 14/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2501 - acc: 0.9122 \n",
            "Epoch 14: val_acc improved from 0.40714 to 0.47143, saving model to percobaan57_noImgPro/model\\vgg_16_57-saved-model-14-acc-0.47.hdf5\n",
            "4/4 [==============================] - 82s 22s/step - loss: 0.2501 - acc: 0.9122 - val_loss: 1.2822 - val_acc: 0.4714\n",
            "Epoch 15/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1670 - acc: 0.9551 \n",
            "Epoch 15: val_acc improved from 0.47143 to 0.51429, saving model to percobaan57_noImgPro/model\\vgg_16_57-saved-model-15-acc-0.51.hdf5\n",
            "4/4 [==============================] - 83s 22s/step - loss: 0.1670 - acc: 0.9551 - val_loss: 1.2241 - val_acc: 0.5143\n",
            "Epoch 16/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1672 - acc: 0.9367 \n",
            "Epoch 16: val_acc did not improve from 0.51429\n",
            "4/4 [==============================] - 82s 22s/step - loss: 0.1672 - acc: 0.9367 - val_loss: 1.2438 - val_acc: 0.5143\n",
            "Epoch 17/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1848 - acc: 0.9367 \n",
            "Epoch 17: val_acc did not improve from 0.51429\n",
            "4/4 [==============================] - 82s 23s/step - loss: 0.1848 - acc: 0.9367 - val_loss: 1.2622 - val_acc: 0.5143\n",
            "Epoch 18/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1290 - acc: 0.9694 \n",
            "Epoch 18: val_acc did not improve from 0.51429\n",
            "4/4 [==============================] - 82s 22s/step - loss: 0.1290 - acc: 0.9694 - val_loss: 1.2514 - val_acc: 0.5143\n",
            "Epoch 19/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1570 - acc: 0.9551 \n",
            "Epoch 19: val_acc improved from 0.51429 to 0.54286, saving model to percobaan57_noImgPro/model\\vgg_16_57-saved-model-19-acc-0.54.hdf5\n",
            "4/4 [==============================] - 82s 22s/step - loss: 0.1570 - acc: 0.9551 - val_loss: 1.2104 - val_acc: 0.5429\n",
            "Epoch 20/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1316 - acc: 0.9551 \n",
            "Epoch 20: val_acc improved from 0.54286 to 0.55000, saving model to percobaan57_noImgPro/model\\vgg_16_57-saved-model-20-acc-0.55.hdf5\n",
            "4/4 [==============================] - 82s 22s/step - loss: 0.1316 - acc: 0.9551 - val_loss: 1.1740 - val_acc: 0.5500\n",
            "Epoch 21/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1522 - acc: 0.9531 \n",
            "Epoch 21: val_acc improved from 0.55000 to 0.55714, saving model to percobaan57_noImgPro/model\\vgg_16_57-saved-model-21-acc-0.56.hdf5\n",
            "4/4 [==============================] - 82s 23s/step - loss: 0.1522 - acc: 0.9531 - val_loss: 1.1119 - val_acc: 0.5571\n",
            "Epoch 22/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1196 - acc: 0.9694 \n",
            "Epoch 22: val_acc improved from 0.55714 to 0.58571, saving model to percobaan57_noImgPro/model\\vgg_16_57-saved-model-22-acc-0.59.hdf5\n",
            "4/4 [==============================] - 83s 22s/step - loss: 0.1196 - acc: 0.9694 - val_loss: 1.0434 - val_acc: 0.5857\n",
            "Epoch 23/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1236 - acc: 0.9612 \n",
            "Epoch 23: val_acc improved from 0.58571 to 0.62143, saving model to percobaan57_noImgPro/model\\vgg_16_57-saved-model-23-acc-0.62.hdf5\n",
            "4/4 [==============================] - 82s 22s/step - loss: 0.1236 - acc: 0.9612 - val_loss: 1.0060 - val_acc: 0.6214\n",
            "Epoch 24/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1455 - acc: 0.9469 \n",
            "Epoch 24: val_acc improved from 0.62143 to 0.66429, saving model to percobaan57_noImgPro/model\\vgg_16_57-saved-model-24-acc-0.66.hdf5\n",
            "4/4 [==============================] - 82s 22s/step - loss: 0.1455 - acc: 0.9469 - val_loss: 0.9614 - val_acc: 0.6643\n",
            "Epoch 25/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1280 - acc: 0.9592 \n",
            "Epoch 25: val_acc improved from 0.66429 to 0.67857, saving model to percobaan57_noImgPro/model\\vgg_16_57-saved-model-25-acc-0.68.hdf5\n",
            "4/4 [==============================] - 82s 23s/step - loss: 0.1280 - acc: 0.9592 - val_loss: 0.9096 - val_acc: 0.6786\n",
            "Epoch 26/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0966 - acc: 0.9755 \n",
            "Epoch 26: val_acc improved from 0.67857 to 0.72143, saving model to percobaan57_noImgPro/model\\vgg_16_57-saved-model-26-acc-0.72.hdf5\n",
            "4/4 [==============================] - 82s 22s/step - loss: 0.0966 - acc: 0.9755 - val_loss: 0.8342 - val_acc: 0.7214\n",
            "Epoch 27/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1125 - acc: 0.9653 \n",
            "Epoch 27: val_acc improved from 0.72143 to 0.72857, saving model to percobaan57_noImgPro/model\\vgg_16_57-saved-model-27-acc-0.73.hdf5\n",
            "4/4 [==============================] - 83s 22s/step - loss: 0.1125 - acc: 0.9653 - val_loss: 0.7793 - val_acc: 0.7286\n",
            "Epoch 28/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0896 - acc: 0.9694 \n",
            "Epoch 28: val_acc improved from 0.72857 to 0.78571, saving model to percobaan57_noImgPro/model\\vgg_16_57-saved-model-28-acc-0.79.hdf5\n",
            "4/4 [==============================] - 82s 23s/step - loss: 0.0896 - acc: 0.9694 - val_loss: 0.7408 - val_acc: 0.7857\n",
            "Epoch 29/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0731 - acc: 0.9857 \n",
            "Epoch 29: val_acc did not improve from 0.78571\n",
            "4/4 [==============================] - 83s 22s/step - loss: 0.0731 - acc: 0.9857 - val_loss: 0.7129 - val_acc: 0.7857\n",
            "Epoch 30/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0744 - acc: 0.9735 \n",
            "Epoch 30: val_acc did not improve from 0.78571\n",
            "4/4 [==============================] - 82s 22s/step - loss: 0.0744 - acc: 0.9735 - val_loss: 0.6957 - val_acc: 0.7857\n",
            "Epoch 31/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0918 - acc: 0.9694 \n",
            "Epoch 31: val_acc improved from 0.78571 to 0.80714, saving model to percobaan57_noImgPro/model\\vgg_16_57-saved-model-31-acc-0.81.hdf5\n",
            "4/4 [==============================] - 82s 23s/step - loss: 0.0918 - acc: 0.9694 - val_loss: 0.6714 - val_acc: 0.8071\n",
            "Epoch 32/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0840 - acc: 0.9714 \n",
            "Epoch 32: val_acc did not improve from 0.80714\n",
            "4/4 [==============================] - 82s 23s/step - loss: 0.0840 - acc: 0.9714 - val_loss: 0.6478 - val_acc: 0.8071\n",
            "Epoch 33/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0791 - acc: 0.9735 \n",
            "Epoch 33: val_acc did not improve from 0.80714\n",
            "4/4 [==============================] - 82s 22s/step - loss: 0.0791 - acc: 0.9735 - val_loss: 0.6577 - val_acc: 0.7714\n",
            "Epoch 34/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0762 - acc: 0.9776 \n",
            "Epoch 34: val_acc did not improve from 0.80714\n",
            "4/4 [==============================] - 82s 22s/step - loss: 0.0762 - acc: 0.9776 - val_loss: 0.6724 - val_acc: 0.7714\n",
            "Epoch 35/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0816 - acc: 0.9714 \n",
            "Epoch 35: val_acc did not improve from 0.80714\n",
            "4/4 [==============================] - 82s 22s/step - loss: 0.0816 - acc: 0.9714 - val_loss: 0.6560 - val_acc: 0.7714\n",
            "Epoch 36/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1011 - acc: 0.9673 \n",
            "Epoch 36: val_acc did not improve from 0.80714\n",
            "4/4 [==============================] - 82s 22s/step - loss: 0.1011 - acc: 0.9673 - val_loss: 0.6270 - val_acc: 0.7929\n",
            "Epoch 37/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0933 - acc: 0.9735 \n",
            "Epoch 37: val_acc did not improve from 0.80714\n",
            "4/4 [==============================] - 82s 22s/step - loss: 0.0933 - acc: 0.9735 - val_loss: 0.6133 - val_acc: 0.8071\n",
            "Epoch 38/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0697 - acc: 0.9796 \n",
            "Epoch 38: val_acc improved from 0.80714 to 0.82857, saving model to percobaan57_noImgPro/model\\vgg_16_57-saved-model-38-acc-0.83.hdf5\n",
            "4/4 [==============================] - 83s 22s/step - loss: 0.0697 - acc: 0.9796 - val_loss: 0.5959 - val_acc: 0.8286\n",
            "Epoch 39/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0604 - acc: 0.9816 \n",
            "Epoch 39: val_acc did not improve from 0.82857\n",
            "4/4 [==============================] - 82s 22s/step - loss: 0.0604 - acc: 0.9816 - val_loss: 0.5808 - val_acc: 0.8214\n",
            "\n",
            "\n",
            "Model Accuracy 0.8285714285714286\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.91      1.00      0.95        10\n",
            "       10000       0.90      0.90      0.90        10\n",
            "      100000       1.00      0.50      0.67        10\n",
            "        2000       0.90      0.90      0.90        10\n",
            "       20000       0.86      0.60      0.71        10\n",
            "        5000       0.90      0.90      0.90        10\n",
            "       50000       0.59      1.00      0.74        10\n",
            "\n",
            "    accuracy                           0.83        70\n",
            "   macro avg       0.86      0.83      0.82        70\n",
            "weighted avg       0.86      0.83      0.82        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 58 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 40\n",
            "learning rate: 0.016413025014048677\n",
            "batch size: 128\n",
            "dropout rate: 0.6346580719144607\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.6934 - acc: 0.3020 \n",
            "Epoch 1: val_acc improved from -inf to 0.14286, saving model to percobaan58_noImgPro/model\\vgg_16_58-saved-model-01-acc-0.14.hdf5\n",
            "4/4 [==============================] - 84s 22s/step - loss: 2.6934 - acc: 0.3020 - val_loss: 3.5216 - val_acc: 0.1429\n",
            "Epoch 2/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.5034 - acc: 0.5122 \n",
            "Epoch 2: val_acc did not improve from 0.14286\n",
            "4/4 [==============================] - 82s 22s/step - loss: 1.5034 - acc: 0.5122 - val_loss: 4.7036 - val_acc: 0.1429\n",
            "Epoch 3/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9953 - acc: 0.6510 \n",
            "Epoch 3: val_acc improved from 0.14286 to 0.17857, saving model to percobaan58_noImgPro/model\\vgg_16_58-saved-model-03-acc-0.18.hdf5\n",
            "4/4 [==============================] - 82s 22s/step - loss: 0.9953 - acc: 0.6510 - val_loss: 4.6416 - val_acc: 0.1786\n",
            "Epoch 4/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8174 - acc: 0.7163 \n",
            "Epoch 4: val_acc improved from 0.17857 to 0.19286, saving model to percobaan58_noImgPro/model\\vgg_16_58-saved-model-04-acc-0.19.hdf5\n",
            "4/4 [==============================] - 81s 22s/step - loss: 0.8174 - acc: 0.7163 - val_loss: 5.0806 - val_acc: 0.1929\n",
            "Epoch 5/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7052 - acc: 0.7449 \n",
            "Epoch 5: val_acc improved from 0.19286 to 0.20714, saving model to percobaan58_noImgPro/model\\vgg_16_58-saved-model-05-acc-0.21.hdf5\n",
            "4/4 [==============================] - 81s 21s/step - loss: 0.7052 - acc: 0.7449 - val_loss: 5.1896 - val_acc: 0.2071\n",
            "Epoch 6/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6991 - acc: 0.7571 \n",
            "Epoch 6: val_acc did not improve from 0.20714\n",
            "4/4 [==============================] - 81s 21s/step - loss: 0.6991 - acc: 0.7571 - val_loss: 5.2764 - val_acc: 0.1714\n",
            "\n",
            "\n",
            "Model Accuracy 0.14285714285714285\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.00      0.00      0.00        10\n",
            "       10000       0.00      0.00      0.00        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.00      0.00      0.00        10\n",
            "       20000       0.14      1.00      0.25        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       0.00      0.00      0.00        10\n",
            "\n",
            "    accuracy                           0.14        70\n",
            "   macro avg       0.02      0.14      0.04        70\n",
            "weighted avg       0.02      0.14      0.04        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 59 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 39\n",
            "learning rate: 0.011381522511268167\n",
            "batch size: 128\n",
            "dropout rate: 0.6673745779355464\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.9471 - acc: 0.2367 \n",
            "Epoch 1: val_acc improved from -inf to 0.27857, saving model to percobaan59_noImgPro/model\\vgg_16_59-saved-model-01-acc-0.28.hdf5\n",
            "4/4 [==============================] - 82s 22s/step - loss: 2.9471 - acc: 0.2367 - val_loss: 2.3340 - val_acc: 0.2786\n",
            "Epoch 2/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.4450 - acc: 0.5122 \n",
            "Epoch 2: val_acc did not improve from 0.27857\n",
            "4/4 [==============================] - 80s 21s/step - loss: 1.4450 - acc: 0.5122 - val_loss: 4.3225 - val_acc: 0.1429\n",
            "Epoch 3/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0285 - acc: 0.6551 \n",
            "Epoch 3: val_acc did not improve from 0.27857\n",
            "4/4 [==============================] - 80s 21s/step - loss: 1.0285 - acc: 0.6551 - val_loss: 4.4706 - val_acc: 0.1429\n",
            "Epoch 4/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9234 - acc: 0.6694 \n",
            "Epoch 4: val_acc did not improve from 0.27857\n",
            "4/4 [==============================] - 80s 22s/step - loss: 0.9234 - acc: 0.6694 - val_loss: 2.9668 - val_acc: 0.2429\n",
            "Epoch 5/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7538 - acc: 0.7224 \n",
            "Epoch 5: val_acc improved from 0.27857 to 0.30714, saving model to percobaan59_noImgPro/model\\vgg_16_59-saved-model-05-acc-0.31.hdf5\n",
            "4/4 [==============================] - 80s 22s/step - loss: 0.7538 - acc: 0.7224 - val_loss: 2.2936 - val_acc: 0.3071\n",
            "Epoch 6/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7470 - acc: 0.7469 \n",
            "Epoch 6: val_acc improved from 0.30714 to 0.32143, saving model to percobaan59_noImgPro/model\\vgg_16_59-saved-model-06-acc-0.32.hdf5\n",
            "4/4 [==============================] - 81s 21s/step - loss: 0.7470 - acc: 0.7469 - val_loss: 2.2237 - val_acc: 0.3214\n",
            "Epoch 7/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5771 - acc: 0.8061 \n",
            "Epoch 7: val_acc improved from 0.32143 to 0.33571, saving model to percobaan59_noImgPro/model\\vgg_16_59-saved-model-07-acc-0.34.hdf5\n",
            "4/4 [==============================] - 81s 21s/step - loss: 0.5771 - acc: 0.8061 - val_loss: 2.0665 - val_acc: 0.3357\n",
            "Epoch 8/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4926 - acc: 0.8367 \n",
            "Epoch 8: val_acc improved from 0.33571 to 0.40714, saving model to percobaan59_noImgPro/model\\vgg_16_59-saved-model-08-acc-0.41.hdf5\n",
            "4/4 [==============================] - 81s 21s/step - loss: 0.4926 - acc: 0.8367 - val_loss: 1.7975 - val_acc: 0.4071\n",
            "Epoch 9/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4998 - acc: 0.8388 \n",
            "Epoch 9: val_acc did not improve from 0.40714\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.4998 - acc: 0.8388 - val_loss: 1.7963 - val_acc: 0.3571\n",
            "Epoch 10/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4865 - acc: 0.8327 \n",
            "Epoch 10: val_acc did not improve from 0.40714\n",
            "4/4 [==============================] - 81s 21s/step - loss: 0.4865 - acc: 0.8327 - val_loss: 1.8176 - val_acc: 0.2857\n",
            "Epoch 11/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4089 - acc: 0.8551 \n",
            "Epoch 11: val_acc did not improve from 0.40714\n",
            "4/4 [==============================] - 80s 22s/step - loss: 0.4089 - acc: 0.8551 - val_loss: 1.6315 - val_acc: 0.3500\n",
            "Epoch 12/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3652 - acc: 0.8816 \n",
            "Epoch 12: val_acc improved from 0.40714 to 0.48571, saving model to percobaan59_noImgPro/model\\vgg_16_59-saved-model-12-acc-0.49.hdf5\n",
            "4/4 [==============================] - 81s 22s/step - loss: 0.3652 - acc: 0.8816 - val_loss: 1.3919 - val_acc: 0.4857\n",
            "Epoch 13/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3968 - acc: 0.8673 \n",
            "Epoch 13: val_acc improved from 0.48571 to 0.55714, saving model to percobaan59_noImgPro/model\\vgg_16_59-saved-model-13-acc-0.56.hdf5\n",
            "4/4 [==============================] - 81s 22s/step - loss: 0.3968 - acc: 0.8673 - val_loss: 1.2736 - val_acc: 0.5571\n",
            "Epoch 14/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3325 - acc: 0.8878 \n",
            "Epoch 14: val_acc improved from 0.55714 to 0.61429, saving model to percobaan59_noImgPro/model\\vgg_16_59-saved-model-14-acc-0.61.hdf5\n",
            "4/4 [==============================] - 81s 21s/step - loss: 0.3325 - acc: 0.8878 - val_loss: 1.1524 - val_acc: 0.6143\n",
            "Epoch 15/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3550 - acc: 0.8714 \n",
            "Epoch 15: val_acc improved from 0.61429 to 0.62857, saving model to percobaan59_noImgPro/model\\vgg_16_59-saved-model-15-acc-0.63.hdf5\n",
            "4/4 [==============================] - 81s 21s/step - loss: 0.3550 - acc: 0.8714 - val_loss: 0.9837 - val_acc: 0.6286\n",
            "Epoch 16/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3140 - acc: 0.8878 \n",
            "Epoch 16: val_acc improved from 0.62857 to 0.67143, saving model to percobaan59_noImgPro/model\\vgg_16_59-saved-model-16-acc-0.67.hdf5\n",
            "4/4 [==============================] - 80s 22s/step - loss: 0.3140 - acc: 0.8878 - val_loss: 0.9037 - val_acc: 0.6714\n",
            "Epoch 17/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2665 - acc: 0.9102 \n",
            "Epoch 17: val_acc did not improve from 0.67143\n",
            "4/4 [==============================] - 81s 21s/step - loss: 0.2665 - acc: 0.9102 - val_loss: 0.9330 - val_acc: 0.6643\n",
            "Epoch 18/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2342 - acc: 0.9204 \n",
            "Epoch 18: val_acc did not improve from 0.67143\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.2342 - acc: 0.9204 - val_loss: 0.9463 - val_acc: 0.6429\n",
            "Epoch 19/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2380 - acc: 0.9143 \n",
            "Epoch 19: val_acc did not improve from 0.67143\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.2380 - acc: 0.9143 - val_loss: 0.9672 - val_acc: 0.6643\n",
            "Epoch 20/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2526 - acc: 0.9163 \n",
            "Epoch 20: val_acc improved from 0.67143 to 0.67857, saving model to percobaan59_noImgPro/model\\vgg_16_59-saved-model-20-acc-0.68.hdf5\n",
            "4/4 [==============================] - 81s 21s/step - loss: 0.2526 - acc: 0.9163 - val_loss: 0.8996 - val_acc: 0.6786\n",
            "Epoch 21/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2413 - acc: 0.9102 \n",
            "Epoch 21: val_acc improved from 0.67857 to 0.68571, saving model to percobaan59_noImgPro/model\\vgg_16_59-saved-model-21-acc-0.69.hdf5\n",
            "4/4 [==============================] - 81s 21s/step - loss: 0.2413 - acc: 0.9102 - val_loss: 0.8556 - val_acc: 0.6857\n",
            "Epoch 22/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2146 - acc: 0.9184 \n",
            "Epoch 22: val_acc improved from 0.68571 to 0.71429, saving model to percobaan59_noImgPro/model\\vgg_16_59-saved-model-22-acc-0.71.hdf5\n",
            "4/4 [==============================] - 82s 23s/step - loss: 0.2146 - acc: 0.9184 - val_loss: 0.8178 - val_acc: 0.7143\n",
            "Epoch 23/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2072 - acc: 0.9265 \n",
            "Epoch 23: val_acc did not improve from 0.71429\n",
            "4/4 [==============================] - 80s 22s/step - loss: 0.2072 - acc: 0.9265 - val_loss: 0.8448 - val_acc: 0.6857\n",
            "Epoch 24/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1252 - acc: 0.9571 \n",
            "Epoch 24: val_acc did not improve from 0.71429\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.1252 - acc: 0.9571 - val_loss: 0.9045 - val_acc: 0.6929\n",
            "Epoch 25/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1946 - acc: 0.9245 \n",
            "Epoch 25: val_acc did not improve from 0.71429\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.1946 - acc: 0.9245 - val_loss: 0.9489 - val_acc: 0.6857\n",
            "Epoch 26/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2057 - acc: 0.9286 \n",
            "Epoch 26: val_acc did not improve from 0.71429\n",
            "4/4 [==============================] - 81s 21s/step - loss: 0.2057 - acc: 0.9286 - val_loss: 1.0397 - val_acc: 0.6643\n",
            "Epoch 27/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1554 - acc: 0.9592 \n",
            "Epoch 27: val_acc did not improve from 0.71429\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.1554 - acc: 0.9592 - val_loss: 1.0777 - val_acc: 0.6571\n",
            "\n",
            "\n",
            "Model Accuracy 0.5428571428571428\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.40      0.57        10\n",
            "       10000       0.53      0.90      0.67        10\n",
            "      100000       1.00      0.20      0.33        10\n",
            "        2000       1.00      0.30      0.46        10\n",
            "       20000       0.38      0.80      0.52        10\n",
            "        5000       0.60      0.30      0.40        10\n",
            "       50000       0.50      0.90      0.64        10\n",
            "\n",
            "    accuracy                           0.54        70\n",
            "   macro avg       0.72      0.54      0.51        70\n",
            "weighted avg       0.72      0.54      0.51        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 60 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 47\n",
            "learning rate: 0.021330490948967468\n",
            "batch size: 128\n",
            "dropout rate: 0.7455138225975613\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 3.0912 - acc: 0.2796 \n",
            "Epoch 1: val_acc improved from -inf to 0.20000, saving model to percobaan60_noImgPro/model\\vgg_16_60-saved-model-01-acc-0.20.hdf5\n",
            "4/4 [==============================] - 81s 21s/step - loss: 3.0912 - acc: 0.2796 - val_loss: 3.1322 - val_acc: 0.2000\n",
            "Epoch 2/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.7876 - acc: 0.4449 \n",
            "Epoch 2: val_acc did not improve from 0.20000\n",
            "4/4 [==============================] - 80s 22s/step - loss: 1.7876 - acc: 0.4449 - val_loss: 4.2065 - val_acc: 0.1857\n",
            "Epoch 3/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.4855 - acc: 0.5000 \n",
            "Epoch 3: val_acc improved from 0.20000 to 0.20714, saving model to percobaan60_noImgPro/model\\vgg_16_60-saved-model-03-acc-0.21.hdf5\n",
            "4/4 [==============================] - 80s 21s/step - loss: 1.4855 - acc: 0.5000 - val_loss: 3.0575 - val_acc: 0.2071\n",
            "Epoch 4/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1842 - acc: 0.5939 \n",
            "Epoch 4: val_acc did not improve from 0.20714\n",
            "4/4 [==============================] - 80s 22s/step - loss: 1.1842 - acc: 0.5939 - val_loss: 3.5938 - val_acc: 0.1643\n",
            "Epoch 5/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1233 - acc: 0.6020 \n",
            "Epoch 5: val_acc did not improve from 0.20714\n",
            "4/4 [==============================] - 80s 22s/step - loss: 1.1233 - acc: 0.6020 - val_loss: 2.8538 - val_acc: 0.2071\n",
            "Epoch 6/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9966 - acc: 0.6755 \n",
            "Epoch 6: val_acc improved from 0.20714 to 0.29286, saving model to percobaan60_noImgPro/model\\vgg_16_60-saved-model-06-acc-0.29.hdf5\n",
            "4/4 [==============================] - 80s 22s/step - loss: 0.9966 - acc: 0.6755 - val_loss: 2.5195 - val_acc: 0.2929\n",
            "Epoch 7/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8773 - acc: 0.6755 \n",
            "Epoch 7: val_acc improved from 0.29286 to 0.33571, saving model to percobaan60_noImgPro/model\\vgg_16_60-saved-model-07-acc-0.34.hdf5\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.8773 - acc: 0.6755 - val_loss: 2.6296 - val_acc: 0.3357\n",
            "Epoch 8/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8532 - acc: 0.6816 \n",
            "Epoch 8: val_acc did not improve from 0.33571\n",
            "4/4 [==============================] - 80s 22s/step - loss: 0.8532 - acc: 0.6816 - val_loss: 2.7078 - val_acc: 0.3286\n",
            "Epoch 9/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7663 - acc: 0.6980 \n",
            "Epoch 9: val_acc did not improve from 0.33571\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.7663 - acc: 0.6980 - val_loss: 2.9216 - val_acc: 0.2714\n",
            "Epoch 10/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7089 - acc: 0.7469 \n",
            "Epoch 10: val_acc did not improve from 0.33571\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.7089 - acc: 0.7469 - val_loss: 2.5443 - val_acc: 0.2643\n",
            "Epoch 11/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5849 - acc: 0.7980 \n",
            "Epoch 11: val_acc did not improve from 0.33571\n",
            "4/4 [==============================] - 81s 21s/step - loss: 0.5849 - acc: 0.7980 - val_loss: 2.1488 - val_acc: 0.3214\n",
            "Epoch 12/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7135 - acc: 0.7449 \n",
            "Epoch 12: val_acc improved from 0.33571 to 0.38571, saving model to percobaan60_noImgPro/model\\vgg_16_60-saved-model-12-acc-0.39.hdf5\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.7135 - acc: 0.7449 - val_loss: 1.8534 - val_acc: 0.3857\n",
            "Epoch 13/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5356 - acc: 0.8204 \n",
            "Epoch 13: val_acc improved from 0.38571 to 0.49286, saving model to percobaan60_noImgPro/model\\vgg_16_60-saved-model-13-acc-0.49.hdf5\n",
            "4/4 [==============================] - 81s 21s/step - loss: 0.5356 - acc: 0.8204 - val_loss: 1.5821 - val_acc: 0.4929\n",
            "Epoch 14/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5780 - acc: 0.7857 \n",
            "Epoch 14: val_acc improved from 0.49286 to 0.50714, saving model to percobaan60_noImgPro/model\\vgg_16_60-saved-model-14-acc-0.51.hdf5\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.5780 - acc: 0.7857 - val_loss: 1.5863 - val_acc: 0.5071\n",
            "Epoch 15/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4338 - acc: 0.8306 \n",
            "Epoch 15: val_acc improved from 0.50714 to 0.51429, saving model to percobaan60_noImgPro/model\\vgg_16_60-saved-model-15-acc-0.51.hdf5\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.4338 - acc: 0.8306 - val_loss: 1.3902 - val_acc: 0.5143\n",
            "Epoch 16/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4389 - acc: 0.8367 \n",
            "Epoch 16: val_acc improved from 0.51429 to 0.56429, saving model to percobaan60_noImgPro/model\\vgg_16_60-saved-model-16-acc-0.56.hdf5\n",
            "4/4 [==============================] - 81s 22s/step - loss: 0.4389 - acc: 0.8367 - val_loss: 1.1969 - val_acc: 0.5643\n",
            "Epoch 17/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4145 - acc: 0.8571 \n",
            "Epoch 17: val_acc improved from 0.56429 to 0.65714, saving model to percobaan60_noImgPro/model\\vgg_16_60-saved-model-17-acc-0.66.hdf5\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.4145 - acc: 0.8571 - val_loss: 0.9656 - val_acc: 0.6571\n",
            "Epoch 18/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4151 - acc: 0.8551 \n",
            "Epoch 18: val_acc improved from 0.65714 to 0.66429, saving model to percobaan60_noImgPro/model\\vgg_16_60-saved-model-18-acc-0.66.hdf5\n",
            "4/4 [==============================] - 81s 21s/step - loss: 0.4151 - acc: 0.8551 - val_loss: 0.8882 - val_acc: 0.6643\n",
            "Epoch 19/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3609 - acc: 0.8837 \n",
            "Epoch 19: val_acc improved from 0.66429 to 0.70714, saving model to percobaan60_noImgPro/model\\vgg_16_60-saved-model-19-acc-0.71.hdf5\n",
            "4/4 [==============================] - 81s 21s/step - loss: 0.3609 - acc: 0.8837 - val_loss: 0.8568 - val_acc: 0.7071\n",
            "Epoch 20/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3739 - acc: 0.8633 \n",
            "Epoch 20: val_acc improved from 0.70714 to 0.72857, saving model to percobaan60_noImgPro/model\\vgg_16_60-saved-model-20-acc-0.73.hdf5\n",
            "4/4 [==============================] - 81s 21s/step - loss: 0.3739 - acc: 0.8633 - val_loss: 0.8513 - val_acc: 0.7286\n",
            "Epoch 21/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3432 - acc: 0.8857 \n",
            "Epoch 21: val_acc improved from 0.72857 to 0.73571, saving model to percobaan60_noImgPro/model\\vgg_16_60-saved-model-21-acc-0.74.hdf5\n",
            "4/4 [==============================] - 81s 21s/step - loss: 0.3432 - acc: 0.8857 - val_loss: 0.8714 - val_acc: 0.7357\n",
            "Epoch 22/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4012 - acc: 0.8612 \n",
            "Epoch 22: val_acc did not improve from 0.73571\n",
            "4/4 [==============================] - 81s 21s/step - loss: 0.4012 - acc: 0.8612 - val_loss: 0.9091 - val_acc: 0.7000\n",
            "Epoch 23/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3060 - acc: 0.8959 \n",
            "Epoch 23: val_acc did not improve from 0.73571\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.3060 - acc: 0.8959 - val_loss: 0.9611 - val_acc: 0.6571\n",
            "Epoch 24/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2458 - acc: 0.9143 \n",
            "Epoch 24: val_acc did not improve from 0.73571\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.2458 - acc: 0.9143 - val_loss: 1.0341 - val_acc: 0.6357\n",
            "Epoch 25/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3170 - acc: 0.8898 \n",
            "Epoch 25: val_acc did not improve from 0.73571\n",
            "4/4 [==============================] - 80s 21s/step - loss: 0.3170 - acc: 0.8898 - val_loss: 1.0897 - val_acc: 0.6714\n",
            "\n",
            "\n",
            "Model Accuracy 0.5857142857142857\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.69      0.90      0.78        10\n",
            "       10000       1.00      0.30      0.46        10\n",
            "      100000       1.00      0.10      0.18        10\n",
            "        2000       1.00      0.60      0.75        10\n",
            "       20000       0.31      0.80      0.44        10\n",
            "        5000       0.67      0.60      0.63        10\n",
            "       50000       0.67      0.80      0.73        10\n",
            "\n",
            "    accuracy                           0.59        70\n",
            "   macro avg       0.76      0.59      0.57        70\n",
            "weighted avg       0.76      0.59      0.57        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 61 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 47\n",
            "learning rate: 0.0324025732241223\n",
            "batch size: 32\n",
            "dropout rate: 0.5323155063415097\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.2780 - acc: 0.3347\n",
            "Epoch 1: val_acc improved from -inf to 0.20714, saving model to percobaan61_noImgPro/model\\vgg_16_61-saved-model-01-acc-0.21.hdf5\n",
            "16/16 [==============================] - 81s 5s/step - loss: 2.2780 - acc: 0.3347 - val_loss: 9.1378 - val_acc: 0.2071\n",
            "Epoch 2/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3823 - acc: 0.5449\n",
            "Epoch 2: val_acc improved from 0.20714 to 0.31429, saving model to percobaan61_noImgPro/model\\vgg_16_61-saved-model-02-acc-0.31.hdf5\n",
            "16/16 [==============================] - 80s 5s/step - loss: 1.3823 - acc: 0.5449 - val_loss: 4.3499 - val_acc: 0.3143\n",
            "Epoch 3/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9943 - acc: 0.6592\n",
            "Epoch 3: val_acc improved from 0.31429 to 0.37143, saving model to percobaan61_noImgPro/model\\vgg_16_61-saved-model-03-acc-0.37.hdf5\n",
            "16/16 [==============================] - 80s 5s/step - loss: 0.9943 - acc: 0.6592 - val_loss: 2.1201 - val_acc: 0.3714\n",
            "Epoch 4/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9132 - acc: 0.7000\n",
            "Epoch 4: val_acc improved from 0.37143 to 0.52857, saving model to percobaan61_noImgPro/model\\vgg_16_61-saved-model-04-acc-0.53.hdf5\n",
            "16/16 [==============================] - 81s 5s/step - loss: 0.9132 - acc: 0.7000 - val_loss: 1.6196 - val_acc: 0.5286\n",
            "Epoch 5/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6116 - acc: 0.7694\n",
            "Epoch 5: val_acc improved from 0.52857 to 0.72143, saving model to percobaan61_noImgPro/model\\vgg_16_61-saved-model-05-acc-0.72.hdf5\n",
            "16/16 [==============================] - 80s 5s/step - loss: 0.6116 - acc: 0.7694 - val_loss: 0.9196 - val_acc: 0.7214\n",
            "Epoch 6/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6338 - acc: 0.8082\n",
            "Epoch 6: val_acc did not improve from 0.72143\n",
            "16/16 [==============================] - 80s 5s/step - loss: 0.6338 - acc: 0.8082 - val_loss: 1.0706 - val_acc: 0.6643\n",
            "Epoch 7/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5213 - acc: 0.8163\n",
            "Epoch 7: val_acc did not improve from 0.72143\n",
            "16/16 [==============================] - 80s 5s/step - loss: 0.5213 - acc: 0.8163 - val_loss: 1.2139 - val_acc: 0.5786\n",
            "Epoch 8/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4770 - acc: 0.8265\n",
            "Epoch 8: val_acc did not improve from 0.72143\n",
            "16/16 [==============================] - 80s 5s/step - loss: 0.4770 - acc: 0.8265 - val_loss: 1.5629 - val_acc: 0.4714\n",
            "Epoch 9/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4380 - acc: 0.8551\n",
            "Epoch 9: val_acc improved from 0.72143 to 0.78571, saving model to percobaan61_noImgPro/model\\vgg_16_61-saved-model-09-acc-0.79.hdf5\n",
            "16/16 [==============================] - 80s 5s/step - loss: 0.4380 - acc: 0.8551 - val_loss: 0.7962 - val_acc: 0.7857\n",
            "Epoch 10/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4826 - acc: 0.8327\n",
            "Epoch 10: val_acc improved from 0.78571 to 0.81429, saving model to percobaan61_noImgPro/model\\vgg_16_61-saved-model-10-acc-0.81.hdf5\n",
            "16/16 [==============================] - 81s 5s/step - loss: 0.4826 - acc: 0.8327 - val_loss: 0.7009 - val_acc: 0.8143\n",
            "Epoch 11/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5120 - acc: 0.8327\n",
            "Epoch 11: val_acc did not improve from 0.81429\n",
            "16/16 [==============================] - 81s 5s/step - loss: 0.5120 - acc: 0.8327 - val_loss: 0.8853 - val_acc: 0.7500\n",
            "Epoch 12/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4451 - acc: 0.8449\n",
            "Epoch 12: val_acc did not improve from 0.81429\n",
            "16/16 [==============================] - 85s 5s/step - loss: 0.4451 - acc: 0.8449 - val_loss: 0.8655 - val_acc: 0.7500\n",
            "Epoch 13/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5234 - acc: 0.8429\n",
            "Epoch 13: val_acc did not improve from 0.81429\n",
            "16/16 [==============================] - 91s 6s/step - loss: 0.5234 - acc: 0.8429 - val_loss: 1.2675 - val_acc: 0.6714\n",
            "Epoch 14/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6112 - acc: 0.7939\n",
            "Epoch 14: val_acc did not improve from 0.81429\n",
            "16/16 [==============================] - 88s 5s/step - loss: 0.6112 - acc: 0.7939 - val_loss: 0.6640 - val_acc: 0.7929\n",
            "Epoch 15/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5429 - acc: 0.8082\n",
            "Epoch 15: val_acc did not improve from 0.81429\n",
            "16/16 [==============================] - 89s 6s/step - loss: 0.5429 - acc: 0.8082 - val_loss: 1.0797 - val_acc: 0.7286\n",
            "Epoch 16/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4446 - acc: 0.8510\n",
            "Epoch 16: val_acc did not improve from 0.81429\n",
            "16/16 [==============================] - 87s 5s/step - loss: 0.4446 - acc: 0.8510 - val_loss: 1.5480 - val_acc: 0.6857\n",
            "Epoch 17/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3494 - acc: 0.8592\n",
            "Epoch 17: val_acc did not improve from 0.81429\n",
            "16/16 [==============================] - 86s 5s/step - loss: 0.3494 - acc: 0.8592 - val_loss: 0.9551 - val_acc: 0.7429\n",
            "Epoch 18/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5220 - acc: 0.8286\n",
            "Epoch 18: val_acc did not improve from 0.81429\n",
            "16/16 [==============================] - 83s 5s/step - loss: 0.5220 - acc: 0.8286 - val_loss: 1.0616 - val_acc: 0.7286\n",
            "Epoch 19/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4067 - acc: 0.8837\n",
            "Epoch 19: val_acc improved from 0.81429 to 0.83571, saving model to percobaan61_noImgPro/model\\vgg_16_61-saved-model-19-acc-0.84.hdf5\n",
            "16/16 [==============================] - 84s 5s/step - loss: 0.4067 - acc: 0.8837 - val_loss: 0.6717 - val_acc: 0.8357\n",
            "\n",
            "\n",
            "Model Accuracy 0.8285714285714286\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.89      0.80      0.84        10\n",
            "       10000       0.90      0.90      0.90        10\n",
            "      100000       1.00      0.90      0.95        10\n",
            "        2000       0.67      1.00      0.80        10\n",
            "       20000       0.64      0.70      0.67        10\n",
            "        5000       1.00      1.00      1.00        10\n",
            "       50000       0.83      0.50      0.62        10\n",
            "\n",
            "    accuracy                           0.83        70\n",
            "   macro avg       0.85      0.83      0.83        70\n",
            "weighted avg       0.85      0.83      0.83        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 62 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 43\n",
            "learning rate: 0.0419174788877968\n",
            "batch size: 32\n",
            "dropout rate: 0.5950615290337063\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.9209 - acc: 0.2878\n",
            "Epoch 1: val_acc improved from -inf to 0.28571, saving model to percobaan62_noImgPro/model\\vgg_16_62-saved-model-01-acc-0.29.hdf5\n",
            "16/16 [==============================] - 91s 6s/step - loss: 2.9209 - acc: 0.2878 - val_loss: 5.3152 - val_acc: 0.2857\n",
            "Epoch 2/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.8966 - acc: 0.4184\n",
            "Epoch 2: val_acc improved from 0.28571 to 0.30000, saving model to percobaan62_noImgPro/model\\vgg_16_62-saved-model-02-acc-0.30.hdf5\n",
            "16/16 [==============================] - 89s 6s/step - loss: 1.8966 - acc: 0.4184 - val_loss: 2.1220 - val_acc: 0.3000\n",
            "Epoch 3/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3812 - acc: 0.5531\n",
            "Epoch 3: val_acc improved from 0.30000 to 0.32857, saving model to percobaan62_noImgPro/model\\vgg_16_62-saved-model-03-acc-0.33.hdf5\n",
            "16/16 [==============================] - 89s 6s/step - loss: 1.3812 - acc: 0.5531 - val_loss: 2.4140 - val_acc: 0.3286\n",
            "Epoch 4/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9991 - acc: 0.6612\n",
            "Epoch 4: val_acc improved from 0.32857 to 0.42857, saving model to percobaan62_noImgPro/model\\vgg_16_62-saved-model-04-acc-0.43.hdf5\n",
            "16/16 [==============================] - 93s 6s/step - loss: 0.9991 - acc: 0.6612 - val_loss: 1.8755 - val_acc: 0.4286\n",
            "Epoch 5/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9498 - acc: 0.6653\n",
            "Epoch 5: val_acc improved from 0.42857 to 0.55714, saving model to percobaan62_noImgPro/model\\vgg_16_62-saved-model-05-acc-0.56.hdf5\n",
            "16/16 [==============================] - 88s 6s/step - loss: 0.9498 - acc: 0.6653 - val_loss: 1.3399 - val_acc: 0.5571\n",
            "Epoch 6/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8743 - acc: 0.6796\n",
            "Epoch 6: val_acc did not improve from 0.55714\n",
            "16/16 [==============================] - 88s 6s/step - loss: 0.8743 - acc: 0.6796 - val_loss: 1.2295 - val_acc: 0.5357\n",
            "Epoch 7/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6909 - acc: 0.7735\n",
            "Epoch 7: val_acc improved from 0.55714 to 0.58571, saving model to percobaan62_noImgPro/model\\vgg_16_62-saved-model-07-acc-0.59.hdf5\n",
            "16/16 [==============================] - 89s 6s/step - loss: 0.6909 - acc: 0.7735 - val_loss: 1.2480 - val_acc: 0.5857\n",
            "Epoch 8/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7386 - acc: 0.7490\n",
            "Epoch 8: val_acc improved from 0.58571 to 0.74286, saving model to percobaan62_noImgPro/model\\vgg_16_62-saved-model-08-acc-0.74.hdf5\n",
            "16/16 [==============================] - 88s 6s/step - loss: 0.7386 - acc: 0.7490 - val_loss: 0.7322 - val_acc: 0.7429\n",
            "Epoch 9/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6918 - acc: 0.7714\n",
            "Epoch 9: val_acc did not improve from 0.74286\n",
            "16/16 [==============================] - 88s 6s/step - loss: 0.6918 - acc: 0.7714 - val_loss: 0.8534 - val_acc: 0.7143\n",
            "Epoch 10/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7518 - acc: 0.7633\n",
            "Epoch 10: val_acc did not improve from 0.74286\n",
            "16/16 [==============================] - 89s 6s/step - loss: 0.7518 - acc: 0.7633 - val_loss: 1.7986 - val_acc: 0.5286\n",
            "Epoch 11/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5549 - acc: 0.8184\n",
            "Epoch 11: val_acc did not improve from 0.74286\n",
            "16/16 [==============================] - 88s 6s/step - loss: 0.5549 - acc: 0.8184 - val_loss: 0.7864 - val_acc: 0.7357\n",
            "Epoch 12/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6663 - acc: 0.7837\n",
            "Epoch 12: val_acc did not improve from 0.74286\n",
            "16/16 [==============================] - 88s 6s/step - loss: 0.6663 - acc: 0.7837 - val_loss: 0.8834 - val_acc: 0.7357\n",
            "Epoch 13/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6082 - acc: 0.8143\n",
            "Epoch 13: val_acc did not improve from 0.74286\n",
            "16/16 [==============================] - 88s 6s/step - loss: 0.6082 - acc: 0.8143 - val_loss: 1.2602 - val_acc: 0.6500\n",
            "\n",
            "\n",
            "Model Accuracy 0.5714285714285714\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.30      0.46        10\n",
            "       10000       0.38      1.00      0.56        10\n",
            "      100000       1.00      0.40      0.57        10\n",
            "        2000       0.88      0.70      0.78        10\n",
            "       20000       0.00      0.00      0.00        10\n",
            "        5000       0.57      0.80      0.67        10\n",
            "       50000       0.53      0.80      0.64        10\n",
            "\n",
            "    accuracy                           0.57        70\n",
            "   macro avg       0.62      0.57      0.52        70\n",
            "weighted avg       0.62      0.57      0.52        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 63 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 47\n",
            "learning rate: 0.038412123460315806\n",
            "batch size: 32\n",
            "dropout rate: 0.6918322085659435\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 3.0066 - acc: 0.2510\n",
            "Epoch 1: val_acc improved from -inf to 0.15714, saving model to percobaan63_noImgPro/model\\vgg_16_63-saved-model-01-acc-0.16.hdf5\n",
            "16/16 [==============================] - 86s 5s/step - loss: 3.0066 - acc: 0.2510 - val_loss: 5.4002 - val_acc: 0.1571\n",
            "Epoch 2/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.0489 - acc: 0.3796\n",
            "Epoch 2: val_acc improved from 0.15714 to 0.22857, saving model to percobaan63_noImgPro/model\\vgg_16_63-saved-model-02-acc-0.23.hdf5\n",
            "16/16 [==============================] - 85s 5s/step - loss: 2.0489 - acc: 0.3796 - val_loss: 3.3928 - val_acc: 0.2286\n",
            "Epoch 3/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.5221 - acc: 0.5102\n",
            "Epoch 3: val_acc improved from 0.22857 to 0.36429, saving model to percobaan63_noImgPro/model\\vgg_16_63-saved-model-03-acc-0.36.hdf5\n",
            "16/16 [==============================] - 85s 5s/step - loss: 1.5221 - acc: 0.5102 - val_loss: 2.1087 - val_acc: 0.3643\n",
            "Epoch 4/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3918 - acc: 0.5408\n",
            "Epoch 4: val_acc did not improve from 0.36429\n",
            "16/16 [==============================] - 85s 5s/step - loss: 1.3918 - acc: 0.5408 - val_loss: 1.8646 - val_acc: 0.3429\n",
            "Epoch 5/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2556 - acc: 0.5837\n",
            "Epoch 5: val_acc improved from 0.36429 to 0.50000, saving model to percobaan63_noImgPro/model\\vgg_16_63-saved-model-05-acc-0.50.hdf5\n",
            "16/16 [==============================] - 85s 5s/step - loss: 1.2556 - acc: 0.5837 - val_loss: 1.6167 - val_acc: 0.5000\n",
            "Epoch 6/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9951 - acc: 0.6327\n",
            "Epoch 6: val_acc did not improve from 0.50000\n",
            "16/16 [==============================] - 85s 5s/step - loss: 0.9951 - acc: 0.6327 - val_loss: 1.6272 - val_acc: 0.5000\n",
            "Epoch 7/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8457 - acc: 0.7082\n",
            "Epoch 7: val_acc improved from 0.50000 to 0.55714, saving model to percobaan63_noImgPro/model\\vgg_16_63-saved-model-07-acc-0.56.hdf5\n",
            "16/16 [==============================] - 85s 5s/step - loss: 0.8457 - acc: 0.7082 - val_loss: 1.3277 - val_acc: 0.5571\n",
            "Epoch 8/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8688 - acc: 0.6939\n",
            "Epoch 8: val_acc improved from 0.55714 to 0.59286, saving model to percobaan63_noImgPro/model\\vgg_16_63-saved-model-08-acc-0.59.hdf5\n",
            "16/16 [==============================] - 85s 5s/step - loss: 0.8688 - acc: 0.6939 - val_loss: 1.1715 - val_acc: 0.5929\n",
            "Epoch 9/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8002 - acc: 0.7265\n",
            "Epoch 9: val_acc improved from 0.59286 to 0.71429, saving model to percobaan63_noImgPro/model\\vgg_16_63-saved-model-09-acc-0.71.hdf5\n",
            "16/16 [==============================] - 85s 5s/step - loss: 0.8002 - acc: 0.7265 - val_loss: 0.8802 - val_acc: 0.7143\n",
            "Epoch 10/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8601 - acc: 0.7041\n",
            "Epoch 10: val_acc did not improve from 0.71429\n",
            "16/16 [==============================] - 91s 6s/step - loss: 0.8601 - acc: 0.7041 - val_loss: 1.2037 - val_acc: 0.5786\n",
            "Epoch 11/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9046 - acc: 0.6878\n",
            "Epoch 11: val_acc did not improve from 0.71429\n",
            "16/16 [==============================] - 102s 7s/step - loss: 0.9046 - acc: 0.6878 - val_loss: 1.1088 - val_acc: 0.6571\n",
            "Epoch 12/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7364 - acc: 0.7286\n",
            "Epoch 12: val_acc improved from 0.71429 to 0.72143, saving model to percobaan63_noImgPro/model\\vgg_16_63-saved-model-12-acc-0.72.hdf5\n",
            "16/16 [==============================] - 99s 6s/step - loss: 0.7364 - acc: 0.7286 - val_loss: 0.8392 - val_acc: 0.7214\n",
            "Epoch 13/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7538 - acc: 0.7633\n",
            "Epoch 13: val_acc improved from 0.72143 to 0.72857, saving model to percobaan63_noImgPro/model\\vgg_16_63-saved-model-13-acc-0.73.hdf5\n",
            "16/16 [==============================] - 99s 6s/step - loss: 0.7538 - acc: 0.7633 - val_loss: 0.8545 - val_acc: 0.7286\n",
            "Epoch 14/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7456 - acc: 0.7735\n",
            "Epoch 14: val_acc improved from 0.72857 to 0.80714, saving model to percobaan63_noImgPro/model\\vgg_16_63-saved-model-14-acc-0.81.hdf5\n",
            "16/16 [==============================] - 104s 7s/step - loss: 0.7456 - acc: 0.7735 - val_loss: 0.7487 - val_acc: 0.8071\n",
            "Epoch 15/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7311 - acc: 0.7531\n",
            "Epoch 15: val_acc improved from 0.80714 to 0.81429, saving model to percobaan63_noImgPro/model\\vgg_16_63-saved-model-15-acc-0.81.hdf5\n",
            "16/16 [==============================] - 88s 6s/step - loss: 0.7311 - acc: 0.7531 - val_loss: 0.6313 - val_acc: 0.8143\n",
            "Epoch 16/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5628 - acc: 0.8102\n",
            "Epoch 16: val_acc improved from 0.81429 to 0.83571, saving model to percobaan63_noImgPro/model\\vgg_16_63-saved-model-16-acc-0.84.hdf5\n",
            "16/16 [==============================] - 86s 6s/step - loss: 0.5628 - acc: 0.8102 - val_loss: 0.5939 - val_acc: 0.8357\n",
            "Epoch 17/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7289 - acc: 0.7755\n",
            "Epoch 17: val_acc improved from 0.83571 to 0.84286, saving model to percobaan63_noImgPro/model\\vgg_16_63-saved-model-17-acc-0.84.hdf5\n",
            "16/16 [==============================] - 86s 5s/step - loss: 0.7289 - acc: 0.7755 - val_loss: 0.5865 - val_acc: 0.8429\n",
            "Epoch 18/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5835 - acc: 0.7837\n",
            "Epoch 18: val_acc did not improve from 0.84286\n",
            "16/16 [==============================] - 86s 5s/step - loss: 0.5835 - acc: 0.7837 - val_loss: 0.6025 - val_acc: 0.8357\n",
            "Epoch 19/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7035 - acc: 0.7796\n",
            "Epoch 19: val_acc did not improve from 0.84286\n",
            "16/16 [==============================] - 86s 5s/step - loss: 0.7035 - acc: 0.7796 - val_loss: 0.7290 - val_acc: 0.8286\n",
            "Epoch 20/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6697 - acc: 0.7714\n",
            "Epoch 20: val_acc did not improve from 0.84286\n",
            "16/16 [==============================] - 86s 5s/step - loss: 0.6697 - acc: 0.7714 - val_loss: 0.6568 - val_acc: 0.8214\n",
            "Epoch 21/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6807 - acc: 0.7735\n",
            "Epoch 21: val_acc did not improve from 0.84286\n",
            "16/16 [==============================] - 86s 5s/step - loss: 0.6807 - acc: 0.7735 - val_loss: 0.8123 - val_acc: 0.7286\n",
            "Epoch 22/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6353 - acc: 0.7898\n",
            "Epoch 22: val_acc did not improve from 0.84286\n",
            "16/16 [==============================] - 86s 5s/step - loss: 0.6353 - acc: 0.7898 - val_loss: 0.8852 - val_acc: 0.7429\n",
            "\n",
            "\n",
            "Model Accuracy 0.7285714285714285\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.60      0.75        10\n",
            "       10000       0.83      1.00      0.91        10\n",
            "      100000       1.00      0.90      0.95        10\n",
            "        2000       0.50      1.00      0.67        10\n",
            "       20000       0.62      0.50      0.56        10\n",
            "        5000       1.00      0.20      0.33        10\n",
            "       50000       0.69      0.90      0.78        10\n",
            "\n",
            "    accuracy                           0.73        70\n",
            "   macro avg       0.81      0.73      0.71        70\n",
            "weighted avg       0.81      0.73      0.71        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 64 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 41\n",
            "learning rate: 0.04544342114611419\n",
            "batch size: 32\n",
            "dropout rate: 0.7345428784708925\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 3.6183 - acc: 0.2449\n",
            "Epoch 1: val_acc improved from -inf to 0.14286, saving model to percobaan64_noImgPro/model\\vgg_16_64-saved-model-01-acc-0.14.hdf5\n",
            "16/16 [==============================] - 84s 5s/step - loss: 3.6183 - acc: 0.2449 - val_loss: 7.2196 - val_acc: 0.1429\n",
            "Epoch 2/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.7898 - acc: 0.3286\n",
            "Epoch 2: val_acc improved from 0.14286 to 0.15000, saving model to percobaan64_noImgPro/model\\vgg_16_64-saved-model-02-acc-0.15.hdf5\n",
            "16/16 [==============================] - 83s 5s/step - loss: 2.7898 - acc: 0.3286 - val_loss: 3.9133 - val_acc: 0.1500\n",
            "Epoch 3/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.8694 - acc: 0.4245\n",
            "Epoch 3: val_acc improved from 0.15000 to 0.33571, saving model to percobaan64_noImgPro/model\\vgg_16_64-saved-model-03-acc-0.34.hdf5\n",
            "16/16 [==============================] - 83s 5s/step - loss: 1.8694 - acc: 0.4245 - val_loss: 1.7734 - val_acc: 0.3357\n",
            "Epoch 4/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.4858 - acc: 0.4857\n",
            "Epoch 4: val_acc improved from 0.33571 to 0.40000, saving model to percobaan64_noImgPro/model\\vgg_16_64-saved-model-04-acc-0.40.hdf5\n",
            "16/16 [==============================] - 83s 5s/step - loss: 1.4858 - acc: 0.4857 - val_loss: 1.8042 - val_acc: 0.4000\n",
            "Epoch 5/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2402 - acc: 0.5204\n",
            "Epoch 5: val_acc improved from 0.40000 to 0.48571, saving model to percobaan64_noImgPro/model\\vgg_16_64-saved-model-05-acc-0.49.hdf5\n",
            "16/16 [==============================] - 83s 5s/step - loss: 1.2402 - acc: 0.5204 - val_loss: 1.5827 - val_acc: 0.4857\n",
            "Epoch 6/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1268 - acc: 0.6184\n",
            "Epoch 6: val_acc improved from 0.48571 to 0.60000, saving model to percobaan64_noImgPro/model\\vgg_16_64-saved-model-06-acc-0.60.hdf5\n",
            "16/16 [==============================] - 83s 5s/step - loss: 1.1268 - acc: 0.6184 - val_loss: 1.6916 - val_acc: 0.6000\n",
            "Epoch 7/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0483 - acc: 0.5980\n",
            "Epoch 7: val_acc did not improve from 0.60000\n",
            "16/16 [==============================] - 84s 5s/step - loss: 1.0483 - acc: 0.5980 - val_loss: 1.4548 - val_acc: 0.5786\n",
            "Epoch 8/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0768 - acc: 0.6163\n",
            "Epoch 8: val_acc improved from 0.60000 to 0.75000, saving model to percobaan64_noImgPro/model\\vgg_16_64-saved-model-08-acc-0.75.hdf5\n",
            "16/16 [==============================] - 83s 5s/step - loss: 1.0768 - acc: 0.6163 - val_loss: 0.8503 - val_acc: 0.7500\n",
            "Epoch 9/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9772 - acc: 0.6429\n",
            "Epoch 9: val_acc did not improve from 0.75000\n",
            "16/16 [==============================] - 83s 5s/step - loss: 0.9772 - acc: 0.6429 - val_loss: 0.9240 - val_acc: 0.6857\n",
            "Epoch 10/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9698 - acc: 0.6755\n",
            "Epoch 10: val_acc improved from 0.75000 to 0.78571, saving model to percobaan64_noImgPro/model\\vgg_16_64-saved-model-10-acc-0.79.hdf5\n",
            "16/16 [==============================] - 83s 5s/step - loss: 0.9698 - acc: 0.6755 - val_loss: 0.8368 - val_acc: 0.7857\n",
            "Epoch 11/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8999 - acc: 0.7020\n",
            "Epoch 11: val_acc did not improve from 0.78571\n",
            "16/16 [==============================] - 83s 5s/step - loss: 0.8999 - acc: 0.7020 - val_loss: 0.8442 - val_acc: 0.7286\n",
            "Epoch 12/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9074 - acc: 0.6755\n",
            "Epoch 12: val_acc did not improve from 0.78571\n",
            "16/16 [==============================] - 83s 5s/step - loss: 0.9074 - acc: 0.6755 - val_loss: 1.1464 - val_acc: 0.6429\n",
            "Epoch 13/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7361 - acc: 0.7551\n",
            "Epoch 13: val_acc did not improve from 0.78571\n",
            "16/16 [==============================] - 83s 5s/step - loss: 0.7361 - acc: 0.7551 - val_loss: 1.0953 - val_acc: 0.6500\n",
            "Epoch 14/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7676 - acc: 0.7490\n",
            "Epoch 14: val_acc did not improve from 0.78571\n",
            "16/16 [==============================] - 83s 5s/step - loss: 0.7676 - acc: 0.7490 - val_loss: 1.1323 - val_acc: 0.6786\n",
            "Epoch 15/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8727 - acc: 0.7061\n",
            "Epoch 15: val_acc did not improve from 0.78571\n",
            "16/16 [==============================] - 83s 5s/step - loss: 0.8727 - acc: 0.7061 - val_loss: 1.1806 - val_acc: 0.6214\n",
            "\n",
            "\n",
            "Model Accuracy 0.6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.70      0.70      0.70        10\n",
            "       10000       0.62      1.00      0.77        10\n",
            "      100000       1.00      0.10      0.18        10\n",
            "        2000       0.59      1.00      0.74        10\n",
            "       20000       0.00      0.00      0.00        10\n",
            "        5000       0.45      1.00      0.62        10\n",
            "       50000       1.00      0.40      0.57        10\n",
            "\n",
            "    accuracy                           0.60        70\n",
            "   macro avg       0.62      0.60      0.51        70\n",
            "weighted avg       0.62      0.60      0.51        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 65 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 46\n",
            "learning rate: 0.03510578985599961\n",
            "batch size: 64\n",
            "dropout rate: 0.5400655375727882\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.3796 - acc: 0.3408\n",
            "Epoch 1: val_acc improved from -inf to 0.28571, saving model to percobaan65_noImgPro/model\\vgg_16_65-saved-model-01-acc-0.29.hdf5\n",
            "8/8 [==============================] - 82s 10s/step - loss: 2.3796 - acc: 0.3408 - val_loss: 6.3423 - val_acc: 0.2857\n",
            "Epoch 2/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4497 - acc: 0.5388\n",
            "Epoch 2: val_acc did not improve from 0.28571\n",
            "8/8 [==============================] - 81s 10s/step - loss: 1.4497 - acc: 0.5388 - val_loss: 5.0892 - val_acc: 0.2357\n",
            "Epoch 3/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9573 - acc: 0.6551\n",
            "Epoch 3: val_acc did not improve from 0.28571\n",
            "8/8 [==============================] - 81s 10s/step - loss: 0.9573 - acc: 0.6551 - val_loss: 5.3993 - val_acc: 0.2643\n",
            "Epoch 4/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7824 - acc: 0.7184\n",
            "Epoch 4: val_acc improved from 0.28571 to 0.42857, saving model to percobaan65_noImgPro/model\\vgg_16_65-saved-model-04-acc-0.43.hdf5\n",
            "8/8 [==============================] - 81s 11s/step - loss: 0.7824 - acc: 0.7184 - val_loss: 3.5220 - val_acc: 0.4286\n",
            "Epoch 5/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7155 - acc: 0.7735\n",
            "Epoch 5: val_acc improved from 0.42857 to 0.47143, saving model to percobaan65_noImgPro/model\\vgg_16_65-saved-model-05-acc-0.47.hdf5\n",
            "8/8 [==============================] - 81s 10s/step - loss: 0.7155 - acc: 0.7735 - val_loss: 2.6920 - val_acc: 0.4714\n",
            "Epoch 6/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6233 - acc: 0.7980\n",
            "Epoch 6: val_acc improved from 0.47143 to 0.53571, saving model to percobaan65_noImgPro/model\\vgg_16_65-saved-model-06-acc-0.54.hdf5\n",
            "8/8 [==============================] - 81s 10s/step - loss: 0.6233 - acc: 0.7980 - val_loss: 2.0670 - val_acc: 0.5357\n",
            "Epoch 7/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5234 - acc: 0.8020\n",
            "Epoch 7: val_acc did not improve from 0.53571\n",
            "8/8 [==============================] - 81s 10s/step - loss: 0.5234 - acc: 0.8020 - val_loss: 1.8775 - val_acc: 0.4786\n",
            "Epoch 8/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5020 - acc: 0.8224\n",
            "Epoch 8: val_acc did not improve from 0.53571\n",
            "8/8 [==============================] - 81s 10s/step - loss: 0.5020 - acc: 0.8224 - val_loss: 1.8933 - val_acc: 0.5071\n",
            "Epoch 9/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3771 - acc: 0.8816\n",
            "Epoch 9: val_acc did not improve from 0.53571\n",
            "8/8 [==============================] - 81s 10s/step - loss: 0.3771 - acc: 0.8816 - val_loss: 1.8781 - val_acc: 0.5214\n",
            "Epoch 10/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3730 - acc: 0.8673\n",
            "Epoch 10: val_acc improved from 0.53571 to 0.54286, saving model to percobaan65_noImgPro/model\\vgg_16_65-saved-model-10-acc-0.54.hdf5\n",
            "8/8 [==============================] - 81s 10s/step - loss: 0.3730 - acc: 0.8673 - val_loss: 1.6401 - val_acc: 0.5429\n",
            "Epoch 11/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3677 - acc: 0.8653\n",
            "Epoch 11: val_acc improved from 0.54286 to 0.59286, saving model to percobaan65_noImgPro/model\\vgg_16_65-saved-model-11-acc-0.59.hdf5\n",
            "8/8 [==============================] - 81s 10s/step - loss: 0.3677 - acc: 0.8653 - val_loss: 1.4220 - val_acc: 0.5929\n",
            "Epoch 12/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3417 - acc: 0.8755\n",
            "Epoch 12: val_acc improved from 0.59286 to 0.60000, saving model to percobaan65_noImgPro/model\\vgg_16_65-saved-model-12-acc-0.60.hdf5\n",
            "8/8 [==============================] - 81s 10s/step - loss: 0.3417 - acc: 0.8755 - val_loss: 1.3025 - val_acc: 0.6000\n",
            "Epoch 13/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2903 - acc: 0.9000\n",
            "Epoch 13: val_acc improved from 0.60000 to 0.62857, saving model to percobaan65_noImgPro/model\\vgg_16_65-saved-model-13-acc-0.63.hdf5\n",
            "8/8 [==============================] - 82s 10s/step - loss: 0.2903 - acc: 0.9000 - val_loss: 1.1852 - val_acc: 0.6286\n",
            "Epoch 14/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3505 - acc: 0.8714\n",
            "Epoch 14: val_acc did not improve from 0.62857\n",
            "8/8 [==============================] - 81s 10s/step - loss: 0.3505 - acc: 0.8714 - val_loss: 1.3262 - val_acc: 0.5857\n",
            "Epoch 15/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3013 - acc: 0.8898\n",
            "Epoch 15: val_acc did not improve from 0.62857\n",
            "8/8 [==============================] - 81s 11s/step - loss: 0.3013 - acc: 0.8898 - val_loss: 2.0198 - val_acc: 0.4429\n",
            "Epoch 16/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2887 - acc: 0.8816\n",
            "Epoch 16: val_acc did not improve from 0.62857\n",
            "8/8 [==============================] - 81s 10s/step - loss: 0.2887 - acc: 0.8816 - val_loss: 1.5106 - val_acc: 0.4857\n",
            "Epoch 17/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2291 - acc: 0.9286\n",
            "Epoch 17: val_acc improved from 0.62857 to 0.71429, saving model to percobaan65_noImgPro/model\\vgg_16_65-saved-model-17-acc-0.71.hdf5\n",
            "8/8 [==============================] - 81s 10s/step - loss: 0.2291 - acc: 0.9286 - val_loss: 0.8564 - val_acc: 0.7143\n",
            "Epoch 18/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2962 - acc: 0.8878\n",
            "Epoch 18: val_acc did not improve from 0.71429\n",
            "8/8 [==============================] - 82s 10s/step - loss: 0.2962 - acc: 0.8878 - val_loss: 1.0123 - val_acc: 0.6714\n",
            "Epoch 19/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2862 - acc: 0.8939\n",
            "Epoch 19: val_acc did not improve from 0.71429\n",
            "8/8 [==============================] - 81s 10s/step - loss: 0.2862 - acc: 0.8939 - val_loss: 1.4720 - val_acc: 0.5571\n",
            "Epoch 20/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2654 - acc: 0.9020\n",
            "Epoch 20: val_acc did not improve from 0.71429\n",
            "8/8 [==============================] - 81s 11s/step - loss: 0.2654 - acc: 0.9020 - val_loss: 1.7010 - val_acc: 0.5286\n",
            "Epoch 21/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2841 - acc: 0.9061\n",
            "Epoch 21: val_acc did not improve from 0.71429\n",
            "8/8 [==============================] - 81s 10s/step - loss: 0.2841 - acc: 0.9061 - val_loss: 1.3498 - val_acc: 0.5643\n",
            "Epoch 22/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3877 - acc: 0.8776\n",
            "Epoch 22: val_acc did not improve from 0.71429\n",
            "8/8 [==============================] - 81s 11s/step - loss: 0.3877 - acc: 0.8776 - val_loss: 1.1414 - val_acc: 0.6071\n",
            "\n",
            "\n",
            "Model Accuracy 0.5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.80      0.40      0.53        10\n",
            "       10000       1.00      0.80      0.89        10\n",
            "      100000       1.00      0.20      0.33        10\n",
            "        2000       0.62      0.50      0.56        10\n",
            "       20000       0.00      0.00      0.00        10\n",
            "        5000       0.75      0.60      0.67        10\n",
            "       50000       0.26      1.00      0.41        10\n",
            "\n",
            "    accuracy                           0.50        70\n",
            "   macro avg       0.63      0.50      0.48        70\n",
            "weighted avg       0.63      0.50      0.48        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 66 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 41\n",
            "learning rate: 0.025477405232305943\n",
            "batch size: 64\n",
            "dropout rate: 0.6475337603577649\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.4496 - acc: 0.3265\n",
            "Epoch 1: val_acc improved from -inf to 0.20000, saving model to percobaan66_noImgPro/model\\vgg_16_66-saved-model-01-acc-0.20.hdf5\n",
            "8/8 [==============================] - 82s 10s/step - loss: 2.4496 - acc: 0.3265 - val_loss: 6.0426 - val_acc: 0.2000\n",
            "Epoch 2/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5693 - acc: 0.4939\n",
            "Epoch 2: val_acc improved from 0.20000 to 0.32143, saving model to percobaan66_noImgPro/model\\vgg_16_66-saved-model-02-acc-0.32.hdf5\n",
            "8/8 [==============================] - 81s 10s/step - loss: 1.5693 - acc: 0.4939 - val_loss: 5.0719 - val_acc: 0.3214\n",
            "Epoch 3/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.2882 - acc: 0.5694\n",
            "Epoch 3: val_acc improved from 0.32143 to 0.37857, saving model to percobaan66_noImgPro/model\\vgg_16_66-saved-model-03-acc-0.38.hdf5\n",
            "8/8 [==============================] - 81s 10s/step - loss: 1.2882 - acc: 0.5694 - val_loss: 3.6847 - val_acc: 0.3786\n",
            "Epoch 4/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9510 - acc: 0.6551\n",
            "Epoch 4: val_acc improved from 0.37857 to 0.40714, saving model to percobaan66_noImgPro/model\\vgg_16_66-saved-model-04-acc-0.41.hdf5\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.9510 - acc: 0.6551 - val_loss: 3.0151 - val_acc: 0.4071\n",
            "Epoch 5/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8450 - acc: 0.7041\n",
            "Epoch 5: val_acc did not improve from 0.40714\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.8450 - acc: 0.7041 - val_loss: 2.2522 - val_acc: 0.4071\n",
            "Epoch 6/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7276 - acc: 0.7245\n",
            "Epoch 6: val_acc improved from 0.40714 to 0.42857, saving model to percobaan66_noImgPro/model\\vgg_16_66-saved-model-06-acc-0.43.hdf5\n",
            "8/8 [==============================] - 80s 11s/step - loss: 0.7276 - acc: 0.7245 - val_loss: 1.9229 - val_acc: 0.4286\n",
            "Epoch 7/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6130 - acc: 0.7796\n",
            "Epoch 7: val_acc improved from 0.42857 to 0.55714, saving model to percobaan66_noImgPro/model\\vgg_16_66-saved-model-07-acc-0.56.hdf5\n",
            "8/8 [==============================] - 81s 10s/step - loss: 0.6130 - acc: 0.7796 - val_loss: 1.6783 - val_acc: 0.5571\n",
            "Epoch 8/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5588 - acc: 0.8020\n",
            "Epoch 8: val_acc did not improve from 0.55714\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.5588 - acc: 0.8020 - val_loss: 1.6047 - val_acc: 0.5357\n",
            "Epoch 9/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4463 - acc: 0.8306\n",
            "Epoch 9: val_acc improved from 0.55714 to 0.57857, saving model to percobaan66_noImgPro/model\\vgg_16_66-saved-model-09-acc-0.58.hdf5\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.4463 - acc: 0.8306 - val_loss: 1.3279 - val_acc: 0.5786\n",
            "Epoch 10/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4322 - acc: 0.8531\n",
            "Epoch 10: val_acc improved from 0.57857 to 0.60000, saving model to percobaan66_noImgPro/model\\vgg_16_66-saved-model-10-acc-0.60.hdf5\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.4322 - acc: 0.8531 - val_loss: 1.1682 - val_acc: 0.6000\n",
            "Epoch 11/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4561 - acc: 0.8510\n",
            "Epoch 11: val_acc did not improve from 0.60000\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.4561 - acc: 0.8510 - val_loss: 1.5421 - val_acc: 0.4214\n",
            "Epoch 12/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3593 - acc: 0.8694\n",
            "Epoch 12: val_acc did not improve from 0.60000\n",
            "8/8 [==============================] - 80s 11s/step - loss: 0.3593 - acc: 0.8694 - val_loss: 1.4253 - val_acc: 0.4786\n",
            "Epoch 13/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3901 - acc: 0.8510\n",
            "Epoch 13: val_acc did not improve from 0.60000\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.3901 - acc: 0.8510 - val_loss: 1.2992 - val_acc: 0.5714\n",
            "Epoch 14/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3869 - acc: 0.8592\n",
            "Epoch 14: val_acc improved from 0.60000 to 0.67143, saving model to percobaan66_noImgPro/model\\vgg_16_66-saved-model-14-acc-0.67.hdf5\n",
            "8/8 [==============================] - 81s 10s/step - loss: 0.3869 - acc: 0.8592 - val_loss: 0.9081 - val_acc: 0.6714\n",
            "Epoch 15/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3668 - acc: 0.8816\n",
            "Epoch 15: val_acc improved from 0.67143 to 0.68571, saving model to percobaan66_noImgPro/model\\vgg_16_66-saved-model-15-acc-0.69.hdf5\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.3668 - acc: 0.8816 - val_loss: 0.8903 - val_acc: 0.6857\n",
            "Epoch 16/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4277 - acc: 0.8531\n",
            "Epoch 16: val_acc improved from 0.68571 to 0.72143, saving model to percobaan66_noImgPro/model\\vgg_16_66-saved-model-16-acc-0.72.hdf5\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.4277 - acc: 0.8531 - val_loss: 0.9249 - val_acc: 0.7214\n",
            "Epoch 17/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3365 - acc: 0.8796\n",
            "Epoch 17: val_acc did not improve from 0.72143\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.3365 - acc: 0.8796 - val_loss: 1.1952 - val_acc: 0.6786\n",
            "Epoch 18/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2581 - acc: 0.9306\n",
            "Epoch 18: val_acc did not improve from 0.72143\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.2581 - acc: 0.9306 - val_loss: 1.1798 - val_acc: 0.6286\n",
            "Epoch 19/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3480 - acc: 0.8837\n",
            "Epoch 19: val_acc did not improve from 0.72143\n",
            "8/8 [==============================] - 82s 10s/step - loss: 0.3480 - acc: 0.8837 - val_loss: 0.9768 - val_acc: 0.7071\n",
            "Epoch 20/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2775 - acc: 0.9020\n",
            "Epoch 20: val_acc did not improve from 0.72143\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.2775 - acc: 0.9020 - val_loss: 0.9957 - val_acc: 0.6714\n",
            "\n",
            "\n",
            "Model Accuracy 0.5571428571428572\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.60      0.75        10\n",
            "       10000       0.73      0.80      0.76        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.34      1.00      0.51        10\n",
            "       20000       0.58      0.70      0.64        10\n",
            "        5000       0.43      0.30      0.35        10\n",
            "       50000       1.00      0.50      0.67        10\n",
            "\n",
            "    accuracy                           0.56        70\n",
            "   macro avg       0.58      0.56      0.53        70\n",
            "weighted avg       0.58      0.56      0.53        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 67 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 45\n",
            "learning rate: 0.03221898468621499\n",
            "batch size: 64\n",
            "dropout rate: 0.6947811546867682\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.5375 - acc: 0.3286\n",
            "Epoch 1: val_acc improved from -inf to 0.18571, saving model to percobaan67_noImgPro/model\\vgg_16_67-saved-model-01-acc-0.19.hdf5\n",
            "8/8 [==============================] - 81s 10s/step - loss: 2.5375 - acc: 0.3286 - val_loss: 4.3188 - val_acc: 0.1857\n",
            "Epoch 2/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.0338 - acc: 0.3980\n",
            "Epoch 2: val_acc improved from 0.18571 to 0.23571, saving model to percobaan67_noImgPro/model\\vgg_16_67-saved-model-02-acc-0.24.hdf5\n",
            "8/8 [==============================] - 80s 10s/step - loss: 2.0338 - acc: 0.3980 - val_loss: 5.2298 - val_acc: 0.2357\n",
            "Epoch 3/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5307 - acc: 0.4918\n",
            "Epoch 3: val_acc improved from 0.23571 to 0.35000, saving model to percobaan67_noImgPro/model\\vgg_16_67-saved-model-03-acc-0.35.hdf5\n",
            "8/8 [==============================] - 80s 10s/step - loss: 1.5307 - acc: 0.4918 - val_loss: 2.7574 - val_acc: 0.3500\n",
            "Epoch 4/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1903 - acc: 0.5918\n",
            "Epoch 4: val_acc did not improve from 0.35000\n",
            "8/8 [==============================] - 80s 10s/step - loss: 1.1903 - acc: 0.5918 - val_loss: 3.5366 - val_acc: 0.2857\n",
            "Epoch 5/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0177 - acc: 0.6490\n",
            "Epoch 5: val_acc did not improve from 0.35000\n",
            "8/8 [==============================] - 80s 11s/step - loss: 1.0177 - acc: 0.6490 - val_loss: 2.2057 - val_acc: 0.2429\n",
            "Epoch 6/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9107 - acc: 0.6959\n",
            "Epoch 6: val_acc improved from 0.35000 to 0.37857, saving model to percobaan67_noImgPro/model\\vgg_16_67-saved-model-06-acc-0.38.hdf5\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.9107 - acc: 0.6959 - val_loss: 1.6557 - val_acc: 0.3786\n",
            "Epoch 7/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7769 - acc: 0.7265\n",
            "Epoch 7: val_acc improved from 0.37857 to 0.55714, saving model to percobaan67_noImgPro/model\\vgg_16_67-saved-model-07-acc-0.56.hdf5\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.7769 - acc: 0.7265 - val_loss: 1.2853 - val_acc: 0.5571\n",
            "Epoch 8/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6267 - acc: 0.7796\n",
            "Epoch 8: val_acc did not improve from 0.55714\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.6267 - acc: 0.7796 - val_loss: 1.3509 - val_acc: 0.4929\n",
            "Epoch 9/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6526 - acc: 0.7796\n",
            "Epoch 9: val_acc did not improve from 0.55714\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.6526 - acc: 0.7796 - val_loss: 1.4568 - val_acc: 0.5000\n",
            "Epoch 10/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6645 - acc: 0.7694\n",
            "Epoch 10: val_acc did not improve from 0.55714\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.6645 - acc: 0.7694 - val_loss: 1.3059 - val_acc: 0.5571\n",
            "Epoch 11/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6621 - acc: 0.7694\n",
            "Epoch 11: val_acc improved from 0.55714 to 0.56429, saving model to percobaan67_noImgPro/model\\vgg_16_67-saved-model-11-acc-0.56.hdf5\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.6621 - acc: 0.7694 - val_loss: 1.1828 - val_acc: 0.5643\n",
            "Epoch 12/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5947 - acc: 0.7939\n",
            "Epoch 12: val_acc improved from 0.56429 to 0.62857, saving model to percobaan67_noImgPro/model\\vgg_16_67-saved-model-12-acc-0.63.hdf5\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.5947 - acc: 0.7939 - val_loss: 1.1802 - val_acc: 0.6286\n",
            "Epoch 13/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4985 - acc: 0.8265\n",
            "Epoch 13: val_acc improved from 0.62857 to 0.64286, saving model to percobaan67_noImgPro/model\\vgg_16_67-saved-model-13-acc-0.64.hdf5\n",
            "8/8 [==============================] - 80s 11s/step - loss: 0.4985 - acc: 0.8265 - val_loss: 1.0354 - val_acc: 0.6429\n",
            "Epoch 14/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5236 - acc: 0.8224\n",
            "Epoch 14: val_acc improved from 0.64286 to 0.70000, saving model to percobaan67_noImgPro/model\\vgg_16_67-saved-model-14-acc-0.70.hdf5\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.5236 - acc: 0.8224 - val_loss: 0.8740 - val_acc: 0.7000\n",
            "Epoch 15/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4870 - acc: 0.8224\n",
            "Epoch 15: val_acc improved from 0.70000 to 0.72143, saving model to percobaan67_noImgPro/model\\vgg_16_67-saved-model-15-acc-0.72.hdf5\n",
            "8/8 [==============================] - 81s 10s/step - loss: 0.4870 - acc: 0.8224 - val_loss: 0.8155 - val_acc: 0.7214\n",
            "Epoch 16/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3825 - acc: 0.8551\n",
            "Epoch 16: val_acc did not improve from 0.72143\n",
            "8/8 [==============================] - 81s 10s/step - loss: 0.3825 - acc: 0.8551 - val_loss: 0.8752 - val_acc: 0.7214\n",
            "Epoch 17/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4034 - acc: 0.8510\n",
            "Epoch 17: val_acc did not improve from 0.72143\n",
            "8/8 [==============================] - 81s 10s/step - loss: 0.4034 - acc: 0.8510 - val_loss: 0.9949 - val_acc: 0.6786\n",
            "Epoch 18/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4307 - acc: 0.8633\n",
            "Epoch 18: val_acc improved from 0.72143 to 0.73571, saving model to percobaan67_noImgPro/model\\vgg_16_67-saved-model-18-acc-0.74.hdf5\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.4307 - acc: 0.8633 - val_loss: 0.7613 - val_acc: 0.7357\n",
            "Epoch 19/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3639 - acc: 0.8653\n",
            "Epoch 19: val_acc improved from 0.73571 to 0.77857, saving model to percobaan67_noImgPro/model\\vgg_16_67-saved-model-19-acc-0.78.hdf5\n",
            "8/8 [==============================] - 81s 11s/step - loss: 0.3639 - acc: 0.8653 - val_loss: 0.7279 - val_acc: 0.7786\n",
            "Epoch 20/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3860 - acc: 0.8653\n",
            "Epoch 20: val_acc did not improve from 0.77857\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.3860 - acc: 0.8653 - val_loss: 0.6973 - val_acc: 0.7714\n",
            "Epoch 21/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3804 - acc: 0.8653\n",
            "Epoch 21: val_acc did not improve from 0.77857\n",
            "8/8 [==============================] - 82s 10s/step - loss: 0.3804 - acc: 0.8653 - val_loss: 0.7737 - val_acc: 0.7571\n",
            "Epoch 22/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3991 - acc: 0.8714\n",
            "Epoch 22: val_acc did not improve from 0.77857\n",
            "8/8 [==============================] - 80s 11s/step - loss: 0.3991 - acc: 0.8714 - val_loss: 0.8011 - val_acc: 0.7571\n",
            "Epoch 23/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3186 - acc: 0.8878\n",
            "Epoch 23: val_acc improved from 0.77857 to 0.80714, saving model to percobaan67_noImgPro/model\\vgg_16_67-saved-model-23-acc-0.81.hdf5\n",
            "8/8 [==============================] - 81s 10s/step - loss: 0.3186 - acc: 0.8878 - val_loss: 0.6293 - val_acc: 0.8071\n",
            "Epoch 24/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3884 - acc: 0.8714\n",
            "Epoch 24: val_acc improved from 0.80714 to 0.85714, saving model to percobaan67_noImgPro/model\\vgg_16_67-saved-model-24-acc-0.86.hdf5\n",
            "8/8 [==============================] - 81s 10s/step - loss: 0.3884 - acc: 0.8714 - val_loss: 0.5676 - val_acc: 0.8571\n",
            "Epoch 25/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3981 - acc: 0.8776\n",
            "Epoch 25: val_acc did not improve from 0.85714\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.3981 - acc: 0.8776 - val_loss: 0.5654 - val_acc: 0.8429\n",
            "Epoch 26/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2976 - acc: 0.8837\n",
            "Epoch 26: val_acc did not improve from 0.85714\n",
            "8/8 [==============================] - 81s 10s/step - loss: 0.2976 - acc: 0.8837 - val_loss: 0.7965 - val_acc: 0.7857\n",
            "Epoch 27/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3945 - acc: 0.8755\n",
            "Epoch 27: val_acc did not improve from 0.85714\n",
            "8/8 [==============================] - 81s 10s/step - loss: 0.3945 - acc: 0.8755 - val_loss: 1.1252 - val_acc: 0.6786\n",
            "Epoch 28/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3386 - acc: 0.8796\n",
            "Epoch 28: val_acc did not improve from 0.85714\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.3386 - acc: 0.8796 - val_loss: 0.8891 - val_acc: 0.7429\n",
            "Epoch 29/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3419 - acc: 0.8980\n",
            "Epoch 29: val_acc did not improve from 0.85714\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.3419 - acc: 0.8980 - val_loss: 1.0519 - val_acc: 0.7214\n",
            "Epoch 30/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3464 - acc: 0.8796\n",
            "Epoch 30: val_acc did not improve from 0.85714\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.3464 - acc: 0.8796 - val_loss: 0.9228 - val_acc: 0.7714\n",
            "\n",
            "\n",
            "Model Accuracy 0.6857142857142857\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.67      0.20      0.31        10\n",
            "       10000       0.71      1.00      0.83        10\n",
            "      100000       1.00      0.40      0.57        10\n",
            "        2000       0.75      0.90      0.82        10\n",
            "       20000       1.00      0.30      0.46        10\n",
            "        5000       0.62      1.00      0.77        10\n",
            "       50000       0.56      1.00      0.71        10\n",
            "\n",
            "    accuracy                           0.69        70\n",
            "   macro avg       0.76      0.69      0.64        70\n",
            "weighted avg       0.76      0.69      0.64        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 68 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 46\n",
            "learning rate: 0.040936413959438\n",
            "batch size: 64\n",
            "dropout rate: 0.7741196298167221\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 3.4060 - acc: 0.2510\n",
            "Epoch 1: val_acc improved from -inf to 0.27143, saving model to percobaan68_noImgPro/model\\vgg_16_68-saved-model-01-acc-0.27.hdf5\n",
            "8/8 [==============================] - 81s 10s/step - loss: 3.4060 - acc: 0.2510 - val_loss: 6.7598 - val_acc: 0.2714\n",
            "Epoch 2/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.5057 - acc: 0.3245\n",
            "Epoch 2: val_acc did not improve from 0.27143\n",
            "8/8 [==============================] - 80s 10s/step - loss: 2.5057 - acc: 0.3245 - val_loss: 6.3570 - val_acc: 0.2214\n",
            "Epoch 3/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.1250 - acc: 0.3714\n",
            "Epoch 3: val_acc did not improve from 0.27143\n",
            "8/8 [==============================] - 80s 11s/step - loss: 2.1250 - acc: 0.3714 - val_loss: 4.3696 - val_acc: 0.2000\n",
            "Epoch 4/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6981 - acc: 0.4469\n",
            "Epoch 4: val_acc did not improve from 0.27143\n",
            "8/8 [==============================] - 80s 10s/step - loss: 1.6981 - acc: 0.4469 - val_loss: 4.1495 - val_acc: 0.1429\n",
            "Epoch 5/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5290 - acc: 0.4531\n",
            "Epoch 5: val_acc did not improve from 0.27143\n",
            "8/8 [==============================] - 80s 11s/step - loss: 1.5290 - acc: 0.4531 - val_loss: 3.2685 - val_acc: 0.2214\n",
            "Epoch 6/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3411 - acc: 0.5000\n",
            "Epoch 6: val_acc did not improve from 0.27143\n",
            "8/8 [==============================] - 79s 10s/step - loss: 1.3411 - acc: 0.5000 - val_loss: 3.2819 - val_acc: 0.2357\n",
            "Epoch 7/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1979 - acc: 0.5776\n",
            "Epoch 7: val_acc did not improve from 0.27143\n",
            "8/8 [==============================] - 80s 10s/step - loss: 1.1979 - acc: 0.5776 - val_loss: 2.6008 - val_acc: 0.2286\n",
            "Epoch 8/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1174 - acc: 0.5959\n",
            "Epoch 8: val_acc improved from 0.27143 to 0.40000, saving model to percobaan68_noImgPro/model\\vgg_16_68-saved-model-08-acc-0.40.hdf5\n",
            "8/8 [==============================] - 80s 10s/step - loss: 1.1174 - acc: 0.5959 - val_loss: 2.0293 - val_acc: 0.4000\n",
            "Epoch 9/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0776 - acc: 0.6163\n",
            "Epoch 9: val_acc did not improve from 0.40000\n",
            "8/8 [==============================] - 80s 11s/step - loss: 1.0776 - acc: 0.6163 - val_loss: 1.9442 - val_acc: 0.3929\n",
            "Epoch 10/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9355 - acc: 0.6776\n",
            "Epoch 10: val_acc improved from 0.40000 to 0.50000, saving model to percobaan68_noImgPro/model\\vgg_16_68-saved-model-10-acc-0.50.hdf5\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.9355 - acc: 0.6776 - val_loss: 1.5885 - val_acc: 0.5000\n",
            "Epoch 11/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8705 - acc: 0.6898\n",
            "Epoch 11: val_acc did not improve from 0.50000\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.8705 - acc: 0.6898 - val_loss: 1.8131 - val_acc: 0.4500\n",
            "Epoch 12/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9420 - acc: 0.6694\n",
            "Epoch 12: val_acc did not improve from 0.50000\n",
            "8/8 [==============================] - 80s 11s/step - loss: 0.9420 - acc: 0.6694 - val_loss: 1.8491 - val_acc: 0.4714\n",
            "Epoch 13/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8605 - acc: 0.6878\n",
            "Epoch 13: val_acc improved from 0.50000 to 0.57857, saving model to percobaan68_noImgPro/model\\vgg_16_68-saved-model-13-acc-0.58.hdf5\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.8605 - acc: 0.6878 - val_loss: 1.3456 - val_acc: 0.5786\n",
            "Epoch 14/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7250 - acc: 0.7551\n",
            "Epoch 14: val_acc did not improve from 0.57857\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.7250 - acc: 0.7551 - val_loss: 1.3031 - val_acc: 0.5500\n",
            "Epoch 15/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7624 - acc: 0.7327\n",
            "Epoch 15: val_acc improved from 0.57857 to 0.64286, saving model to percobaan68_noImgPro/model\\vgg_16_68-saved-model-15-acc-0.64.hdf5\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.7624 - acc: 0.7327 - val_loss: 1.0442 - val_acc: 0.6429\n",
            "Epoch 16/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7398 - acc: 0.7510\n",
            "Epoch 16: val_acc improved from 0.64286 to 0.76429, saving model to percobaan68_noImgPro/model\\vgg_16_68-saved-model-16-acc-0.76.hdf5\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.7398 - acc: 0.7510 - val_loss: 0.8555 - val_acc: 0.7643\n",
            "Epoch 17/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6977 - acc: 0.7551\n",
            "Epoch 17: val_acc did not improve from 0.76429\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.6977 - acc: 0.7551 - val_loss: 0.9231 - val_acc: 0.7071\n",
            "Epoch 18/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6333 - acc: 0.7776\n",
            "Epoch 18: val_acc did not improve from 0.76429\n",
            "8/8 [==============================] - 80s 11s/step - loss: 0.6333 - acc: 0.7776 - val_loss: 0.9377 - val_acc: 0.7429\n",
            "Epoch 19/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7161 - acc: 0.7694\n",
            "Epoch 19: val_acc did not improve from 0.76429\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.7161 - acc: 0.7694 - val_loss: 1.1829 - val_acc: 0.6071\n",
            "Epoch 20/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5723 - acc: 0.8163\n",
            "Epoch 20: val_acc did not improve from 0.76429\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.5723 - acc: 0.8163 - val_loss: 1.4016 - val_acc: 0.5929\n",
            "Epoch 21/46\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6016 - acc: 0.7857\n",
            "Epoch 21: val_acc did not improve from 0.76429\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.6016 - acc: 0.7857 - val_loss: 0.9256 - val_acc: 0.6929\n",
            "\n",
            "\n",
            "Model Accuracy 0.6142857142857143\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.40      0.57        10\n",
            "       10000       0.73      0.80      0.76        10\n",
            "      100000       0.90      0.90      0.90        10\n",
            "        2000       1.00      0.30      0.46        10\n",
            "       20000       0.30      0.30      0.30        10\n",
            "        5000       0.86      0.60      0.71        10\n",
            "       50000       0.40      1.00      0.57        10\n",
            "\n",
            "    accuracy                           0.61        70\n",
            "   macro avg       0.74      0.61      0.61        70\n",
            "weighted avg       0.74      0.61      0.61        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 69 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 45\n",
            "learning rate: 0.04711277843383355\n",
            "batch size: 128\n",
            "dropout rate: 0.5395299349768057\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/45\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.6095 - acc: 0.2959 \n",
            "Epoch 1: val_acc improved from -inf to 0.14286, saving model to percobaan69_noImgPro/model\\vgg_16_69-saved-model-01-acc-0.14.hdf5\n",
            "4/4 [==============================] - 97s 25s/step - loss: 2.6095 - acc: 0.2959 - val_loss: 15.0431 - val_acc: 0.1429\n",
            "Epoch 2/45\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.6719 - acc: 0.4694 \n",
            "Epoch 2: val_acc improved from 0.14286 to 0.44286, saving model to percobaan69_noImgPro/model\\vgg_16_69-saved-model-02-acc-0.44.hdf5\n",
            "4/4 [==============================] - 95s 25s/step - loss: 1.6719 - acc: 0.4694 - val_loss: 2.6004 - val_acc: 0.4429\n",
            "Epoch 3/45\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2323 - acc: 0.5857 \n",
            "Epoch 3: val_acc did not improve from 0.44286\n",
            "4/4 [==============================] - 95s 25s/step - loss: 1.2323 - acc: 0.5857 - val_loss: 4.4976 - val_acc: 0.3143\n",
            "Epoch 4/45\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8707 - acc: 0.7061 \n",
            "Epoch 4: val_acc did not improve from 0.44286\n",
            "4/4 [==============================] - 95s 25s/step - loss: 0.8707 - acc: 0.7061 - val_loss: 5.7720 - val_acc: 0.3071\n",
            "Epoch 5/45\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7389 - acc: 0.7449 \n",
            "Epoch 5: val_acc did not improve from 0.44286\n",
            "4/4 [==============================] - 95s 25s/step - loss: 0.7389 - acc: 0.7449 - val_loss: 6.2672 - val_acc: 0.2714\n",
            "Epoch 6/45\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7095 - acc: 0.7388 \n",
            "Epoch 6: val_acc did not improve from 0.44286\n",
            "4/4 [==============================] - 95s 25s/step - loss: 0.7095 - acc: 0.7388 - val_loss: 3.3175 - val_acc: 0.3143\n",
            "Epoch 7/45\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5682 - acc: 0.8000 \n",
            "Epoch 7: val_acc improved from 0.44286 to 0.47857, saving model to percobaan69_noImgPro/model\\vgg_16_69-saved-model-07-acc-0.48.hdf5\n",
            "4/4 [==============================] - 95s 26s/step - loss: 0.5682 - acc: 0.8000 - val_loss: 1.7495 - val_acc: 0.4786\n",
            "Epoch 8/45\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4972 - acc: 0.8204 \n",
            "Epoch 8: val_acc did not improve from 0.47857\n",
            "4/4 [==============================] - 95s 25s/step - loss: 0.4972 - acc: 0.8204 - val_loss: 2.0561 - val_acc: 0.4000\n",
            "Epoch 9/45\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4948 - acc: 0.8367 \n",
            "Epoch 9: val_acc did not improve from 0.47857\n",
            "4/4 [==============================] - 95s 25s/step - loss: 0.4948 - acc: 0.8367 - val_loss: 2.4148 - val_acc: 0.3500\n",
            "Epoch 10/45\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3567 - acc: 0.8776 \n",
            "Epoch 10: val_acc did not improve from 0.47857\n",
            "4/4 [==============================] - 95s 25s/step - loss: 0.3567 - acc: 0.8776 - val_loss: 1.9049 - val_acc: 0.4214\n",
            "Epoch 11/45\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3546 - acc: 0.8796 \n",
            "Epoch 11: val_acc improved from 0.47857 to 0.56429, saving model to percobaan69_noImgPro/model\\vgg_16_69-saved-model-11-acc-0.56.hdf5\n",
            "4/4 [==============================] - 95s 25s/step - loss: 0.3546 - acc: 0.8796 - val_loss: 1.0753 - val_acc: 0.5643\n",
            "Epoch 12/45\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3191 - acc: 0.8878 \n",
            "Epoch 12: val_acc improved from 0.56429 to 0.59286, saving model to percobaan69_noImgPro/model\\vgg_16_69-saved-model-12-acc-0.59.hdf5\n",
            "4/4 [==============================] - 95s 25s/step - loss: 0.3191 - acc: 0.8878 - val_loss: 1.1444 - val_acc: 0.5929\n",
            "Epoch 13/45\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3107 - acc: 0.8898 \n",
            "Epoch 13: val_acc did not improve from 0.59286\n",
            "4/4 [==============================] - 95s 26s/step - loss: 0.3107 - acc: 0.8898 - val_loss: 1.3395 - val_acc: 0.5714\n",
            "Epoch 14/45\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2596 - acc: 0.9102 \n",
            "Epoch 14: val_acc improved from 0.59286 to 0.60714, saving model to percobaan69_noImgPro/model\\vgg_16_69-saved-model-14-acc-0.61.hdf5\n",
            "4/4 [==============================] - 95s 25s/step - loss: 0.2596 - acc: 0.9102 - val_loss: 1.4226 - val_acc: 0.6071\n",
            "Epoch 15/45\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3059 - acc: 0.8918 \n",
            "Epoch 15: val_acc did not improve from 0.60714\n",
            "4/4 [==============================] - 95s 25s/step - loss: 0.3059 - acc: 0.8918 - val_loss: 1.4033 - val_acc: 0.6000\n",
            "Epoch 16/45\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2430 - acc: 0.9082 \n",
            "Epoch 16: val_acc improved from 0.60714 to 0.65000, saving model to percobaan69_noImgPro/model\\vgg_16_69-saved-model-16-acc-0.65.hdf5\n",
            "4/4 [==============================] - 95s 25s/step - loss: 0.2430 - acc: 0.9082 - val_loss: 1.2185 - val_acc: 0.6500\n",
            "\n",
            "\n",
            "Model Accuracy 0.6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.48      1.00      0.65        10\n",
            "       10000       1.00      0.40      0.57        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.67      0.80      0.73        10\n",
            "       20000       0.58      0.70      0.64        10\n",
            "        5000       0.50      0.60      0.55        10\n",
            "       50000       0.78      0.70      0.74        10\n",
            "\n",
            "    accuracy                           0.60        70\n",
            "   macro avg       0.57      0.60      0.55        70\n",
            "weighted avg       0.57      0.60      0.55        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 70 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 41\n",
            "learning rate: 0.036948476327394536\n",
            "batch size: 128\n",
            "dropout rate: 0.6292675460443933\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/41\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.4450 - acc: 0.3184 \n",
            "Epoch 1: val_acc improved from -inf to 0.26429, saving model to percobaan70_noImgPro/model\\vgg_16_70-saved-model-01-acc-0.26.hdf5\n",
            "4/4 [==============================] - 90s 24s/step - loss: 2.4450 - acc: 0.3184 - val_loss: 4.0270 - val_acc: 0.2643\n",
            "Epoch 2/41\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.4909 - acc: 0.5347 \n",
            "Epoch 2: val_acc did not improve from 0.26429\n",
            "4/4 [==============================] - 89s 24s/step - loss: 1.4909 - acc: 0.5347 - val_loss: 5.2649 - val_acc: 0.2500\n",
            "Epoch 3/41\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2932 - acc: 0.5367 \n",
            "Epoch 3: val_acc improved from 0.26429 to 0.36429, saving model to percobaan70_noImgPro/model\\vgg_16_70-saved-model-03-acc-0.36.hdf5\n",
            "4/4 [==============================] - 89s 23s/step - loss: 1.2932 - acc: 0.5367 - val_loss: 4.0469 - val_acc: 0.3643\n",
            "Epoch 4/41\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1434 - acc: 0.6102 \n",
            "Epoch 4: val_acc did not improve from 0.36429\n",
            "4/4 [==============================] - 89s 23s/step - loss: 1.1434 - acc: 0.6102 - val_loss: 3.5065 - val_acc: 0.3571\n",
            "Epoch 5/41\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8744 - acc: 0.7041 \n",
            "Epoch 5: val_acc improved from 0.36429 to 0.37857, saving model to percobaan70_noImgPro/model\\vgg_16_70-saved-model-05-acc-0.38.hdf5\n",
            "4/4 [==============================] - 89s 23s/step - loss: 0.8744 - acc: 0.7041 - val_loss: 3.9195 - val_acc: 0.3786\n",
            "Epoch 6/41\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7279 - acc: 0.7612 \n",
            "Epoch 6: val_acc did not improve from 0.37857\n",
            "4/4 [==============================] - 88s 23s/step - loss: 0.7279 - acc: 0.7612 - val_loss: 4.3902 - val_acc: 0.2643\n",
            "Epoch 7/41\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7238 - acc: 0.7429 \n",
            "Epoch 7: val_acc did not improve from 0.37857\n",
            "4/4 [==============================] - 87s 23s/step - loss: 0.7238 - acc: 0.7429 - val_loss: 6.1957 - val_acc: 0.1857\n",
            "Epoch 8/41\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6452 - acc: 0.7612 \n",
            "Epoch 8: val_acc did not improve from 0.37857\n",
            "4/4 [==============================] - 85s 23s/step - loss: 0.6452 - acc: 0.7612 - val_loss: 7.4481 - val_acc: 0.1429\n",
            "Epoch 9/41\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4952 - acc: 0.8327 \n",
            "Epoch 9: val_acc did not improve from 0.37857\n",
            "4/4 [==============================] - 86s 22s/step - loss: 0.4952 - acc: 0.8327 - val_loss: 6.3791 - val_acc: 0.2500\n",
            "\n",
            "\n",
            "Model Accuracy 0.22857142857142856\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.00      0.00      0.00        10\n",
            "       10000       0.00      0.00      0.00        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.00      0.00      0.00        10\n",
            "       20000       0.16      0.90      0.28        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       0.47      0.70      0.56        10\n",
            "\n",
            "    accuracy                           0.23        70\n",
            "   macro avg       0.09      0.23      0.12        70\n",
            "weighted avg       0.09      0.23      0.12        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 71 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 41\n",
            "learning rate: 0.03146642764999384\n",
            "batch size: 128\n",
            "dropout rate: 0.6960082246834093\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/41\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.8406 - acc: 0.2633 \n",
            "Epoch 1: val_acc improved from -inf to 0.19286, saving model to percobaan71_noImgPro/model\\vgg_16_71-saved-model-01-acc-0.19.hdf5\n",
            "4/4 [==============================] - 80s 22s/step - loss: 2.8406 - acc: 0.2633 - val_loss: 5.2573 - val_acc: 0.1929\n",
            "Epoch 2/41\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.0090 - acc: 0.4041 \n",
            "Epoch 2: val_acc did not improve from 0.19286\n",
            "4/4 [==============================] - 82s 22s/step - loss: 2.0090 - acc: 0.4041 - val_loss: 8.5362 - val_acc: 0.1429\n",
            "Epoch 3/41\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.4470 - acc: 0.4816 \n",
            "Epoch 3: val_acc did not improve from 0.19286\n",
            "4/4 [==============================] - 81s 21s/step - loss: 1.4470 - acc: 0.4816 - val_loss: 8.6449 - val_acc: 0.1429\n",
            "Epoch 4/41\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2026 - acc: 0.5633 \n",
            "Epoch 4: val_acc did not improve from 0.19286\n",
            "4/4 [==============================] - 80s 21s/step - loss: 1.2026 - acc: 0.5633 - val_loss: 6.5282 - val_acc: 0.1714\n",
            "Epoch 5/41\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1179 - acc: 0.5959 \n",
            "Epoch 5: val_acc did not improve from 0.19286\n",
            "4/4 [==============================] - 80s 21s/step - loss: 1.1179 - acc: 0.5959 - val_loss: 6.7058 - val_acc: 0.1714\n",
            "Epoch 6/41\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8983 - acc: 0.6694 \n",
            "Epoch 6: val_acc improved from 0.19286 to 0.20000, saving model to percobaan71_noImgPro/model\\vgg_16_71-saved-model-06-acc-0.20.hdf5\n",
            "4/4 [==============================] - 79s 22s/step - loss: 0.8983 - acc: 0.6694 - val_loss: 6.3152 - val_acc: 0.2000\n",
            "\n",
            "\n",
            "Model Accuracy 0.18571428571428572\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.10      0.18        10\n",
            "       10000       0.00      0.00      0.00        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.00      0.00      0.00        10\n",
            "       20000       0.15      1.00      0.26        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       0.67      0.20      0.31        10\n",
            "\n",
            "    accuracy                           0.19        70\n",
            "   macro avg       0.26      0.19      0.11        70\n",
            "weighted avg       0.26      0.19      0.11        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 72 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 44\n",
            "learning rate: 0.03212767513452438\n",
            "batch size: 128\n",
            "dropout rate: 0.7934341953052013\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/44\n",
            "4/4 [==============================] - ETA: 0s - loss: 3.5869 - acc: 0.1857 \n",
            "Epoch 1: val_acc improved from -inf to 0.29286, saving model to percobaan72_noImgPro/model\\vgg_16_72-saved-model-01-acc-0.29.hdf5\n",
            "4/4 [==============================] - 78s 20s/step - loss: 3.5869 - acc: 0.1857 - val_loss: 3.2104 - val_acc: 0.2929\n",
            "Epoch 2/44\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.3342 - acc: 0.3265 \n",
            "Epoch 2: val_acc did not improve from 0.29286\n",
            "4/4 [==============================] - 78s 22s/step - loss: 2.3342 - acc: 0.3265 - val_loss: 5.4659 - val_acc: 0.1929\n",
            "Epoch 3/44\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.0673 - acc: 0.3776 \n",
            "Epoch 3: val_acc did not improve from 0.29286\n",
            "4/4 [==============================] - 76s 20s/step - loss: 2.0673 - acc: 0.3776 - val_loss: 4.5900 - val_acc: 0.2071\n",
            "Epoch 4/44\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.8080 - acc: 0.4163 \n",
            "Epoch 4: val_acc did not improve from 0.29286\n",
            "4/4 [==============================] - 78s 21s/step - loss: 1.8080 - acc: 0.4163 - val_loss: 3.7315 - val_acc: 0.1929\n",
            "Epoch 5/44\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.6140 - acc: 0.4245 \n",
            "Epoch 5: val_acc did not improve from 0.29286\n",
            "4/4 [==============================] - 76s 20s/step - loss: 1.6140 - acc: 0.4245 - val_loss: 3.2939 - val_acc: 0.2286\n",
            "Epoch 6/44\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.3927 - acc: 0.5000 \n",
            "Epoch 6: val_acc did not improve from 0.29286\n",
            "4/4 [==============================] - 77s 20s/step - loss: 1.3927 - acc: 0.5000 - val_loss: 2.7891 - val_acc: 0.2143\n",
            "Epoch 7/44\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.3003 - acc: 0.5102 \n",
            "Epoch 7: val_acc did not improve from 0.29286\n",
            "4/4 [==============================] - 77s 21s/step - loss: 1.3003 - acc: 0.5102 - val_loss: 2.1543 - val_acc: 0.2571\n",
            "Epoch 8/44\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2567 - acc: 0.5347 \n",
            "Epoch 8: val_acc improved from 0.29286 to 0.30000, saving model to percobaan72_noImgPro/model\\vgg_16_72-saved-model-08-acc-0.30.hdf5\n",
            "4/4 [==============================] - 76s 21s/step - loss: 1.2567 - acc: 0.5347 - val_loss: 1.9493 - val_acc: 0.3000\n",
            "Epoch 9/44\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1663 - acc: 0.5592 \n",
            "Epoch 9: val_acc did not improve from 0.30000\n",
            "4/4 [==============================] - 76s 20s/step - loss: 1.1663 - acc: 0.5592 - val_loss: 2.0725 - val_acc: 0.2857\n",
            "Epoch 10/44\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0792 - acc: 0.5898 \n",
            "Epoch 10: val_acc improved from 0.30000 to 0.32143, saving model to percobaan72_noImgPro/model\\vgg_16_72-saved-model-10-acc-0.32.hdf5\n",
            "4/4 [==============================] - 77s 20s/step - loss: 1.0792 - acc: 0.5898 - val_loss: 1.8408 - val_acc: 0.3214\n",
            "Epoch 11/44\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9697 - acc: 0.6694 \n",
            "Epoch 11: val_acc improved from 0.32143 to 0.33571, saving model to percobaan72_noImgPro/model\\vgg_16_72-saved-model-11-acc-0.34.hdf5\n",
            "4/4 [==============================] - 76s 20s/step - loss: 0.9697 - acc: 0.6694 - val_loss: 1.7152 - val_acc: 0.3357\n",
            "Epoch 12/44\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9036 - acc: 0.6571 \n",
            "Epoch 12: val_acc improved from 0.33571 to 0.34286, saving model to percobaan72_noImgPro/model\\vgg_16_72-saved-model-12-acc-0.34.hdf5\n",
            "4/4 [==============================] - 76s 20s/step - loss: 0.9036 - acc: 0.6571 - val_loss: 1.6271 - val_acc: 0.3429\n",
            "Epoch 13/44\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8285 - acc: 0.7041 \n",
            "Epoch 13: val_acc improved from 0.34286 to 0.37143, saving model to percobaan72_noImgPro/model\\vgg_16_72-saved-model-13-acc-0.37.hdf5\n",
            "4/4 [==============================] - 76s 20s/step - loss: 0.8285 - acc: 0.7041 - val_loss: 1.5672 - val_acc: 0.3714\n",
            "Epoch 14/44\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7791 - acc: 0.7020 \n",
            "Epoch 14: val_acc did not improve from 0.37143\n",
            "4/4 [==============================] - 77s 21s/step - loss: 0.7791 - acc: 0.7020 - val_loss: 1.5478 - val_acc: 0.3643\n",
            "Epoch 15/44\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7694 - acc: 0.7347 \n",
            "Epoch 15: val_acc improved from 0.37143 to 0.39286, saving model to percobaan72_noImgPro/model\\vgg_16_72-saved-model-15-acc-0.39.hdf5\n",
            "4/4 [==============================] - 75s 21s/step - loss: 0.7694 - acc: 0.7347 - val_loss: 1.6371 - val_acc: 0.3929\n",
            "Epoch 16/44\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7241 - acc: 0.7347 \n",
            "Epoch 16: val_acc improved from 0.39286 to 0.41429, saving model to percobaan72_noImgPro/model\\vgg_16_72-saved-model-16-acc-0.41.hdf5\n",
            "4/4 [==============================] - 76s 20s/step - loss: 0.7241 - acc: 0.7347 - val_loss: 1.6781 - val_acc: 0.4143\n",
            "Epoch 17/44\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5999 - acc: 0.7857 \n",
            "Epoch 17: val_acc improved from 0.41429 to 0.45714, saving model to percobaan72_noImgPro/model\\vgg_16_72-saved-model-17-acc-0.46.hdf5\n",
            "4/4 [==============================] - 76s 20s/step - loss: 0.5999 - acc: 0.7857 - val_loss: 1.6936 - val_acc: 0.4571\n",
            "Epoch 18/44\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6777 - acc: 0.7592 \n",
            "Epoch 18: val_acc improved from 0.45714 to 0.48571, saving model to percobaan72_noImgPro/model\\vgg_16_72-saved-model-18-acc-0.49.hdf5\n",
            "4/4 [==============================] - 76s 20s/step - loss: 0.6777 - acc: 0.7592 - val_loss: 1.6615 - val_acc: 0.4857\n",
            "Epoch 19/44\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6591 - acc: 0.7796 \n",
            "Epoch 19: val_acc did not improve from 0.48571\n",
            "4/4 [==============================] - 76s 20s/step - loss: 0.6591 - acc: 0.7796 - val_loss: 1.7953 - val_acc: 0.4500\n",
            "\n",
            "\n",
            "Model Accuracy 0.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.30      0.46        10\n",
            "       10000       0.34      1.00      0.51        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       1.00      0.20      0.33        10\n",
            "       20000       0.30      1.00      0.47        10\n",
            "        5000       1.00      0.10      0.18        10\n",
            "       50000       1.00      0.20      0.33        10\n",
            "\n",
            "    accuracy                           0.40        70\n",
            "   macro avg       0.66      0.40      0.33        70\n",
            "weighted avg       0.66      0.40      0.33        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 73 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 47\n",
            "learning rate: 0.06698139375607384\n",
            "batch size: 32\n",
            "dropout rate: 0.5413751453714145\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 3.0483 - acc: 0.3041\n",
            "Epoch 1: val_acc improved from -inf to 0.15714, saving model to percobaan73_noImgPro/model\\vgg_16_73-saved-model-01-acc-0.16.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 3.0483 - acc: 0.3041 - val_loss: 14.0811 - val_acc: 0.1571\n",
            "Epoch 2/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.9753 - acc: 0.4551\n",
            "Epoch 2: val_acc did not improve from 0.15714\n",
            "16/16 [==============================] - 76s 5s/step - loss: 1.9753 - acc: 0.4551 - val_loss: 7.9275 - val_acc: 0.1429\n",
            "Epoch 3/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.5707 - acc: 0.5041\n",
            "Epoch 3: val_acc did not improve from 0.15714\n",
            "16/16 [==============================] - 75s 5s/step - loss: 1.5707 - acc: 0.5041 - val_loss: 6.8630 - val_acc: 0.1429\n",
            "Epoch 4/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2678 - acc: 0.5776\n",
            "Epoch 4: val_acc improved from 0.15714 to 0.32143, saving model to percobaan73_noImgPro/model\\vgg_16_73-saved-model-04-acc-0.32.hdf5\n",
            "16/16 [==============================] - 75s 5s/step - loss: 1.2678 - acc: 0.5776 - val_loss: 2.3503 - val_acc: 0.3214\n",
            "Epoch 5/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1120 - acc: 0.6245\n",
            "Epoch 5: val_acc did not improve from 0.32143\n",
            "16/16 [==============================] - 75s 5s/step - loss: 1.1120 - acc: 0.6245 - val_loss: 1.9812 - val_acc: 0.2857\n",
            "Epoch 6/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8818 - acc: 0.6857\n",
            "Epoch 6: val_acc improved from 0.32143 to 0.40714, saving model to percobaan73_noImgPro/model\\vgg_16_73-saved-model-06-acc-0.41.hdf5\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.8818 - acc: 0.6857 - val_loss: 2.2590 - val_acc: 0.4071\n",
            "Epoch 7/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8640 - acc: 0.7000\n",
            "Epoch 7: val_acc did not improve from 0.40714\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.8640 - acc: 0.7000 - val_loss: 2.3680 - val_acc: 0.3857\n",
            "Epoch 8/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8565 - acc: 0.7306\n",
            "Epoch 8: val_acc improved from 0.40714 to 0.41429, saving model to percobaan73_noImgPro/model\\vgg_16_73-saved-model-08-acc-0.41.hdf5\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.8565 - acc: 0.7306 - val_loss: 1.7658 - val_acc: 0.4143\n",
            "Epoch 9/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8729 - acc: 0.7143\n",
            "Epoch 9: val_acc improved from 0.41429 to 0.55714, saving model to percobaan73_noImgPro/model\\vgg_16_73-saved-model-09-acc-0.56.hdf5\n",
            "16/16 [==============================] - 76s 5s/step - loss: 0.8729 - acc: 0.7143 - val_loss: 1.3906 - val_acc: 0.5571\n",
            "Epoch 10/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8661 - acc: 0.7122\n",
            "Epoch 10: val_acc did not improve from 0.55714\n",
            "16/16 [==============================] - 74s 5s/step - loss: 0.8661 - acc: 0.7122 - val_loss: 2.1292 - val_acc: 0.3714\n",
            "Epoch 11/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8037 - acc: 0.7408\n",
            "Epoch 11: val_acc improved from 0.55714 to 0.64286, saving model to percobaan73_noImgPro/model\\vgg_16_73-saved-model-11-acc-0.64.hdf5\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.8037 - acc: 0.7408 - val_loss: 1.2070 - val_acc: 0.6429\n",
            "Epoch 12/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7593 - acc: 0.7306\n",
            "Epoch 12: val_acc did not improve from 0.64286\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.7593 - acc: 0.7306 - val_loss: 1.5829 - val_acc: 0.5214\n",
            "Epoch 13/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7340 - acc: 0.7592\n",
            "Epoch 13: val_acc improved from 0.64286 to 0.72143, saving model to percobaan73_noImgPro/model\\vgg_16_73-saved-model-13-acc-0.72.hdf5\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.7340 - acc: 0.7592 - val_loss: 0.8875 - val_acc: 0.7214\n",
            "Epoch 14/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6380 - acc: 0.8000\n",
            "Epoch 14: val_acc did not improve from 0.72143\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.6380 - acc: 0.8000 - val_loss: 1.4435 - val_acc: 0.6000\n",
            "Epoch 15/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9539 - acc: 0.7000\n",
            "Epoch 15: val_acc improved from 0.72143 to 0.78571, saving model to percobaan73_noImgPro/model\\vgg_16_73-saved-model-15-acc-0.79.hdf5\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.9539 - acc: 0.7000 - val_loss: 0.7608 - val_acc: 0.7857\n",
            "Epoch 16/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8281 - acc: 0.7796\n",
            "Epoch 16: val_acc did not improve from 0.78571\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.8281 - acc: 0.7796 - val_loss: 1.4910 - val_acc: 0.6571\n",
            "Epoch 17/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8430 - acc: 0.7837\n",
            "Epoch 17: val_acc did not improve from 0.78571\n",
            "16/16 [==============================] - 74s 5s/step - loss: 0.8430 - acc: 0.7837 - val_loss: 0.9596 - val_acc: 0.7214\n",
            "Epoch 18/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8552 - acc: 0.7714\n",
            "Epoch 18: val_acc improved from 0.78571 to 0.80714, saving model to percobaan73_noImgPro/model\\vgg_16_73-saved-model-18-acc-0.81.hdf5\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.8552 - acc: 0.7714 - val_loss: 0.6190 - val_acc: 0.8071\n",
            "Epoch 19/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7624 - acc: 0.7796\n",
            "Epoch 19: val_acc did not improve from 0.80714\n",
            "16/16 [==============================] - 74s 5s/step - loss: 0.7624 - acc: 0.7796 - val_loss: 1.1079 - val_acc: 0.7071\n",
            "Epoch 20/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7825 - acc: 0.7490\n",
            "Epoch 20: val_acc did not improve from 0.80714\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.7825 - acc: 0.7490 - val_loss: 0.8319 - val_acc: 0.7857\n",
            "Epoch 21/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6043 - acc: 0.8306\n",
            "Epoch 21: val_acc did not improve from 0.80714\n",
            "16/16 [==============================] - 74s 5s/step - loss: 0.6043 - acc: 0.8306 - val_loss: 0.9311 - val_acc: 0.7500\n",
            "Epoch 22/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7966 - acc: 0.7714\n",
            "Epoch 22: val_acc did not improve from 0.80714\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.7966 - acc: 0.7714 - val_loss: 1.3226 - val_acc: 0.7357\n",
            "Epoch 23/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7548 - acc: 0.7714\n",
            "Epoch 23: val_acc did not improve from 0.80714\n",
            "16/16 [==============================] - 74s 5s/step - loss: 0.7548 - acc: 0.7714 - val_loss: 1.3432 - val_acc: 0.7357\n",
            "\n",
            "\n",
            "Model Accuracy 0.7\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.67      1.00      0.80        10\n",
            "       10000       1.00      0.30      0.46        10\n",
            "      100000       1.00      0.70      0.82        10\n",
            "        2000       0.83      0.50      0.62        10\n",
            "       20000       0.80      0.40      0.53        10\n",
            "        5000       0.50      1.00      0.67        10\n",
            "       50000       0.71      1.00      0.83        10\n",
            "\n",
            "    accuracy                           0.70        70\n",
            "   macro avg       0.79      0.70      0.68        70\n",
            "weighted avg       0.79      0.70      0.68        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 74 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 41\n",
            "learning rate: 0.06392344349289787\n",
            "batch size: 32\n",
            "dropout rate: 0.5852976519209827\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 3.4835 - acc: 0.2367\n",
            "Epoch 1: val_acc improved from -inf to 0.18571, saving model to percobaan74_noImgPro/model\\vgg_16_74-saved-model-01-acc-0.19.hdf5\n",
            "16/16 [==============================] - 76s 5s/step - loss: 3.4835 - acc: 0.2367 - val_loss: 9.9180 - val_acc: 0.1857\n",
            "Epoch 2/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.2134 - acc: 0.4020\n",
            "Epoch 2: val_acc improved from 0.18571 to 0.35714, saving model to percobaan74_noImgPro/model\\vgg_16_74-saved-model-02-acc-0.36.hdf5\n",
            "16/16 [==============================] - 75s 5s/step - loss: 2.2134 - acc: 0.4020 - val_loss: 2.4552 - val_acc: 0.3571\n",
            "Epoch 3/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.4862 - acc: 0.5122\n",
            "Epoch 3: val_acc did not improve from 0.35714\n",
            "16/16 [==============================] - 74s 5s/step - loss: 1.4862 - acc: 0.5122 - val_loss: 2.1827 - val_acc: 0.3071\n",
            "Epoch 4/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3128 - acc: 0.5469\n",
            "Epoch 4: val_acc did not improve from 0.35714\n",
            "16/16 [==============================] - 74s 5s/step - loss: 1.3128 - acc: 0.5469 - val_loss: 1.9656 - val_acc: 0.3571\n",
            "Epoch 5/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9518 - acc: 0.6735\n",
            "Epoch 5: val_acc improved from 0.35714 to 0.37857, saving model to percobaan74_noImgPro/model\\vgg_16_74-saved-model-05-acc-0.38.hdf5\n",
            "16/16 [==============================] - 74s 5s/step - loss: 0.9518 - acc: 0.6735 - val_loss: 1.9642 - val_acc: 0.3786\n",
            "Epoch 6/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8675 - acc: 0.7041\n",
            "Epoch 6: val_acc improved from 0.37857 to 0.42143, saving model to percobaan74_noImgPro/model\\vgg_16_74-saved-model-06-acc-0.42.hdf5\n",
            "16/16 [==============================] - 74s 5s/step - loss: 0.8675 - acc: 0.7041 - val_loss: 2.8413 - val_acc: 0.4214\n",
            "Epoch 7/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9927 - acc: 0.6429\n",
            "Epoch 7: val_acc improved from 0.42143 to 0.44286, saving model to percobaan74_noImgPro/model\\vgg_16_74-saved-model-07-acc-0.44.hdf5\n",
            "16/16 [==============================] - 74s 5s/step - loss: 0.9927 - acc: 0.6429 - val_loss: 1.9786 - val_acc: 0.4429\n",
            "Epoch 8/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9015 - acc: 0.6980\n",
            "Epoch 8: val_acc did not improve from 0.44286\n",
            "16/16 [==============================] - 74s 5s/step - loss: 0.9015 - acc: 0.6980 - val_loss: 2.2728 - val_acc: 0.3857\n",
            "Epoch 9/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8026 - acc: 0.7245\n",
            "Epoch 9: val_acc improved from 0.44286 to 0.55714, saving model to percobaan74_noImgPro/model\\vgg_16_74-saved-model-09-acc-0.56.hdf5\n",
            "16/16 [==============================] - 74s 5s/step - loss: 0.8026 - acc: 0.7245 - val_loss: 1.7141 - val_acc: 0.5571\n",
            "Epoch 10/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7073 - acc: 0.7898\n",
            "Epoch 10: val_acc did not improve from 0.55714\n",
            "16/16 [==============================] - 74s 5s/step - loss: 0.7073 - acc: 0.7898 - val_loss: 2.6456 - val_acc: 0.4214\n",
            "Epoch 11/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7733 - acc: 0.7714\n",
            "Epoch 11: val_acc improved from 0.55714 to 0.62143, saving model to percobaan74_noImgPro/model\\vgg_16_74-saved-model-11-acc-0.62.hdf5\n",
            "16/16 [==============================] - 73s 5s/step - loss: 0.7733 - acc: 0.7714 - val_loss: 1.4621 - val_acc: 0.6214\n",
            "Epoch 12/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7561 - acc: 0.7469\n",
            "Epoch 12: val_acc did not improve from 0.62143\n",
            "16/16 [==============================] - 74s 5s/step - loss: 0.7561 - acc: 0.7469 - val_loss: 2.7195 - val_acc: 0.4143\n",
            "Epoch 13/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8334 - acc: 0.7408\n",
            "Epoch 13: val_acc improved from 0.62143 to 0.63571, saving model to percobaan74_noImgPro/model\\vgg_16_74-saved-model-13-acc-0.64.hdf5\n",
            "16/16 [==============================] - 74s 5s/step - loss: 0.8334 - acc: 0.7408 - val_loss: 1.5540 - val_acc: 0.6357\n",
            "Epoch 14/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8184 - acc: 0.7388\n",
            "Epoch 14: val_acc did not improve from 0.63571\n",
            "16/16 [==============================] - 74s 5s/step - loss: 0.8184 - acc: 0.7388 - val_loss: 1.7872 - val_acc: 0.6143\n",
            "Epoch 15/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8719 - acc: 0.7245\n",
            "Epoch 15: val_acc did not improve from 0.63571\n",
            "16/16 [==============================] - 73s 5s/step - loss: 0.8719 - acc: 0.7245 - val_loss: 1.8637 - val_acc: 0.5857\n",
            "Epoch 16/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7667 - acc: 0.7571\n",
            "Epoch 16: val_acc improved from 0.63571 to 0.68571, saving model to percobaan74_noImgPro/model\\vgg_16_74-saved-model-16-acc-0.69.hdf5\n",
            "16/16 [==============================] - 74s 5s/step - loss: 0.7667 - acc: 0.7571 - val_loss: 1.2896 - val_acc: 0.6857\n",
            "Epoch 17/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9166 - acc: 0.7347\n",
            "Epoch 17: val_acc did not improve from 0.68571\n",
            "16/16 [==============================] - 74s 5s/step - loss: 0.9166 - acc: 0.7347 - val_loss: 2.3525 - val_acc: 0.5214\n",
            "Epoch 18/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7797 - acc: 0.7306\n",
            "Epoch 18: val_acc did not improve from 0.68571\n",
            "16/16 [==============================] - 73s 5s/step - loss: 0.7797 - acc: 0.7306 - val_loss: 1.4832 - val_acc: 0.6714\n",
            "Epoch 19/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9128 - acc: 0.7245\n",
            "Epoch 19: val_acc improved from 0.68571 to 0.77857, saving model to percobaan74_noImgPro/model\\vgg_16_74-saved-model-19-acc-0.78.hdf5\n",
            "16/16 [==============================] - 73s 5s/step - loss: 0.9128 - acc: 0.7245 - val_loss: 1.1601 - val_acc: 0.7786\n",
            "Epoch 20/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8909 - acc: 0.7673\n",
            "Epoch 20: val_acc did not improve from 0.77857\n",
            "16/16 [==============================] - 74s 5s/step - loss: 0.8909 - acc: 0.7673 - val_loss: 2.1145 - val_acc: 0.6643\n",
            "Epoch 21/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9049 - acc: 0.7551\n",
            "Epoch 21: val_acc did not improve from 0.77857\n",
            "16/16 [==============================] - 73s 5s/step - loss: 0.9049 - acc: 0.7551 - val_loss: 2.9814 - val_acc: 0.4929\n",
            "Epoch 22/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9442 - acc: 0.7408\n",
            "Epoch 22: val_acc did not improve from 0.77857\n",
            "16/16 [==============================] - 74s 5s/step - loss: 0.9442 - acc: 0.7408 - val_loss: 2.5046 - val_acc: 0.5857\n",
            "Epoch 23/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6514 - acc: 0.8122\n",
            "Epoch 23: val_acc did not improve from 0.77857\n",
            "16/16 [==============================] - 73s 5s/step - loss: 0.6514 - acc: 0.8122 - val_loss: 2.0242 - val_acc: 0.6214\n",
            "Epoch 24/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8355 - acc: 0.7776\n",
            "Epoch 24: val_acc did not improve from 0.77857\n",
            "16/16 [==============================] - 74s 5s/step - loss: 0.8355 - acc: 0.7776 - val_loss: 2.1850 - val_acc: 0.6500\n",
            "\n",
            "\n",
            "Model Accuracy 0.6142857142857143\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.40      0.57        10\n",
            "       10000       0.67      0.80      0.73        10\n",
            "      100000       1.00      0.80      0.89        10\n",
            "        2000       1.00      0.30      0.46        10\n",
            "       20000       1.00      0.20      0.33        10\n",
            "        5000       0.42      1.00      0.59        10\n",
            "       50000       0.47      0.80      0.59        10\n",
            "\n",
            "    accuracy                           0.61        70\n",
            "   macro avg       0.79      0.61      0.59        70\n",
            "weighted avg       0.79      0.61      0.59        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 75 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 39\n",
            "learning rate: 0.056572217929273465\n",
            "batch size: 32\n",
            "dropout rate: 0.6808616345992075\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/39\n",
            "16/16 [==============================] - ETA: 0s - loss: 3.6877 - acc: 0.2714\n",
            "Epoch 1: val_acc improved from -inf to 0.18571, saving model to percobaan75_noImgPro/model\\vgg_16_75-saved-model-01-acc-0.19.hdf5\n",
            "16/16 [==============================] - 75s 5s/step - loss: 3.6877 - acc: 0.2714 - val_loss: 8.9351 - val_acc: 0.1857\n",
            "Epoch 2/39\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.3731 - acc: 0.3184\n",
            "Epoch 2: val_acc improved from 0.18571 to 0.32857, saving model to percobaan75_noImgPro/model\\vgg_16_75-saved-model-02-acc-0.33.hdf5\n",
            "16/16 [==============================] - 74s 5s/step - loss: 2.3731 - acc: 0.3184 - val_loss: 2.8409 - val_acc: 0.3286\n",
            "Epoch 3/39\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.7602 - acc: 0.4122\n",
            "Epoch 3: val_acc did not improve from 0.32857\n",
            "16/16 [==============================] - 73s 5s/step - loss: 1.7602 - acc: 0.4122 - val_loss: 2.6117 - val_acc: 0.1929\n",
            "Epoch 4/39\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.4999 - acc: 0.4735\n",
            "Epoch 4: val_acc improved from 0.32857 to 0.35714, saving model to percobaan75_noImgPro/model\\vgg_16_75-saved-model-04-acc-0.36.hdf5\n",
            "16/16 [==============================] - 73s 5s/step - loss: 1.4999 - acc: 0.4735 - val_loss: 1.9785 - val_acc: 0.3571\n",
            "Epoch 5/39\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2398 - acc: 0.5490\n",
            "Epoch 5: val_acc improved from 0.35714 to 0.47143, saving model to percobaan75_noImgPro/model\\vgg_16_75-saved-model-05-acc-0.47.hdf5\n",
            "16/16 [==============================] - 73s 5s/step - loss: 1.2398 - acc: 0.5490 - val_loss: 1.8848 - val_acc: 0.4714\n",
            "Epoch 6/39\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2422 - acc: 0.5776\n",
            "Epoch 6: val_acc did not improve from 0.47143\n",
            "16/16 [==============================] - 73s 5s/step - loss: 1.2422 - acc: 0.5776 - val_loss: 2.1165 - val_acc: 0.3286\n",
            "Epoch 7/39\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0445 - acc: 0.6041\n",
            "Epoch 7: val_acc improved from 0.47143 to 0.51429, saving model to percobaan75_noImgPro/model\\vgg_16_75-saved-model-07-acc-0.51.hdf5\n",
            "16/16 [==============================] - 73s 5s/step - loss: 1.0445 - acc: 0.6041 - val_loss: 1.5019 - val_acc: 0.5143\n",
            "Epoch 8/39\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0021 - acc: 0.6694\n",
            "Epoch 8: val_acc improved from 0.51429 to 0.57857, saving model to percobaan75_noImgPro/model\\vgg_16_75-saved-model-08-acc-0.58.hdf5\n",
            "16/16 [==============================] - 74s 5s/step - loss: 1.0021 - acc: 0.6694 - val_loss: 1.2276 - val_acc: 0.5786\n",
            "Epoch 9/39\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0702 - acc: 0.6449\n",
            "Epoch 9: val_acc did not improve from 0.57857\n",
            "16/16 [==============================] - 73s 5s/step - loss: 1.0702 - acc: 0.6449 - val_loss: 1.6195 - val_acc: 0.4143\n",
            "Epoch 10/39\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0525 - acc: 0.6776\n",
            "Epoch 10: val_acc did not improve from 0.57857\n",
            "16/16 [==============================] - 73s 5s/step - loss: 1.0525 - acc: 0.6776 - val_loss: 2.3332 - val_acc: 0.3429\n",
            "Epoch 11/39\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9207 - acc: 0.6551\n",
            "Epoch 11: val_acc did not improve from 0.57857\n",
            "16/16 [==============================] - 73s 5s/step - loss: 0.9207 - acc: 0.6551 - val_loss: 1.6596 - val_acc: 0.5214\n",
            "Epoch 12/39\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8696 - acc: 0.7041\n",
            "Epoch 12: val_acc improved from 0.57857 to 0.61429, saving model to percobaan75_noImgPro/model\\vgg_16_75-saved-model-12-acc-0.61.hdf5\n",
            "16/16 [==============================] - 73s 5s/step - loss: 0.8696 - acc: 0.7041 - val_loss: 1.2180 - val_acc: 0.6143\n",
            "Epoch 13/39\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0191 - acc: 0.6735\n",
            "Epoch 13: val_acc did not improve from 0.61429\n",
            "16/16 [==============================] - 73s 5s/step - loss: 1.0191 - acc: 0.6735 - val_loss: 2.0715 - val_acc: 0.5429\n",
            "Epoch 14/39\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9118 - acc: 0.6796\n",
            "Epoch 14: val_acc did not improve from 0.61429\n",
            "16/16 [==============================] - 73s 5s/step - loss: 0.9118 - acc: 0.6796 - val_loss: 4.0804 - val_acc: 0.3429\n",
            "Epoch 15/39\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8383 - acc: 0.7102\n",
            "Epoch 15: val_acc did not improve from 0.61429\n",
            "16/16 [==============================] - 73s 5s/step - loss: 0.8383 - acc: 0.7102 - val_loss: 5.4659 - val_acc: 0.3429\n",
            "Epoch 16/39\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8572 - acc: 0.7245\n",
            "Epoch 16: val_acc did not improve from 0.61429\n",
            "16/16 [==============================] - 73s 5s/step - loss: 0.8572 - acc: 0.7245 - val_loss: 3.3162 - val_acc: 0.4286\n",
            "Epoch 17/39\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9054 - acc: 0.7102\n",
            "Epoch 17: val_acc did not improve from 0.61429\n",
            "16/16 [==============================] - 73s 5s/step - loss: 0.9054 - acc: 0.7102 - val_loss: 3.9626 - val_acc: 0.4214\n",
            "\n",
            "\n",
            "Model Accuracy 0.45714285714285713\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.45      1.00      0.62        10\n",
            "       10000       0.00      0.00      0.00        10\n",
            "      100000       0.91      1.00      0.95        10\n",
            "        2000       1.00      0.20      0.33        10\n",
            "       20000       0.00      0.00      0.00        10\n",
            "        5000       0.24      0.80      0.37        10\n",
            "       50000       1.00      0.20      0.33        10\n",
            "\n",
            "    accuracy                           0.46        70\n",
            "   macro avg       0.52      0.46      0.37        70\n",
            "weighted avg       0.52      0.46      0.37        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 76 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 42\n",
            "learning rate: 0.05918509628551732\n",
            "batch size: 32\n",
            "dropout rate: 0.7866902326462578\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/42\n",
            "16/16 [==============================] - ETA: 0s - loss: 4.4123 - acc: 0.2041\n",
            "Epoch 1: val_acc improved from -inf to 0.17143, saving model to percobaan76_noImgPro/model\\vgg_16_76-saved-model-01-acc-0.17.hdf5\n",
            "16/16 [==============================] - 74s 5s/step - loss: 4.4123 - acc: 0.2041 - val_loss: 8.1208 - val_acc: 0.1714\n",
            "Epoch 2/42\n",
            "16/16 [==============================] - ETA: 0s - loss: 3.3954 - acc: 0.2755\n",
            "Epoch 2: val_acc improved from 0.17143 to 0.27857, saving model to percobaan76_noImgPro/model\\vgg_16_76-saved-model-02-acc-0.28.hdf5\n",
            "16/16 [==============================] - 73s 5s/step - loss: 3.3954 - acc: 0.2755 - val_loss: 2.7144 - val_acc: 0.2786\n",
            "Epoch 3/42\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.2983 - acc: 0.3041\n",
            "Epoch 3: val_acc did not improve from 0.27857\n",
            "16/16 [==============================] - 73s 5s/step - loss: 2.2983 - acc: 0.3041 - val_loss: 2.2927 - val_acc: 0.2143\n",
            "Epoch 4/42\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.7983 - acc: 0.3551\n",
            "Epoch 4: val_acc improved from 0.27857 to 0.40000, saving model to percobaan76_noImgPro/model\\vgg_16_76-saved-model-04-acc-0.40.hdf5\n",
            "16/16 [==============================] - 73s 5s/step - loss: 1.7983 - acc: 0.3551 - val_loss: 1.8601 - val_acc: 0.4000\n",
            "Epoch 5/42\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.5822 - acc: 0.4327\n",
            "Epoch 5: val_acc did not improve from 0.40000\n",
            "16/16 [==============================] - 73s 5s/step - loss: 1.5822 - acc: 0.4327 - val_loss: 1.9512 - val_acc: 0.3571\n",
            "Epoch 6/42\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.6945 - acc: 0.3857\n",
            "Epoch 6: val_acc did not improve from 0.40000\n",
            "16/16 [==============================] - 73s 5s/step - loss: 1.6945 - acc: 0.3857 - val_loss: 1.5273 - val_acc: 0.3500\n",
            "Epoch 7/42\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.5172 - acc: 0.4531\n",
            "Epoch 7: val_acc improved from 0.40000 to 0.49286, saving model to percobaan76_noImgPro/model\\vgg_16_76-saved-model-07-acc-0.49.hdf5\n",
            "16/16 [==============================] - 73s 5s/step - loss: 1.5172 - acc: 0.4531 - val_loss: 1.3869 - val_acc: 0.4929\n",
            "Epoch 8/42\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.4711 - acc: 0.4714\n",
            "Epoch 8: val_acc did not improve from 0.49286\n",
            "16/16 [==============================] - 73s 5s/step - loss: 1.4711 - acc: 0.4714 - val_loss: 1.3696 - val_acc: 0.4500\n",
            "Epoch 9/42\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.4299 - acc: 0.4857\n",
            "Epoch 9: val_acc did not improve from 0.49286\n",
            "16/16 [==============================] - 73s 5s/step - loss: 1.4299 - acc: 0.4857 - val_loss: 1.5040 - val_acc: 0.3643\n",
            "Epoch 10/42\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2900 - acc: 0.5367\n",
            "Epoch 10: val_acc did not improve from 0.49286\n",
            "16/16 [==============================] - 73s 5s/step - loss: 1.2900 - acc: 0.5367 - val_loss: 1.5298 - val_acc: 0.4000\n",
            "Epoch 11/42\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2362 - acc: 0.5490\n",
            "Epoch 11: val_acc did not improve from 0.49286\n",
            "16/16 [==============================] - 73s 5s/step - loss: 1.2362 - acc: 0.5490 - val_loss: 1.8721 - val_acc: 0.3143\n",
            "Epoch 12/42\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2543 - acc: 0.5653\n",
            "Epoch 12: val_acc did not improve from 0.49286\n",
            "16/16 [==============================] - 73s 5s/step - loss: 1.2543 - acc: 0.5653 - val_loss: 2.3349 - val_acc: 0.2286\n",
            "Epoch 13/42\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3625 - acc: 0.5184\n",
            "Epoch 13: val_acc improved from 0.49286 to 0.57143, saving model to percobaan76_noImgPro/model\\vgg_16_76-saved-model-13-acc-0.57.hdf5\n",
            "16/16 [==============================] - 73s 5s/step - loss: 1.3625 - acc: 0.5184 - val_loss: 1.5056 - val_acc: 0.5714\n",
            "\n",
            "\n",
            "Model Accuracy 0.4857142857142857\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.20      0.33        10\n",
            "       10000       0.67      0.80      0.73        10\n",
            "      100000       1.00      0.20      0.33        10\n",
            "        2000       0.47      0.90      0.62        10\n",
            "       20000       0.00      0.00      0.00        10\n",
            "        5000       0.29      0.80      0.42        10\n",
            "       50000       0.71      0.50      0.59        10\n",
            "\n",
            "    accuracy                           0.49        70\n",
            "   macro avg       0.59      0.49      0.43        70\n",
            "weighted avg       0.59      0.49      0.43        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 77 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 45\n",
            "learning rate: 0.062270088622348334\n",
            "batch size: 64\n",
            "dropout rate: 0.5437485841268793\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.5968 - acc: 0.3224\n",
            "Epoch 1: val_acc improved from -inf to 0.14286, saving model to percobaan77_noImgPro/model\\vgg_16_77-saved-model-01-acc-0.14.hdf5\n",
            "8/8 [==============================] - 86s 11s/step - loss: 2.5968 - acc: 0.3224 - val_loss: 15.7409 - val_acc: 0.1429\n",
            "Epoch 2/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7307 - acc: 0.4673\n",
            "Epoch 2: val_acc improved from 0.14286 to 0.17143, saving model to percobaan77_noImgPro/model\\vgg_16_77-saved-model-02-acc-0.17.hdf5\n",
            "8/8 [==============================] - 85s 11s/step - loss: 1.7307 - acc: 0.4673 - val_loss: 8.4670 - val_acc: 0.1714\n",
            "Epoch 3/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.2233 - acc: 0.6020\n",
            "Epoch 3: val_acc did not improve from 0.17143\n",
            "8/8 [==============================] - 85s 11s/step - loss: 1.2233 - acc: 0.6020 - val_loss: 7.7744 - val_acc: 0.1429\n",
            "Epoch 4/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9680 - acc: 0.6735\n",
            "Epoch 4: val_acc improved from 0.17143 to 0.22143, saving model to percobaan77_noImgPro/model\\vgg_16_77-saved-model-04-acc-0.22.hdf5\n",
            "8/8 [==============================] - 85s 11s/step - loss: 0.9680 - acc: 0.6735 - val_loss: 3.5733 - val_acc: 0.2214\n",
            "Epoch 5/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7754 - acc: 0.7469\n",
            "Epoch 5: val_acc improved from 0.22143 to 0.34286, saving model to percobaan77_noImgPro/model\\vgg_16_77-saved-model-05-acc-0.34.hdf5\n",
            "8/8 [==============================] - 85s 11s/step - loss: 0.7754 - acc: 0.7469 - val_loss: 2.1135 - val_acc: 0.3429\n",
            "Epoch 6/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7274 - acc: 0.7571\n",
            "Epoch 6: val_acc improved from 0.34286 to 0.40000, saving model to percobaan77_noImgPro/model\\vgg_16_77-saved-model-06-acc-0.40.hdf5\n",
            "8/8 [==============================] - 85s 11s/step - loss: 0.7274 - acc: 0.7571 - val_loss: 1.7081 - val_acc: 0.4000\n",
            "Epoch 7/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6241 - acc: 0.7776\n",
            "Epoch 7: val_acc improved from 0.40000 to 0.59286, saving model to percobaan77_noImgPro/model\\vgg_16_77-saved-model-07-acc-0.59.hdf5\n",
            "8/8 [==============================] - 86s 11s/step - loss: 0.6241 - acc: 0.7776 - val_loss: 1.1912 - val_acc: 0.5929\n",
            "Epoch 8/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6291 - acc: 0.8000\n",
            "Epoch 8: val_acc improved from 0.59286 to 0.67143, saving model to percobaan77_noImgPro/model\\vgg_16_77-saved-model-08-acc-0.67.hdf5\n",
            "8/8 [==============================] - 85s 11s/step - loss: 0.6291 - acc: 0.8000 - val_loss: 0.9762 - val_acc: 0.6714\n",
            "Epoch 9/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5638 - acc: 0.8143\n",
            "Epoch 9: val_acc did not improve from 0.67143\n",
            "8/8 [==============================] - 85s 11s/step - loss: 0.5638 - acc: 0.8143 - val_loss: 2.6239 - val_acc: 0.3929\n",
            "Epoch 10/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5135 - acc: 0.8184\n",
            "Epoch 10: val_acc did not improve from 0.67143\n",
            "8/8 [==============================] - 85s 11s/step - loss: 0.5135 - acc: 0.8184 - val_loss: 2.2883 - val_acc: 0.4214\n",
            "Epoch 11/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4800 - acc: 0.8347\n",
            "Epoch 11: val_acc did not improve from 0.67143\n",
            "8/8 [==============================] - 85s 11s/step - loss: 0.4800 - acc: 0.8347 - val_loss: 1.5352 - val_acc: 0.5357\n",
            "Epoch 12/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4477 - acc: 0.8408\n",
            "Epoch 12: val_acc did not improve from 0.67143\n",
            "8/8 [==============================] - 85s 11s/step - loss: 0.4477 - acc: 0.8408 - val_loss: 1.2733 - val_acc: 0.5643\n",
            "Epoch 13/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4711 - acc: 0.8408\n",
            "Epoch 13: val_acc did not improve from 0.67143\n",
            "8/8 [==============================] - 85s 11s/step - loss: 0.4711 - acc: 0.8408 - val_loss: 1.5288 - val_acc: 0.5643\n",
            "\n",
            "\n",
            "Model Accuracy 0.4857142857142857\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.20      0.33        10\n",
            "       10000       1.00      0.50      0.67        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       1.00      0.30      0.46        10\n",
            "       20000       0.30      1.00      0.47        10\n",
            "        5000       0.50      0.70      0.58        10\n",
            "       50000       0.54      0.70      0.61        10\n",
            "\n",
            "    accuracy                           0.49        70\n",
            "   macro avg       0.62      0.49      0.45        70\n",
            "weighted avg       0.62      0.49      0.45        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 78 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 44\n",
            "learning rate: 0.07291144411361447\n",
            "batch size: 64\n",
            "dropout rate: 0.5812252549116338\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.9299 - acc: 0.2408\n",
            "Epoch 1: val_acc improved from -inf to 0.21429, saving model to percobaan78_noImgPro/model\\vgg_16_78-saved-model-01-acc-0.21.hdf5\n",
            "8/8 [==============================] - 81s 10s/step - loss: 2.9299 - acc: 0.2408 - val_loss: 13.4661 - val_acc: 0.2143\n",
            "Epoch 2/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.9650 - acc: 0.4041\n",
            "Epoch 2: val_acc did not improve from 0.21429\n",
            "8/8 [==============================] - 81s 10s/step - loss: 1.9650 - acc: 0.4041 - val_loss: 10.8139 - val_acc: 0.1429\n",
            "Epoch 3/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5174 - acc: 0.4796\n",
            "Epoch 3: val_acc did not improve from 0.21429\n",
            "8/8 [==============================] - 81s 10s/step - loss: 1.5174 - acc: 0.4796 - val_loss: 5.7366 - val_acc: 0.1929\n",
            "Epoch 4/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3971 - acc: 0.5327\n",
            "Epoch 4: val_acc did not improve from 0.21429\n",
            "8/8 [==============================] - 80s 11s/step - loss: 1.3971 - acc: 0.5327 - val_loss: 6.7318 - val_acc: 0.1429\n",
            "Epoch 5/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.2056 - acc: 0.5449\n",
            "Epoch 5: val_acc did not improve from 0.21429\n",
            "8/8 [==============================] - 80s 10s/step - loss: 1.2056 - acc: 0.5449 - val_loss: 5.7436 - val_acc: 0.1500\n",
            "Epoch 6/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0537 - acc: 0.6510\n",
            "Epoch 6: val_acc did not improve from 0.21429\n",
            "8/8 [==============================] - 80s 10s/step - loss: 1.0537 - acc: 0.6510 - val_loss: 8.1063 - val_acc: 0.1500\n",
            "Epoch 7/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9317 - acc: 0.6776\n",
            "Epoch 7: val_acc did not improve from 0.21429\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.9317 - acc: 0.6776 - val_loss: 6.8609 - val_acc: 0.1714\n",
            "Epoch 8/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8878 - acc: 0.6959\n",
            "Epoch 8: val_acc improved from 0.21429 to 0.26429, saving model to percobaan78_noImgPro/model\\vgg_16_78-saved-model-08-acc-0.26.hdf5\n",
            "8/8 [==============================] - 80s 11s/step - loss: 0.8878 - acc: 0.6959 - val_loss: 2.6996 - val_acc: 0.2643\n",
            "Epoch 9/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7495 - acc: 0.7286\n",
            "Epoch 9: val_acc improved from 0.26429 to 0.47143, saving model to percobaan78_noImgPro/model\\vgg_16_78-saved-model-09-acc-0.47.hdf5\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.7495 - acc: 0.7286 - val_loss: 1.3198 - val_acc: 0.4714\n",
            "Epoch 10/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6574 - acc: 0.7551\n",
            "Epoch 10: val_acc did not improve from 0.47143\n",
            "8/8 [==============================] - 81s 10s/step - loss: 0.6574 - acc: 0.7551 - val_loss: 1.5233 - val_acc: 0.4071\n",
            "Epoch 11/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6603 - acc: 0.7776\n",
            "Epoch 11: val_acc did not improve from 0.47143\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.6603 - acc: 0.7776 - val_loss: 4.0742 - val_acc: 0.2286\n",
            "Epoch 12/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5929 - acc: 0.7959\n",
            "Epoch 12: val_acc did not improve from 0.47143\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.5929 - acc: 0.7959 - val_loss: 2.8459 - val_acc: 0.3643\n",
            "Epoch 13/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6588 - acc: 0.7837\n",
            "Epoch 13: val_acc did not improve from 0.47143\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.6588 - acc: 0.7837 - val_loss: 5.1116 - val_acc: 0.2143\n",
            "Epoch 14/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5933 - acc: 0.8000\n",
            "Epoch 14: val_acc did not improve from 0.47143\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.5933 - acc: 0.8000 - val_loss: 2.1420 - val_acc: 0.3714\n",
            "\n",
            "\n",
            "Model Accuracy 0.38571428571428573\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.00      0.00      0.00        10\n",
            "       10000       1.00      0.60      0.75        10\n",
            "      100000       1.00      0.10      0.18        10\n",
            "        2000       0.75      0.30      0.43        10\n",
            "       20000       0.23      1.00      0.37        10\n",
            "        5000       0.67      0.20      0.31        10\n",
            "       50000       0.42      0.50      0.45        10\n",
            "\n",
            "    accuracy                           0.39        70\n",
            "   macro avg       0.58      0.39      0.36        70\n",
            "weighted avg       0.58      0.39      0.36        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 79 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 44\n",
            "learning rate: 0.05159433229172141\n",
            "batch size: 64\n",
            "dropout rate: 0.6767810530881683\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.9694 - acc: 0.2633\n",
            "Epoch 1: val_acc improved from -inf to 0.14286, saving model to percobaan79_noImgPro/model\\vgg_16_79-saved-model-01-acc-0.14.hdf5\n",
            "8/8 [==============================] - 79s 10s/step - loss: 2.9694 - acc: 0.2633 - val_loss: 17.4384 - val_acc: 0.1429\n",
            "Epoch 2/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.1596 - acc: 0.3714\n",
            "Epoch 2: val_acc improved from 0.14286 to 0.20714, saving model to percobaan79_noImgPro/model\\vgg_16_79-saved-model-02-acc-0.21.hdf5\n",
            "8/8 [==============================] - 77s 10s/step - loss: 2.1596 - acc: 0.3714 - val_loss: 7.6899 - val_acc: 0.2071\n",
            "Epoch 3/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7216 - acc: 0.4571\n",
            "Epoch 3: val_acc improved from 0.20714 to 0.22857, saving model to percobaan79_noImgPro/model\\vgg_16_79-saved-model-03-acc-0.23.hdf5\n",
            "8/8 [==============================] - 78s 10s/step - loss: 1.7216 - acc: 0.4571 - val_loss: 6.0785 - val_acc: 0.2286\n",
            "Epoch 4/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4371 - acc: 0.4837\n",
            "Epoch 4: val_acc improved from 0.22857 to 0.33571, saving model to percobaan79_noImgPro/model\\vgg_16_79-saved-model-04-acc-0.34.hdf5\n",
            "8/8 [==============================] - 77s 10s/step - loss: 1.4371 - acc: 0.4837 - val_loss: 4.0593 - val_acc: 0.3357\n",
            "Epoch 5/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1396 - acc: 0.5694\n",
            "Epoch 5: val_acc did not improve from 0.33571\n",
            "8/8 [==============================] - 77s 10s/step - loss: 1.1396 - acc: 0.5694 - val_loss: 3.0980 - val_acc: 0.3286\n",
            "Epoch 6/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0050 - acc: 0.6367\n",
            "Epoch 6: val_acc did not improve from 0.33571\n",
            "8/8 [==============================] - 77s 10s/step - loss: 1.0050 - acc: 0.6367 - val_loss: 2.7388 - val_acc: 0.3357\n",
            "Epoch 7/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8834 - acc: 0.6918\n",
            "Epoch 7: val_acc did not improve from 0.33571\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.8834 - acc: 0.6918 - val_loss: 2.8755 - val_acc: 0.3143\n",
            "Epoch 8/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8412 - acc: 0.6878\n",
            "Epoch 8: val_acc did not improve from 0.33571\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.8412 - acc: 0.6878 - val_loss: 2.7059 - val_acc: 0.2929\n",
            "Epoch 9/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6673 - acc: 0.7776\n",
            "Epoch 9: val_acc improved from 0.33571 to 0.41429, saving model to percobaan79_noImgPro/model\\vgg_16_79-saved-model-09-acc-0.41.hdf5\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.6673 - acc: 0.7776 - val_loss: 2.2330 - val_acc: 0.4143\n",
            "Epoch 10/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6259 - acc: 0.7776\n",
            "Epoch 10: val_acc improved from 0.41429 to 0.52857, saving model to percobaan79_noImgPro/model\\vgg_16_79-saved-model-10-acc-0.53.hdf5\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.6259 - acc: 0.7776 - val_loss: 1.2964 - val_acc: 0.5286\n",
            "Epoch 11/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7309 - acc: 0.7286\n",
            "Epoch 11: val_acc improved from 0.52857 to 0.63571, saving model to percobaan79_noImgPro/model\\vgg_16_79-saved-model-11-acc-0.64.hdf5\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.7309 - acc: 0.7286 - val_loss: 1.1381 - val_acc: 0.6357\n",
            "Epoch 12/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7254 - acc: 0.7469\n",
            "Epoch 12: val_acc improved from 0.63571 to 0.65714, saving model to percobaan79_noImgPro/model\\vgg_16_79-saved-model-12-acc-0.66.hdf5\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.7254 - acc: 0.7469 - val_loss: 0.9541 - val_acc: 0.6571\n",
            "Epoch 13/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5293 - acc: 0.8122\n",
            "Epoch 13: val_acc did not improve from 0.65714\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.5293 - acc: 0.8122 - val_loss: 1.4710 - val_acc: 0.4143\n",
            "Epoch 14/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5616 - acc: 0.7939\n",
            "Epoch 14: val_acc did not improve from 0.65714\n",
            "8/8 [==============================] - 82s 11s/step - loss: 0.5616 - acc: 0.7939 - val_loss: 1.7041 - val_acc: 0.3500\n",
            "Epoch 15/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5011 - acc: 0.8265\n",
            "Epoch 15: val_acc improved from 0.65714 to 0.70714, saving model to percobaan79_noImgPro/model\\vgg_16_79-saved-model-15-acc-0.71.hdf5\n",
            "8/8 [==============================] - 81s 10s/step - loss: 0.5011 - acc: 0.8265 - val_loss: 0.8737 - val_acc: 0.7071\n",
            "Epoch 16/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5712 - acc: 0.7980\n",
            "Epoch 16: val_acc improved from 0.70714 to 0.74286, saving model to percobaan79_noImgPro/model\\vgg_16_79-saved-model-16-acc-0.74.hdf5\n",
            "8/8 [==============================] - 78s 10s/step - loss: 0.5712 - acc: 0.7980 - val_loss: 0.8904 - val_acc: 0.7429\n",
            "Epoch 17/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4426 - acc: 0.8408\n",
            "Epoch 17: val_acc did not improve from 0.74286\n",
            "8/8 [==============================] - 78s 10s/step - loss: 0.4426 - acc: 0.8408 - val_loss: 1.0297 - val_acc: 0.6643\n",
            "Epoch 18/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4994 - acc: 0.8184\n",
            "Epoch 18: val_acc did not improve from 0.74286\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.4994 - acc: 0.8184 - val_loss: 0.8363 - val_acc: 0.7071\n",
            "Epoch 19/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5098 - acc: 0.8327\n",
            "Epoch 19: val_acc did not improve from 0.74286\n",
            "8/8 [==============================] - 78s 10s/step - loss: 0.5098 - acc: 0.8327 - val_loss: 1.4351 - val_acc: 0.5500\n",
            "Epoch 20/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4538 - acc: 0.8265\n",
            "Epoch 20: val_acc did not improve from 0.74286\n",
            "8/8 [==============================] - 78s 10s/step - loss: 0.4538 - acc: 0.8265 - val_loss: 1.2494 - val_acc: 0.5714\n",
            "Epoch 21/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5034 - acc: 0.8388\n",
            "Epoch 21: val_acc did not improve from 0.74286\n",
            "8/8 [==============================] - 78s 10s/step - loss: 0.5034 - acc: 0.8388 - val_loss: 1.0522 - val_acc: 0.6714\n",
            "Epoch 22/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5512 - acc: 0.8245\n",
            "Epoch 22: val_acc did not improve from 0.74286\n",
            "8/8 [==============================] - 78s 10s/step - loss: 0.5512 - acc: 0.8245 - val_loss: 1.0109 - val_acc: 0.7143\n",
            "Epoch 23/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5690 - acc: 0.8061\n",
            "Epoch 23: val_acc did not improve from 0.74286\n",
            "8/8 [==============================] - 78s 10s/step - loss: 0.5690 - acc: 0.8061 - val_loss: 1.1343 - val_acc: 0.6214\n",
            "\n",
            "\n",
            "Model Accuracy 0.5714285714285714\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.89      0.80      0.84        10\n",
            "       10000       1.00      0.60      0.75        10\n",
            "      100000       1.00      0.30      0.46        10\n",
            "        2000       0.62      0.50      0.56        10\n",
            "       20000       0.00      0.00      0.00        10\n",
            "        5000       0.67      0.80      0.73        10\n",
            "       50000       0.31      1.00      0.48        10\n",
            "\n",
            "    accuracy                           0.57        70\n",
            "   macro avg       0.64      0.57      0.54        70\n",
            "weighted avg       0.64      0.57      0.54        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 80 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 44\n",
            "learning rate: 0.06885726003756203\n",
            "batch size: 64\n",
            "dropout rate: 0.7618449154168362\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 4.0626 - acc: 0.2245\n",
            "Epoch 1: val_acc improved from -inf to 0.21429, saving model to percobaan80_noImgPro/model\\vgg_16_80-saved-model-01-acc-0.21.hdf5\n",
            "8/8 [==============================] - 79s 10s/step - loss: 4.0626 - acc: 0.2245 - val_loss: 8.7547 - val_acc: 0.2143\n",
            "Epoch 2/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.9787 - acc: 0.3020\n",
            "Epoch 2: val_acc did not improve from 0.21429\n",
            "8/8 [==============================] - 76s 10s/step - loss: 2.9787 - acc: 0.3020 - val_loss: 11.7916 - val_acc: 0.1786\n",
            "Epoch 3/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.0736 - acc: 0.3551\n",
            "Epoch 3: val_acc did not improve from 0.21429\n",
            "8/8 [==============================] - 76s 10s/step - loss: 2.0736 - acc: 0.3551 - val_loss: 6.3531 - val_acc: 0.2143\n",
            "Epoch 4/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7331 - acc: 0.3939\n",
            "Epoch 4: val_acc did not improve from 0.21429\n",
            "8/8 [==============================] - 76s 10s/step - loss: 1.7331 - acc: 0.3939 - val_loss: 4.3484 - val_acc: 0.1857\n",
            "Epoch 5/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5667 - acc: 0.4469\n",
            "Epoch 5: val_acc did not improve from 0.21429\n",
            "8/8 [==============================] - 76s 10s/step - loss: 1.5667 - acc: 0.4469 - val_loss: 3.1672 - val_acc: 0.1714\n",
            "Epoch 6/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4916 - acc: 0.4327\n",
            "Epoch 6: val_acc did not improve from 0.21429\n",
            "8/8 [==============================] - 76s 10s/step - loss: 1.4916 - acc: 0.4327 - val_loss: 3.4981 - val_acc: 0.1786\n",
            "Epoch 7/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3129 - acc: 0.5061\n",
            "Epoch 7: val_acc did not improve from 0.21429\n",
            "8/8 [==============================] - 76s 10s/step - loss: 1.3129 - acc: 0.5061 - val_loss: 4.3284 - val_acc: 0.1714\n",
            "Epoch 8/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.2127 - acc: 0.5776\n",
            "Epoch 8: val_acc improved from 0.21429 to 0.25714, saving model to percobaan80_noImgPro/model\\vgg_16_80-saved-model-08-acc-0.26.hdf5\n",
            "8/8 [==============================] - 76s 10s/step - loss: 1.2127 - acc: 0.5776 - val_loss: 2.5603 - val_acc: 0.2571\n",
            "Epoch 9/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.2283 - acc: 0.5490\n",
            "Epoch 9: val_acc improved from 0.25714 to 0.26429, saving model to percobaan80_noImgPro/model\\vgg_16_80-saved-model-09-acc-0.26.hdf5\n",
            "8/8 [==============================] - 76s 10s/step - loss: 1.2283 - acc: 0.5490 - val_loss: 2.9108 - val_acc: 0.2643\n",
            "Epoch 10/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1000 - acc: 0.6020\n",
            "Epoch 10: val_acc did not improve from 0.26429\n",
            "8/8 [==============================] - 76s 10s/step - loss: 1.1000 - acc: 0.6020 - val_loss: 2.9630 - val_acc: 0.2500\n",
            "Epoch 11/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0604 - acc: 0.6224\n",
            "Epoch 11: val_acc did not improve from 0.26429\n",
            "8/8 [==============================] - 76s 10s/step - loss: 1.0604 - acc: 0.6224 - val_loss: 3.0595 - val_acc: 0.2643\n",
            "Epoch 12/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0352 - acc: 0.6367\n",
            "Epoch 12: val_acc improved from 0.26429 to 0.27857, saving model to percobaan80_noImgPro/model\\vgg_16_80-saved-model-12-acc-0.28.hdf5\n",
            "8/8 [==============================] - 76s 10s/step - loss: 1.0352 - acc: 0.6367 - val_loss: 2.5540 - val_acc: 0.2786\n",
            "Epoch 13/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0146 - acc: 0.6408\n",
            "Epoch 13: val_acc improved from 0.27857 to 0.29286, saving model to percobaan80_noImgPro/model\\vgg_16_80-saved-model-13-acc-0.29.hdf5\n",
            "8/8 [==============================] - 77s 10s/step - loss: 1.0146 - acc: 0.6408 - val_loss: 2.5178 - val_acc: 0.2929\n",
            "Epoch 14/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9891 - acc: 0.6755\n",
            "Epoch 14: val_acc improved from 0.29286 to 0.34286, saving model to percobaan80_noImgPro/model\\vgg_16_80-saved-model-14-acc-0.34.hdf5\n",
            "8/8 [==============================] - 76s 10s/step - loss: 0.9891 - acc: 0.6755 - val_loss: 2.1626 - val_acc: 0.3429\n",
            "Epoch 15/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8282 - acc: 0.6939\n",
            "Epoch 15: val_acc did not improve from 0.34286\n",
            "8/8 [==============================] - 76s 10s/step - loss: 0.8282 - acc: 0.6939 - val_loss: 2.0892 - val_acc: 0.3143\n",
            "Epoch 16/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9270 - acc: 0.6918\n",
            "Epoch 16: val_acc improved from 0.34286 to 0.58571, saving model to percobaan80_noImgPro/model\\vgg_16_80-saved-model-16-acc-0.59.hdf5\n",
            "8/8 [==============================] - 76s 10s/step - loss: 0.9270 - acc: 0.6918 - val_loss: 1.0496 - val_acc: 0.5857\n",
            "Epoch 17/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8515 - acc: 0.6939\n",
            "Epoch 17: val_acc improved from 0.58571 to 0.62857, saving model to percobaan80_noImgPro/model\\vgg_16_80-saved-model-17-acc-0.63.hdf5\n",
            "8/8 [==============================] - 77s 10s/step - loss: 0.8515 - acc: 0.6939 - val_loss: 1.0632 - val_acc: 0.6286\n",
            "Epoch 18/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8211 - acc: 0.7041\n",
            "Epoch 18: val_acc did not improve from 0.62857\n",
            "8/8 [==============================] - 76s 10s/step - loss: 0.8211 - acc: 0.7041 - val_loss: 1.5089 - val_acc: 0.5429\n",
            "Epoch 19/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8096 - acc: 0.7020\n",
            "Epoch 19: val_acc did not improve from 0.62857\n",
            "8/8 [==============================] - 76s 10s/step - loss: 0.8096 - acc: 0.7020 - val_loss: 1.6273 - val_acc: 0.4571\n",
            "Epoch 20/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7636 - acc: 0.7469\n",
            "Epoch 20: val_acc did not improve from 0.62857\n",
            "8/8 [==============================] - 76s 10s/step - loss: 0.7636 - acc: 0.7469 - val_loss: 1.7106 - val_acc: 0.4500\n",
            "Epoch 21/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7523 - acc: 0.7510\n",
            "Epoch 21: val_acc did not improve from 0.62857\n",
            "8/8 [==============================] - 76s 10s/step - loss: 0.7523 - acc: 0.7510 - val_loss: 1.2391 - val_acc: 0.5786\n",
            "\n",
            "\n",
            "Model Accuracy 0.5428571428571428\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.45      1.00      0.62        10\n",
            "       10000       1.00      0.20      0.33        10\n",
            "      100000       1.00      0.40      0.57        10\n",
            "        2000       1.00      0.20      0.33        10\n",
            "       20000       0.32      0.80      0.46        10\n",
            "        5000       0.80      0.40      0.53        10\n",
            "       50000       0.80      0.80      0.80        10\n",
            "\n",
            "    accuracy                           0.54        70\n",
            "   macro avg       0.77      0.54      0.52        70\n",
            "weighted avg       0.77      0.54      0.52        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 81 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 47\n",
            "learning rate: 0.05971504934655231\n",
            "batch size: 128\n",
            "dropout rate: 0.5527144773507067\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.6217 - acc: 0.2796 \n",
            "Epoch 1: val_acc improved from -inf to 0.26429, saving model to percobaan81_noImgPro/model\\vgg_16_81-saved-model-01-acc-0.26.hdf5\n",
            "4/4 [==============================] - 77s 20s/step - loss: 2.6217 - acc: 0.2796 - val_loss: 7.9772 - val_acc: 0.2643\n",
            "Epoch 2/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.6391 - acc: 0.5102 \n",
            "Epoch 2: val_acc did not improve from 0.26429\n",
            "4/4 [==============================] - 77s 20s/step - loss: 1.6391 - acc: 0.5102 - val_loss: 9.9216 - val_acc: 0.1429\n",
            "Epoch 3/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.3580 - acc: 0.5755 \n",
            "Epoch 3: val_acc improved from 0.26429 to 0.47143, saving model to percobaan81_noImgPro/model\\vgg_16_81-saved-model-03-acc-0.47.hdf5\n",
            "4/4 [==============================] - 77s 20s/step - loss: 1.3580 - acc: 0.5755 - val_loss: 4.4881 - val_acc: 0.4714\n",
            "Epoch 4/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1099 - acc: 0.6347 \n",
            "Epoch 4: val_acc did not improve from 0.47143\n",
            "4/4 [==============================] - 77s 20s/step - loss: 1.1099 - acc: 0.6347 - val_loss: 4.4034 - val_acc: 0.4643\n",
            "Epoch 5/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9180 - acc: 0.6796 \n",
            "Epoch 5: val_acc did not improve from 0.47143\n",
            "4/4 [==============================] - 77s 20s/step - loss: 0.9180 - acc: 0.6796 - val_loss: 4.6787 - val_acc: 0.4071\n",
            "Epoch 6/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7002 - acc: 0.7612 \n",
            "Epoch 6: val_acc did not improve from 0.47143\n",
            "4/4 [==============================] - 77s 21s/step - loss: 0.7002 - acc: 0.7612 - val_loss: 5.5095 - val_acc: 0.3000\n",
            "Epoch 7/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6098 - acc: 0.7776 \n",
            "Epoch 7: val_acc did not improve from 0.47143\n",
            "4/4 [==============================] - 77s 20s/step - loss: 0.6098 - acc: 0.7776 - val_loss: 4.9924 - val_acc: 0.2643\n",
            "Epoch 8/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5748 - acc: 0.8061 \n",
            "Epoch 8: val_acc did not improve from 0.47143\n",
            "4/4 [==============================] - 77s 20s/step - loss: 0.5748 - acc: 0.8061 - val_loss: 4.0831 - val_acc: 0.3071\n",
            "Epoch 9/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5224 - acc: 0.8184 \n",
            "Epoch 9: val_acc did not improve from 0.47143\n",
            "4/4 [==============================] - 77s 20s/step - loss: 0.5224 - acc: 0.8184 - val_loss: 4.2330 - val_acc: 0.2857\n",
            "Epoch 10/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4309 - acc: 0.8531 \n",
            "Epoch 10: val_acc did not improve from 0.47143\n",
            "4/4 [==============================] - 77s 20s/step - loss: 0.4309 - acc: 0.8531 - val_loss: 4.3259 - val_acc: 0.2714\n",
            "Epoch 11/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4950 - acc: 0.8490 \n",
            "Epoch 11: val_acc did not improve from 0.47143\n",
            "4/4 [==============================] - 77s 20s/step - loss: 0.4950 - acc: 0.8490 - val_loss: 4.2457 - val_acc: 0.2643\n",
            "Epoch 12/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3232 - acc: 0.8735 \n",
            "Epoch 12: val_acc did not improve from 0.47143\n",
            "4/4 [==============================] - 77s 21s/step - loss: 0.3232 - acc: 0.8735 - val_loss: 3.7924 - val_acc: 0.3357\n",
            "Epoch 13/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3771 - acc: 0.8592 \n",
            "Epoch 13: val_acc did not improve from 0.47143\n",
            "4/4 [==============================] - 77s 20s/step - loss: 0.3771 - acc: 0.8592 - val_loss: 3.1320 - val_acc: 0.4071\n",
            "Epoch 14/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3263 - acc: 0.8878 \n",
            "Epoch 14: val_acc did not improve from 0.47143\n",
            "4/4 [==============================] - 77s 20s/step - loss: 0.3263 - acc: 0.8878 - val_loss: 3.4631 - val_acc: 0.3857\n",
            "Epoch 15/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4145 - acc: 0.8673 \n",
            "Epoch 15: val_acc did not improve from 0.47143\n",
            "4/4 [==============================] - 77s 20s/step - loss: 0.4145 - acc: 0.8673 - val_loss: 3.6225 - val_acc: 0.4000\n",
            "Epoch 16/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3663 - acc: 0.8837 \n",
            "Epoch 16: val_acc did not improve from 0.47143\n",
            "4/4 [==============================] - 77s 20s/step - loss: 0.3663 - acc: 0.8837 - val_loss: 3.3100 - val_acc: 0.4071\n",
            "Epoch 17/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3028 - acc: 0.9163 \n",
            "Epoch 17: val_acc did not improve from 0.47143\n",
            "4/4 [==============================] - 77s 20s/step - loss: 0.3028 - acc: 0.9163 - val_loss: 3.3878 - val_acc: 0.3643\n",
            "Epoch 18/47\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3306 - acc: 0.8980 \n",
            "Epoch 18: val_acc did not improve from 0.47143\n",
            "4/4 [==============================] - 77s 20s/step - loss: 0.3306 - acc: 0.8980 - val_loss: 3.2416 - val_acc: 0.3643\n",
            "\n",
            "\n",
            "Model Accuracy 0.2857142857142857\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.10      0.18        10\n",
            "       10000       0.47      0.80      0.59        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.50      0.10      0.17        10\n",
            "       20000       0.00      0.00      0.00        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       0.20      1.00      0.33        10\n",
            "\n",
            "    accuracy                           0.29        70\n",
            "   macro avg       0.31      0.29      0.18        70\n",
            "weighted avg       0.31      0.29      0.18        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 82 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 39\n",
            "learning rate: 0.06266656947744377\n",
            "batch size: 128\n",
            "dropout rate: 0.6064223618744655\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.9026 - acc: 0.2694 \n",
            "Epoch 1: val_acc improved from -inf to 0.25714, saving model to percobaan82_noImgPro/model\\vgg_16_82-saved-model-01-acc-0.26.hdf5\n",
            "4/4 [==============================] - 77s 20s/step - loss: 2.9026 - acc: 0.2694 - val_loss: 6.4822 - val_acc: 0.2571\n",
            "Epoch 2/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.0590 - acc: 0.3939 \n",
            "Epoch 2: val_acc did not improve from 0.25714\n",
            "4/4 [==============================] - 76s 20s/step - loss: 2.0590 - acc: 0.3939 - val_loss: 8.2547 - val_acc: 0.1929\n",
            "Epoch 3/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.6454 - acc: 0.4653 \n",
            "Epoch 3: val_acc did not improve from 0.25714\n",
            "4/4 [==============================] - 76s 20s/step - loss: 1.6454 - acc: 0.4653 - val_loss: 8.6639 - val_acc: 0.2214\n",
            "Epoch 4/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0903 - acc: 0.6224 \n",
            "Epoch 4: val_acc improved from 0.25714 to 0.26429, saving model to percobaan82_noImgPro/model\\vgg_16_82-saved-model-04-acc-0.26.hdf5\n",
            "4/4 [==============================] - 76s 20s/step - loss: 1.0903 - acc: 0.6224 - val_loss: 5.1841 - val_acc: 0.2643\n",
            "Epoch 5/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9673 - acc: 0.6449 \n",
            "Epoch 5: val_acc improved from 0.26429 to 0.40000, saving model to percobaan82_noImgPro/model\\vgg_16_82-saved-model-05-acc-0.40.hdf5\n",
            "4/4 [==============================] - 76s 20s/step - loss: 0.9673 - acc: 0.6449 - val_loss: 2.7853 - val_acc: 0.4000\n",
            "Epoch 6/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9231 - acc: 0.6837 \n",
            "Epoch 6: val_acc did not improve from 0.40000\n",
            "4/4 [==============================] - 76s 20s/step - loss: 0.9231 - acc: 0.6837 - val_loss: 3.6812 - val_acc: 0.3143\n",
            "Epoch 7/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7436 - acc: 0.7306 \n",
            "Epoch 7: val_acc did not improve from 0.40000\n",
            "4/4 [==============================] - 76s 21s/step - loss: 0.7436 - acc: 0.7306 - val_loss: 4.5452 - val_acc: 0.2786\n",
            "Epoch 8/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7053 - acc: 0.7571 \n",
            "Epoch 8: val_acc did not improve from 0.40000\n",
            "4/4 [==============================] - 76s 20s/step - loss: 0.7053 - acc: 0.7571 - val_loss: 5.2560 - val_acc: 0.2571\n",
            "Epoch 9/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6166 - acc: 0.7735 \n",
            "Epoch 9: val_acc did not improve from 0.40000\n",
            "4/4 [==============================] - 76s 20s/step - loss: 0.6166 - acc: 0.7735 - val_loss: 4.1217 - val_acc: 0.3071\n",
            "Epoch 10/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5705 - acc: 0.8061 \n",
            "Epoch 10: val_acc improved from 0.40000 to 0.40714, saving model to percobaan82_noImgPro/model\\vgg_16_82-saved-model-10-acc-0.41.hdf5\n",
            "4/4 [==============================] - 76s 21s/step - loss: 0.5705 - acc: 0.8061 - val_loss: 2.4447 - val_acc: 0.4071\n",
            "Epoch 11/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5351 - acc: 0.8041 \n",
            "Epoch 11: val_acc did not improve from 0.40714\n",
            "4/4 [==============================] - 76s 20s/step - loss: 0.5351 - acc: 0.8041 - val_loss: 2.7201 - val_acc: 0.3571\n",
            "Epoch 12/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4610 - acc: 0.8469 \n",
            "Epoch 12: val_acc did not improve from 0.40714\n",
            "4/4 [==============================] - 76s 21s/step - loss: 0.4610 - acc: 0.8469 - val_loss: 2.8953 - val_acc: 0.3643\n",
            "Epoch 13/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4041 - acc: 0.8571 \n",
            "Epoch 13: val_acc did not improve from 0.40714\n",
            "4/4 [==============================] - 76s 21s/step - loss: 0.4041 - acc: 0.8571 - val_loss: 3.6744 - val_acc: 0.3071\n",
            "Epoch 14/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4187 - acc: 0.8612 \n",
            "Epoch 14: val_acc did not improve from 0.40714\n",
            "4/4 [==============================] - 76s 20s/step - loss: 0.4187 - acc: 0.8612 - val_loss: 4.2218 - val_acc: 0.2643\n",
            "Epoch 15/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3960 - acc: 0.8571 \n",
            "Epoch 15: val_acc did not improve from 0.40714\n",
            "4/4 [==============================] - 76s 20s/step - loss: 0.3960 - acc: 0.8571 - val_loss: 3.9662 - val_acc: 0.2786\n",
            "\n",
            "\n",
            "Model Accuracy 0.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.10      0.18        10\n",
            "       10000       0.33      0.10      0.15        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.00      0.00      0.00        10\n",
            "       20000       0.67      0.20      0.31        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       0.16      1.00      0.27        10\n",
            "\n",
            "    accuracy                           0.20        70\n",
            "   macro avg       0.31      0.20      0.13        70\n",
            "weighted avg       0.31      0.20      0.13        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 83 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 40\n",
            "learning rate: 0.062827615143139\n",
            "batch size: 128\n",
            "dropout rate: 0.6712696140217007\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 3.0405 - acc: 0.2980 \n",
            "Epoch 1: val_acc improved from -inf to 0.15714, saving model to percobaan83_noImgPro/model\\vgg_16_83-saved-model-01-acc-0.16.hdf5\n",
            "4/4 [==============================] - 76s 21s/step - loss: 3.0405 - acc: 0.2980 - val_loss: 14.2008 - val_acc: 0.1571\n",
            "Epoch 2/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.0880 - acc: 0.3735 \n",
            "Epoch 2: val_acc improved from 0.15714 to 0.17857, saving model to percobaan83_noImgPro/model\\vgg_16_83-saved-model-02-acc-0.18.hdf5\n",
            "4/4 [==============================] - 76s 21s/step - loss: 2.0880 - acc: 0.3735 - val_loss: 12.8197 - val_acc: 0.1786\n",
            "Epoch 3/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.7731 - acc: 0.4653 \n",
            "Epoch 3: val_acc improved from 0.17857 to 0.26429, saving model to percobaan83_noImgPro/model\\vgg_16_83-saved-model-03-acc-0.26.hdf5\n",
            "4/4 [==============================] - 76s 20s/step - loss: 1.7731 - acc: 0.4653 - val_loss: 10.4094 - val_acc: 0.2643\n",
            "Epoch 4/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.4786 - acc: 0.5265 \n",
            "Epoch 4: val_acc did not improve from 0.26429\n",
            "4/4 [==============================] - 75s 20s/step - loss: 1.4786 - acc: 0.5265 - val_loss: 10.6324 - val_acc: 0.2357\n",
            "Epoch 5/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2658 - acc: 0.5571 \n",
            "Epoch 5: val_acc improved from 0.26429 to 0.27857, saving model to percobaan83_noImgPro/model\\vgg_16_83-saved-model-05-acc-0.28.hdf5\n",
            "4/4 [==============================] - 75s 20s/step - loss: 1.2658 - acc: 0.5571 - val_loss: 8.6952 - val_acc: 0.2786\n",
            "Epoch 6/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0477 - acc: 0.6469 \n",
            "Epoch 6: val_acc did not improve from 0.27857\n",
            "4/4 [==============================] - 76s 20s/step - loss: 1.0477 - acc: 0.6469 - val_loss: 6.1288 - val_acc: 0.2357\n",
            "Epoch 7/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9309 - acc: 0.6755 \n",
            "Epoch 7: val_acc did not improve from 0.27857\n",
            "4/4 [==============================] - 75s 20s/step - loss: 0.9309 - acc: 0.6755 - val_loss: 4.9540 - val_acc: 0.2357\n",
            "Epoch 8/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9388 - acc: 0.6531 \n",
            "Epoch 8: val_acc did not improve from 0.27857\n",
            "4/4 [==============================] - 75s 20s/step - loss: 0.9388 - acc: 0.6531 - val_loss: 4.6974 - val_acc: 0.2571\n",
            "Epoch 9/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7695 - acc: 0.7224 \n",
            "Epoch 9: val_acc improved from 0.27857 to 0.30714, saving model to percobaan83_noImgPro/model\\vgg_16_83-saved-model-09-acc-0.31.hdf5\n",
            "4/4 [==============================] - 75s 21s/step - loss: 0.7695 - acc: 0.7224 - val_loss: 4.6391 - val_acc: 0.3071\n",
            "Epoch 10/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6805 - acc: 0.7531 \n",
            "Epoch 10: val_acc did not improve from 0.30714\n",
            "4/4 [==============================] - 76s 21s/step - loss: 0.6805 - acc: 0.7531 - val_loss: 4.1416 - val_acc: 0.3071\n",
            "Epoch 11/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6975 - acc: 0.7510 \n",
            "Epoch 11: val_acc did not improve from 0.30714\n",
            "4/4 [==============================] - 76s 21s/step - loss: 0.6975 - acc: 0.7510 - val_loss: 3.9764 - val_acc: 0.3071\n",
            "Epoch 12/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5633 - acc: 0.8143 \n",
            "Epoch 12: val_acc did not improve from 0.30714\n",
            "4/4 [==============================] - 76s 20s/step - loss: 0.5633 - acc: 0.8143 - val_loss: 4.0721 - val_acc: 0.3000\n",
            "Epoch 13/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6796 - acc: 0.7633 \n",
            "Epoch 13: val_acc improved from 0.30714 to 0.34286, saving model to percobaan83_noImgPro/model\\vgg_16_83-saved-model-13-acc-0.34.hdf5\n",
            "4/4 [==============================] - 76s 20s/step - loss: 0.6796 - acc: 0.7633 - val_loss: 3.7505 - val_acc: 0.3429\n",
            "Epoch 14/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5182 - acc: 0.8245 \n",
            "Epoch 14: val_acc improved from 0.34286 to 0.40000, saving model to percobaan83_noImgPro/model\\vgg_16_83-saved-model-14-acc-0.40.hdf5\n",
            "4/4 [==============================] - 77s 20s/step - loss: 0.5182 - acc: 0.8245 - val_loss: 2.6194 - val_acc: 0.4000\n",
            "Epoch 15/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5298 - acc: 0.8184 \n",
            "Epoch 15: val_acc did not improve from 0.40000\n",
            "4/4 [==============================] - 76s 20s/step - loss: 0.5298 - acc: 0.8184 - val_loss: 2.1111 - val_acc: 0.3786\n",
            "Epoch 16/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4760 - acc: 0.8184 \n",
            "Epoch 16: val_acc did not improve from 0.40000\n",
            "4/4 [==============================] - 76s 20s/step - loss: 0.4760 - acc: 0.8184 - val_loss: 2.9739 - val_acc: 0.3214\n",
            "Epoch 17/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4486 - acc: 0.8408 \n",
            "Epoch 17: val_acc improved from 0.40000 to 0.41429, saving model to percobaan83_noImgPro/model\\vgg_16_83-saved-model-17-acc-0.41.hdf5\n",
            "4/4 [==============================] - 76s 20s/step - loss: 0.4486 - acc: 0.8408 - val_loss: 2.9270 - val_acc: 0.4143\n",
            "Epoch 18/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3937 - acc: 0.8694 \n",
            "Epoch 18: val_acc improved from 0.41429 to 0.43571, saving model to percobaan83_noImgPro/model\\vgg_16_83-saved-model-18-acc-0.44.hdf5\n",
            "4/4 [==============================] - 76s 20s/step - loss: 0.3937 - acc: 0.8694 - val_loss: 2.4079 - val_acc: 0.4357\n",
            "Epoch 19/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4264 - acc: 0.8531 \n",
            "Epoch 19: val_acc improved from 0.43571 to 0.47143, saving model to percobaan83_noImgPro/model\\vgg_16_83-saved-model-19-acc-0.47.hdf5\n",
            "4/4 [==============================] - 76s 20s/step - loss: 0.4264 - acc: 0.8531 - val_loss: 2.2710 - val_acc: 0.4714\n",
            "Epoch 20/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4769 - acc: 0.8306 \n",
            "Epoch 20: val_acc improved from 0.47143 to 0.47857, saving model to percobaan83_noImgPro/model\\vgg_16_83-saved-model-20-acc-0.48.hdf5\n",
            "4/4 [==============================] - 76s 20s/step - loss: 0.4769 - acc: 0.8306 - val_loss: 2.2583 - val_acc: 0.4786\n",
            "\n",
            "\n",
            "Model Accuracy 0.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.45      0.50      0.48        10\n",
            "       10000       0.83      0.50      0.62        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.00      0.00      0.00        10\n",
            "       20000       0.00      0.00      0.00        10\n",
            "        5000       1.00      0.10      0.18        10\n",
            "       50000       0.20      1.00      0.34        10\n",
            "\n",
            "    accuracy                           0.30        70\n",
            "   macro avg       0.36      0.30      0.23        70\n",
            "weighted avg       0.36      0.30      0.23        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 84 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 44\n",
            "learning rate: 0.05440035592238784\n",
            "batch size: 128\n",
            "dropout rate: 0.7474872199419714\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/44\n",
            "4/4 [==============================] - ETA: 0s - loss: 3.1140 - acc: 0.2490 \n",
            "Epoch 1: val_acc improved from -inf to 0.14286, saving model to percobaan84_noImgPro/model\\vgg_16_84-saved-model-01-acc-0.14.hdf5\n",
            "4/4 [==============================] - 76s 20s/step - loss: 3.1140 - acc: 0.2490 - val_loss: 9.1788 - val_acc: 0.1429\n",
            "Epoch 2/44\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.5085 - acc: 0.3449 \n",
            "Epoch 2: val_acc improved from 0.14286 to 0.19286, saving model to percobaan84_noImgPro/model\\vgg_16_84-saved-model-02-acc-0.19.hdf5\n",
            "4/4 [==============================] - 76s 20s/step - loss: 2.5085 - acc: 0.3449 - val_loss: 4.8112 - val_acc: 0.1929\n",
            "Epoch 3/44\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.9841 - acc: 0.4163 \n",
            "Epoch 3: val_acc improved from 0.19286 to 0.34286, saving model to percobaan84_noImgPro/model\\vgg_16_84-saved-model-03-acc-0.34.hdf5\n",
            "4/4 [==============================] - 76s 20s/step - loss: 1.9841 - acc: 0.4163 - val_loss: 3.9728 - val_acc: 0.3429\n",
            "Epoch 4/44\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.6685 - acc: 0.4551 \n",
            "Epoch 4: val_acc improved from 0.34286 to 0.36429, saving model to percobaan84_noImgPro/model\\vgg_16_84-saved-model-04-acc-0.36.hdf5\n",
            "4/4 [==============================] - 75s 20s/step - loss: 1.6685 - acc: 0.4551 - val_loss: 3.1897 - val_acc: 0.3643\n",
            "Epoch 5/44\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2832 - acc: 0.5551 \n",
            "Epoch 5: val_acc did not improve from 0.36429\n",
            "4/4 [==============================] - 75s 20s/step - loss: 1.2832 - acc: 0.5551 - val_loss: 2.5856 - val_acc: 0.3286\n",
            "Epoch 6/44\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1584 - acc: 0.5755 \n",
            "Epoch 6: val_acc did not improve from 0.36429\n",
            "4/4 [==============================] - 75s 20s/step - loss: 1.1584 - acc: 0.5755 - val_loss: 2.9626 - val_acc: 0.2143\n",
            "Epoch 7/44\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1818 - acc: 0.5796 \n",
            "Epoch 7: val_acc did not improve from 0.36429\n",
            "4/4 [==============================] - 75s 20s/step - loss: 1.1818 - acc: 0.5796 - val_loss: 3.2536 - val_acc: 0.1714\n",
            "Epoch 8/44\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1082 - acc: 0.6163 \n",
            "Epoch 8: val_acc did not improve from 0.36429\n",
            "4/4 [==============================] - 74s 20s/step - loss: 1.1082 - acc: 0.6163 - val_loss: 2.2589 - val_acc: 0.2357\n",
            "Epoch 9/44\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9605 - acc: 0.6531 \n",
            "Epoch 9: val_acc did not improve from 0.36429\n",
            "4/4 [==============================] - 75s 20s/step - loss: 0.9605 - acc: 0.6531 - val_loss: 1.7592 - val_acc: 0.3286\n",
            "Epoch 10/44\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8311 - acc: 0.7000 \n",
            "Epoch 10: val_acc improved from 0.36429 to 0.37857, saving model to percobaan84_noImgPro/model\\vgg_16_84-saved-model-10-acc-0.38.hdf5\n",
            "4/4 [==============================] - 75s 20s/step - loss: 0.8311 - acc: 0.7000 - val_loss: 1.7540 - val_acc: 0.3786\n",
            "Epoch 11/44\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7405 - acc: 0.7265 \n",
            "Epoch 11: val_acc did not improve from 0.37857\n",
            "4/4 [==============================] - 74s 20s/step - loss: 0.7405 - acc: 0.7265 - val_loss: 2.2964 - val_acc: 0.3143\n",
            "Epoch 12/44\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7967 - acc: 0.7184 \n",
            "Epoch 12: val_acc improved from 0.37857 to 0.41429, saving model to percobaan84_noImgPro/model\\vgg_16_84-saved-model-12-acc-0.41.hdf5\n",
            "4/4 [==============================] - 75s 20s/step - loss: 0.7967 - acc: 0.7184 - val_loss: 2.1369 - val_acc: 0.4143\n",
            "Epoch 13/44\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7553 - acc: 0.7122 \n",
            "Epoch 13: val_acc improved from 0.41429 to 0.47857, saving model to percobaan84_noImgPro/model\\vgg_16_84-saved-model-13-acc-0.48.hdf5\n",
            "4/4 [==============================] - 75s 21s/step - loss: 0.7553 - acc: 0.7122 - val_loss: 2.0283 - val_acc: 0.4786\n",
            "Epoch 14/44\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6388 - acc: 0.7633 \n",
            "Epoch 14: val_acc did not improve from 0.47857\n",
            "4/4 [==============================] - 75s 20s/step - loss: 0.6388 - acc: 0.7633 - val_loss: 2.1541 - val_acc: 0.4714\n",
            "Epoch 15/44\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6031 - acc: 0.7980 \n",
            "Epoch 15: val_acc did not improve from 0.47857\n",
            "4/4 [==============================] - 74s 20s/step - loss: 0.6031 - acc: 0.7980 - val_loss: 2.0686 - val_acc: 0.4714\n",
            "\n",
            "\n",
            "Model Accuracy 0.34285714285714286\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.40      0.57        10\n",
            "       10000       0.44      0.70      0.54        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       1.00      0.10      0.18        10\n",
            "       20000       0.22      1.00      0.36        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       1.00      0.20      0.33        10\n",
            "\n",
            "    accuracy                           0.34        70\n",
            "   macro avg       0.52      0.34      0.28        70\n",
            "weighted avg       0.52      0.34      0.28        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 85 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 43\n",
            "learning rate: 0.08089764280833031\n",
            "batch size: 32\n",
            "dropout rate: 0.530404217453236\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 3.3733 - acc: 0.2837\n",
            "Epoch 1: val_acc improved from -inf to 0.20000, saving model to percobaan85_noImgPro/model\\vgg_16_85-saved-model-01-acc-0.20.hdf5\n",
            "16/16 [==============================] - 194s 12s/step - loss: 3.3733 - acc: 0.2837 - val_loss: 8.5621 - val_acc: 0.2000\n",
            "Epoch 2/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.1736 - acc: 0.4061\n",
            "Epoch 2: val_acc improved from 0.20000 to 0.25000, saving model to percobaan85_noImgPro/model\\vgg_16_85-saved-model-02-acc-0.25.hdf5\n",
            "16/16 [==============================] - 201s 13s/step - loss: 2.1736 - acc: 0.4061 - val_loss: 6.6849 - val_acc: 0.2500\n",
            "Epoch 3/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.7546 - acc: 0.4592\n",
            "Epoch 3: val_acc did not improve from 0.25000\n",
            "16/16 [==============================] - 193s 12s/step - loss: 1.7546 - acc: 0.4592 - val_loss: 8.2519 - val_acc: 0.1571\n",
            "Epoch 4/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2068 - acc: 0.5837\n",
            "Epoch 4: val_acc did not improve from 0.25000\n",
            "16/16 [==============================] - 194s 12s/step - loss: 1.2068 - acc: 0.5837 - val_loss: 5.6884 - val_acc: 0.1571\n",
            "Epoch 5/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1211 - acc: 0.6490\n",
            "Epoch 5: val_acc improved from 0.25000 to 0.32857, saving model to percobaan85_noImgPro/model\\vgg_16_85-saved-model-05-acc-0.33.hdf5\n",
            "16/16 [==============================] - 196s 13s/step - loss: 1.1211 - acc: 0.6490 - val_loss: 2.4939 - val_acc: 0.3286\n",
            "Epoch 6/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0135 - acc: 0.6694\n",
            "Epoch 6: val_acc improved from 0.32857 to 0.44286, saving model to percobaan85_noImgPro/model\\vgg_16_85-saved-model-06-acc-0.44.hdf5\n",
            "16/16 [==============================] - 200s 13s/step - loss: 1.0135 - acc: 0.6694 - val_loss: 2.5280 - val_acc: 0.4429\n",
            "Epoch 7/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0277 - acc: 0.6959\n",
            "Epoch 7: val_acc improved from 0.44286 to 0.45000, saving model to percobaan85_noImgPro/model\\vgg_16_85-saved-model-07-acc-0.45.hdf5\n",
            "16/16 [==============================] - 198s 13s/step - loss: 1.0277 - acc: 0.6959 - val_loss: 3.2359 - val_acc: 0.4500\n",
            "Epoch 8/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9693 - acc: 0.6837\n",
            "Epoch 8: val_acc did not improve from 0.45000\n",
            "16/16 [==============================] - 191s 12s/step - loss: 0.9693 - acc: 0.6837 - val_loss: 5.0739 - val_acc: 0.1500\n",
            "Epoch 9/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9252 - acc: 0.6755\n",
            "Epoch 9: val_acc improved from 0.45000 to 0.50000, saving model to percobaan85_noImgPro/model\\vgg_16_85-saved-model-09-acc-0.50.hdf5\n",
            "16/16 [==============================] - 190s 12s/step - loss: 0.9252 - acc: 0.6755 - val_loss: 1.6778 - val_acc: 0.5000\n",
            "Epoch 10/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9001 - acc: 0.7041\n",
            "Epoch 10: val_acc did not improve from 0.50000\n",
            "16/16 [==============================] - 198s 13s/step - loss: 0.9001 - acc: 0.7041 - val_loss: 2.1701 - val_acc: 0.4857\n",
            "Epoch 11/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9875 - acc: 0.7020\n",
            "Epoch 11: val_acc did not improve from 0.50000\n",
            "16/16 [==============================] - 195s 12s/step - loss: 0.9875 - acc: 0.7020 - val_loss: 2.5584 - val_acc: 0.4143\n",
            "Epoch 12/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0425 - acc: 0.7041\n",
            "Epoch 12: val_acc did not improve from 0.50000\n",
            "16/16 [==============================] - 202s 13s/step - loss: 1.0425 - acc: 0.7041 - val_loss: 5.5416 - val_acc: 0.2571\n",
            "Epoch 13/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8694 - acc: 0.7245\n",
            "Epoch 13: val_acc improved from 0.50000 to 0.58571, saving model to percobaan85_noImgPro/model\\vgg_16_85-saved-model-13-acc-0.59.hdf5\n",
            "16/16 [==============================] - 194s 12s/step - loss: 0.8694 - acc: 0.7245 - val_loss: 1.7763 - val_acc: 0.5857\n",
            "Epoch 14/43\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9052 - acc: 0.7347\n",
            "Epoch 14: val_acc did not improve from 0.58571\n",
            "16/16 [==============================] - 195s 12s/step - loss: 0.9052 - acc: 0.7347 - val_loss: 1.9747 - val_acc: 0.5714\n",
            "\n",
            "\n",
            "Model Accuracy 0.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.00      0.00      0.00        10\n",
            "       10000       0.53      0.90      0.67        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.67      0.20      0.31        10\n",
            "       20000       0.33      0.10      0.15        10\n",
            "        5000       0.26      0.90      0.41        10\n",
            "       50000       0.54      0.70      0.61        10\n",
            "\n",
            "    accuracy                           0.40        70\n",
            "   macro avg       0.33      0.40      0.31        70\n",
            "weighted avg       0.33      0.40      0.31        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 86 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 41\n",
            "learning rate: 0.09630756590417831\n",
            "batch size: 32\n",
            "dropout rate: 0.5756779594445361\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 4.0260 - acc: 0.2429\n",
            "Epoch 1: val_acc improved from -inf to 0.15714, saving model to percobaan86_noImgPro/model\\vgg_16_86-saved-model-01-acc-0.16.hdf5\n",
            "16/16 [==============================] - 224s 14s/step - loss: 4.0260 - acc: 0.2429 - val_loss: 15.9702 - val_acc: 0.1571\n",
            "Epoch 2/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.5101 - acc: 0.3612\n",
            "Epoch 2: val_acc did not improve from 0.15714\n",
            "16/16 [==============================] - 204s 13s/step - loss: 2.5101 - acc: 0.3612 - val_loss: 11.7719 - val_acc: 0.1429\n",
            "Epoch 3/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.8300 - acc: 0.4469\n",
            "Epoch 3: val_acc improved from 0.15714 to 0.23571, saving model to percobaan86_noImgPro/model\\vgg_16_86-saved-model-03-acc-0.24.hdf5\n",
            "16/16 [==============================] - 207s 14s/step - loss: 1.8300 - acc: 0.4469 - val_loss: 5.5126 - val_acc: 0.2357\n",
            "Epoch 4/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.6128 - acc: 0.4816 \n",
            "Epoch 4: val_acc improved from 0.23571 to 0.27857, saving model to percobaan86_noImgPro/model\\vgg_16_86-saved-model-04-acc-0.28.hdf5\n",
            "16/16 [==============================] - 230s 15s/step - loss: 1.6128 - acc: 0.4816 - val_loss: 4.9596 - val_acc: 0.2786\n",
            "Epoch 5/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.4571 - acc: 0.5531\n",
            "Epoch 5: val_acc did not improve from 0.27857\n",
            "16/16 [==============================] - 208s 13s/step - loss: 1.4571 - acc: 0.5531 - val_loss: 4.6206 - val_acc: 0.2071\n",
            "Epoch 6/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2148 - acc: 0.5857\n",
            "Epoch 6: val_acc did not improve from 0.27857\n",
            "16/16 [==============================] - 212s 13s/step - loss: 1.2148 - acc: 0.5857 - val_loss: 3.8861 - val_acc: 0.2429\n",
            "Epoch 7/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1686 - acc: 0.6531\n",
            "Epoch 7: val_acc did not improve from 0.27857\n",
            "16/16 [==============================] - 211s 13s/step - loss: 1.1686 - acc: 0.6531 - val_loss: 4.6908 - val_acc: 0.2571\n",
            "Epoch 8/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0382 - acc: 0.6429\n",
            "Epoch 8: val_acc did not improve from 0.27857\n",
            "16/16 [==============================] - 217s 14s/step - loss: 1.0382 - acc: 0.6429 - val_loss: 5.7785 - val_acc: 0.2429\n",
            "Epoch 9/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1129 - acc: 0.6327\n",
            "Epoch 9: val_acc did not improve from 0.27857\n",
            "16/16 [==============================] - 215s 14s/step - loss: 1.1129 - acc: 0.6327 - val_loss: 4.6930 - val_acc: 0.2786\n",
            "Epoch 10/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0392 - acc: 0.6694\n",
            "Epoch 10: val_acc improved from 0.27857 to 0.44286, saving model to percobaan86_noImgPro/model\\vgg_16_86-saved-model-10-acc-0.44.hdf5\n",
            "16/16 [==============================] - 213s 14s/step - loss: 1.0392 - acc: 0.6694 - val_loss: 3.2838 - val_acc: 0.4429\n",
            "Epoch 11/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0450 - acc: 0.6673\n",
            "Epoch 11: val_acc improved from 0.44286 to 0.51429, saving model to percobaan86_noImgPro/model\\vgg_16_86-saved-model-11-acc-0.51.hdf5\n",
            "16/16 [==============================] - 215s 14s/step - loss: 1.0450 - acc: 0.6673 - val_loss: 2.0647 - val_acc: 0.5143\n",
            "Epoch 12/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0620 - acc: 0.6898\n",
            "Epoch 12: val_acc did not improve from 0.51429\n",
            "16/16 [==============================] - 212s 13s/step - loss: 1.0620 - acc: 0.6898 - val_loss: 2.5251 - val_acc: 0.3929\n",
            "Epoch 13/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9363 - acc: 0.7163\n",
            "Epoch 13: val_acc did not improve from 0.51429\n",
            "16/16 [==============================] - 217s 14s/step - loss: 0.9363 - acc: 0.7163 - val_loss: 3.3602 - val_acc: 0.4214\n",
            "Epoch 14/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8936 - acc: 0.7408\n",
            "Epoch 14: val_acc improved from 0.51429 to 0.60714, saving model to percobaan86_noImgPro/model\\vgg_16_86-saved-model-14-acc-0.61.hdf5\n",
            "16/16 [==============================] - 213s 13s/step - loss: 0.8936 - acc: 0.7408 - val_loss: 1.8407 - val_acc: 0.6071\n",
            "Epoch 15/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9887 - acc: 0.7327\n",
            "Epoch 15: val_acc improved from 0.60714 to 0.66429, saving model to percobaan86_noImgPro/model\\vgg_16_86-saved-model-15-acc-0.66.hdf5\n",
            "16/16 [==============================] - 216s 14s/step - loss: 0.9887 - acc: 0.7327 - val_loss: 1.3797 - val_acc: 0.6643\n",
            "Epoch 16/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1475 - acc: 0.6796\n",
            "Epoch 16: val_acc improved from 0.66429 to 0.68571, saving model to percobaan86_noImgPro/model\\vgg_16_86-saved-model-16-acc-0.69.hdf5\n",
            "16/16 [==============================] - 211s 14s/step - loss: 1.1475 - acc: 0.6796 - val_loss: 1.5191 - val_acc: 0.6857\n",
            "Epoch 17/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9019 - acc: 0.7469\n",
            "Epoch 17: val_acc did not improve from 0.68571\n",
            "16/16 [==============================] - 213s 14s/step - loss: 0.9019 - acc: 0.7469 - val_loss: 10.9019 - val_acc: 0.2214\n",
            "Epoch 18/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3384 - acc: 0.6816 \n",
            "Epoch 18: val_acc did not improve from 0.68571\n",
            "16/16 [==============================] - 217s 14s/step - loss: 1.3384 - acc: 0.6816 - val_loss: 6.2219 - val_acc: 0.5071\n",
            "Epoch 19/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.7234 - acc: 0.6429\n",
            "Epoch 19: val_acc improved from 0.68571 to 0.72857, saving model to percobaan86_noImgPro/model\\vgg_16_86-saved-model-19-acc-0.73.hdf5\n",
            "16/16 [==============================] - 213s 13s/step - loss: 1.7234 - acc: 0.6429 - val_loss: 1.5733 - val_acc: 0.7286\n",
            "Epoch 20/41\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.8531 - acc: 0.6592\n",
            "Epoch 20: val_acc did not improve from 0.72857\n",
            "16/16 [==============================] - 198s 13s/step - loss: 1.8531 - acc: 0.6592 - val_loss: 2.3166 - val_acc: 0.7143\n",
            "\n",
            "\n",
            "Model Accuracy 0.6285714285714286\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.20      0.33        10\n",
            "       10000       0.89      0.80      0.84        10\n",
            "      100000       0.38      1.00      0.56        10\n",
            "        2000       0.62      0.80      0.70        10\n",
            "       20000       0.80      0.40      0.53        10\n",
            "        5000       0.80      0.40      0.53        10\n",
            "       50000       0.80      0.80      0.80        10\n",
            "\n",
            "    accuracy                           0.63        70\n",
            "   macro avg       0.76      0.63      0.61        70\n",
            "weighted avg       0.76      0.63      0.61        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 87 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 44\n",
            "learning rate: 0.09824545770416719\n",
            "batch size: 32\n",
            "dropout rate: 0.7215226082274058\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/44\n",
            "16/16 [==============================] - ETA: 0s - loss: 5.0533 - acc: 0.2082\n",
            "Epoch 1: val_acc improved from -inf to 0.17857, saving model to percobaan87_noImgPro/model\\vgg_16_87-saved-model-01-acc-0.18.hdf5\n",
            "16/16 [==============================] - 206s 13s/step - loss: 5.0533 - acc: 0.2082 - val_loss: 12.9228 - val_acc: 0.1786\n",
            "Epoch 2/44\n",
            "16/16 [==============================] - ETA: 0s - loss: 3.2886 - acc: 0.2980\n",
            "Epoch 2: val_acc improved from 0.17857 to 0.25714, saving model to percobaan87_noImgPro/model\\vgg_16_87-saved-model-02-acc-0.26.hdf5\n",
            "16/16 [==============================] - 201s 13s/step - loss: 3.2886 - acc: 0.2980 - val_loss: 2.9203 - val_acc: 0.2571\n",
            "Epoch 3/44\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.5390 - acc: 0.3184\n",
            "Epoch 3: val_acc did not improve from 0.25714\n",
            "16/16 [==============================] - 202s 13s/step - loss: 2.5390 - acc: 0.3184 - val_loss: 3.1286 - val_acc: 0.1714\n",
            "Epoch 4/44\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.0740 - acc: 0.3490\n",
            "Epoch 4: val_acc did not improve from 0.25714\n",
            "16/16 [==============================] - 201s 13s/step - loss: 2.0740 - acc: 0.3490 - val_loss: 2.8735 - val_acc: 0.2000\n",
            "Epoch 5/44\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.8605 - acc: 0.3898\n",
            "Epoch 5: val_acc improved from 0.25714 to 0.32143, saving model to percobaan87_noImgPro/model\\vgg_16_87-saved-model-05-acc-0.32.hdf5\n",
            "16/16 [==============================] - 202s 13s/step - loss: 1.8605 - acc: 0.3898 - val_loss: 2.3441 - val_acc: 0.3214\n",
            "Epoch 6/44\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.7145 - acc: 0.4551\n",
            "Epoch 6: val_acc improved from 0.32143 to 0.37143, saving model to percobaan87_noImgPro/model\\vgg_16_87-saved-model-06-acc-0.37.hdf5\n",
            "16/16 [==============================] - 198s 13s/step - loss: 1.7145 - acc: 0.4551 - val_loss: 1.9273 - val_acc: 0.3714\n",
            "Epoch 7/44\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.9543 - acc: 0.4204\n",
            "Epoch 7: val_acc improved from 0.37143 to 0.52857, saving model to percobaan87_noImgPro/model\\vgg_16_87-saved-model-07-acc-0.53.hdf5\n",
            "16/16 [==============================] - 200s 13s/step - loss: 1.9543 - acc: 0.4204 - val_loss: 1.6152 - val_acc: 0.5286\n",
            "Epoch 8/44\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.6633 - acc: 0.4429\n",
            "Epoch 8: val_acc did not improve from 0.52857\n",
            "16/16 [==============================] - 203s 13s/step - loss: 1.6633 - acc: 0.4429 - val_loss: 2.0285 - val_acc: 0.3500\n",
            "Epoch 9/44\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.5197 - acc: 0.5122\n",
            "Epoch 9: val_acc did not improve from 0.52857\n",
            "16/16 [==============================] - 195s 12s/step - loss: 1.5197 - acc: 0.5122 - val_loss: 1.9255 - val_acc: 0.4571\n",
            "Epoch 10/44\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.4865 - acc: 0.5184\n",
            "Epoch 10: val_acc did not improve from 0.52857\n",
            "16/16 [==============================] - 201s 13s/step - loss: 1.4865 - acc: 0.5184 - val_loss: 3.1751 - val_acc: 0.2857\n",
            "Epoch 11/44\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.9998 - acc: 0.4918\n",
            "Epoch 11: val_acc did not improve from 0.52857\n",
            "16/16 [==============================] - 193s 13s/step - loss: 1.9998 - acc: 0.4918 - val_loss: 1.8245 - val_acc: 0.3714\n",
            "Epoch 12/44\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.6464 - acc: 0.5204\n",
            "Epoch 12: val_acc did not improve from 0.52857\n",
            "16/16 [==============================] - 198s 12s/step - loss: 1.6464 - acc: 0.5204 - val_loss: 1.7322 - val_acc: 0.5143\n",
            "\n",
            "\n",
            "Model Accuracy 0.4857142857142857\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.48      1.00      0.65        10\n",
            "       10000       1.00      0.50      0.67        10\n",
            "      100000       0.89      0.80      0.84        10\n",
            "        2000       0.00      0.00      0.00        10\n",
            "       20000       0.00      0.00      0.00        10\n",
            "        5000       1.00      0.10      0.18        10\n",
            "       50000       0.29      1.00      0.45        10\n",
            "\n",
            "    accuracy                           0.49        70\n",
            "   macro avg       0.52      0.49      0.40        70\n",
            "weighted avg       0.52      0.49      0.40        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 88 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 47\n",
            "learning rate: 0.09869709619674959\n",
            "batch size: 32\n",
            "dropout rate: 0.7588466577178008\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 5.4620 - acc: 0.2122\n",
            "Epoch 1: val_acc improved from -inf to 0.14286, saving model to percobaan88_noImgPro/model\\vgg_16_88-saved-model-01-acc-0.14.hdf5\n",
            "16/16 [==============================] - 132s 8s/step - loss: 5.4620 - acc: 0.2122 - val_loss: 23.2108 - val_acc: 0.1429\n",
            "Epoch 2/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 4.1876 - acc: 0.2265\n",
            "Epoch 2: val_acc did not improve from 0.14286\n",
            "16/16 [==============================] - 131s 8s/step - loss: 4.1876 - acc: 0.2265 - val_loss: 12.4708 - val_acc: 0.1429\n",
            "Epoch 3/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.9974 - acc: 0.2163\n",
            "Epoch 3: val_acc improved from 0.14286 to 0.20000, saving model to percobaan88_noImgPro/model\\vgg_16_88-saved-model-03-acc-0.20.hdf5\n",
            "16/16 [==============================] - 130s 8s/step - loss: 2.9974 - acc: 0.2163 - val_loss: 3.4117 - val_acc: 0.2000\n",
            "Epoch 4/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.4218 - acc: 0.2755\n",
            "Epoch 4: val_acc improved from 0.20000 to 0.25714, saving model to percobaan88_noImgPro/model\\vgg_16_88-saved-model-04-acc-0.26.hdf5\n",
            "16/16 [==============================] - 129s 8s/step - loss: 2.4218 - acc: 0.2755 - val_loss: 2.4885 - val_acc: 0.2571\n",
            "Epoch 5/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.1143 - acc: 0.3000\n",
            "Epoch 5: val_acc did not improve from 0.25714\n",
            "16/16 [==============================] - 131s 8s/step - loss: 2.1143 - acc: 0.3000 - val_loss: 2.8590 - val_acc: 0.1429\n",
            "Epoch 6/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.8226 - acc: 0.3612\n",
            "Epoch 6: val_acc did not improve from 0.25714\n",
            "16/16 [==============================] - 130s 8s/step - loss: 1.8226 - acc: 0.3612 - val_loss: 2.6874 - val_acc: 0.2071\n",
            "Epoch 7/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.6626 - acc: 0.4265\n",
            "Epoch 7: val_acc did not improve from 0.25714\n",
            "16/16 [==============================] - 128s 8s/step - loss: 1.6626 - acc: 0.4265 - val_loss: 5.5475 - val_acc: 0.1429\n",
            "Epoch 8/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.7274 - acc: 0.4102\n",
            "Epoch 8: val_acc did not improve from 0.25714\n",
            "16/16 [==============================] - 130s 8s/step - loss: 1.7274 - acc: 0.4102 - val_loss: 4.1609 - val_acc: 0.1429\n",
            "Epoch 9/47\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.6406 - acc: 0.4469\n",
            "Epoch 9: val_acc did not improve from 0.25714\n",
            "16/16 [==============================] - 129s 8s/step - loss: 1.6406 - acc: 0.4469 - val_loss: 2.7371 - val_acc: 0.1714\n",
            "\n",
            "\n",
            "Model Accuracy 0.18571428571428572\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.10      0.18        10\n",
            "       10000       0.22      0.20      0.21        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.00      0.00      0.00        10\n",
            "       20000       0.17      1.00      0.29        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       0.00      0.00      0.00        10\n",
            "\n",
            "    accuracy                           0.19        70\n",
            "   macro avg       0.20      0.19      0.10        70\n",
            "weighted avg       0.20      0.19      0.10        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 89 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 41\n",
            "learning rate: 0.08054367257550588\n",
            "batch size: 64\n",
            "dropout rate: 0.5186875717808102\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.9484 - acc: 0.2857\n",
            "Epoch 1: val_acc improved from -inf to 0.20714, saving model to percobaan89_noImgPro/model\\vgg_16_89-saved-model-01-acc-0.21.hdf5\n",
            "8/8 [==============================] - 107s 14s/step - loss: 2.9484 - acc: 0.2857 - val_loss: 7.3741 - val_acc: 0.2071\n",
            "Epoch 2/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.0668 - acc: 0.4388 \n",
            "Epoch 2: val_acc improved from 0.20714 to 0.25714, saving model to percobaan89_noImgPro/model\\vgg_16_89-saved-model-02-acc-0.26.hdf5\n",
            "8/8 [==============================] - 115s 15s/step - loss: 2.0668 - acc: 0.4388 - val_loss: 5.2237 - val_acc: 0.2571\n",
            "Epoch 3/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4611 - acc: 0.5265 \n",
            "Epoch 3: val_acc did not improve from 0.25714\n",
            "8/8 [==============================] - 113s 14s/step - loss: 1.4611 - acc: 0.5265 - val_loss: 4.8331 - val_acc: 0.2000\n",
            "Epoch 4/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0649 - acc: 0.6245 \n",
            "Epoch 4: val_acc improved from 0.25714 to 0.26429, saving model to percobaan89_noImgPro/model\\vgg_16_89-saved-model-04-acc-0.26.hdf5\n",
            "8/8 [==============================] - 114s 15s/step - loss: 1.0649 - acc: 0.6245 - val_loss: 4.3560 - val_acc: 0.2643\n",
            "Epoch 5/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9944 - acc: 0.6673 \n",
            "Epoch 5: val_acc improved from 0.26429 to 0.28571, saving model to percobaan89_noImgPro/model\\vgg_16_89-saved-model-05-acc-0.29.hdf5\n",
            "8/8 [==============================] - 114s 15s/step - loss: 0.9944 - acc: 0.6673 - val_loss: 4.0856 - val_acc: 0.2857\n",
            "Epoch 6/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7753 - acc: 0.7122 \n",
            "Epoch 6: val_acc improved from 0.28571 to 0.43571, saving model to percobaan89_noImgPro/model\\vgg_16_89-saved-model-06-acc-0.44.hdf5\n",
            "8/8 [==============================] - 113s 14s/step - loss: 0.7753 - acc: 0.7122 - val_loss: 2.0555 - val_acc: 0.4357\n",
            "Epoch 7/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7036 - acc: 0.7837 \n",
            "Epoch 7: val_acc did not improve from 0.43571\n",
            "8/8 [==============================] - 114s 15s/step - loss: 0.7036 - acc: 0.7837 - val_loss: 2.1375 - val_acc: 0.4071\n",
            "Epoch 8/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6604 - acc: 0.7776 \n",
            "Epoch 8: val_acc improved from 0.43571 to 0.50714, saving model to percobaan89_noImgPro/model\\vgg_16_89-saved-model-08-acc-0.51.hdf5\n",
            "8/8 [==============================] - 114s 15s/step - loss: 0.6604 - acc: 0.7776 - val_loss: 1.7777 - val_acc: 0.5071\n",
            "Epoch 9/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6791 - acc: 0.7918 \n",
            "Epoch 9: val_acc did not improve from 0.50714\n",
            "8/8 [==============================] - 113s 14s/step - loss: 0.6791 - acc: 0.7918 - val_loss: 2.9539 - val_acc: 0.3714\n",
            "Epoch 10/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6572 - acc: 0.7714 \n",
            "Epoch 10: val_acc improved from 0.50714 to 0.52143, saving model to percobaan89_noImgPro/model\\vgg_16_89-saved-model-10-acc-0.52.hdf5\n",
            "8/8 [==============================] - 114s 15s/step - loss: 0.6572 - acc: 0.7714 - val_loss: 2.2058 - val_acc: 0.5214\n",
            "Epoch 11/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5885 - acc: 0.8143 \n",
            "Epoch 11: val_acc did not improve from 0.52143\n",
            "8/8 [==============================] - 114s 15s/step - loss: 0.5885 - acc: 0.8143 - val_loss: 1.6044 - val_acc: 0.5143\n",
            "Epoch 12/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5760 - acc: 0.7878 \n",
            "Epoch 12: val_acc did not improve from 0.52143\n",
            "8/8 [==============================] - 110s 14s/step - loss: 0.5760 - acc: 0.7878 - val_loss: 1.9556 - val_acc: 0.4571\n",
            "Epoch 13/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5423 - acc: 0.8143 \n",
            "Epoch 13: val_acc did not improve from 0.52143\n",
            "8/8 [==============================] - 114s 15s/step - loss: 0.5423 - acc: 0.8143 - val_loss: 2.2357 - val_acc: 0.4571\n",
            "Epoch 14/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5929 - acc: 0.8408 \n",
            "Epoch 14: val_acc improved from 0.52143 to 0.66429, saving model to percobaan89_noImgPro/model\\vgg_16_89-saved-model-14-acc-0.66.hdf5\n",
            "8/8 [==============================] - 114s 15s/step - loss: 0.5929 - acc: 0.8408 - val_loss: 1.1225 - val_acc: 0.6643\n",
            "Epoch 15/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5119 - acc: 0.8449 \n",
            "Epoch 15: val_acc did not improve from 0.66429\n",
            "8/8 [==============================] - 112s 14s/step - loss: 0.5119 - acc: 0.8449 - val_loss: 1.2669 - val_acc: 0.5857\n",
            "Epoch 16/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4947 - acc: 0.8306 \n",
            "Epoch 16: val_acc did not improve from 0.66429\n",
            "8/8 [==============================] - 115s 15s/step - loss: 0.4947 - acc: 0.8306 - val_loss: 2.3243 - val_acc: 0.4786\n",
            "Epoch 17/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4656 - acc: 0.8612 \n",
            "Epoch 17: val_acc did not improve from 0.66429\n",
            "8/8 [==============================] - 114s 15s/step - loss: 0.4656 - acc: 0.8612 - val_loss: 1.2561 - val_acc: 0.6643\n",
            "Epoch 18/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4453 - acc: 0.8531 \n",
            "Epoch 18: val_acc improved from 0.66429 to 0.72143, saving model to percobaan89_noImgPro/model\\vgg_16_89-saved-model-18-acc-0.72.hdf5\n",
            "8/8 [==============================] - 114s 15s/step - loss: 0.4453 - acc: 0.8531 - val_loss: 1.1718 - val_acc: 0.7214\n",
            "Epoch 19/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3418 - acc: 0.8714 \n",
            "Epoch 19: val_acc improved from 0.72143 to 0.75000, saving model to percobaan89_noImgPro/model\\vgg_16_89-saved-model-19-acc-0.75.hdf5\n",
            "8/8 [==============================] - 114s 15s/step - loss: 0.3418 - acc: 0.8714 - val_loss: 0.9108 - val_acc: 0.7500\n",
            "Epoch 20/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3808 - acc: 0.8673 \n",
            "Epoch 20: val_acc did not improve from 0.75000\n",
            "8/8 [==============================] - 114s 15s/step - loss: 0.3808 - acc: 0.8673 - val_loss: 0.8446 - val_acc: 0.7500\n",
            "Epoch 21/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4435 - acc: 0.8735 \n",
            "Epoch 21: val_acc did not improve from 0.75000\n",
            "8/8 [==============================] - 114s 15s/step - loss: 0.4435 - acc: 0.8735 - val_loss: 1.6834 - val_acc: 0.5714\n",
            "Epoch 22/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4782 - acc: 0.8612 \n",
            "Epoch 22: val_acc did not improve from 0.75000\n",
            "8/8 [==============================] - 114s 15s/step - loss: 0.4782 - acc: 0.8612 - val_loss: 1.2676 - val_acc: 0.6500\n",
            "Epoch 23/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4998 - acc: 0.8653 \n",
            "Epoch 23: val_acc improved from 0.75000 to 0.77143, saving model to percobaan89_noImgPro/model\\vgg_16_89-saved-model-23-acc-0.77.hdf5\n",
            "8/8 [==============================] - 113s 14s/step - loss: 0.4998 - acc: 0.8653 - val_loss: 0.8650 - val_acc: 0.7714\n",
            "Epoch 24/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5321 - acc: 0.8612 \n",
            "Epoch 24: val_acc did not improve from 0.77143\n",
            "8/8 [==============================] - 115s 15s/step - loss: 0.5321 - acc: 0.8612 - val_loss: 1.0860 - val_acc: 0.6857\n",
            "Epoch 25/41\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4569 - acc: 0.8571 \n",
            "Epoch 25: val_acc did not improve from 0.77143\n",
            "8/8 [==============================] - 113s 14s/step - loss: 0.4569 - acc: 0.8571 - val_loss: 0.9377 - val_acc: 0.7500\n",
            "\n",
            "\n",
            "Model Accuracy 0.6857142857142857\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.30      0.46        10\n",
            "       10000       1.00      0.90      0.95        10\n",
            "      100000       1.00      0.60      0.75        10\n",
            "        2000       0.53      0.90      0.67        10\n",
            "       20000       1.00      0.30      0.46        10\n",
            "        5000       0.75      0.90      0.82        10\n",
            "       50000       0.45      0.90      0.60        10\n",
            "\n",
            "    accuracy                           0.69        70\n",
            "   macro avg       0.82      0.69      0.67        70\n",
            "weighted avg       0.82      0.69      0.67        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 90 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 45\n",
            "learning rate: 0.09420374761670497\n",
            "batch size: 64\n",
            "dropout rate: 0.6323338200542761\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 3.3316 - acc: 0.2755\n",
            "Epoch 1: val_acc improved from -inf to 0.14286, saving model to percobaan90_noImgPro/model\\vgg_16_90-saved-model-01-acc-0.14.hdf5\n",
            "8/8 [==============================] - 108s 14s/step - loss: 3.3316 - acc: 0.2755 - val_loss: 24.3447 - val_acc: 0.1429\n",
            "Epoch 2/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.4923 - acc: 0.3837 \n",
            "Epoch 2: val_acc improved from 0.14286 to 0.18571, saving model to percobaan90_noImgPro/model\\vgg_16_90-saved-model-02-acc-0.19.hdf5\n",
            "8/8 [==============================] - 117s 15s/step - loss: 2.4923 - acc: 0.3837 - val_loss: 8.8649 - val_acc: 0.1857\n",
            "Epoch 3/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8463 - acc: 0.3959 \n",
            "Epoch 3: val_acc improved from 0.18571 to 0.38571, saving model to percobaan90_noImgPro/model\\vgg_16_90-saved-model-03-acc-0.39.hdf5\n",
            "8/8 [==============================] - 115s 15s/step - loss: 1.8463 - acc: 0.3959 - val_loss: 3.4360 - val_acc: 0.3857\n",
            "Epoch 4/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5384 - acc: 0.5122 \n",
            "Epoch 4: val_acc did not improve from 0.38571\n",
            "8/8 [==============================] - 116s 15s/step - loss: 1.5384 - acc: 0.5122 - val_loss: 3.6901 - val_acc: 0.2857\n",
            "Epoch 5/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4589 - acc: 0.5143 \n",
            "Epoch 5: val_acc improved from 0.38571 to 0.40000, saving model to percobaan90_noImgPro/model\\vgg_16_90-saved-model-05-acc-0.40.hdf5\n",
            "8/8 [==============================] - 114s 15s/step - loss: 1.4589 - acc: 0.5143 - val_loss: 3.5630 - val_acc: 0.4000\n",
            "Epoch 6/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.2319 - acc: 0.5796 \n",
            "Epoch 6: val_acc did not improve from 0.40000\n",
            "8/8 [==============================] - 116s 15s/step - loss: 1.2319 - acc: 0.5796 - val_loss: 4.8937 - val_acc: 0.1714\n",
            "Epoch 7/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1048 - acc: 0.6306 \n",
            "Epoch 7: val_acc did not improve from 0.40000\n",
            "8/8 [==============================] - 116s 15s/step - loss: 1.1048 - acc: 0.6306 - val_loss: 3.4598 - val_acc: 0.3214\n",
            "Epoch 8/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0206 - acc: 0.6469 \n",
            "Epoch 8: val_acc improved from 0.40000 to 0.55000, saving model to percobaan90_noImgPro/model\\vgg_16_90-saved-model-08-acc-0.55.hdf5\n",
            "8/8 [==============================] - 115s 15s/step - loss: 1.0206 - acc: 0.6469 - val_loss: 1.4931 - val_acc: 0.5500\n",
            "Epoch 9/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8888 - acc: 0.6959 \n",
            "Epoch 9: val_acc improved from 0.55000 to 0.73571, saving model to percobaan90_noImgPro/model\\vgg_16_90-saved-model-09-acc-0.74.hdf5\n",
            "8/8 [==============================] - 116s 15s/step - loss: 0.8888 - acc: 0.6959 - val_loss: 0.9593 - val_acc: 0.7357\n",
            "Epoch 10/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8052 - acc: 0.7265 \n",
            "Epoch 10: val_acc did not improve from 0.73571\n",
            "8/8 [==============================] - 115s 15s/step - loss: 0.8052 - acc: 0.7265 - val_loss: 1.2094 - val_acc: 0.6357\n",
            "Epoch 11/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8335 - acc: 0.7388 \n",
            "Epoch 11: val_acc did not improve from 0.73571\n",
            "8/8 [==============================] - 116s 15s/step - loss: 0.8335 - acc: 0.7388 - val_loss: 1.7025 - val_acc: 0.5643\n",
            "Epoch 12/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7036 - acc: 0.7204 \n",
            "Epoch 12: val_acc did not improve from 0.73571\n",
            "8/8 [==============================] - 114s 15s/step - loss: 0.7036 - acc: 0.7204 - val_loss: 1.7072 - val_acc: 0.5714\n",
            "Epoch 13/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7384 - acc: 0.7469 \n",
            "Epoch 13: val_acc did not improve from 0.73571\n",
            "8/8 [==============================] - 116s 15s/step - loss: 0.7384 - acc: 0.7469 - val_loss: 1.2759 - val_acc: 0.6000\n",
            "Epoch 14/45\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7026 - acc: 0.7592 \n",
            "Epoch 14: val_acc did not improve from 0.73571\n",
            "8/8 [==============================] - 114s 15s/step - loss: 0.7026 - acc: 0.7592 - val_loss: 2.4136 - val_acc: 0.4857\n",
            "\n",
            "\n",
            "Model Accuracy 0.4142857142857143\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.20      0.33        10\n",
            "       10000       0.45      0.90      0.60        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.31      1.00      0.48        10\n",
            "       20000       0.00      0.00      0.00        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       0.53      0.80      0.64        10\n",
            "\n",
            "    accuracy                           0.41        70\n",
            "   macro avg       0.33      0.41      0.29        70\n",
            "weighted avg       0.33      0.41      0.29        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 91 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 39\n",
            "learning rate: 0.08231544393644043\n",
            "batch size: 64\n",
            "dropout rate: 0.6543141510138896\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/39\n",
            "8/8 [==============================] - ETA: 0s - loss: 3.4704 - acc: 0.2449 \n",
            "Epoch 1: val_acc improved from -inf to 0.14286, saving model to percobaan91_noImgPro/model\\vgg_16_91-saved-model-01-acc-0.14.hdf5\n",
            "8/8 [==============================] - 110s 14s/step - loss: 3.4704 - acc: 0.2449 - val_loss: 13.2323 - val_acc: 0.1429\n",
            "Epoch 2/39\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.4394 - acc: 0.3224 \n",
            "Epoch 2: val_acc improved from 0.14286 to 0.16429, saving model to percobaan91_noImgPro/model\\vgg_16_91-saved-model-02-acc-0.16.hdf5\n",
            "8/8 [==============================] - 110s 14s/step - loss: 2.4394 - acc: 0.3224 - val_loss: 9.8587 - val_acc: 0.1643\n",
            "Epoch 3/39\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8770 - acc: 0.4347 \n",
            "Epoch 3: val_acc improved from 0.16429 to 0.20000, saving model to percobaan91_noImgPro/model\\vgg_16_91-saved-model-03-acc-0.20.hdf5\n",
            "8/8 [==============================] - 109s 14s/step - loss: 1.8770 - acc: 0.4347 - val_loss: 7.9258 - val_acc: 0.2000\n",
            "Epoch 4/39\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4983 - acc: 0.4796 \n",
            "Epoch 4: val_acc did not improve from 0.20000\n",
            "8/8 [==============================] - 107s 14s/step - loss: 1.4983 - acc: 0.4796 - val_loss: 7.6292 - val_acc: 0.1857\n",
            "Epoch 5/39\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3869 - acc: 0.4714 \n",
            "Epoch 5: val_acc improved from 0.20000 to 0.23571, saving model to percobaan91_noImgPro/model\\vgg_16_91-saved-model-05-acc-0.24.hdf5\n",
            "8/8 [==============================] - 110s 14s/step - loss: 1.3869 - acc: 0.4714 - val_loss: 5.7135 - val_acc: 0.2357\n",
            "Epoch 6/39\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1538 - acc: 0.6143\n",
            "Epoch 6: val_acc did not improve from 0.23571\n",
            "8/8 [==============================] - 106s 14s/step - loss: 1.1538 - acc: 0.6143 - val_loss: 5.7508 - val_acc: 0.2143\n",
            "Epoch 7/39\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1705 - acc: 0.6245 \n",
            "Epoch 7: val_acc did not improve from 0.23571\n",
            "8/8 [==============================] - 109s 14s/step - loss: 1.1705 - acc: 0.6245 - val_loss: 5.1160 - val_acc: 0.1643\n",
            "Epoch 8/39\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9406 - acc: 0.6837\n",
            "Epoch 8: val_acc did not improve from 0.23571\n",
            "8/8 [==============================] - 108s 14s/step - loss: 0.9406 - acc: 0.6837 - val_loss: 6.0603 - val_acc: 0.1786\n",
            "Epoch 9/39\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0016 - acc: 0.6592\n",
            "Epoch 9: val_acc improved from 0.23571 to 0.40000, saving model to percobaan91_noImgPro/model\\vgg_16_91-saved-model-09-acc-0.40.hdf5\n",
            "8/8 [==============================] - 108s 14s/step - loss: 1.0016 - acc: 0.6592 - val_loss: 2.7896 - val_acc: 0.4000\n",
            "Epoch 10/39\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7986 - acc: 0.7184 \n",
            "Epoch 10: val_acc did not improve from 0.40000\n",
            "8/8 [==============================] - 107s 14s/step - loss: 0.7986 - acc: 0.7184 - val_loss: 4.1311 - val_acc: 0.1857\n",
            "Epoch 11/39\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7119 - acc: 0.7612 \n",
            "Epoch 11: val_acc improved from 0.40000 to 0.42143, saving model to percobaan91_noImgPro/model\\vgg_16_91-saved-model-11-acc-0.42.hdf5\n",
            "8/8 [==============================] - 107s 14s/step - loss: 0.7119 - acc: 0.7612 - val_loss: 2.0610 - val_acc: 0.4214\n",
            "Epoch 12/39\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8526 - acc: 0.7245 \n",
            "Epoch 12: val_acc improved from 0.42143 to 0.42857, saving model to percobaan91_noImgPro/model\\vgg_16_91-saved-model-12-acc-0.43.hdf5\n",
            "8/8 [==============================] - 109s 14s/step - loss: 0.8526 - acc: 0.7245 - val_loss: 2.2177 - val_acc: 0.4286\n",
            "Epoch 13/39\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7934 - acc: 0.7449\n",
            "Epoch 13: val_acc improved from 0.42857 to 0.50000, saving model to percobaan91_noImgPro/model\\vgg_16_91-saved-model-13-acc-0.50.hdf5\n",
            "8/8 [==============================] - 106s 14s/step - loss: 0.7934 - acc: 0.7449 - val_loss: 2.4152 - val_acc: 0.5000\n",
            "Epoch 14/39\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6770 - acc: 0.7816 \n",
            "Epoch 14: val_acc did not improve from 0.50000\n",
            "8/8 [==============================] - 109s 14s/step - loss: 0.6770 - acc: 0.7816 - val_loss: 2.1241 - val_acc: 0.4286\n",
            "Epoch 15/39\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7233 - acc: 0.7816\n",
            "Epoch 15: val_acc did not improve from 0.50000\n",
            "8/8 [==============================] - 106s 14s/step - loss: 0.7233 - acc: 0.7816 - val_loss: 2.2265 - val_acc: 0.4071\n",
            "Epoch 16/39\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6878 - acc: 0.7571 \n",
            "Epoch 16: val_acc did not improve from 0.50000\n",
            "8/8 [==============================] - 108s 14s/step - loss: 0.6878 - acc: 0.7571 - val_loss: 2.1688 - val_acc: 0.4214\n",
            "\n",
            "\n",
            "Model Accuracy 0.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.00      0.00      0.00        10\n",
            "       10000       1.00      0.60      0.75        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.56      0.50      0.53        10\n",
            "       20000       1.00      0.10      0.18        10\n",
            "        5000       0.43      0.60      0.50        10\n",
            "       50000       0.25      1.00      0.40        10\n",
            "\n",
            "    accuracy                           0.40        70\n",
            "   macro avg       0.46      0.40      0.34        70\n",
            "weighted avg       0.46      0.40      0.34        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 92 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 44\n",
            "learning rate: 0.08413975663252353\n",
            "batch size: 64\n",
            "dropout rate: 0.7789253411554502\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 4.3341 - acc: 0.2000\n",
            "Epoch 1: val_acc improved from -inf to 0.12857, saving model to percobaan92_noImgPro/model\\vgg_16_92-saved-model-01-acc-0.13.hdf5\n",
            "8/8 [==============================] - 100s 13s/step - loss: 4.3341 - acc: 0.2000 - val_loss: 15.1303 - val_acc: 0.1286\n",
            "Epoch 2/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 3.7296 - acc: 0.2857\n",
            "Epoch 2: val_acc improved from 0.12857 to 0.25000, saving model to percobaan92_noImgPro/model\\vgg_16_92-saved-model-02-acc-0.25.hdf5\n",
            "8/8 [==============================] - 100s 13s/step - loss: 3.7296 - acc: 0.2857 - val_loss: 5.0158 - val_acc: 0.2500\n",
            "Epoch 3/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.4143 - acc: 0.2816 \n",
            "Epoch 3: val_acc did not improve from 0.25000\n",
            "8/8 [==============================] - 103s 14s/step - loss: 2.4143 - acc: 0.2816 - val_loss: 3.0329 - val_acc: 0.2357\n",
            "Epoch 4/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.0090 - acc: 0.3163\n",
            "Epoch 4: val_acc did not improve from 0.25000\n",
            "8/8 [==============================] - 103s 13s/step - loss: 2.0090 - acc: 0.3163 - val_loss: 2.7847 - val_acc: 0.1857\n",
            "Epoch 5/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8262 - acc: 0.3551\n",
            "Epoch 5: val_acc did not improve from 0.25000\n",
            "8/8 [==============================] - 102s 13s/step - loss: 1.8262 - acc: 0.3551 - val_loss: 2.3120 - val_acc: 0.2429\n",
            "Epoch 6/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8304 - acc: 0.3286\n",
            "Epoch 6: val_acc improved from 0.25000 to 0.33571, saving model to percobaan92_noImgPro/model\\vgg_16_92-saved-model-06-acc-0.34.hdf5\n",
            "8/8 [==============================] - 101s 13s/step - loss: 1.8304 - acc: 0.3286 - val_loss: 2.1926 - val_acc: 0.3357\n",
            "Epoch 7/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5976 - acc: 0.4490\n",
            "Epoch 7: val_acc improved from 0.33571 to 0.36429, saving model to percobaan92_noImgPro/model\\vgg_16_92-saved-model-07-acc-0.36.hdf5\n",
            "8/8 [==============================] - 102s 13s/step - loss: 1.5976 - acc: 0.4490 - val_loss: 2.2296 - val_acc: 0.3643\n",
            "Epoch 8/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4524 - acc: 0.4898\n",
            "Epoch 8: val_acc did not improve from 0.36429\n",
            "8/8 [==============================] - 103s 13s/step - loss: 1.4524 - acc: 0.4898 - val_loss: 2.3113 - val_acc: 0.3286\n",
            "Epoch 9/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3723 - acc: 0.4918\n",
            "Epoch 9: val_acc improved from 0.36429 to 0.43571, saving model to percobaan92_noImgPro/model\\vgg_16_92-saved-model-09-acc-0.44.hdf5\n",
            "8/8 [==============================] - 102s 13s/step - loss: 1.3723 - acc: 0.4918 - val_loss: 2.1742 - val_acc: 0.4357\n",
            "Epoch 10/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3180 - acc: 0.5224\n",
            "Epoch 10: val_acc improved from 0.43571 to 0.47857, saving model to percobaan92_noImgPro/model\\vgg_16_92-saved-model-10-acc-0.48.hdf5\n",
            "8/8 [==============================] - 101s 13s/step - loss: 1.3180 - acc: 0.5224 - val_loss: 1.7944 - val_acc: 0.4786\n",
            "Epoch 11/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3810 - acc: 0.5224\n",
            "Epoch 11: val_acc did not improve from 0.47857\n",
            "8/8 [==============================] - 101s 13s/step - loss: 1.3810 - acc: 0.5224 - val_loss: 1.8361 - val_acc: 0.4071\n",
            "Epoch 12/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.2824 - acc: 0.5184\n",
            "Epoch 12: val_acc did not improve from 0.47857\n",
            "8/8 [==============================] - 102s 13s/step - loss: 1.2824 - acc: 0.5184 - val_loss: 2.1029 - val_acc: 0.3857\n",
            "Epoch 13/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.2702 - acc: 0.5224\n",
            "Epoch 13: val_acc did not improve from 0.47857\n",
            "8/8 [==============================] - 101s 13s/step - loss: 1.2702 - acc: 0.5224 - val_loss: 1.8641 - val_acc: 0.3357\n",
            "Epoch 14/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1910 - acc: 0.5796 \n",
            "Epoch 14: val_acc did not improve from 0.47857\n",
            "8/8 [==============================] - 103s 13s/step - loss: 1.1910 - acc: 0.5796 - val_loss: 1.9481 - val_acc: 0.3071\n",
            "Epoch 15/44\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1202 - acc: 0.5898\n",
            "Epoch 15: val_acc did not improve from 0.47857\n",
            "8/8 [==============================] - 101s 13s/step - loss: 1.1202 - acc: 0.5898 - val_loss: 1.9070 - val_acc: 0.4500\n",
            "\n",
            "\n",
            "Model Accuracy 0.32857142857142857\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.10      0.18        10\n",
            "       10000       0.23      0.90      0.37        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       1.00      0.10      0.18        10\n",
            "       20000       1.00      0.20      0.33        10\n",
            "        5000       0.33      0.10      0.15        10\n",
            "       50000       0.38      0.90      0.53        10\n",
            "\n",
            "    accuracy                           0.33        70\n",
            "   macro avg       0.56      0.33      0.25        70\n",
            "weighted avg       0.56      0.33      0.25        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 93 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 45\n",
            "learning rate: 0.07651261683469705\n",
            "batch size: 128\n",
            "dropout rate: 0.5237486670920499\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/45\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.7418 - acc: 0.2755 \n",
            "Epoch 1: val_acc improved from -inf to 0.30714, saving model to percobaan93_noImgPro/model\\vgg_16_93-saved-model-01-acc-0.31.hdf5\n",
            "4/4 [==============================] - 179s 46s/step - loss: 2.7418 - acc: 0.2755 - val_loss: 5.7981 - val_acc: 0.3071\n",
            "Epoch 2/45\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.8324 - acc: 0.4143 \n",
            "Epoch 2: val_acc did not improve from 0.30714\n",
            "4/4 [==============================] - 175s 47s/step - loss: 1.8324 - acc: 0.4143 - val_loss: 11.6062 - val_acc: 0.2786\n",
            "Epoch 3/45\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2986 - acc: 0.6061 \n",
            "Epoch 3: val_acc did not improve from 0.30714\n",
            "4/4 [==============================] - 177s 49s/step - loss: 1.2986 - acc: 0.6061 - val_loss: 6.4144 - val_acc: 0.2857\n",
            "Epoch 4/45\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0317 - acc: 0.6429 \n",
            "Epoch 4: val_acc did not improve from 0.30714\n",
            "4/4 [==============================] - 177s 47s/step - loss: 1.0317 - acc: 0.6429 - val_loss: 6.6638 - val_acc: 0.2357\n",
            "Epoch 5/45\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8675 - acc: 0.6918 \n",
            "Epoch 5: val_acc did not improve from 0.30714\n",
            "4/4 [==============================] - 175s 47s/step - loss: 0.8675 - acc: 0.6918 - val_loss: 7.9815 - val_acc: 0.1929\n",
            "Epoch 6/45\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7259 - acc: 0.7714 \n",
            "Epoch 6: val_acc did not improve from 0.30714\n",
            "4/4 [==============================] - 174s 47s/step - loss: 0.7259 - acc: 0.7714 - val_loss: 7.3097 - val_acc: 0.2571\n",
            "\n",
            "\n",
            "Model Accuracy 0.21428571428571427\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.17      1.00      0.29        10\n",
            "       10000       0.00      0.00      0.00        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.00      0.00      0.00        10\n",
            "       20000       0.00      0.00      0.00        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       0.83      0.50      0.62        10\n",
            "\n",
            "    accuracy                           0.21        70\n",
            "   macro avg       0.14      0.21      0.13        70\n",
            "weighted avg       0.14      0.21      0.13        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 94 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 43\n",
            "learning rate: 0.09757464689264725\n",
            "batch size: 128\n",
            "dropout rate: 0.6051247423444349\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/43\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.9685 - acc: 0.3143 \n",
            "Epoch 1: val_acc improved from -inf to 0.30714, saving model to percobaan94_noImgPro/model\\vgg_16_94-saved-model-01-acc-0.31.hdf5\n",
            "4/4 [==============================] - 176s 47s/step - loss: 2.9685 - acc: 0.3143 - val_loss: 8.8353 - val_acc: 0.3071\n",
            "Epoch 2/43\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.4432 - acc: 0.3633 \n",
            "Epoch 2: val_acc did not improve from 0.30714\n",
            "4/4 [==============================] - 185s 49s/step - loss: 2.4432 - acc: 0.3633 - val_loss: 6.7882 - val_acc: 0.2857\n",
            "Epoch 3/43\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.6954 - acc: 0.5102 \n",
            "Epoch 3: val_acc did not improve from 0.30714\n",
            "4/4 [==============================] - 165s 46s/step - loss: 1.6954 - acc: 0.5102 - val_loss: 6.7481 - val_acc: 0.2071\n",
            "Epoch 4/43\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.4974 - acc: 0.5143 \n",
            "Epoch 4: val_acc improved from 0.30714 to 0.34286, saving model to percobaan94_noImgPro/model\\vgg_16_94-saved-model-04-acc-0.34.hdf5\n",
            "4/4 [==============================] - 165s 44s/step - loss: 1.4974 - acc: 0.5143 - val_loss: 3.7772 - val_acc: 0.3429\n",
            "Epoch 5/43\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2790 - acc: 0.5755 \n",
            "Epoch 5: val_acc improved from 0.34286 to 0.37857, saving model to percobaan94_noImgPro/model\\vgg_16_94-saved-model-05-acc-0.38.hdf5\n",
            "4/4 [==============================] - 170s 45s/step - loss: 1.2790 - acc: 0.5755 - val_loss: 3.3784 - val_acc: 0.3786\n",
            "Epoch 6/43\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0656 - acc: 0.6286 \n",
            "Epoch 6: val_acc improved from 0.37857 to 0.42143, saving model to percobaan94_noImgPro/model\\vgg_16_94-saved-model-06-acc-0.42.hdf5\n",
            "4/4 [==============================] - 164s 44s/step - loss: 1.0656 - acc: 0.6286 - val_loss: 2.9310 - val_acc: 0.4214\n",
            "Epoch 7/43\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9191 - acc: 0.6714 \n",
            "Epoch 7: val_acc did not improve from 0.42143\n",
            "4/4 [==============================] - 165s 44s/step - loss: 0.9191 - acc: 0.6714 - val_loss: 3.2124 - val_acc: 0.3857\n",
            "Epoch 8/43\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8326 - acc: 0.7204 \n",
            "Epoch 8: val_acc improved from 0.42143 to 0.46429, saving model to percobaan94_noImgPro/model\\vgg_16_94-saved-model-08-acc-0.46.hdf5\n",
            "4/4 [==============================] - 169s 44s/step - loss: 0.8326 - acc: 0.7204 - val_loss: 3.1631 - val_acc: 0.4643\n",
            "Epoch 9/43\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7593 - acc: 0.7184 \n",
            "Epoch 9: val_acc did not improve from 0.46429\n",
            "4/4 [==============================] - 166s 44s/step - loss: 0.7593 - acc: 0.7184 - val_loss: 3.2311 - val_acc: 0.3786\n",
            "Epoch 10/43\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7543 - acc: 0.7694 \n",
            "Epoch 10: val_acc did not improve from 0.46429\n",
            "4/4 [==============================] - 166s 44s/step - loss: 0.7543 - acc: 0.7694 - val_loss: 4.4935 - val_acc: 0.3429\n",
            "Epoch 11/43\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6146 - acc: 0.8061 \n",
            "Epoch 11: val_acc did not improve from 0.46429\n",
            "4/4 [==============================] - 167s 47s/step - loss: 0.6146 - acc: 0.8061 - val_loss: 3.8192 - val_acc: 0.3929\n",
            "\n",
            "\n",
            "Model Accuracy 0.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.10      0.18        10\n",
            "       10000       0.20      1.00      0.34        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       1.00      0.10      0.18        10\n",
            "       20000       0.00      0.00      0.00        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       0.47      0.90      0.62        10\n",
            "\n",
            "    accuracy                           0.30        70\n",
            "   macro avg       0.38      0.30      0.19        70\n",
            "weighted avg       0.38      0.30      0.19        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 95 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 39\n",
            "learning rate: 0.08171992118605788\n",
            "batch size: 128\n",
            "dropout rate: 0.6743381041170281\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 3.2897 - acc: 0.2306 \n",
            "Epoch 1: val_acc improved from -inf to 0.17857, saving model to percobaan95_noImgPro/model\\vgg_16_95-saved-model-01-acc-0.18.hdf5\n",
            "4/4 [==============================] - 176s 49s/step - loss: 3.2897 - acc: 0.2306 - val_loss: 10.0215 - val_acc: 0.1786\n",
            "Epoch 2/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.4972 - acc: 0.3531 \n",
            "Epoch 2: val_acc did not improve from 0.17857\n",
            "4/4 [==============================] - 173s 47s/step - loss: 2.4972 - acc: 0.3531 - val_loss: 6.8673 - val_acc: 0.1571\n",
            "Epoch 3/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.8287 - acc: 0.4224 \n",
            "Epoch 3: val_acc did not improve from 0.17857\n",
            "4/4 [==============================] - 173s 47s/step - loss: 1.8287 - acc: 0.4224 - val_loss: 7.4958 - val_acc: 0.1714\n",
            "Epoch 4/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.5307 - acc: 0.4980 \n",
            "Epoch 4: val_acc improved from 0.17857 to 0.20714, saving model to percobaan95_noImgPro/model\\vgg_16_95-saved-model-04-acc-0.21.hdf5\n",
            "4/4 [==============================] - 171s 48s/step - loss: 1.5307 - acc: 0.4980 - val_loss: 5.5576 - val_acc: 0.2071\n",
            "Epoch 5/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2616 - acc: 0.5347 \n",
            "Epoch 5: val_acc did not improve from 0.20714\n",
            "4/4 [==============================] - 171s 48s/step - loss: 1.2616 - acc: 0.5347 - val_loss: 3.0701 - val_acc: 0.2071\n",
            "Epoch 6/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1400 - acc: 0.5755 \n",
            "Epoch 6: val_acc improved from 0.20714 to 0.35000, saving model to percobaan95_noImgPro/model\\vgg_16_95-saved-model-06-acc-0.35.hdf5\n",
            "4/4 [==============================] - 177s 48s/step - loss: 1.1400 - acc: 0.5755 - val_loss: 1.8606 - val_acc: 0.3500\n",
            "Epoch 7/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0553 - acc: 0.6388 \n",
            "Epoch 7: val_acc did not improve from 0.35000\n",
            "4/4 [==============================] - 178s 48s/step - loss: 1.0553 - acc: 0.6388 - val_loss: 2.5119 - val_acc: 0.3429\n",
            "Epoch 8/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0123 - acc: 0.6612 \n",
            "Epoch 8: val_acc improved from 0.35000 to 0.37857, saving model to percobaan95_noImgPro/model\\vgg_16_95-saved-model-08-acc-0.38.hdf5\n",
            "4/4 [==============================] - 176s 50s/step - loss: 1.0123 - acc: 0.6612 - val_loss: 2.6976 - val_acc: 0.3786\n",
            "Epoch 9/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9093 - acc: 0.6776 \n",
            "Epoch 9: val_acc did not improve from 0.37857\n",
            "4/4 [==============================] - 170s 47s/step - loss: 0.9093 - acc: 0.6776 - val_loss: 4.0459 - val_acc: 0.2857\n",
            "Epoch 10/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7886 - acc: 0.7306 \n",
            "Epoch 10: val_acc did not improve from 0.37857\n",
            "4/4 [==============================] - 170s 45s/step - loss: 0.7886 - acc: 0.7306 - val_loss: 6.2349 - val_acc: 0.2286\n",
            "Epoch 11/39\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7924 - acc: 0.7163 \n",
            "Epoch 11: val_acc did not improve from 0.37857\n",
            "4/4 [==============================] - 171s 48s/step - loss: 0.7924 - acc: 0.7163 - val_loss: 4.8394 - val_acc: 0.2500\n",
            "\n",
            "\n",
            "Model Accuracy 0.2857142857142857\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.62      0.80      0.70        10\n",
            "       10000       0.00      0.00      0.00        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.00      0.00      0.00        10\n",
            "       20000       0.18      0.90      0.30        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       0.50      0.30      0.37        10\n",
            "\n",
            "    accuracy                           0.29        70\n",
            "   macro avg       0.19      0.29      0.20        70\n",
            "weighted avg       0.19      0.29      0.20        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 96 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 42\n",
            "learning rate: 0.08354636121146751\n",
            "batch size: 128\n",
            "dropout rate: 0.7264866354983216\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/42\n",
            "4/4 [==============================] - ETA: 0s - loss: 3.4753 - acc: 0.2388 \n",
            "Epoch 1: val_acc improved from -inf to 0.25000, saving model to percobaan96_noImgPro/model\\vgg_16_96-saved-model-01-acc-0.25.hdf5\n",
            "4/4 [==============================] - 191s 52s/step - loss: 3.4753 - acc: 0.2388 - val_loss: 11.5067 - val_acc: 0.2500\n",
            "Epoch 2/42\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.7985 - acc: 0.3204 \n",
            "Epoch 2: val_acc did not improve from 0.25000\n",
            "4/4 [==============================] - 189s 52s/step - loss: 2.7985 - acc: 0.3204 - val_loss: 7.8602 - val_acc: 0.1571\n",
            "Epoch 3/42\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.1649 - acc: 0.4020 \n",
            "Epoch 3: val_acc did not improve from 0.25000\n",
            "4/4 [==============================] - 197s 55s/step - loss: 2.1649 - acc: 0.4020 - val_loss: 4.8356 - val_acc: 0.2500\n",
            "Epoch 4/42\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.8100 - acc: 0.4265 \n",
            "Epoch 4: val_acc improved from 0.25000 to 0.40000, saving model to percobaan96_noImgPro/model\\vgg_16_96-saved-model-04-acc-0.40.hdf5\n",
            "4/4 [==============================] - 186s 52s/step - loss: 1.8100 - acc: 0.4265 - val_loss: 3.1880 - val_acc: 0.4000\n",
            "Epoch 5/42\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.6198 - acc: 0.4367 \n",
            "Epoch 5: val_acc did not improve from 0.40000\n",
            "4/4 [==============================] - 192s 53s/step - loss: 1.6198 - acc: 0.4367 - val_loss: 3.4252 - val_acc: 0.3357\n",
            "Epoch 6/42\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.3883 - acc: 0.4857 \n",
            "Epoch 6: val_acc did not improve from 0.40000\n",
            "4/4 [==============================] - 191s 55s/step - loss: 1.3883 - acc: 0.4857 - val_loss: 3.0341 - val_acc: 0.3643\n",
            "Epoch 7/42\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2884 - acc: 0.5306 \n",
            "Epoch 7: val_acc improved from 0.40000 to 0.40714, saving model to percobaan96_noImgPro/model\\vgg_16_96-saved-model-07-acc-0.41.hdf5\n",
            "4/4 [==============================] - 187s 52s/step - loss: 1.2884 - acc: 0.5306 - val_loss: 2.7767 - val_acc: 0.4071\n",
            "Epoch 8/42\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2280 - acc: 0.5490 \n",
            "Epoch 8: val_acc did not improve from 0.40714\n",
            "4/4 [==============================] - 192s 54s/step - loss: 1.2280 - acc: 0.5490 - val_loss: 2.2911 - val_acc: 0.4071\n",
            "Epoch 9/42\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0760 - acc: 0.6224 \n",
            "Epoch 9: val_acc improved from 0.40714 to 0.43571, saving model to percobaan96_noImgPro/model\\vgg_16_96-saved-model-09-acc-0.44.hdf5\n",
            "4/4 [==============================] - 185s 52s/step - loss: 1.0760 - acc: 0.6224 - val_loss: 2.3467 - val_acc: 0.4357\n",
            "Epoch 10/42\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9983 - acc: 0.6612 \n",
            "Epoch 10: val_acc did not improve from 0.43571\n",
            "4/4 [==============================] - 197s 55s/step - loss: 0.9983 - acc: 0.6612 - val_loss: 3.0505 - val_acc: 0.2857\n",
            "Epoch 11/42\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0370 - acc: 0.6388 \n",
            "Epoch 11: val_acc did not improve from 0.43571\n",
            "4/4 [==============================] - 191s 53s/step - loss: 1.0370 - acc: 0.6388 - val_loss: 2.5756 - val_acc: 0.3643\n",
            "Epoch 12/42\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9462 - acc: 0.6653 \n",
            "Epoch 12: val_acc did not improve from 0.43571\n",
            "4/4 [==============================] - 187s 52s/step - loss: 0.9462 - acc: 0.6653 - val_loss: 2.5129 - val_acc: 0.4214\n",
            "Epoch 13/42\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9004 - acc: 0.6816 \n",
            "Epoch 13: val_acc did not improve from 0.43571\n",
            "4/4 [==============================] - 200s 53s/step - loss: 0.9004 - acc: 0.6816 - val_loss: 2.6864 - val_acc: 0.4071\n",
            "\n",
            "\n",
            "Model Accuracy 0.2571428571428571\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.10      0.18        10\n",
            "       10000       0.19      1.00      0.31        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.00      0.00      0.00        10\n",
            "       20000       0.47      0.70      0.56        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       0.00      0.00      0.00        10\n",
            "\n",
            "    accuracy                           0.26        70\n",
            "   macro avg       0.24      0.26      0.15        70\n",
            "weighted avg       0.24      0.26      0.15        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 97 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 50\n",
            "learning rate: 0.01625412684038976\n",
            "batch size: 32\n",
            "dropout rate: 0.5367568989558104\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.3197 - acc: 0.3245\n",
            "Epoch 1: val_acc improved from -inf to 0.29286, saving model to percobaan97_noImgPro/model\\vgg_16_97-saved-model-01-acc-0.29.hdf5\n",
            "16/16 [==============================] - 209s 14s/step - loss: 2.3197 - acc: 0.3245 - val_loss: 2.3858 - val_acc: 0.2929\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2797 - acc: 0.5571\n",
            "Epoch 2: val_acc did not improve from 0.29286\n",
            "16/16 [==============================] - 210s 13s/step - loss: 1.2797 - acc: 0.5571 - val_loss: 2.4029 - val_acc: 0.2357\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9878 - acc: 0.6673 \n",
            "Epoch 3: val_acc improved from 0.29286 to 0.45714, saving model to percobaan97_noImgPro/model\\vgg_16_97-saved-model-03-acc-0.46.hdf5\n",
            "16/16 [==============================] - 216s 14s/step - loss: 0.9878 - acc: 0.6673 - val_loss: 1.3965 - val_acc: 0.4571\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8029 - acc: 0.7224\n",
            "Epoch 4: val_acc improved from 0.45714 to 0.55714, saving model to percobaan97_noImgPro/model\\vgg_16_97-saved-model-04-acc-0.56.hdf5\n",
            "16/16 [==============================] - 211s 13s/step - loss: 0.8029 - acc: 0.7224 - val_loss: 1.1852 - val_acc: 0.5571\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6067 - acc: 0.7673\n",
            "Epoch 5: val_acc improved from 0.55714 to 0.58571, saving model to percobaan97_noImgPro/model\\vgg_16_97-saved-model-05-acc-0.59.hdf5\n",
            "16/16 [==============================] - 212s 13s/step - loss: 0.6067 - acc: 0.7673 - val_loss: 1.0332 - val_acc: 0.5857\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5694 - acc: 0.8224 \n",
            "Epoch 6: val_acc improved from 0.58571 to 0.60000, saving model to percobaan97_noImgPro/model\\vgg_16_97-saved-model-06-acc-0.60.hdf5\n",
            "16/16 [==============================] - 218s 14s/step - loss: 0.5694 - acc: 0.8224 - val_loss: 1.1383 - val_acc: 0.6000\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5192 - acc: 0.8143\n",
            "Epoch 7: val_acc did not improve from 0.60000\n",
            "16/16 [==============================] - 210s 13s/step - loss: 0.5192 - acc: 0.8143 - val_loss: 1.0844 - val_acc: 0.6000\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5123 - acc: 0.8306 \n",
            "Epoch 8: val_acc improved from 0.60000 to 0.67857, saving model to percobaan97_noImgPro/model\\vgg_16_97-saved-model-08-acc-0.68.hdf5\n",
            "16/16 [==============================] - 213s 14s/step - loss: 0.5123 - acc: 0.8306 - val_loss: 0.9004 - val_acc: 0.6786\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4545 - acc: 0.8551\n",
            "Epoch 9: val_acc did not improve from 0.67857\n",
            "16/16 [==============================] - 206s 13s/step - loss: 0.4545 - acc: 0.8551 - val_loss: 0.9970 - val_acc: 0.5929\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4303 - acc: 0.8449\n",
            "Epoch 10: val_acc improved from 0.67857 to 0.82143, saving model to percobaan97_noImgPro/model\\vgg_16_97-saved-model-10-acc-0.82.hdf5\n",
            "16/16 [==============================] - 206s 13s/step - loss: 0.4303 - acc: 0.8449 - val_loss: 0.5479 - val_acc: 0.8214\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2875 - acc: 0.8939\n",
            "Epoch 11: val_acc did not improve from 0.82143\n",
            "16/16 [==============================] - 212s 13s/step - loss: 0.2875 - acc: 0.8939 - val_loss: 0.5884 - val_acc: 0.7857\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3625 - acc: 0.8837 \n",
            "Epoch 12: val_acc did not improve from 0.82143\n",
            "16/16 [==============================] - 216s 14s/step - loss: 0.3625 - acc: 0.8837 - val_loss: 0.5472 - val_acc: 0.8071\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3688 - acc: 0.8755\n",
            "Epoch 13: val_acc improved from 0.82143 to 0.84286, saving model to percobaan97_noImgPro/model\\vgg_16_97-saved-model-13-acc-0.84.hdf5\n",
            "16/16 [==============================] - 202s 13s/step - loss: 0.3688 - acc: 0.8755 - val_loss: 0.5251 - val_acc: 0.8429\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3000 - acc: 0.8878 \n",
            "Epoch 14: val_acc did not improve from 0.84286\n",
            "16/16 [==============================] - 222s 14s/step - loss: 0.3000 - acc: 0.8878 - val_loss: 0.6266 - val_acc: 0.8071\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4626 - acc: 0.8612\n",
            "Epoch 15: val_acc did not improve from 0.84286\n",
            "16/16 [==============================] - 210s 13s/step - loss: 0.4626 - acc: 0.8612 - val_loss: 0.7106 - val_acc: 0.7929\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4718 - acc: 0.8551\n",
            "Epoch 16: val_acc did not improve from 0.84286\n",
            "16/16 [==============================] - 211s 14s/step - loss: 0.4718 - acc: 0.8551 - val_loss: 0.5791 - val_acc: 0.8214\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3022 - acc: 0.9020\n",
            "Epoch 17: val_acc did not improve from 0.84286\n",
            "16/16 [==============================] - 208s 13s/step - loss: 0.3022 - acc: 0.9020 - val_loss: 0.6640 - val_acc: 0.8214\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3517 - acc: 0.8857\n",
            "Epoch 18: val_acc improved from 0.84286 to 0.85714, saving model to percobaan97_noImgPro/model\\vgg_16_97-saved-model-18-acc-0.86.hdf5\n",
            "16/16 [==============================] - 205s 13s/step - loss: 0.3517 - acc: 0.8857 - val_loss: 0.5136 - val_acc: 0.8571\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3078 - acc: 0.8816\n",
            "Epoch 19: val_acc improved from 0.85714 to 0.87143, saving model to percobaan97_noImgPro/model\\vgg_16_97-saved-model-19-acc-0.87.hdf5\n",
            "16/16 [==============================] - 208s 13s/step - loss: 0.3078 - acc: 0.8816 - val_loss: 0.5060 - val_acc: 0.8714\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2726 - acc: 0.8959\n",
            "Epoch 20: val_acc did not improve from 0.87143\n",
            "16/16 [==============================] - 202s 13s/step - loss: 0.2726 - acc: 0.8959 - val_loss: 0.6057 - val_acc: 0.8571\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2828 - acc: 0.8980\n",
            "Epoch 21: val_acc did not improve from 0.87143\n",
            "16/16 [==============================] - 214s 13s/step - loss: 0.2828 - acc: 0.8980 - val_loss: 0.6494 - val_acc: 0.8357\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2880 - acc: 0.9000\n",
            "Epoch 22: val_acc did not improve from 0.87143\n",
            "16/16 [==============================] - 212s 13s/step - loss: 0.2880 - acc: 0.9000 - val_loss: 0.7363 - val_acc: 0.8143\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2778 - acc: 0.9224 \n",
            "Epoch 23: val_acc improved from 0.87143 to 0.87857, saving model to percobaan97_noImgPro/model\\vgg_16_97-saved-model-23-acc-0.88.hdf5\n",
            "16/16 [==============================] - 214s 14s/step - loss: 0.2778 - acc: 0.9224 - val_loss: 0.5841 - val_acc: 0.8786\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2584 - acc: 0.9082\n",
            "Epoch 24: val_acc improved from 0.87857 to 0.89286, saving model to percobaan97_noImgPro/model\\vgg_16_97-saved-model-24-acc-0.89.hdf5\n",
            "16/16 [==============================] - 211s 13s/step - loss: 0.2584 - acc: 0.9082 - val_loss: 0.5433 - val_acc: 0.8929\n",
            "\n",
            "\n",
            "Model Accuracy 0.8714285714285714\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.80      0.89        10\n",
            "       10000       1.00      0.90      0.95        10\n",
            "      100000       0.91      1.00      0.95        10\n",
            "        2000       0.64      0.90      0.75        10\n",
            "       20000       0.89      0.80      0.84        10\n",
            "        5000       0.82      0.90      0.86        10\n",
            "       50000       1.00      0.80      0.89        10\n",
            "\n",
            "    accuracy                           0.87        70\n",
            "   macro avg       0.89      0.87      0.88        70\n",
            "weighted avg       0.89      0.87      0.88        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 98 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 50\n",
            "learning rate: 0.0070250674028153\n",
            "batch size: 32\n",
            "dropout rate: 0.6405050388877433\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.5691 - acc: 0.2959\n",
            "Epoch 1: val_acc improved from -inf to 0.35000, saving model to percobaan98_noImgPro/model\\vgg_16_98-saved-model-01-acc-0.35.hdf5\n",
            "16/16 [==============================] - 183s 12s/step - loss: 2.5691 - acc: 0.2959 - val_loss: 2.6122 - val_acc: 0.3500\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.5775 - acc: 0.4918\n",
            "Epoch 2: val_acc did not improve from 0.35000\n",
            "16/16 [==============================] - 180s 11s/step - loss: 1.5775 - acc: 0.4918 - val_loss: 1.9897 - val_acc: 0.3000\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1076 - acc: 0.6020\n",
            "Epoch 3: val_acc improved from 0.35000 to 0.41429, saving model to percobaan98_noImgPro/model\\vgg_16_98-saved-model-03-acc-0.41.hdf5\n",
            "16/16 [==============================] - 177s 11s/step - loss: 1.1076 - acc: 0.6020 - val_loss: 1.5771 - val_acc: 0.4143\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9073 - acc: 0.7102\n",
            "Epoch 4: val_acc did not improve from 0.41429\n",
            "16/16 [==============================] - 176s 11s/step - loss: 0.9073 - acc: 0.7102 - val_loss: 1.5053 - val_acc: 0.4000\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7738 - acc: 0.7490\n",
            "Epoch 5: val_acc improved from 0.41429 to 0.51429, saving model to percobaan98_noImgPro/model\\vgg_16_98-saved-model-05-acc-0.51.hdf5\n",
            "16/16 [==============================] - 172s 11s/step - loss: 0.7738 - acc: 0.7490 - val_loss: 1.2678 - val_acc: 0.5143\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6507 - acc: 0.7735\n",
            "Epoch 6: val_acc improved from 0.51429 to 0.67143, saving model to percobaan98_noImgPro/model\\vgg_16_98-saved-model-06-acc-0.67.hdf5\n",
            "16/16 [==============================] - 175s 11s/step - loss: 0.6507 - acc: 0.7735 - val_loss: 1.0043 - val_acc: 0.6714\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5561 - acc: 0.8000\n",
            "Epoch 7: val_acc improved from 0.67143 to 0.73571, saving model to percobaan98_noImgPro/model\\vgg_16_98-saved-model-07-acc-0.74.hdf5\n",
            "16/16 [==============================] - 171s 11s/step - loss: 0.5561 - acc: 0.8000 - val_loss: 0.8215 - val_acc: 0.7357\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4948 - acc: 0.8388\n",
            "Epoch 8: val_acc improved from 0.73571 to 0.75714, saving model to percobaan98_noImgPro/model\\vgg_16_98-saved-model-08-acc-0.76.hdf5\n",
            "16/16 [==============================] - 177s 11s/step - loss: 0.4948 - acc: 0.8388 - val_loss: 0.7250 - val_acc: 0.7571\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4921 - acc: 0.8163\n",
            "Epoch 9: val_acc did not improve from 0.75714\n",
            "16/16 [==============================] - 173s 11s/step - loss: 0.4921 - acc: 0.8163 - val_loss: 0.7130 - val_acc: 0.7571\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5175 - acc: 0.8204\n",
            "Epoch 10: val_acc improved from 0.75714 to 0.80000, saving model to percobaan98_noImgPro/model\\vgg_16_98-saved-model-10-acc-0.80.hdf5\n",
            "16/16 [==============================] - 176s 11s/step - loss: 0.5175 - acc: 0.8204 - val_loss: 0.6053 - val_acc: 0.8000\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4074 - acc: 0.8429\n",
            "Epoch 11: val_acc improved from 0.80000 to 0.85000, saving model to percobaan98_noImgPro/model\\vgg_16_98-saved-model-11-acc-0.85.hdf5\n",
            "16/16 [==============================] - 176s 11s/step - loss: 0.4074 - acc: 0.8429 - val_loss: 0.5577 - val_acc: 0.8500\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4322 - acc: 0.8531\n",
            "Epoch 12: val_acc improved from 0.85000 to 0.85714, saving model to percobaan98_noImgPro/model\\vgg_16_98-saved-model-12-acc-0.86.hdf5\n",
            "16/16 [==============================] - 175s 11s/step - loss: 0.4322 - acc: 0.8531 - val_loss: 0.4904 - val_acc: 0.8571\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4127 - acc: 0.8592\n",
            "Epoch 13: val_acc improved from 0.85714 to 0.90000, saving model to percobaan98_noImgPro/model\\vgg_16_98-saved-model-13-acc-0.90.hdf5\n",
            "16/16 [==============================] - 176s 11s/step - loss: 0.4127 - acc: 0.8592 - val_loss: 0.4559 - val_acc: 0.9000\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3756 - acc: 0.8714\n",
            "Epoch 14: val_acc did not improve from 0.90000\n",
            "16/16 [==============================] - 173s 11s/step - loss: 0.3756 - acc: 0.8714 - val_loss: 0.4905 - val_acc: 0.8714\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4418 - acc: 0.8510\n",
            "Epoch 15: val_acc did not improve from 0.90000\n",
            "16/16 [==============================] - 175s 11s/step - loss: 0.4418 - acc: 0.8510 - val_loss: 0.5011 - val_acc: 0.8357\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4338 - acc: 0.8673\n",
            "Epoch 16: val_acc did not improve from 0.90000\n",
            "16/16 [==============================] - 174s 11s/step - loss: 0.4338 - acc: 0.8673 - val_loss: 0.4395 - val_acc: 0.8571\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3385 - acc: 0.8694\n",
            "Epoch 17: val_acc did not improve from 0.90000\n",
            "16/16 [==============================] - 178s 11s/step - loss: 0.3385 - acc: 0.8694 - val_loss: 0.4042 - val_acc: 0.8786\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3616 - acc: 0.8694\n",
            "Epoch 18: val_acc did not improve from 0.90000\n",
            "16/16 [==============================] - 174s 11s/step - loss: 0.3616 - acc: 0.8694 - val_loss: 0.3790 - val_acc: 0.8929\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3197 - acc: 0.8776\n",
            "Epoch 19: val_acc did not improve from 0.90000\n",
            "16/16 [==============================] - 173s 11s/step - loss: 0.3197 - acc: 0.8776 - val_loss: 0.4130 - val_acc: 0.8929\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3475 - acc: 0.8796\n",
            "Epoch 20: val_acc did not improve from 0.90000\n",
            "16/16 [==============================] - 172s 11s/step - loss: 0.3475 - acc: 0.8796 - val_loss: 0.4039 - val_acc: 0.8857\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3979 - acc: 0.8592\n",
            "Epoch 21: val_acc did not improve from 0.90000\n",
            "16/16 [==============================] - 172s 11s/step - loss: 0.3979 - acc: 0.8592 - val_loss: 0.3902 - val_acc: 0.8857\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3784 - acc: 0.8633\n",
            "Epoch 22: val_acc did not improve from 0.90000\n",
            "16/16 [==============================] - 174s 11s/step - loss: 0.3784 - acc: 0.8633 - val_loss: 0.3992 - val_acc: 0.8714\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2896 - acc: 0.9061\n",
            "Epoch 23: val_acc did not improve from 0.90000\n",
            "16/16 [==============================] - 177s 11s/step - loss: 0.2896 - acc: 0.9061 - val_loss: 0.4442 - val_acc: 0.8643\n",
            "\n",
            "\n",
            "Model Accuracy 0.9285714285714286\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.91      1.00      0.95        10\n",
            "       10000       1.00      0.90      0.95        10\n",
            "      100000       0.91      1.00      0.95        10\n",
            "        2000       0.83      1.00      0.91        10\n",
            "       20000       1.00      0.60      0.75        10\n",
            "        5000       1.00      1.00      1.00        10\n",
            "       50000       0.91      1.00      0.95        10\n",
            "\n",
            "    accuracy                           0.93        70\n",
            "   macro avg       0.94      0.93      0.92        70\n",
            "weighted avg       0.94      0.93      0.92        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 99 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 54\n",
            "learning rate: 0.014654132736817977\n",
            "batch size: 32\n",
            "dropout rate: 0.6576940541883354\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/54\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.6529 - acc: 0.2898\n",
            "Epoch 1: val_acc improved from -inf to 0.14286, saving model to percobaan99_noImgPro/model\\vgg_16_99-saved-model-01-acc-0.14.hdf5\n",
            "16/16 [==============================] - 122s 8s/step - loss: 2.6529 - acc: 0.2898 - val_loss: 3.5708 - val_acc: 0.1429\n",
            "Epoch 2/54\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.4981 - acc: 0.5061\n",
            "Epoch 2: val_acc improved from 0.14286 to 0.16429, saving model to percobaan99_noImgPro/model\\vgg_16_99-saved-model-02-acc-0.16.hdf5\n",
            "16/16 [==============================] - 117s 7s/step - loss: 1.4981 - acc: 0.5061 - val_loss: 3.5123 - val_acc: 0.1643\n",
            "Epoch 3/54\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3028 - acc: 0.5490\n",
            "Epoch 3: val_acc improved from 0.16429 to 0.39286, saving model to percobaan99_noImgPro/model\\vgg_16_99-saved-model-03-acc-0.39.hdf5\n",
            "16/16 [==============================] - 127s 8s/step - loss: 1.3028 - acc: 0.5490 - val_loss: 1.6605 - val_acc: 0.3929\n",
            "Epoch 4/54\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8629 - acc: 0.7000\n",
            "Epoch 4: val_acc improved from 0.39286 to 0.49286, saving model to percobaan99_noImgPro/model\\vgg_16_99-saved-model-04-acc-0.49.hdf5\n",
            "16/16 [==============================] - 128s 8s/step - loss: 0.8629 - acc: 0.7000 - val_loss: 1.2962 - val_acc: 0.4929\n",
            "Epoch 5/54\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7034 - acc: 0.7551\n",
            "Epoch 5: val_acc improved from 0.49286 to 0.67143, saving model to percobaan99_noImgPro/model\\vgg_16_99-saved-model-05-acc-0.67.hdf5\n",
            "16/16 [==============================] - 128s 8s/step - loss: 0.7034 - acc: 0.7551 - val_loss: 1.0867 - val_acc: 0.6714\n",
            "Epoch 6/54\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8093 - acc: 0.7163\n",
            "Epoch 6: val_acc did not improve from 0.67143\n",
            "16/16 [==============================] - 127s 8s/step - loss: 0.8093 - acc: 0.7163 - val_loss: 1.1919 - val_acc: 0.4929\n",
            "Epoch 7/54\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6784 - acc: 0.7592\n",
            "Epoch 7: val_acc did not improve from 0.67143\n",
            "16/16 [==============================] - 128s 8s/step - loss: 0.6784 - acc: 0.7592 - val_loss: 1.1060 - val_acc: 0.6000\n",
            "Epoch 8/54\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5650 - acc: 0.8143\n",
            "Epoch 8: val_acc improved from 0.67143 to 0.69286, saving model to percobaan99_noImgPro/model\\vgg_16_99-saved-model-08-acc-0.69.hdf5\n",
            "16/16 [==============================] - 127s 8s/step - loss: 0.5650 - acc: 0.8143 - val_loss: 0.8803 - val_acc: 0.6929\n",
            "Epoch 9/54\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5539 - acc: 0.8143\n",
            "Epoch 9: val_acc improved from 0.69286 to 0.72857, saving model to percobaan99_noImgPro/model\\vgg_16_99-saved-model-09-acc-0.73.hdf5\n",
            "16/16 [==============================] - 128s 8s/step - loss: 0.5539 - acc: 0.8143 - val_loss: 0.7438 - val_acc: 0.7286\n",
            "Epoch 10/54\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5289 - acc: 0.8000\n",
            "Epoch 10: val_acc improved from 0.72857 to 0.78571, saving model to percobaan99_noImgPro/model\\vgg_16_99-saved-model-10-acc-0.79.hdf5\n",
            "16/16 [==============================] - 127s 8s/step - loss: 0.5289 - acc: 0.8000 - val_loss: 0.6169 - val_acc: 0.7857\n",
            "Epoch 11/54\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4478 - acc: 0.8469\n",
            "Epoch 11: val_acc improved from 0.78571 to 0.82857, saving model to percobaan99_noImgPro/model\\vgg_16_99-saved-model-11-acc-0.83.hdf5\n",
            "16/16 [==============================] - 127s 8s/step - loss: 0.4478 - acc: 0.8469 - val_loss: 0.5338 - val_acc: 0.8286\n",
            "Epoch 12/54\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5041 - acc: 0.8367\n",
            "Epoch 12: val_acc improved from 0.82857 to 0.83571, saving model to percobaan99_noImgPro/model\\vgg_16_99-saved-model-12-acc-0.84.hdf5\n",
            "16/16 [==============================] - 129s 8s/step - loss: 0.5041 - acc: 0.8367 - val_loss: 0.5551 - val_acc: 0.8357\n",
            "Epoch 13/54\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4580 - acc: 0.8592\n",
            "Epoch 13: val_acc did not improve from 0.83571\n",
            "16/16 [==============================] - 126s 8s/step - loss: 0.4580 - acc: 0.8592 - val_loss: 0.6395 - val_acc: 0.8214\n",
            "Epoch 14/54\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5227 - acc: 0.8245\n",
            "Epoch 14: val_acc improved from 0.83571 to 0.85000, saving model to percobaan99_noImgPro/model\\vgg_16_99-saved-model-14-acc-0.85.hdf5\n",
            "16/16 [==============================] - 129s 8s/step - loss: 0.5227 - acc: 0.8245 - val_loss: 0.5231 - val_acc: 0.8500\n",
            "Epoch 15/54\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4645 - acc: 0.8429\n",
            "Epoch 15: val_acc did not improve from 0.85000\n",
            "16/16 [==============================] - 127s 8s/step - loss: 0.4645 - acc: 0.8429 - val_loss: 0.5458 - val_acc: 0.8071\n",
            "Epoch 16/54\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4518 - acc: 0.8429\n",
            "Epoch 16: val_acc improved from 0.85000 to 0.87143, saving model to percobaan99_noImgPro/model\\vgg_16_99-saved-model-16-acc-0.87.hdf5\n",
            "16/16 [==============================] - 128s 8s/step - loss: 0.4518 - acc: 0.8429 - val_loss: 0.4881 - val_acc: 0.8714\n",
            "Epoch 17/54\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3974 - acc: 0.8531\n",
            "Epoch 17: val_acc improved from 0.87143 to 0.87857, saving model to percobaan99_noImgPro/model\\vgg_16_99-saved-model-17-acc-0.88.hdf5\n",
            "16/16 [==============================] - 129s 8s/step - loss: 0.3974 - acc: 0.8531 - val_loss: 0.4925 - val_acc: 0.8786\n",
            "Epoch 18/54\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4621 - acc: 0.8531\n",
            "Epoch 18: val_acc did not improve from 0.87857\n",
            "16/16 [==============================] - 126s 8s/step - loss: 0.4621 - acc: 0.8531 - val_loss: 0.5179 - val_acc: 0.8500\n",
            "Epoch 19/54\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4479 - acc: 0.8367\n",
            "Epoch 19: val_acc did not improve from 0.87857\n",
            "16/16 [==============================] - 127s 8s/step - loss: 0.4479 - acc: 0.8367 - val_loss: 0.5635 - val_acc: 0.8643\n",
            "Epoch 20/54\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3402 - acc: 0.8857\n",
            "Epoch 20: val_acc did not improve from 0.87857\n",
            "16/16 [==============================] - 126s 8s/step - loss: 0.3402 - acc: 0.8857 - val_loss: 0.6658 - val_acc: 0.8071\n",
            "Epoch 21/54\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4286 - acc: 0.8327\n",
            "Epoch 21: val_acc did not improve from 0.87857\n",
            "16/16 [==============================] - 128s 8s/step - loss: 0.4286 - acc: 0.8327 - val_loss: 0.6588 - val_acc: 0.8000\n",
            "\n",
            "\n",
            "Model Accuracy 0.7714285714285715\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.80      0.80      0.80        10\n",
            "       10000       1.00      0.90      0.95        10\n",
            "      100000       1.00      0.40      0.57        10\n",
            "        2000       0.83      1.00      0.91        10\n",
            "       20000       1.00      0.40      0.57        10\n",
            "        5000       0.50      1.00      0.67        10\n",
            "       50000       0.82      0.90      0.86        10\n",
            "\n",
            "    accuracy                           0.77        70\n",
            "   macro avg       0.85      0.77      0.76        70\n",
            "weighted avg       0.85      0.77      0.76        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 100 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 50\n",
            "learning rate: 0.02468743932159409\n",
            "batch size: 32\n",
            "dropout rate: 0.7517110558169999\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.9684 - acc: 0.2694\n",
            "Epoch 1: val_acc improved from -inf to 0.23571, saving model to percobaan100_noImgPro/model\\vgg_16_100-saved-model-01-acc-0.24.hdf5\n",
            "16/16 [==============================] - 117s 7s/step - loss: 2.9684 - acc: 0.2694 - val_loss: 3.6228 - val_acc: 0.2357\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.0994 - acc: 0.3673\n",
            "Epoch 2: val_acc did not improve from 0.23571\n",
            "16/16 [==============================] - 136s 9s/step - loss: 2.0994 - acc: 0.3673 - val_loss: 2.6153 - val_acc: 0.2357\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.6014 - acc: 0.4857\n",
            "Epoch 3: val_acc did not improve from 0.23571\n",
            "16/16 [==============================] - 136s 9s/step - loss: 1.6014 - acc: 0.4857 - val_loss: 2.0517 - val_acc: 0.2286\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.4486 - acc: 0.5184\n",
            "Epoch 4: val_acc improved from 0.23571 to 0.50714, saving model to percobaan100_noImgPro/model\\vgg_16_100-saved-model-04-acc-0.51.hdf5\n",
            "16/16 [==============================] - 134s 9s/step - loss: 1.4486 - acc: 0.5184 - val_loss: 1.4398 - val_acc: 0.5071\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3208 - acc: 0.5510\n",
            "Epoch 5: val_acc improved from 0.50714 to 0.53571, saving model to percobaan100_noImgPro/model\\vgg_16_100-saved-model-05-acc-0.54.hdf5\n",
            "16/16 [==============================] - 135s 9s/step - loss: 1.3208 - acc: 0.5510 - val_loss: 1.2545 - val_acc: 0.5357\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1661 - acc: 0.6082\n",
            "Epoch 6: val_acc improved from 0.53571 to 0.70714, saving model to percobaan100_noImgPro/model\\vgg_16_100-saved-model-06-acc-0.71.hdf5\n",
            "16/16 [==============================] - 134s 8s/step - loss: 1.1661 - acc: 0.6082 - val_loss: 1.0016 - val_acc: 0.7071\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0741 - acc: 0.6143\n",
            "Epoch 7: val_acc did not improve from 0.70714\n",
            "16/16 [==============================] - 134s 8s/step - loss: 1.0741 - acc: 0.6143 - val_loss: 0.9549 - val_acc: 0.6857\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9219 - acc: 0.6612\n",
            "Epoch 8: val_acc did not improve from 0.70714\n",
            "16/16 [==============================] - 139s 9s/step - loss: 0.9219 - acc: 0.6612 - val_loss: 1.0790 - val_acc: 0.5714\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8970 - acc: 0.6898\n",
            "Epoch 9: val_acc did not improve from 0.70714\n",
            "16/16 [==============================] - 137s 9s/step - loss: 0.8970 - acc: 0.6898 - val_loss: 0.9733 - val_acc: 0.6357\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7941 - acc: 0.7347\n",
            "Epoch 10: val_acc improved from 0.70714 to 0.72857, saving model to percobaan100_noImgPro/model\\vgg_16_100-saved-model-10-acc-0.73.hdf5\n",
            "16/16 [==============================] - 137s 9s/step - loss: 0.7941 - acc: 0.7347 - val_loss: 0.7905 - val_acc: 0.7286\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7407 - acc: 0.7327\n",
            "Epoch 11: val_acc improved from 0.72857 to 0.75000, saving model to percobaan100_noImgPro/model\\vgg_16_100-saved-model-11-acc-0.75.hdf5\n",
            "16/16 [==============================] - 135s 9s/step - loss: 0.7407 - acc: 0.7327 - val_loss: 0.7589 - val_acc: 0.7500\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7114 - acc: 0.7571\n",
            "Epoch 12: val_acc did not improve from 0.75000\n",
            "16/16 [==============================] - 134s 8s/step - loss: 0.7114 - acc: 0.7571 - val_loss: 0.7465 - val_acc: 0.7214\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7615 - acc: 0.7551\n",
            "Epoch 13: val_acc did not improve from 0.75000\n",
            "16/16 [==============================] - 137s 9s/step - loss: 0.7615 - acc: 0.7551 - val_loss: 0.9124 - val_acc: 0.7143\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6749 - acc: 0.7531\n",
            "Epoch 14: val_acc did not improve from 0.75000\n",
            "16/16 [==============================] - 135s 9s/step - loss: 0.6749 - acc: 0.7531 - val_loss: 0.7784 - val_acc: 0.7357\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6430 - acc: 0.7898\n",
            "Epoch 15: val_acc improved from 0.75000 to 0.81429, saving model to percobaan100_noImgPro/model\\vgg_16_100-saved-model-15-acc-0.81.hdf5\n",
            "16/16 [==============================] - 134s 8s/step - loss: 0.6430 - acc: 0.7898 - val_loss: 0.6121 - val_acc: 0.8143\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6801 - acc: 0.7551\n",
            "Epoch 16: val_acc did not improve from 0.81429\n",
            "16/16 [==============================] - 136s 9s/step - loss: 0.6801 - acc: 0.7551 - val_loss: 0.6823 - val_acc: 0.7857\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6455 - acc: 0.7837\n",
            "Epoch 17: val_acc did not improve from 0.81429\n",
            "16/16 [==============================] - 136s 9s/step - loss: 0.6455 - acc: 0.7837 - val_loss: 0.6762 - val_acc: 0.8071\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7004 - acc: 0.7612\n",
            "Epoch 18: val_acc did not improve from 0.81429\n",
            "16/16 [==============================] - 136s 9s/step - loss: 0.7004 - acc: 0.7612 - val_loss: 0.7781 - val_acc: 0.7714\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7087 - acc: 0.7429\n",
            "Epoch 19: val_acc improved from 0.81429 to 0.82143, saving model to percobaan100_noImgPro/model\\vgg_16_100-saved-model-19-acc-0.82.hdf5\n",
            "16/16 [==============================] - 139s 9s/step - loss: 0.7087 - acc: 0.7429 - val_loss: 0.5501 - val_acc: 0.8214\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6974 - acc: 0.7653\n",
            "Epoch 20: val_acc improved from 0.82143 to 0.85000, saving model to percobaan100_noImgPro/model\\vgg_16_100-saved-model-20-acc-0.85.hdf5\n",
            "16/16 [==============================] - 136s 9s/step - loss: 0.6974 - acc: 0.7653 - val_loss: 0.5063 - val_acc: 0.8500\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6218 - acc: 0.7755\n",
            "Epoch 21: val_acc did not improve from 0.85000\n",
            "16/16 [==============================] - 136s 9s/step - loss: 0.6218 - acc: 0.7755 - val_loss: 0.6682 - val_acc: 0.7714\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5553 - acc: 0.7959\n",
            "Epoch 22: val_acc did not improve from 0.85000\n",
            "16/16 [==============================] - 137s 9s/step - loss: 0.5553 - acc: 0.7959 - val_loss: 0.6793 - val_acc: 0.7643\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6432 - acc: 0.7776\n",
            "Epoch 23: val_acc did not improve from 0.85000\n",
            "16/16 [==============================] - 136s 9s/step - loss: 0.6432 - acc: 0.7776 - val_loss: 0.7177 - val_acc: 0.8214\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6490 - acc: 0.7776\n",
            "Epoch 24: val_acc did not improve from 0.85000\n",
            "16/16 [==============================] - 136s 9s/step - loss: 0.6490 - acc: 0.7776 - val_loss: 0.6336 - val_acc: 0.8286\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6547 - acc: 0.7796\n",
            "Epoch 25: val_acc did not improve from 0.85000\n",
            "16/16 [==============================] - 136s 9s/step - loss: 0.6547 - acc: 0.7796 - val_loss: 0.5324 - val_acc: 0.8286\n",
            "\n",
            "\n",
            "Model Accuracy 0.8285714285714286\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.86      0.60      0.71        10\n",
            "       10000       1.00      1.00      1.00        10\n",
            "      100000       1.00      0.90      0.95        10\n",
            "        2000       0.53      1.00      0.69        10\n",
            "       20000       1.00      0.50      0.67        10\n",
            "        5000       0.90      0.90      0.90        10\n",
            "       50000       0.90      0.90      0.90        10\n",
            "\n",
            "    accuracy                           0.83        70\n",
            "   macro avg       0.88      0.83      0.83        70\n",
            "weighted avg       0.88      0.83      0.83        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 101 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 55\n",
            "learning rate: 0.022852070070134463\n",
            "batch size: 64\n",
            "dropout rate: 0.5558493916476301\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.3636 - acc: 0.3388 \n",
            "Epoch 1: val_acc improved from -inf to 0.25714, saving model to percobaan101_noImgPro/model\\vgg_16_101-saved-model-01-acc-0.26.hdf5\n",
            "8/8 [==============================] - 128s 16s/step - loss: 2.3636 - acc: 0.3388 - val_loss: 2.6049 - val_acc: 0.2571\n",
            "Epoch 2/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.2770 - acc: 0.5571 \n",
            "Epoch 2: val_acc improved from 0.25714 to 0.30000, saving model to percobaan101_noImgPro/model\\vgg_16_101-saved-model-02-acc-0.30.hdf5\n",
            "8/8 [==============================] - 133s 17s/step - loss: 1.2770 - acc: 0.5571 - val_loss: 4.2906 - val_acc: 0.3000\n",
            "Epoch 3/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0366 - acc: 0.6327 \n",
            "Epoch 3: val_acc improved from 0.30000 to 0.41429, saving model to percobaan101_noImgPro/model\\vgg_16_101-saved-model-03-acc-0.41.hdf5\n",
            "8/8 [==============================] - 132s 18s/step - loss: 1.0366 - acc: 0.6327 - val_loss: 2.0325 - val_acc: 0.4143\n",
            "Epoch 4/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8228 - acc: 0.7061 \n",
            "Epoch 4: val_acc did not improve from 0.41429\n",
            "8/8 [==============================] - 133s 17s/step - loss: 0.8228 - acc: 0.7061 - val_loss: 2.3327 - val_acc: 0.3143\n",
            "Epoch 5/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6205 - acc: 0.7918 \n",
            "Epoch 5: val_acc did not improve from 0.41429\n",
            "8/8 [==============================] - 129s 17s/step - loss: 0.6205 - acc: 0.7918 - val_loss: 2.1488 - val_acc: 0.2643\n",
            "Epoch 6/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5113 - acc: 0.8429 \n",
            "Epoch 6: val_acc improved from 0.41429 to 0.50000, saving model to percobaan101_noImgPro/model\\vgg_16_101-saved-model-06-acc-0.50.hdf5\n",
            "8/8 [==============================] - 132s 18s/step - loss: 0.5113 - acc: 0.8429 - val_loss: 1.3199 - val_acc: 0.5000\n",
            "Epoch 7/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4599 - acc: 0.8367 \n",
            "Epoch 7: val_acc improved from 0.50000 to 0.65000, saving model to percobaan101_noImgPro/model\\vgg_16_101-saved-model-07-acc-0.65.hdf5\n",
            "8/8 [==============================] - 132s 17s/step - loss: 0.4599 - acc: 0.8367 - val_loss: 1.0179 - val_acc: 0.6500\n",
            "Epoch 8/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4066 - acc: 0.8592 \n",
            "Epoch 8: val_acc improved from 0.65000 to 0.70714, saving model to percobaan101_noImgPro/model\\vgg_16_101-saved-model-08-acc-0.71.hdf5\n",
            "8/8 [==============================] - 132s 17s/step - loss: 0.4066 - acc: 0.8592 - val_loss: 0.8522 - val_acc: 0.7071\n",
            "Epoch 9/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3982 - acc: 0.8633 \n",
            "Epoch 9: val_acc improved from 0.70714 to 0.75000, saving model to percobaan101_noImgPro/model\\vgg_16_101-saved-model-09-acc-0.75.hdf5\n",
            "8/8 [==============================] - 134s 17s/step - loss: 0.3982 - acc: 0.8633 - val_loss: 0.7957 - val_acc: 0.7500\n",
            "Epoch 10/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2936 - acc: 0.9061 \n",
            "Epoch 10: val_acc improved from 0.75000 to 0.77857, saving model to percobaan101_noImgPro/model\\vgg_16_101-saved-model-10-acc-0.78.hdf5\n",
            "8/8 [==============================] - 132s 18s/step - loss: 0.2936 - acc: 0.9061 - val_loss: 0.6836 - val_acc: 0.7786\n",
            "Epoch 11/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2625 - acc: 0.9163 \n",
            "Epoch 11: val_acc did not improve from 0.77857\n",
            "8/8 [==============================] - 132s 17s/step - loss: 0.2625 - acc: 0.9163 - val_loss: 0.7281 - val_acc: 0.7571\n",
            "Epoch 12/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3323 - acc: 0.8898 \n",
            "Epoch 12: val_acc did not improve from 0.77857\n",
            "8/8 [==============================] - 134s 17s/step - loss: 0.3323 - acc: 0.8898 - val_loss: 0.7307 - val_acc: 0.7571\n",
            "Epoch 13/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3177 - acc: 0.8918 \n",
            "Epoch 13: val_acc did not improve from 0.77857\n",
            "8/8 [==============================] - 132s 17s/step - loss: 0.3177 - acc: 0.8918 - val_loss: 0.7937 - val_acc: 0.7429\n",
            "Epoch 14/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2990 - acc: 0.8857 \n",
            "Epoch 14: val_acc did not improve from 0.77857\n",
            "8/8 [==============================] - 132s 17s/step - loss: 0.2990 - acc: 0.8857 - val_loss: 0.8581 - val_acc: 0.7429\n",
            "Epoch 15/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2989 - acc: 0.8837 \n",
            "Epoch 15: val_acc did not improve from 0.77857\n",
            "8/8 [==============================] - 131s 17s/step - loss: 0.2989 - acc: 0.8837 - val_loss: 0.7779 - val_acc: 0.7786\n",
            "\n",
            "\n",
            "Model Accuracy 0.7428571428571429\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.40      0.57        10\n",
            "       10000       0.56      1.00      0.71        10\n",
            "      100000       1.00      0.70      0.82        10\n",
            "        2000       0.88      0.70      0.78        10\n",
            "       20000       0.80      0.40      0.53        10\n",
            "        5000       0.91      1.00      0.95        10\n",
            "       50000       0.59      1.00      0.74        10\n",
            "\n",
            "    accuracy                           0.74        70\n",
            "   macro avg       0.82      0.74      0.73        70\n",
            "weighted avg       0.82      0.74      0.73        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 102 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 48\n",
            "learning rate: 0.0017890422422136472\n",
            "batch size: 64\n",
            "dropout rate: 0.6174627683670726\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 3.1714 - acc: 0.1653 \n",
            "Epoch 1: val_acc improved from -inf to 0.24286, saving model to percobaan102_noImgPro/model\\vgg_16_102-saved-model-01-acc-0.24.hdf5\n",
            "8/8 [==============================] - 113s 14s/step - loss: 3.1714 - acc: 0.1653 - val_loss: 2.0764 - val_acc: 0.2429\n",
            "Epoch 2/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.1033 - acc: 0.3449 \n",
            "Epoch 2: val_acc improved from 0.24286 to 0.26429, saving model to percobaan102_noImgPro/model\\vgg_16_102-saved-model-02-acc-0.26.hdf5\n",
            "8/8 [==============================] - 120s 15s/step - loss: 2.1033 - acc: 0.3449 - val_loss: 1.9583 - val_acc: 0.2643\n",
            "Epoch 3/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5472 - acc: 0.4980 \n",
            "Epoch 3: val_acc improved from 0.26429 to 0.37857, saving model to percobaan102_noImgPro/model\\vgg_16_102-saved-model-03-acc-0.38.hdf5\n",
            "8/8 [==============================] - 115s 15s/step - loss: 1.5472 - acc: 0.4980 - val_loss: 1.7339 - val_acc: 0.3786\n",
            "Epoch 4/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3774 - acc: 0.5388 \n",
            "Epoch 4: val_acc improved from 0.37857 to 0.44286, saving model to percobaan102_noImgPro/model\\vgg_16_102-saved-model-04-acc-0.44.hdf5\n",
            "8/8 [==============================] - 119s 15s/step - loss: 1.3774 - acc: 0.5388 - val_loss: 1.5954 - val_acc: 0.4429\n",
            "Epoch 5/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0717 - acc: 0.6122 \n",
            "Epoch 5: val_acc improved from 0.44286 to 0.46429, saving model to percobaan102_noImgPro/model\\vgg_16_102-saved-model-05-acc-0.46.hdf5\n",
            "8/8 [==============================] - 118s 15s/step - loss: 1.0717 - acc: 0.6122 - val_loss: 1.4710 - val_acc: 0.4643\n",
            "Epoch 6/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8957 - acc: 0.6857 \n",
            "Epoch 6: val_acc did not improve from 0.46429\n",
            "8/8 [==============================] - 117s 15s/step - loss: 0.8957 - acc: 0.6857 - val_loss: 1.4635 - val_acc: 0.3929\n",
            "Epoch 7/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8254 - acc: 0.7204 \n",
            "Epoch 7: val_acc did not improve from 0.46429\n",
            "8/8 [==============================] - 116s 15s/step - loss: 0.8254 - acc: 0.7204 - val_loss: 1.4255 - val_acc: 0.4286\n",
            "Epoch 8/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7410 - acc: 0.7469 \n",
            "Epoch 8: val_acc improved from 0.46429 to 0.48571, saving model to percobaan102_noImgPro/model\\vgg_16_102-saved-model-08-acc-0.49.hdf5\n",
            "8/8 [==============================] - 118s 15s/step - loss: 0.7410 - acc: 0.7469 - val_loss: 1.3358 - val_acc: 0.4857\n",
            "Epoch 9/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6525 - acc: 0.7796 \n",
            "Epoch 9: val_acc improved from 0.48571 to 0.58571, saving model to percobaan102_noImgPro/model\\vgg_16_102-saved-model-09-acc-0.59.hdf5\n",
            "8/8 [==============================] - 116s 15s/step - loss: 0.6525 - acc: 0.7796 - val_loss: 1.2127 - val_acc: 0.5857\n",
            "Epoch 10/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7225 - acc: 0.7367 \n",
            "Epoch 10: val_acc improved from 0.58571 to 0.65000, saving model to percobaan102_noImgPro/model\\vgg_16_102-saved-model-10-acc-0.65.hdf5\n",
            "8/8 [==============================] - 119s 15s/step - loss: 0.7225 - acc: 0.7367 - val_loss: 1.1131 - val_acc: 0.6500\n",
            "Epoch 11/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5249 - acc: 0.8184 \n",
            "Epoch 11: val_acc improved from 0.65000 to 0.69286, saving model to percobaan102_noImgPro/model\\vgg_16_102-saved-model-11-acc-0.69.hdf5\n",
            "8/8 [==============================] - 118s 15s/step - loss: 0.5249 - acc: 0.8184 - val_loss: 1.0519 - val_acc: 0.6929\n",
            "Epoch 12/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4739 - acc: 0.8388 \n",
            "Epoch 12: val_acc improved from 0.69286 to 0.72857, saving model to percobaan102_noImgPro/model\\vgg_16_102-saved-model-12-acc-0.73.hdf5\n",
            "8/8 [==============================] - 118s 16s/step - loss: 0.4739 - acc: 0.8388 - val_loss: 0.9967 - val_acc: 0.7286\n",
            "Epoch 13/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4557 - acc: 0.8306 \n",
            "Epoch 13: val_acc did not improve from 0.72857\n",
            "8/8 [==============================] - 116s 15s/step - loss: 0.4557 - acc: 0.8306 - val_loss: 0.9584 - val_acc: 0.7214\n",
            "Epoch 14/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4336 - acc: 0.8571 \n",
            "Epoch 14: val_acc did not improve from 0.72857\n",
            "8/8 [==============================] - 117s 15s/step - loss: 0.4336 - acc: 0.8571 - val_loss: 0.9051 - val_acc: 0.7214\n",
            "Epoch 15/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4511 - acc: 0.8673 \n",
            "Epoch 15: val_acc improved from 0.72857 to 0.76429, saving model to percobaan102_noImgPro/model\\vgg_16_102-saved-model-15-acc-0.76.hdf5\n",
            "8/8 [==============================] - 118s 15s/step - loss: 0.4511 - acc: 0.8673 - val_loss: 0.8319 - val_acc: 0.7643\n",
            "Epoch 16/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4154 - acc: 0.8531 \n",
            "Epoch 16: val_acc improved from 0.76429 to 0.77857, saving model to percobaan102_noImgPro/model\\vgg_16_102-saved-model-16-acc-0.78.hdf5\n",
            "8/8 [==============================] - 117s 15s/step - loss: 0.4154 - acc: 0.8531 - val_loss: 0.7933 - val_acc: 0.7786\n",
            "Epoch 17/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3291 - acc: 0.8918 \n",
            "Epoch 17: val_acc improved from 0.77857 to 0.80714, saving model to percobaan102_noImgPro/model\\vgg_16_102-saved-model-17-acc-0.81.hdf5\n",
            "8/8 [==============================] - 118s 15s/step - loss: 0.3291 - acc: 0.8918 - val_loss: 0.7593 - val_acc: 0.8071\n",
            "Epoch 18/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3688 - acc: 0.8755 \n",
            "Epoch 18: val_acc improved from 0.80714 to 0.81429, saving model to percobaan102_noImgPro/model\\vgg_16_102-saved-model-18-acc-0.81.hdf5\n",
            "8/8 [==============================] - 117s 15s/step - loss: 0.3688 - acc: 0.8755 - val_loss: 0.7203 - val_acc: 0.8143\n",
            "Epoch 19/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3648 - acc: 0.8592 \n",
            "Epoch 19: val_acc improved from 0.81429 to 0.82857, saving model to percobaan102_noImgPro/model\\vgg_16_102-saved-model-19-acc-0.83.hdf5\n",
            "8/8 [==============================] - 118s 15s/step - loss: 0.3648 - acc: 0.8592 - val_loss: 0.6735 - val_acc: 0.8286\n",
            "Epoch 20/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3227 - acc: 0.8939 \n",
            "Epoch 20: val_acc improved from 0.82857 to 0.83571, saving model to percobaan102_noImgPro/model\\vgg_16_102-saved-model-20-acc-0.84.hdf5\n",
            "8/8 [==============================] - 118s 15s/step - loss: 0.3227 - acc: 0.8939 - val_loss: 0.6417 - val_acc: 0.8357\n",
            "Epoch 21/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3041 - acc: 0.9082 \n",
            "Epoch 21: val_acc improved from 0.83571 to 0.86429, saving model to percobaan102_noImgPro/model\\vgg_16_102-saved-model-21-acc-0.86.hdf5\n",
            "8/8 [==============================] - 117s 15s/step - loss: 0.3041 - acc: 0.9082 - val_loss: 0.6120 - val_acc: 0.8643\n",
            "Epoch 22/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2915 - acc: 0.9020 \n",
            "Epoch 22: val_acc improved from 0.86429 to 0.87143, saving model to percobaan102_noImgPro/model\\vgg_16_102-saved-model-22-acc-0.87.hdf5\n",
            "8/8 [==============================] - 118s 15s/step - loss: 0.2915 - acc: 0.9020 - val_loss: 0.5919 - val_acc: 0.8714\n",
            "Epoch 23/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2793 - acc: 0.9061 \n",
            "Epoch 23: val_acc did not improve from 0.87143\n",
            "8/8 [==============================] - 118s 15s/step - loss: 0.2793 - acc: 0.9061 - val_loss: 0.5709 - val_acc: 0.8714\n",
            "Epoch 24/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2700 - acc: 0.9184 \n",
            "Epoch 24: val_acc did not improve from 0.87143\n",
            "8/8 [==============================] - 117s 15s/step - loss: 0.2700 - acc: 0.9184 - val_loss: 0.5524 - val_acc: 0.8643\n",
            "Epoch 25/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2775 - acc: 0.9041 \n",
            "Epoch 25: val_acc did not improve from 0.87143\n",
            "8/8 [==============================] - 117s 15s/step - loss: 0.2775 - acc: 0.9041 - val_loss: 0.5354 - val_acc: 0.8643\n",
            "Epoch 26/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2539 - acc: 0.9265 \n",
            "Epoch 26: val_acc did not improve from 0.87143\n",
            "8/8 [==============================] - 117s 16s/step - loss: 0.2539 - acc: 0.9265 - val_loss: 0.5097 - val_acc: 0.8714\n",
            "Epoch 27/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3176 - acc: 0.9041 \n",
            "Epoch 27: val_acc improved from 0.87143 to 0.87857, saving model to percobaan102_noImgPro/model\\vgg_16_102-saved-model-27-acc-0.88.hdf5\n",
            "8/8 [==============================] - 116s 15s/step - loss: 0.3176 - acc: 0.9041 - val_loss: 0.4907 - val_acc: 0.8786\n",
            "Epoch 28/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2420 - acc: 0.9286 \n",
            "Epoch 28: val_acc improved from 0.87857 to 0.88571, saving model to percobaan102_noImgPro/model\\vgg_16_102-saved-model-28-acc-0.89.hdf5\n",
            "8/8 [==============================] - 118s 15s/step - loss: 0.2420 - acc: 0.9286 - val_loss: 0.4885 - val_acc: 0.8857\n",
            "Epoch 29/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2461 - acc: 0.9184 \n",
            "Epoch 29: val_acc did not improve from 0.88571\n",
            "8/8 [==============================] - 117s 15s/step - loss: 0.2461 - acc: 0.9184 - val_loss: 0.4852 - val_acc: 0.8714\n",
            "Epoch 30/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2151 - acc: 0.9204 \n",
            "Epoch 30: val_acc did not improve from 0.88571\n",
            "8/8 [==============================] - 117s 15s/step - loss: 0.2151 - acc: 0.9204 - val_loss: 0.4613 - val_acc: 0.8714\n",
            "Epoch 31/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1959 - acc: 0.9327 \n",
            "Epoch 31: val_acc did not improve from 0.88571\n",
            "8/8 [==============================] - 117s 15s/step - loss: 0.1959 - acc: 0.9327 - val_loss: 0.4462 - val_acc: 0.8714\n",
            "Epoch 32/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2223 - acc: 0.9265 \n",
            "Epoch 32: val_acc did not improve from 0.88571\n",
            "8/8 [==============================] - 117s 15s/step - loss: 0.2223 - acc: 0.9265 - val_loss: 0.4379 - val_acc: 0.8714\n",
            "Epoch 33/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1818 - acc: 0.9429 \n",
            "Epoch 33: val_acc did not improve from 0.88571\n",
            "8/8 [==============================] - 116s 15s/step - loss: 0.1818 - acc: 0.9429 - val_loss: 0.4372 - val_acc: 0.8714\n",
            "Epoch 34/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2115 - acc: 0.9388 \n",
            "Epoch 34: val_acc did not improve from 0.88571\n",
            "8/8 [==============================] - 116s 15s/step - loss: 0.2115 - acc: 0.9388 - val_loss: 0.4298 - val_acc: 0.8786\n",
            "Epoch 35/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2150 - acc: 0.9245 \n",
            "Epoch 35: val_acc improved from 0.88571 to 0.89286, saving model to percobaan102_noImgPro/model\\vgg_16_102-saved-model-35-acc-0.89.hdf5\n",
            "8/8 [==============================] - 119s 16s/step - loss: 0.2150 - acc: 0.9245 - val_loss: 0.4196 - val_acc: 0.8929\n",
            "Epoch 36/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1564 - acc: 0.9551 \n",
            "Epoch 36: val_acc did not improve from 0.89286\n",
            "8/8 [==============================] - 117s 15s/step - loss: 0.1564 - acc: 0.9551 - val_loss: 0.4139 - val_acc: 0.8929\n",
            "Epoch 37/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1772 - acc: 0.9388 \n",
            "Epoch 37: val_acc did not improve from 0.89286\n",
            "8/8 [==============================] - 117s 15s/step - loss: 0.1772 - acc: 0.9388 - val_loss: 0.4248 - val_acc: 0.8929\n",
            "Epoch 38/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1609 - acc: 0.9510 \n",
            "Epoch 38: val_acc did not improve from 0.89286\n",
            "8/8 [==============================] - 116s 15s/step - loss: 0.1609 - acc: 0.9510 - val_loss: 0.4282 - val_acc: 0.8857\n",
            "Epoch 39/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1897 - acc: 0.9367 \n",
            "Epoch 39: val_acc did not improve from 0.89286\n",
            "8/8 [==============================] - 117s 16s/step - loss: 0.1897 - acc: 0.9367 - val_loss: 0.4334 - val_acc: 0.8857\n",
            "Epoch 40/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1325 - acc: 0.9592 \n",
            "Epoch 40: val_acc did not improve from 0.89286\n",
            "8/8 [==============================] - 118s 15s/step - loss: 0.1325 - acc: 0.9592 - val_loss: 0.4297 - val_acc: 0.8786\n",
            "Epoch 41/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1470 - acc: 0.9551 \n",
            "Epoch 41: val_acc did not improve from 0.89286\n",
            "8/8 [==============================] - 118s 15s/step - loss: 0.1470 - acc: 0.9551 - val_loss: 0.4064 - val_acc: 0.8857\n",
            "Epoch 42/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1688 - acc: 0.9367 \n",
            "Epoch 42: val_acc improved from 0.89286 to 0.90000, saving model to percobaan102_noImgPro/model\\vgg_16_102-saved-model-42-acc-0.90.hdf5\n",
            "8/8 [==============================] - 117s 15s/step - loss: 0.1688 - acc: 0.9367 - val_loss: 0.4024 - val_acc: 0.9000\n",
            "Epoch 43/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1583 - acc: 0.9510 \n",
            "Epoch 43: val_acc did not improve from 0.90000\n",
            "8/8 [==============================] - 116s 15s/step - loss: 0.1583 - acc: 0.9510 - val_loss: 0.4028 - val_acc: 0.8929\n",
            "Epoch 44/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1528 - acc: 0.9510 \n",
            "Epoch 44: val_acc did not improve from 0.90000\n",
            "8/8 [==============================] - 119s 15s/step - loss: 0.1528 - acc: 0.9510 - val_loss: 0.4107 - val_acc: 0.8786\n",
            "Epoch 45/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1507 - acc: 0.9449 \n",
            "Epoch 45: val_acc did not improve from 0.90000\n",
            "8/8 [==============================] - 116s 15s/step - loss: 0.1507 - acc: 0.9449 - val_loss: 0.4272 - val_acc: 0.8786\n",
            "Epoch 46/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1548 - acc: 0.9592 \n",
            "Epoch 46: val_acc did not improve from 0.90000\n",
            "8/8 [==============================] - 118s 15s/step - loss: 0.1548 - acc: 0.9592 - val_loss: 0.4256 - val_acc: 0.8786\n",
            "Epoch 47/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1638 - acc: 0.9449 \n",
            "Epoch 47: val_acc did not improve from 0.90000\n",
            "8/8 [==============================] - 117s 15s/step - loss: 0.1638 - acc: 0.9449 - val_loss: 0.4112 - val_acc: 0.8857\n",
            "\n",
            "\n",
            "Model Accuracy 0.9142857142857143\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.90      0.95        10\n",
            "       10000       0.91      1.00      0.95        10\n",
            "      100000       1.00      0.90      0.95        10\n",
            "        2000       0.71      1.00      0.83        10\n",
            "       20000       0.89      0.80      0.84        10\n",
            "        5000       1.00      0.90      0.95        10\n",
            "       50000       1.00      0.90      0.95        10\n",
            "\n",
            "    accuracy                           0.91        70\n",
            "   macro avg       0.93      0.91      0.92        70\n",
            "weighted avg       0.93      0.91      0.92        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 103 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 54\n",
            "learning rate: 0.016501515711377784\n",
            "batch size: 64\n",
            "dropout rate: 0.6852190216309288\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.7106 - acc: 0.2980 \n",
            "Epoch 1: val_acc improved from -inf to 0.17857, saving model to percobaan103_noImgPro/model\\vgg_16_103-saved-model-01-acc-0.18.hdf5\n",
            "8/8 [==============================] - 195s 25s/step - loss: 2.7106 - acc: 0.2980 - val_loss: 4.1075 - val_acc: 0.1786\n",
            "Epoch 2/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5539 - acc: 0.4796 \n",
            "Epoch 2: val_acc improved from 0.17857 to 0.27857, saving model to percobaan103_noImgPro/model\\vgg_16_103-saved-model-02-acc-0.28.hdf5\n",
            "8/8 [==============================] - 193s 25s/step - loss: 1.5539 - acc: 0.4796 - val_loss: 3.1490 - val_acc: 0.2786\n",
            "Epoch 3/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.2165 - acc: 0.5878 \n",
            "Epoch 3: val_acc did not improve from 0.27857\n",
            "8/8 [==============================] - 191s 25s/step - loss: 1.2165 - acc: 0.5878 - val_loss: 2.7609 - val_acc: 0.2571\n",
            "Epoch 4/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0629 - acc: 0.6061 \n",
            "Epoch 4: val_acc did not improve from 0.27857\n",
            "8/8 [==============================] - 191s 25s/step - loss: 1.0629 - acc: 0.6061 - val_loss: 3.1309 - val_acc: 0.2000\n",
            "Epoch 5/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8543 - acc: 0.6755 \n",
            "Epoch 5: val_acc improved from 0.27857 to 0.30000, saving model to percobaan103_noImgPro/model\\vgg_16_103-saved-model-05-acc-0.30.hdf5\n",
            "8/8 [==============================] - 192s 26s/step - loss: 0.8543 - acc: 0.6755 - val_loss: 2.7501 - val_acc: 0.3000\n",
            "Epoch 6/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7735 - acc: 0.7286 \n",
            "Epoch 6: val_acc improved from 0.30000 to 0.38571, saving model to percobaan103_noImgPro/model\\vgg_16_103-saved-model-06-acc-0.39.hdf5\n",
            "8/8 [==============================] - 192s 25s/step - loss: 0.7735 - acc: 0.7286 - val_loss: 2.0642 - val_acc: 0.3857\n",
            "Epoch 7/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7383 - acc: 0.7571 \n",
            "Epoch 7: val_acc did not improve from 0.38571\n",
            "8/8 [==============================] - 192s 25s/step - loss: 0.7383 - acc: 0.7571 - val_loss: 1.9922 - val_acc: 0.3643\n",
            "Epoch 8/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6107 - acc: 0.7816 \n",
            "Epoch 8: val_acc improved from 0.38571 to 0.47857, saving model to percobaan103_noImgPro/model\\vgg_16_103-saved-model-08-acc-0.48.hdf5\n",
            "8/8 [==============================] - 191s 24s/step - loss: 0.6107 - acc: 0.7816 - val_loss: 1.6551 - val_acc: 0.4786\n",
            "Epoch 9/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5440 - acc: 0.8163 \n",
            "Epoch 9: val_acc did not improve from 0.47857\n",
            "8/8 [==============================] - 193s 25s/step - loss: 0.5440 - acc: 0.8163 - val_loss: 1.6805 - val_acc: 0.4786\n",
            "Epoch 10/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5129 - acc: 0.8286 \n",
            "Epoch 10: val_acc improved from 0.47857 to 0.51429, saving model to percobaan103_noImgPro/model\\vgg_16_103-saved-model-10-acc-0.51.hdf5\n",
            "8/8 [==============================] - 192s 25s/step - loss: 0.5129 - acc: 0.8286 - val_loss: 1.4212 - val_acc: 0.5143\n",
            "Epoch 11/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3433 - acc: 0.8694 \n",
            "Epoch 11: val_acc did not improve from 0.51429\n",
            "8/8 [==============================] - 192s 25s/step - loss: 0.3433 - acc: 0.8694 - val_loss: 1.4658 - val_acc: 0.5071\n",
            "Epoch 12/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4057 - acc: 0.8633 \n",
            "Epoch 12: val_acc improved from 0.51429 to 0.58571, saving model to percobaan103_noImgPro/model\\vgg_16_103-saved-model-12-acc-0.59.hdf5\n",
            "8/8 [==============================] - 189s 24s/step - loss: 0.4057 - acc: 0.8633 - val_loss: 1.4154 - val_acc: 0.5857\n",
            "Epoch 13/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3737 - acc: 0.8653 \n",
            "Epoch 13: val_acc improved from 0.58571 to 0.63571, saving model to percobaan103_noImgPro/model\\vgg_16_103-saved-model-13-acc-0.64.hdf5\n",
            "8/8 [==============================] - 190s 24s/step - loss: 0.3737 - acc: 0.8653 - val_loss: 1.3949 - val_acc: 0.6357\n",
            "Epoch 14/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3812 - acc: 0.8776 \n",
            "Epoch 14: val_acc did not improve from 0.63571\n",
            "8/8 [==============================] - 192s 25s/step - loss: 0.3812 - acc: 0.8776 - val_loss: 1.2944 - val_acc: 0.6071\n",
            "Epoch 15/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3800 - acc: 0.8510 \n",
            "Epoch 15: val_acc improved from 0.63571 to 0.65714, saving model to percobaan103_noImgPro/model\\vgg_16_103-saved-model-15-acc-0.66.hdf5\n",
            "8/8 [==============================] - 192s 24s/step - loss: 0.3800 - acc: 0.8510 - val_loss: 1.1029 - val_acc: 0.6571\n",
            "Epoch 16/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3469 - acc: 0.8714 \n",
            "Epoch 16: val_acc did not improve from 0.65714\n",
            "8/8 [==============================] - 193s 25s/step - loss: 0.3469 - acc: 0.8714 - val_loss: 1.0030 - val_acc: 0.6571\n",
            "Epoch 17/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4058 - acc: 0.8571 \n",
            "Epoch 17: val_acc improved from 0.65714 to 0.67857, saving model to percobaan103_noImgPro/model\\vgg_16_103-saved-model-17-acc-0.68.hdf5\n",
            "8/8 [==============================] - 196s 25s/step - loss: 0.4058 - acc: 0.8571 - val_loss: 1.0085 - val_acc: 0.6786\n",
            "Epoch 18/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3576 - acc: 0.8694 \n",
            "Epoch 18: val_acc improved from 0.67857 to 0.70714, saving model to percobaan103_noImgPro/model\\vgg_16_103-saved-model-18-acc-0.71.hdf5\n",
            "8/8 [==============================] - 190s 24s/step - loss: 0.3576 - acc: 0.8694 - val_loss: 0.8828 - val_acc: 0.7071\n",
            "Epoch 19/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3015 - acc: 0.8918 \n",
            "Epoch 19: val_acc did not improve from 0.70714\n",
            "8/8 [==============================] - 192s 26s/step - loss: 0.3015 - acc: 0.8918 - val_loss: 0.8999 - val_acc: 0.7071\n",
            "Epoch 20/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3254 - acc: 0.8857 \n",
            "Epoch 20: val_acc improved from 0.70714 to 0.74286, saving model to percobaan103_noImgPro/model\\vgg_16_103-saved-model-20-acc-0.74.hdf5\n",
            "8/8 [==============================] - 193s 25s/step - loss: 0.3254 - acc: 0.8857 - val_loss: 0.7565 - val_acc: 0.7429\n",
            "Epoch 21/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2830 - acc: 0.9000 \n",
            "Epoch 21: val_acc improved from 0.74286 to 0.82857, saving model to percobaan103_noImgPro/model\\vgg_16_103-saved-model-21-acc-0.83.hdf5\n",
            "8/8 [==============================] - 191s 25s/step - loss: 0.2830 - acc: 0.9000 - val_loss: 0.5745 - val_acc: 0.8286\n",
            "Epoch 22/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2381 - acc: 0.9102 \n",
            "Epoch 22: val_acc did not improve from 0.82857\n",
            "8/8 [==============================] - 194s 26s/step - loss: 0.2381 - acc: 0.9102 - val_loss: 0.5491 - val_acc: 0.8000\n",
            "Epoch 23/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3759 - acc: 0.8857 \n",
            "Epoch 23: val_acc improved from 0.82857 to 0.85714, saving model to percobaan103_noImgPro/model\\vgg_16_103-saved-model-23-acc-0.86.hdf5\n",
            "8/8 [==============================] - 190s 24s/step - loss: 0.3759 - acc: 0.8857 - val_loss: 0.5274 - val_acc: 0.8571\n",
            "Epoch 24/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3218 - acc: 0.8878 \n",
            "Epoch 24: val_acc did not improve from 0.85714\n",
            "8/8 [==============================] - 189s 25s/step - loss: 0.3218 - acc: 0.8878 - val_loss: 0.5401 - val_acc: 0.8500\n",
            "Epoch 25/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3068 - acc: 0.8980 \n",
            "Epoch 25: val_acc did not improve from 0.85714\n",
            "8/8 [==============================] - 188s 25s/step - loss: 0.3068 - acc: 0.8980 - val_loss: 0.5070 - val_acc: 0.8429\n",
            "Epoch 26/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2571 - acc: 0.9204 \n",
            "Epoch 26: val_acc did not improve from 0.85714\n",
            "8/8 [==============================] - 167s 22s/step - loss: 0.2571 - acc: 0.9204 - val_loss: 0.4993 - val_acc: 0.8429\n",
            "Epoch 27/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2439 - acc: 0.9143 \n",
            "Epoch 27: val_acc did not improve from 0.85714\n",
            "8/8 [==============================] - 173s 22s/step - loss: 0.2439 - acc: 0.9143 - val_loss: 0.5372 - val_acc: 0.8500\n",
            "Epoch 28/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2907 - acc: 0.9061 \n",
            "Epoch 28: val_acc did not improve from 0.85714\n",
            "8/8 [==============================] - 173s 22s/step - loss: 0.2907 - acc: 0.9061 - val_loss: 0.5536 - val_acc: 0.8429\n",
            "Epoch 29/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2661 - acc: 0.9122 \n",
            "Epoch 29: val_acc improved from 0.85714 to 0.86429, saving model to percobaan103_noImgPro/model\\vgg_16_103-saved-model-29-acc-0.86.hdf5\n",
            "8/8 [==============================] - 172s 22s/step - loss: 0.2661 - acc: 0.9122 - val_loss: 0.5066 - val_acc: 0.8643\n",
            "Epoch 30/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2114 - acc: 0.9367 \n",
            "Epoch 30: val_acc did not improve from 0.86429\n",
            "8/8 [==============================] - 173s 22s/step - loss: 0.2114 - acc: 0.9367 - val_loss: 0.5204 - val_acc: 0.8571\n",
            "Epoch 31/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3033 - acc: 0.9000 \n",
            "Epoch 31: val_acc improved from 0.86429 to 0.87857, saving model to percobaan103_noImgPro/model\\vgg_16_103-saved-model-31-acc-0.88.hdf5\n",
            "8/8 [==============================] - 172s 22s/step - loss: 0.3033 - acc: 0.9000 - val_loss: 0.4753 - val_acc: 0.8786\n",
            "Epoch 32/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1935 - acc: 0.9265 \n",
            "Epoch 32: val_acc did not improve from 0.87857\n",
            "8/8 [==============================] - 173s 22s/step - loss: 0.1935 - acc: 0.9265 - val_loss: 0.4586 - val_acc: 0.8714\n",
            "Epoch 33/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2710 - acc: 0.9082 \n",
            "Epoch 33: val_acc did not improve from 0.87857\n",
            "8/8 [==============================] - 173s 22s/step - loss: 0.2710 - acc: 0.9082 - val_loss: 0.4454 - val_acc: 0.8571\n",
            "Epoch 34/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1944 - acc: 0.9429 \n",
            "Epoch 34: val_acc did not improve from 0.87857\n",
            "8/8 [==============================] - 173s 22s/step - loss: 0.1944 - acc: 0.9429 - val_loss: 0.4434 - val_acc: 0.8714\n",
            "Epoch 35/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2151 - acc: 0.9286 \n",
            "Epoch 35: val_acc did not improve from 0.87857\n",
            "8/8 [==============================] - 173s 22s/step - loss: 0.2151 - acc: 0.9286 - val_loss: 0.4474 - val_acc: 0.8714\n",
            "Epoch 36/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2115 - acc: 0.9122 \n",
            "Epoch 36: val_acc did not improve from 0.87857\n",
            "8/8 [==============================] - 173s 22s/step - loss: 0.2115 - acc: 0.9122 - val_loss: 0.5020 - val_acc: 0.8643\n",
            "Epoch 37/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2255 - acc: 0.9224 \n",
            "Epoch 37: val_acc did not improve from 0.87857\n",
            "8/8 [==============================] - 174s 22s/step - loss: 0.2255 - acc: 0.9224 - val_loss: 0.5887 - val_acc: 0.8643\n",
            "Epoch 38/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2449 - acc: 0.9163 \n",
            "Epoch 38: val_acc improved from 0.87857 to 0.88571, saving model to percobaan103_noImgPro/model\\vgg_16_103-saved-model-38-acc-0.89.hdf5\n",
            "8/8 [==============================] - 172s 22s/step - loss: 0.2449 - acc: 0.9163 - val_loss: 0.5299 - val_acc: 0.8857\n",
            "Epoch 39/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2226 - acc: 0.9143 \n",
            "Epoch 39: val_acc did not improve from 0.88571\n",
            "8/8 [==============================] - 174s 22s/step - loss: 0.2226 - acc: 0.9143 - val_loss: 0.5191 - val_acc: 0.8643\n",
            "\n",
            "\n",
            "Model Accuracy 0.8571428571428571\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.90      0.90      0.90        10\n",
            "       10000       1.00      1.00      1.00        10\n",
            "      100000       1.00      0.50      0.67        10\n",
            "        2000       0.77      1.00      0.87        10\n",
            "       20000       0.86      0.60      0.71        10\n",
            "        5000       0.83      1.00      0.91        10\n",
            "       50000       0.77      1.00      0.87        10\n",
            "\n",
            "    accuracy                           0.86        70\n",
            "   macro avg       0.88      0.86      0.85        70\n",
            "weighted avg       0.88      0.86      0.85        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 104 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 51\n",
            "learning rate: 0.023680307760531743\n",
            "batch size: 64\n",
            "dropout rate: 0.7769735659432513\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 3.3232 - acc: 0.2776 \n",
            "Epoch 1: val_acc improved from -inf to 0.22857, saving model to percobaan104_noImgPro/model\\vgg_16_104-saved-model-01-acc-0.23.hdf5\n",
            "8/8 [==============================] - 166s 21s/step - loss: 3.3232 - acc: 0.2776 - val_loss: 4.2317 - val_acc: 0.2286\n",
            "Epoch 2/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.0232 - acc: 0.3490 \n",
            "Epoch 2: val_acc improved from 0.22857 to 0.30714, saving model to percobaan104_noImgPro/model\\vgg_16_104-saved-model-02-acc-0.31.hdf5\n",
            "8/8 [==============================] - 166s 21s/step - loss: 2.0232 - acc: 0.3490 - val_loss: 4.1746 - val_acc: 0.3071\n",
            "Epoch 3/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7817 - acc: 0.4531 \n",
            "Epoch 3: val_acc did not improve from 0.30714\n",
            "8/8 [==============================] - 165s 21s/step - loss: 1.7817 - acc: 0.4531 - val_loss: 4.8974 - val_acc: 0.1571\n",
            "Epoch 4/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5198 - acc: 0.4633 \n",
            "Epoch 4: val_acc did not improve from 0.30714\n",
            "8/8 [==============================] - 165s 21s/step - loss: 1.5198 - acc: 0.4633 - val_loss: 3.1739 - val_acc: 0.2143\n",
            "Epoch 5/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3532 - acc: 0.5082 \n",
            "Epoch 5: val_acc did not improve from 0.30714\n",
            "8/8 [==============================] - 165s 21s/step - loss: 1.3532 - acc: 0.5082 - val_loss: 2.6049 - val_acc: 0.2286\n",
            "Epoch 6/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1584 - acc: 0.6020 \n",
            "Epoch 6: val_acc did not improve from 0.30714\n",
            "8/8 [==============================] - 165s 21s/step - loss: 1.1584 - acc: 0.6020 - val_loss: 2.2888 - val_acc: 0.3071\n",
            "Epoch 7/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0859 - acc: 0.6143 \n",
            "Epoch 7: val_acc did not improve from 0.30714\n",
            "8/8 [==============================] - 166s 21s/step - loss: 1.0859 - acc: 0.6143 - val_loss: 2.1571 - val_acc: 0.2571\n",
            "Epoch 8/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9622 - acc: 0.6388 \n",
            "Epoch 8: val_acc improved from 0.30714 to 0.45000, saving model to percobaan104_noImgPro/model\\vgg_16_104-saved-model-08-acc-0.45.hdf5\n",
            "8/8 [==============================] - 165s 21s/step - loss: 0.9622 - acc: 0.6388 - val_loss: 1.5498 - val_acc: 0.4500\n",
            "Epoch 9/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8156 - acc: 0.7000 \n",
            "Epoch 9: val_acc improved from 0.45000 to 0.46429, saving model to percobaan104_noImgPro/model\\vgg_16_104-saved-model-09-acc-0.46.hdf5\n",
            "8/8 [==============================] - 166s 21s/step - loss: 0.8156 - acc: 0.7000 - val_loss: 1.5362 - val_acc: 0.4643\n",
            "Epoch 10/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8552 - acc: 0.7082 \n",
            "Epoch 10: val_acc did not improve from 0.46429\n",
            "8/8 [==============================] - 165s 21s/step - loss: 0.8552 - acc: 0.7082 - val_loss: 1.5974 - val_acc: 0.3714\n",
            "Epoch 11/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7848 - acc: 0.7143 \n",
            "Epoch 11: val_acc improved from 0.46429 to 0.50714, saving model to percobaan104_noImgPro/model\\vgg_16_104-saved-model-11-acc-0.51.hdf5\n",
            "8/8 [==============================] - 165s 21s/step - loss: 0.7848 - acc: 0.7143 - val_loss: 1.3283 - val_acc: 0.5071\n",
            "Epoch 12/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7545 - acc: 0.7469 \n",
            "Epoch 12: val_acc improved from 0.50714 to 0.55714, saving model to percobaan104_noImgPro/model\\vgg_16_104-saved-model-12-acc-0.56.hdf5\n",
            "8/8 [==============================] - 165s 21s/step - loss: 0.7545 - acc: 0.7469 - val_loss: 1.3188 - val_acc: 0.5571\n",
            "Epoch 13/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7623 - acc: 0.7408 \n",
            "Epoch 13: val_acc improved from 0.55714 to 0.57857, saving model to percobaan104_noImgPro/model\\vgg_16_104-saved-model-13-acc-0.58.hdf5\n",
            "8/8 [==============================] - 166s 21s/step - loss: 0.7623 - acc: 0.7408 - val_loss: 1.1297 - val_acc: 0.5786\n",
            "Epoch 14/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6302 - acc: 0.7837 \n",
            "Epoch 14: val_acc did not improve from 0.57857\n",
            "8/8 [==============================] - 165s 21s/step - loss: 0.6302 - acc: 0.7837 - val_loss: 1.0980 - val_acc: 0.5357\n",
            "Epoch 15/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6646 - acc: 0.7571 \n",
            "Epoch 15: val_acc improved from 0.57857 to 0.65714, saving model to percobaan104_noImgPro/model\\vgg_16_104-saved-model-15-acc-0.66.hdf5\n",
            "8/8 [==============================] - 165s 22s/step - loss: 0.6646 - acc: 0.7571 - val_loss: 0.8734 - val_acc: 0.6571\n",
            "Epoch 16/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5772 - acc: 0.7918 \n",
            "Epoch 16: val_acc improved from 0.65714 to 0.77857, saving model to percobaan104_noImgPro/model\\vgg_16_104-saved-model-16-acc-0.78.hdf5\n",
            "8/8 [==============================] - 166s 21s/step - loss: 0.5772 - acc: 0.7918 - val_loss: 0.7519 - val_acc: 0.7786\n",
            "Epoch 17/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5225 - acc: 0.8061 \n",
            "Epoch 17: val_acc improved from 0.77857 to 0.79286, saving model to percobaan104_noImgPro/model\\vgg_16_104-saved-model-17-acc-0.79.hdf5\n",
            "8/8 [==============================] - 165s 21s/step - loss: 0.5225 - acc: 0.8061 - val_loss: 0.7044 - val_acc: 0.7929\n",
            "Epoch 18/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6048 - acc: 0.8122 \n",
            "Epoch 18: val_acc did not improve from 0.79286\n",
            "8/8 [==============================] - 165s 21s/step - loss: 0.6048 - acc: 0.8122 - val_loss: 0.6418 - val_acc: 0.7857\n",
            "Epoch 19/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4593 - acc: 0.8367 \n",
            "Epoch 19: val_acc did not improve from 0.79286\n",
            "8/8 [==============================] - 165s 21s/step - loss: 0.4593 - acc: 0.8367 - val_loss: 0.6603 - val_acc: 0.7857\n",
            "Epoch 20/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5037 - acc: 0.8224 \n",
            "Epoch 20: val_acc did not improve from 0.79286\n",
            "8/8 [==============================] - 165s 21s/step - loss: 0.5037 - acc: 0.8224 - val_loss: 0.7341 - val_acc: 0.7643\n",
            "Epoch 21/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4789 - acc: 0.8204 \n",
            "Epoch 21: val_acc did not improve from 0.79286\n",
            "8/8 [==============================] - 166s 21s/step - loss: 0.4789 - acc: 0.8204 - val_loss: 0.8233 - val_acc: 0.7071\n",
            "Epoch 22/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5234 - acc: 0.8265 \n",
            "Epoch 22: val_acc did not improve from 0.79286\n",
            "8/8 [==============================] - 165s 21s/step - loss: 0.5234 - acc: 0.8265 - val_loss: 0.7298 - val_acc: 0.7500\n",
            "Epoch 23/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4590 - acc: 0.8408 \n",
            "Epoch 23: val_acc did not improve from 0.79286\n",
            "8/8 [==============================] - 165s 21s/step - loss: 0.4590 - acc: 0.8408 - val_loss: 0.6539 - val_acc: 0.7786\n",
            "\n",
            "\n",
            "Model Accuracy 0.7\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.88      0.70      0.78        10\n",
            "       10000       0.82      0.90      0.86        10\n",
            "      100000       1.00      0.70      0.82        10\n",
            "        2000       0.71      0.50      0.59        10\n",
            "       20000       0.67      0.20      0.31        10\n",
            "        5000       0.90      0.90      0.90        10\n",
            "       50000       0.42      1.00      0.59        10\n",
            "\n",
            "    accuracy                           0.70        70\n",
            "   macro avg       0.77      0.70      0.69        70\n",
            "weighted avg       0.77      0.70      0.69        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 105 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 48\n",
            "learning rate: 0.018759841309215514\n",
            "batch size: 128\n",
            "dropout rate: 0.5277537981102871\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/48\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.3897 - acc: 0.3184 \n",
            "Epoch 1: val_acc improved from -inf to 0.30000, saving model to percobaan105_noImgPro/model\\vgg_16_105-saved-model-01-acc-0.30.hdf5\n",
            "4/4 [==============================] - 158s 41s/step - loss: 2.3897 - acc: 0.3184 - val_loss: 2.6661 - val_acc: 0.3000\n",
            "Epoch 2/48\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1234 - acc: 0.6061 \n",
            "Epoch 2: val_acc did not improve from 0.30000\n",
            "4/4 [==============================] - 156s 41s/step - loss: 1.1234 - acc: 0.6061 - val_loss: 3.8068 - val_acc: 0.2143\n",
            "Epoch 3/48\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8665 - acc: 0.7020 \n",
            "Epoch 3: val_acc did not improve from 0.30000\n",
            "4/4 [==============================] - 156s 41s/step - loss: 0.8665 - acc: 0.7020 - val_loss: 6.1906 - val_acc: 0.1429\n",
            "Epoch 4/48\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6926 - acc: 0.7551 \n",
            "Epoch 4: val_acc did not improve from 0.30000\n",
            "4/4 [==============================] - 156s 41s/step - loss: 0.6926 - acc: 0.7551 - val_loss: 4.7335 - val_acc: 0.2071\n",
            "Epoch 5/48\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5927 - acc: 0.7776 \n",
            "Epoch 5: val_acc did not improve from 0.30000\n",
            "4/4 [==============================] - 156s 41s/step - loss: 0.5927 - acc: 0.7776 - val_loss: 2.9931 - val_acc: 0.2857\n",
            "Epoch 6/48\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4893 - acc: 0.8286 \n",
            "Epoch 6: val_acc improved from 0.30000 to 0.32143, saving model to percobaan105_noImgPro/model\\vgg_16_105-saved-model-06-acc-0.32.hdf5\n",
            "4/4 [==============================] - 157s 41s/step - loss: 0.4893 - acc: 0.8286 - val_loss: 2.3728 - val_acc: 0.3214\n",
            "Epoch 7/48\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3843 - acc: 0.8776 \n",
            "Epoch 7: val_acc did not improve from 0.32143\n",
            "4/4 [==============================] - 156s 41s/step - loss: 0.3843 - acc: 0.8776 - val_loss: 2.6408 - val_acc: 0.3000\n",
            "Epoch 8/48\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3988 - acc: 0.8388 \n",
            "Epoch 8: val_acc improved from 0.32143 to 0.42857, saving model to percobaan105_noImgPro/model\\vgg_16_105-saved-model-08-acc-0.43.hdf5\n",
            "4/4 [==============================] - 156s 41s/step - loss: 0.3988 - acc: 0.8388 - val_loss: 2.0764 - val_acc: 0.4286\n",
            "Epoch 9/48\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3240 - acc: 0.8918 \n",
            "Epoch 9: val_acc improved from 0.42857 to 0.55000, saving model to percobaan105_noImgPro/model\\vgg_16_105-saved-model-09-acc-0.55.hdf5\n",
            "4/4 [==============================] - 156s 43s/step - loss: 0.3240 - acc: 0.8918 - val_loss: 1.5383 - val_acc: 0.5500\n",
            "Epoch 10/48\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2723 - acc: 0.9020 \n",
            "Epoch 10: val_acc improved from 0.55000 to 0.55714, saving model to percobaan105_noImgPro/model\\vgg_16_105-saved-model-10-acc-0.56.hdf5\n",
            "4/4 [==============================] - 156s 41s/step - loss: 0.2723 - acc: 0.9020 - val_loss: 1.4246 - val_acc: 0.5571\n",
            "Epoch 11/48\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2356 - acc: 0.9163 \n",
            "Epoch 11: val_acc did not improve from 0.55714\n",
            "4/4 [==============================] - 157s 43s/step - loss: 0.2356 - acc: 0.9163 - val_loss: 1.5646 - val_acc: 0.5357\n",
            "Epoch 12/48\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2710 - acc: 0.9102 \n",
            "Epoch 12: val_acc did not improve from 0.55714\n",
            "4/4 [==============================] - 157s 42s/step - loss: 0.2710 - acc: 0.9102 - val_loss: 1.6581 - val_acc: 0.5214\n",
            "Epoch 13/48\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2035 - acc: 0.9286 \n",
            "Epoch 13: val_acc did not improve from 0.55714\n",
            "4/4 [==============================] - 156s 41s/step - loss: 0.2035 - acc: 0.9286 - val_loss: 1.7169 - val_acc: 0.5214\n",
            "Epoch 14/48\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1933 - acc: 0.9306 \n",
            "Epoch 14: val_acc did not improve from 0.55714\n",
            "4/4 [==============================] - 156s 43s/step - loss: 0.1933 - acc: 0.9306 - val_loss: 1.6515 - val_acc: 0.5429\n",
            "Epoch 15/48\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1866 - acc: 0.9490 \n",
            "Epoch 15: val_acc did not improve from 0.55714\n",
            "4/4 [==============================] - 156s 41s/step - loss: 0.1866 - acc: 0.9490 - val_loss: 1.6127 - val_acc: 0.5429\n",
            "\n",
            "\n",
            "Model Accuracy 0.35714285714285715\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.50      0.30      0.37        10\n",
            "       10000       0.67      0.40      0.50        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.75      0.30      0.43        10\n",
            "       20000       0.60      0.30      0.40        10\n",
            "        5000       1.00      0.20      0.33        10\n",
            "       50000       0.21      1.00      0.35        10\n",
            "\n",
            "    accuracy                           0.36        70\n",
            "   macro avg       0.53      0.36      0.34        70\n",
            "weighted avg       0.53      0.36      0.34        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 106 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 54\n",
            "learning rate: 0.015622899303237911\n",
            "batch size: 128\n",
            "dropout rate: 0.5824454210894686\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.4973 - acc: 0.2980 \n",
            "Epoch 1: val_acc improved from -inf to 0.14286, saving model to percobaan106_noImgPro/model\\vgg_16_106-saved-model-01-acc-0.14.hdf5\n",
            "4/4 [==============================] - 150s 41s/step - loss: 2.4973 - acc: 0.2980 - val_loss: 3.7466 - val_acc: 0.1429\n",
            "Epoch 2/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2230 - acc: 0.5816 \n",
            "Epoch 2: val_acc did not improve from 0.14286\n",
            "4/4 [==============================] - 149s 39s/step - loss: 1.2230 - acc: 0.5816 - val_loss: 4.2584 - val_acc: 0.1429\n",
            "Epoch 3/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9196 - acc: 0.6755 \n",
            "Epoch 3: val_acc improved from 0.14286 to 0.18571, saving model to percobaan106_noImgPro/model\\vgg_16_106-saved-model-03-acc-0.19.hdf5\n",
            "4/4 [==============================] - 149s 39s/step - loss: 0.9196 - acc: 0.6755 - val_loss: 4.4283 - val_acc: 0.1857\n",
            "Epoch 4/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7583 - acc: 0.7449 \n",
            "Epoch 4: val_acc improved from 0.18571 to 0.20000, saving model to percobaan106_noImgPro/model\\vgg_16_106-saved-model-04-acc-0.20.hdf5\n",
            "4/4 [==============================] - 149s 39s/step - loss: 0.7583 - acc: 0.7449 - val_loss: 3.7687 - val_acc: 0.2000\n",
            "Epoch 5/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6086 - acc: 0.8020 \n",
            "Epoch 5: val_acc improved from 0.20000 to 0.21429, saving model to percobaan106_noImgPro/model\\vgg_16_106-saved-model-05-acc-0.21.hdf5\n",
            "4/4 [==============================] - 149s 39s/step - loss: 0.6086 - acc: 0.8020 - val_loss: 3.3082 - val_acc: 0.2143\n",
            "Epoch 6/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6190 - acc: 0.7816 \n",
            "Epoch 6: val_acc did not improve from 0.21429\n",
            "4/4 [==============================] - 149s 40s/step - loss: 0.6190 - acc: 0.7816 - val_loss: 2.6093 - val_acc: 0.2143\n",
            "Epoch 7/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4403 - acc: 0.8510 \n",
            "Epoch 7: val_acc improved from 0.21429 to 0.25714, saving model to percobaan106_noImgPro/model\\vgg_16_106-saved-model-07-acc-0.26.hdf5\n",
            "4/4 [==============================] - 149s 39s/step - loss: 0.4403 - acc: 0.8510 - val_loss: 2.1087 - val_acc: 0.2571\n",
            "Epoch 8/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4375 - acc: 0.8510 \n",
            "Epoch 8: val_acc improved from 0.25714 to 0.32143, saving model to percobaan106_noImgPro/model\\vgg_16_106-saved-model-08-acc-0.32.hdf5\n",
            "4/4 [==============================] - 149s 39s/step - loss: 0.4375 - acc: 0.8510 - val_loss: 1.7912 - val_acc: 0.3214\n",
            "Epoch 9/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3516 - acc: 0.8837 \n",
            "Epoch 9: val_acc improved from 0.32143 to 0.40714, saving model to percobaan106_noImgPro/model\\vgg_16_106-saved-model-09-acc-0.41.hdf5\n",
            "4/4 [==============================] - 149s 39s/step - loss: 0.3516 - acc: 0.8837 - val_loss: 1.4288 - val_acc: 0.4071\n",
            "Epoch 10/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3090 - acc: 0.9082 \n",
            "Epoch 10: val_acc improved from 0.40714 to 0.41429, saving model to percobaan106_noImgPro/model\\vgg_16_106-saved-model-10-acc-0.41.hdf5\n",
            "4/4 [==============================] - 149s 41s/step - loss: 0.3090 - acc: 0.9082 - val_loss: 1.3971 - val_acc: 0.4143\n",
            "Epoch 11/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2678 - acc: 0.9163 \n",
            "Epoch 11: val_acc did not improve from 0.41429\n",
            "4/4 [==============================] - 149s 39s/step - loss: 0.2678 - acc: 0.9163 - val_loss: 1.5272 - val_acc: 0.3929\n",
            "Epoch 12/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3144 - acc: 0.8878 \n",
            "Epoch 12: val_acc did not improve from 0.41429\n",
            "4/4 [==============================] - 149s 39s/step - loss: 0.3144 - acc: 0.8878 - val_loss: 1.4983 - val_acc: 0.4071\n",
            "Epoch 13/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2584 - acc: 0.9224 \n",
            "Epoch 13: val_acc improved from 0.41429 to 0.43571, saving model to percobaan106_noImgPro/model\\vgg_16_106-saved-model-13-acc-0.44.hdf5\n",
            "4/4 [==============================] - 175s 48s/step - loss: 0.2584 - acc: 0.9224 - val_loss: 1.2500 - val_acc: 0.4357\n",
            "Epoch 14/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2232 - acc: 0.9306 \n",
            "Epoch 14: val_acc improved from 0.43571 to 0.60714, saving model to percobaan106_noImgPro/model\\vgg_16_106-saved-model-14-acc-0.61.hdf5\n",
            "4/4 [==============================] - 185s 51s/step - loss: 0.2232 - acc: 0.9306 - val_loss: 1.0097 - val_acc: 0.6071\n",
            "Epoch 15/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2230 - acc: 0.9163 \n",
            "Epoch 15: val_acc improved from 0.60714 to 0.71429, saving model to percobaan106_noImgPro/model\\vgg_16_106-saved-model-15-acc-0.71.hdf5\n",
            "4/4 [==============================] - 185s 50s/step - loss: 0.2230 - acc: 0.9163 - val_loss: 0.9088 - val_acc: 0.7143\n",
            "Epoch 16/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2015 - acc: 0.9286 \n",
            "Epoch 16: val_acc improved from 0.71429 to 0.73571, saving model to percobaan106_noImgPro/model\\vgg_16_106-saved-model-16-acc-0.74.hdf5\n",
            "4/4 [==============================] - 178s 50s/step - loss: 0.2015 - acc: 0.9286 - val_loss: 0.8923 - val_acc: 0.7357\n",
            "Epoch 17/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1853 - acc: 0.9347 \n",
            "Epoch 17: val_acc did not improve from 0.73571\n",
            "4/4 [==============================] - 181s 49s/step - loss: 0.1853 - acc: 0.9347 - val_loss: 0.9611 - val_acc: 0.7143\n",
            "Epoch 18/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2195 - acc: 0.9245 \n",
            "Epoch 18: val_acc did not improve from 0.73571\n",
            "4/4 [==============================] - 182s 49s/step - loss: 0.2195 - acc: 0.9245 - val_loss: 0.9393 - val_acc: 0.7214\n",
            "Epoch 19/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1808 - acc: 0.9286 \n",
            "Epoch 19: val_acc did not improve from 0.73571\n",
            "4/4 [==============================] - 180s 51s/step - loss: 0.1808 - acc: 0.9286 - val_loss: 0.8128 - val_acc: 0.7357\n",
            "Epoch 20/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2050 - acc: 0.9286 \n",
            "Epoch 20: val_acc improved from 0.73571 to 0.77857, saving model to percobaan106_noImgPro/model\\vgg_16_106-saved-model-20-acc-0.78.hdf5\n",
            "4/4 [==============================] - 191s 53s/step - loss: 0.2050 - acc: 0.9286 - val_loss: 0.7069 - val_acc: 0.7786\n",
            "Epoch 21/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1581 - acc: 0.9551 \n",
            "Epoch 21: val_acc improved from 0.77857 to 0.79286, saving model to percobaan106_noImgPro/model\\vgg_16_106-saved-model-21-acc-0.79.hdf5\n",
            "4/4 [==============================] - 177s 48s/step - loss: 0.1581 - acc: 0.9551 - val_loss: 0.6754 - val_acc: 0.7929\n",
            "Epoch 22/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1354 - acc: 0.9531 \n",
            "Epoch 22: val_acc did not improve from 0.79286\n",
            "4/4 [==============================] - 182s 49s/step - loss: 0.1354 - acc: 0.9531 - val_loss: 0.6969 - val_acc: 0.7786\n",
            "Epoch 23/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1492 - acc: 0.9551 \n",
            "Epoch 23: val_acc did not improve from 0.79286\n",
            "4/4 [==============================] - 174s 48s/step - loss: 0.1492 - acc: 0.9551 - val_loss: 0.7263 - val_acc: 0.7857\n",
            "Epoch 24/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1102 - acc: 0.9694 \n",
            "Epoch 24: val_acc did not improve from 0.79286\n",
            "4/4 [==============================] - 181s 49s/step - loss: 0.1102 - acc: 0.9694 - val_loss: 0.8338 - val_acc: 0.7500\n",
            "Epoch 25/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1247 - acc: 0.9633 \n",
            "Epoch 25: val_acc did not improve from 0.79286\n",
            "4/4 [==============================] - 181s 49s/step - loss: 0.1247 - acc: 0.9633 - val_loss: 0.9460 - val_acc: 0.7286\n",
            "Epoch 26/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0852 - acc: 0.9776 \n",
            "Epoch 26: val_acc did not improve from 0.79286\n",
            "4/4 [==============================] - 178s 48s/step - loss: 0.0852 - acc: 0.9776 - val_loss: 1.0159 - val_acc: 0.6929\n",
            "\n",
            "\n",
            "Model Accuracy 0.6\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.90      0.90      0.90        10\n",
            "       10000       0.88      0.70      0.78        10\n",
            "      100000       1.00      0.10      0.18        10\n",
            "        2000       1.00      0.20      0.33        10\n",
            "       20000       1.00      0.40      0.57        10\n",
            "        5000       0.64      0.90      0.75        10\n",
            "       50000       0.32      1.00      0.49        10\n",
            "\n",
            "    accuracy                           0.60        70\n",
            "   macro avg       0.82      0.60      0.57        70\n",
            "weighted avg       0.82      0.60      0.57        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 107 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 50\n",
            "learning rate: 0.008112104188693387\n",
            "batch size: 128\n",
            "dropout rate: 0.716549525043203\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.9294 - acc: 0.2653 \n",
            "Epoch 1: val_acc improved from -inf to 0.21429, saving model to percobaan107_noImgPro/model\\vgg_16_107-saved-model-01-acc-0.21.hdf5\n",
            "4/4 [==============================] - 199s 54s/step - loss: 2.9294 - acc: 0.2653 - val_loss: 3.5246 - val_acc: 0.2143\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.8294 - acc: 0.4551 \n",
            "Epoch 2: val_acc improved from 0.21429 to 0.22143, saving model to percobaan107_noImgPro/model\\vgg_16_107-saved-model-02-acc-0.22.hdf5\n",
            "4/4 [==============================] - 203s 56s/step - loss: 1.8294 - acc: 0.4551 - val_loss: 3.2307 - val_acc: 0.2214\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.3581 - acc: 0.5571 \n",
            "Epoch 3: val_acc improved from 0.22143 to 0.26429, saving model to percobaan107_noImgPro/model\\vgg_16_107-saved-model-03-acc-0.26.hdf5\n",
            "4/4 [==============================] - 199s 55s/step - loss: 1.3581 - acc: 0.5571 - val_loss: 3.0146 - val_acc: 0.2643\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0934 - acc: 0.6224 \n",
            "Epoch 4: val_acc did not improve from 0.26429\n",
            "4/4 [==============================] - 182s 50s/step - loss: 1.0934 - acc: 0.6224 - val_loss: 2.7372 - val_acc: 0.2643\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9183 - acc: 0.6796 \n",
            "Epoch 5: val_acc did not improve from 0.26429\n",
            "4/4 [==============================] - 198s 54s/step - loss: 0.9183 - acc: 0.6796 - val_loss: 2.7476 - val_acc: 0.2643\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9291 - acc: 0.6837 \n",
            "Epoch 6: val_acc did not improve from 0.26429\n",
            "4/4 [==============================] - 197s 55s/step - loss: 0.9291 - acc: 0.6837 - val_loss: 3.0182 - val_acc: 0.2429\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7509 - acc: 0.7327 \n",
            "Epoch 7: val_acc did not improve from 0.26429\n",
            "4/4 [==============================] - 197s 54s/step - loss: 0.7509 - acc: 0.7327 - val_loss: 3.1045 - val_acc: 0.2143\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7004 - acc: 0.7388 \n",
            "Epoch 8: val_acc did not improve from 0.26429\n",
            "4/4 [==============================] - 196s 56s/step - loss: 0.7004 - acc: 0.7388 - val_loss: 2.8128 - val_acc: 0.2286\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6317 - acc: 0.8041 \n",
            "Epoch 9: val_acc did not improve from 0.26429\n",
            "4/4 [==============================] - 207s 54s/step - loss: 0.6317 - acc: 0.8041 - val_loss: 2.3314 - val_acc: 0.2500\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5927 - acc: 0.7939 \n",
            "Epoch 10: val_acc did not improve from 0.26429\n",
            "4/4 [==============================] - 215s 60s/step - loss: 0.5927 - acc: 0.7939 - val_loss: 1.8781 - val_acc: 0.2643\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4970 - acc: 0.8265 \n",
            "Epoch 11: val_acc improved from 0.26429 to 0.37143, saving model to percobaan107_noImgPro/model\\vgg_16_107-saved-model-11-acc-0.37.hdf5\n",
            "4/4 [==============================] - 206s 55s/step - loss: 0.4970 - acc: 0.8265 - val_loss: 1.5567 - val_acc: 0.3714\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4741 - acc: 0.8347 \n",
            "Epoch 12: val_acc improved from 0.37143 to 0.42857, saving model to percobaan107_noImgPro/model\\vgg_16_107-saved-model-12-acc-0.43.hdf5\n",
            "4/4 [==============================] - 191s 54s/step - loss: 0.4741 - acc: 0.8347 - val_loss: 1.4233 - val_acc: 0.4286\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3950 - acc: 0.8653 \n",
            "Epoch 13: val_acc did not improve from 0.42857\n",
            "4/4 [==============================] - 197s 54s/step - loss: 0.3950 - acc: 0.8653 - val_loss: 1.4016 - val_acc: 0.4214\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4076 - acc: 0.8612 \n",
            "Epoch 14: val_acc did not improve from 0.42857\n",
            "4/4 [==============================] - 196s 54s/step - loss: 0.4076 - acc: 0.8612 - val_loss: 1.4088 - val_acc: 0.4214\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3738 - acc: 0.8469 \n",
            "Epoch 15: val_acc improved from 0.42857 to 0.44286, saving model to percobaan107_noImgPro/model\\vgg_16_107-saved-model-15-acc-0.44.hdf5\n",
            "4/4 [==============================] - 197s 55s/step - loss: 0.3738 - acc: 0.8469 - val_loss: 1.3861 - val_acc: 0.4429\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3816 - acc: 0.8633 \n",
            "Epoch 16: val_acc improved from 0.44286 to 0.49286, saving model to percobaan107_noImgPro/model\\vgg_16_107-saved-model-16-acc-0.49.hdf5\n",
            "4/4 [==============================] - 201s 55s/step - loss: 0.3816 - acc: 0.8633 - val_loss: 1.3242 - val_acc: 0.4929\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3234 - acc: 0.8939 \n",
            "Epoch 17: val_acc improved from 0.49286 to 0.55000, saving model to percobaan107_noImgPro/model\\vgg_16_107-saved-model-17-acc-0.55.hdf5\n",
            "4/4 [==============================] - 192s 53s/step - loss: 0.3234 - acc: 0.8939 - val_loss: 1.2358 - val_acc: 0.5500\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3163 - acc: 0.8878 \n",
            "Epoch 18: val_acc did not improve from 0.55000\n",
            "4/4 [==============================] - 187s 51s/step - loss: 0.3163 - acc: 0.8878 - val_loss: 1.1623 - val_acc: 0.5500\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3604 - acc: 0.8837 \n",
            "Epoch 19: val_acc improved from 0.55000 to 0.58571, saving model to percobaan107_noImgPro/model\\vgg_16_107-saved-model-19-acc-0.59.hdf5\n",
            "4/4 [==============================] - 201s 57s/step - loss: 0.3604 - acc: 0.8837 - val_loss: 1.0915 - val_acc: 0.5857\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2569 - acc: 0.9020 \n",
            "Epoch 20: val_acc improved from 0.58571 to 0.60714, saving model to percobaan107_noImgPro/model\\vgg_16_107-saved-model-20-acc-0.61.hdf5\n",
            "4/4 [==============================] - 191s 52s/step - loss: 0.2569 - acc: 0.9020 - val_loss: 1.0466 - val_acc: 0.6071\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2617 - acc: 0.9061 \n",
            "Epoch 21: val_acc improved from 0.60714 to 0.67143, saving model to percobaan107_noImgPro/model\\vgg_16_107-saved-model-21-acc-0.67.hdf5\n",
            "4/4 [==============================] - 199s 55s/step - loss: 0.2617 - acc: 0.9061 - val_loss: 0.9859 - val_acc: 0.6714\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2692 - acc: 0.9041 \n",
            "Epoch 22: val_acc did not improve from 0.67143\n",
            "4/4 [==============================] - 196s 54s/step - loss: 0.2692 - acc: 0.9041 - val_loss: 1.0032 - val_acc: 0.6214\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2565 - acc: 0.8980 \n",
            "Epoch 23: val_acc did not improve from 0.67143\n",
            "4/4 [==============================] - 196s 54s/step - loss: 0.2565 - acc: 0.8980 - val_loss: 1.0131 - val_acc: 0.6071\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2166 - acc: 0.9347 \n",
            "Epoch 24: val_acc did not improve from 0.67143\n",
            "4/4 [==============================] - 202s 55s/step - loss: 0.2166 - acc: 0.9347 - val_loss: 1.0326 - val_acc: 0.6071\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2488 - acc: 0.9143 \n",
            "Epoch 25: val_acc did not improve from 0.67143\n",
            "4/4 [==============================] - 194s 54s/step - loss: 0.2488 - acc: 0.9143 - val_loss: 0.9623 - val_acc: 0.6643\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2632 - acc: 0.9163 \n",
            "Epoch 26: val_acc improved from 0.67143 to 0.73571, saving model to percobaan107_noImgPro/model\\vgg_16_107-saved-model-26-acc-0.74.hdf5\n",
            "4/4 [==============================] - 198s 53s/step - loss: 0.2632 - acc: 0.9163 - val_loss: 0.8643 - val_acc: 0.7357\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2119 - acc: 0.9224 \n",
            "Epoch 27: val_acc improved from 0.73571 to 0.75000, saving model to percobaan107_noImgPro/model\\vgg_16_107-saved-model-27-acc-0.75.hdf5\n",
            "4/4 [==============================] - 191s 53s/step - loss: 0.2119 - acc: 0.9224 - val_loss: 0.8282 - val_acc: 0.7500\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2005 - acc: 0.9469 \n",
            "Epoch 28: val_acc improved from 0.75000 to 0.76429, saving model to percobaan107_noImgPro/model\\vgg_16_107-saved-model-28-acc-0.76.hdf5\n",
            "4/4 [==============================] - 197s 57s/step - loss: 0.2005 - acc: 0.9469 - val_loss: 0.8069 - val_acc: 0.7643\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2049 - acc: 0.9347 \n",
            "Epoch 29: val_acc improved from 0.76429 to 0.79286, saving model to percobaan107_noImgPro/model\\vgg_16_107-saved-model-29-acc-0.79.hdf5\n",
            "4/4 [==============================] - 196s 55s/step - loss: 0.2049 - acc: 0.9347 - val_loss: 0.7508 - val_acc: 0.7929\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2629 - acc: 0.9082 \n",
            "Epoch 30: val_acc improved from 0.79286 to 0.82143, saving model to percobaan107_noImgPro/model\\vgg_16_107-saved-model-30-acc-0.82.hdf5\n",
            "4/4 [==============================] - 191s 52s/step - loss: 0.2629 - acc: 0.9082 - val_loss: 0.6926 - val_acc: 0.8214\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2499 - acc: 0.9041 \n",
            "Epoch 31: val_acc did not improve from 0.82143\n",
            "4/4 [==============================] - 190s 52s/step - loss: 0.2499 - acc: 0.9041 - val_loss: 0.6684 - val_acc: 0.8000\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1679 - acc: 0.9449 \n",
            "Epoch 32: val_acc did not improve from 0.82143\n",
            "4/4 [==============================] - 210s 58s/step - loss: 0.1679 - acc: 0.9449 - val_loss: 0.6359 - val_acc: 0.8071\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1989 - acc: 0.9163 \n",
            "Epoch 33: val_acc did not improve from 0.82143\n",
            "4/4 [==============================] - 210s 56s/step - loss: 0.1989 - acc: 0.9163 - val_loss: 0.6299 - val_acc: 0.8071\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2053 - acc: 0.9347 \n",
            "Epoch 34: val_acc did not improve from 0.82143\n",
            "4/4 [==============================] - 190s 52s/step - loss: 0.2053 - acc: 0.9347 - val_loss: 0.6430 - val_acc: 0.8071\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2170 - acc: 0.9224 \n",
            "Epoch 35: val_acc did not improve from 0.82143\n",
            "4/4 [==============================] - 201s 58s/step - loss: 0.2170 - acc: 0.9224 - val_loss: 0.6464 - val_acc: 0.8000\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1750 - acc: 0.9367 \n",
            "Epoch 36: val_acc did not improve from 0.82143\n",
            "4/4 [==============================] - 196s 54s/step - loss: 0.1750 - acc: 0.9367 - val_loss: 0.6317 - val_acc: 0.7929\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1691 - acc: 0.9449 \n",
            "Epoch 37: val_acc did not improve from 0.82143\n",
            "4/4 [==============================] - 194s 54s/step - loss: 0.1691 - acc: 0.9449 - val_loss: 0.6252 - val_acc: 0.8000\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1881 - acc: 0.9367 \n",
            "Epoch 38: val_acc did not improve from 0.82143\n",
            "4/4 [==============================] - 197s 54s/step - loss: 0.1881 - acc: 0.9367 - val_loss: 0.6127 - val_acc: 0.8214\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1574 - acc: 0.9571 \n",
            "Epoch 39: val_acc did not improve from 0.82143\n",
            "4/4 [==============================] - 193s 54s/step - loss: 0.1574 - acc: 0.9571 - val_loss: 0.6037 - val_acc: 0.8143\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1741 - acc: 0.9327 \n",
            "Epoch 40: val_acc improved from 0.82143 to 0.82857, saving model to percobaan107_noImgPro/model\\vgg_16_107-saved-model-40-acc-0.83.hdf5\n",
            "4/4 [==============================] - 206s 57s/step - loss: 0.1741 - acc: 0.9327 - val_loss: 0.5729 - val_acc: 0.8286\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1910 - acc: 0.9306 \n",
            "Epoch 41: val_acc improved from 0.82857 to 0.83571, saving model to percobaan107_noImgPro/model\\vgg_16_107-saved-model-41-acc-0.84.hdf5\n",
            "4/4 [==============================] - 210s 56s/step - loss: 0.1910 - acc: 0.9306 - val_loss: 0.5800 - val_acc: 0.8357\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1665 - acc: 0.9469 \n",
            "Epoch 42: val_acc did not improve from 0.83571\n",
            "4/4 [==============================] - 192s 52s/step - loss: 0.1665 - acc: 0.9469 - val_loss: 0.6184 - val_acc: 0.8143\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1790 - acc: 0.9510 \n",
            "Epoch 43: val_acc did not improve from 0.83571\n",
            "4/4 [==============================] - 200s 56s/step - loss: 0.1790 - acc: 0.9510 - val_loss: 0.6445 - val_acc: 0.7857\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1653 - acc: 0.9429 \n",
            "Epoch 44: val_acc did not improve from 0.83571\n",
            "4/4 [==============================] - 201s 57s/step - loss: 0.1653 - acc: 0.9429 - val_loss: 0.6657 - val_acc: 0.7857\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2151 - acc: 0.9224 \n",
            "Epoch 45: val_acc did not improve from 0.83571\n",
            "4/4 [==============================] - 193s 52s/step - loss: 0.2151 - acc: 0.9224 - val_loss: 0.6640 - val_acc: 0.8000\n",
            "\n",
            "\n",
            "Model Accuracy 0.7714285714285715\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.82      0.90      0.86        10\n",
            "       10000       1.00      0.80      0.89        10\n",
            "      100000       1.00      0.30      0.46        10\n",
            "        2000       0.80      0.80      0.80        10\n",
            "       20000       0.64      0.70      0.67        10\n",
            "        5000       0.64      0.90      0.75        10\n",
            "       50000       0.77      1.00      0.87        10\n",
            "\n",
            "    accuracy                           0.77        70\n",
            "   macro avg       0.81      0.77      0.76        70\n",
            "weighted avg       0.81      0.77      0.76        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 108 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 49\n",
            "learning rate: 0.002327010690950279\n",
            "batch size: 128\n",
            "dropout rate: 0.7517522417520746\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 3.8116 - acc: 0.1510 \n",
            "Epoch 1: val_acc improved from -inf to 0.14286, saving model to percobaan108_noImgPro/model\\vgg_16_108-saved-model-01-acc-0.14.hdf5\n",
            "4/4 [==============================] - 198s 54s/step - loss: 3.8116 - acc: 0.1510 - val_loss: 2.5411 - val_acc: 0.1429\n",
            "Epoch 2/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 3.1072 - acc: 0.2388 \n",
            "Epoch 2: val_acc did not improve from 0.14286\n",
            "4/4 [==============================] - 198s 56s/step - loss: 3.1072 - acc: 0.2388 - val_loss: 2.5118 - val_acc: 0.1429\n",
            "Epoch 3/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.4198 - acc: 0.3204 \n",
            "Epoch 3: val_acc improved from 0.14286 to 0.15000, saving model to percobaan108_noImgPro/model\\vgg_16_108-saved-model-03-acc-0.15.hdf5\n",
            "4/4 [==============================] - 194s 52s/step - loss: 2.4198 - acc: 0.3204 - val_loss: 2.3044 - val_acc: 0.1500\n",
            "Epoch 4/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.9622 - acc: 0.4143 \n",
            "Epoch 4: val_acc improved from 0.15000 to 0.16429, saving model to percobaan108_noImgPro/model\\vgg_16_108-saved-model-04-acc-0.16.hdf5\n",
            "4/4 [==============================] - 200s 54s/step - loss: 1.9622 - acc: 0.4143 - val_loss: 2.1590 - val_acc: 0.1643\n",
            "Epoch 5/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.8200 - acc: 0.4163 \n",
            "Epoch 5: val_acc improved from 0.16429 to 0.17857, saving model to percobaan108_noImgPro/model\\vgg_16_108-saved-model-05-acc-0.18.hdf5\n",
            "4/4 [==============================] - 200s 54s/step - loss: 1.8200 - acc: 0.4163 - val_loss: 2.0757 - val_acc: 0.1786\n",
            "Epoch 6/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.6172 - acc: 0.5041 \n",
            "Epoch 6: val_acc improved from 0.17857 to 0.22143, saving model to percobaan108_noImgPro/model\\vgg_16_108-saved-model-06-acc-0.22.hdf5\n",
            "4/4 [==============================] - 196s 53s/step - loss: 1.6172 - acc: 0.5041 - val_loss: 2.0141 - val_acc: 0.2214\n",
            "Epoch 7/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1813 - acc: 0.5776 \n",
            "Epoch 7: val_acc improved from 0.22143 to 0.25714, saving model to percobaan108_noImgPro/model\\vgg_16_108-saved-model-07-acc-0.26.hdf5\n",
            "4/4 [==============================] - 201s 54s/step - loss: 1.1813 - acc: 0.5776 - val_loss: 1.9650 - val_acc: 0.2571\n",
            "Epoch 8/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2218 - acc: 0.5837 \n",
            "Epoch 8: val_acc improved from 0.25714 to 0.27143, saving model to percobaan108_noImgPro/model\\vgg_16_108-saved-model-08-acc-0.27.hdf5\n",
            "4/4 [==============================] - 203s 54s/step - loss: 1.2218 - acc: 0.5837 - val_loss: 1.9005 - val_acc: 0.2714\n",
            "Epoch 9/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1525 - acc: 0.6163 \n",
            "Epoch 9: val_acc improved from 0.27143 to 0.28571, saving model to percobaan108_noImgPro/model\\vgg_16_108-saved-model-09-acc-0.29.hdf5\n",
            "4/4 [==============================] - 180s 52s/step - loss: 1.1525 - acc: 0.6163 - val_loss: 1.8770 - val_acc: 0.2857\n",
            "Epoch 10/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1054 - acc: 0.6122 \n",
            "Epoch 10: val_acc did not improve from 0.28571\n",
            "4/4 [==============================] - 201s 52s/step - loss: 1.1054 - acc: 0.6122 - val_loss: 1.8370 - val_acc: 0.2714\n",
            "Epoch 11/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9989 - acc: 0.6469 \n",
            "Epoch 11: val_acc did not improve from 0.28571\n",
            "4/4 [==============================] - 195s 52s/step - loss: 0.9989 - acc: 0.6469 - val_loss: 1.7509 - val_acc: 0.2714\n",
            "Epoch 12/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9160 - acc: 0.6857 \n",
            "Epoch 12: val_acc did not improve from 0.28571\n",
            "4/4 [==============================] - 203s 55s/step - loss: 0.9160 - acc: 0.6857 - val_loss: 1.6601 - val_acc: 0.2857\n",
            "Epoch 13/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8793 - acc: 0.6939 \n",
            "Epoch 13: val_acc did not improve from 0.28571\n",
            "4/4 [==============================] - 203s 53s/step - loss: 0.8793 - acc: 0.6939 - val_loss: 1.5800 - val_acc: 0.2857\n",
            "Epoch 14/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8365 - acc: 0.7020 \n",
            "Epoch 14: val_acc improved from 0.28571 to 0.29286, saving model to percobaan108_noImgPro/model\\vgg_16_108-saved-model-14-acc-0.29.hdf5\n",
            "4/4 [==============================] - 201s 56s/step - loss: 0.8365 - acc: 0.7020 - val_loss: 1.5094 - val_acc: 0.2929\n",
            "Epoch 15/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6956 - acc: 0.7469 \n",
            "Epoch 15: val_acc improved from 0.29286 to 0.34286, saving model to percobaan108_noImgPro/model\\vgg_16_108-saved-model-15-acc-0.34.hdf5\n",
            "4/4 [==============================] - 202s 52s/step - loss: 0.6956 - acc: 0.7469 - val_loss: 1.4535 - val_acc: 0.3429\n",
            "Epoch 16/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7489 - acc: 0.7469 \n",
            "Epoch 16: val_acc improved from 0.34286 to 0.37857, saving model to percobaan108_noImgPro/model\\vgg_16_108-saved-model-16-acc-0.38.hdf5\n",
            "4/4 [==============================] - 198s 53s/step - loss: 0.7489 - acc: 0.7469 - val_loss: 1.3787 - val_acc: 0.3786\n",
            "Epoch 17/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6626 - acc: 0.7735 \n",
            "Epoch 17: val_acc improved from 0.37857 to 0.44286, saving model to percobaan108_noImgPro/model\\vgg_16_108-saved-model-17-acc-0.44.hdf5\n",
            "4/4 [==============================] - 202s 54s/step - loss: 0.6626 - acc: 0.7735 - val_loss: 1.2966 - val_acc: 0.4429\n",
            "Epoch 18/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6245 - acc: 0.7612 \n",
            "Epoch 18: val_acc improved from 0.44286 to 0.48571, saving model to percobaan108_noImgPro/model\\vgg_16_108-saved-model-18-acc-0.49.hdf5\n",
            "4/4 [==============================] - 197s 53s/step - loss: 0.6245 - acc: 0.7612 - val_loss: 1.2204 - val_acc: 0.4857\n",
            "Epoch 19/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6448 - acc: 0.7633 \n",
            "Epoch 19: val_acc improved from 0.48571 to 0.53571, saving model to percobaan108_noImgPro/model\\vgg_16_108-saved-model-19-acc-0.54.hdf5\n",
            "4/4 [==============================] - 205s 54s/step - loss: 0.6448 - acc: 0.7633 - val_loss: 1.1618 - val_acc: 0.5357\n",
            "Epoch 20/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5416 - acc: 0.8224 \n",
            "Epoch 20: val_acc improved from 0.53571 to 0.57143, saving model to percobaan108_noImgPro/model\\vgg_16_108-saved-model-20-acc-0.57.hdf5\n",
            "4/4 [==============================] - 207s 54s/step - loss: 0.5416 - acc: 0.8224 - val_loss: 1.1247 - val_acc: 0.5714\n",
            "Epoch 21/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4844 - acc: 0.8122 \n",
            "Epoch 21: val_acc improved from 0.57143 to 0.58571, saving model to percobaan108_noImgPro/model\\vgg_16_108-saved-model-21-acc-0.59.hdf5\n",
            "4/4 [==============================] - 202s 57s/step - loss: 0.4844 - acc: 0.8122 - val_loss: 1.0960 - val_acc: 0.5857\n",
            "Epoch 22/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5929 - acc: 0.7735 \n",
            "Epoch 22: val_acc did not improve from 0.58571\n",
            "4/4 [==============================] - 193s 53s/step - loss: 0.5929 - acc: 0.7735 - val_loss: 1.0804 - val_acc: 0.5857\n",
            "Epoch 23/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5656 - acc: 0.7918 \n",
            "Epoch 23: val_acc did not improve from 0.58571\n",
            "4/4 [==============================] - 198s 52s/step - loss: 0.5656 - acc: 0.7918 - val_loss: 1.0735 - val_acc: 0.5857\n",
            "Epoch 24/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4718 - acc: 0.8347 \n",
            "Epoch 24: val_acc improved from 0.58571 to 0.60000, saving model to percobaan108_noImgPro/model\\vgg_16_108-saved-model-24-acc-0.60.hdf5\n",
            "4/4 [==============================] - 202s 58s/step - loss: 0.4718 - acc: 0.8347 - val_loss: 1.0549 - val_acc: 0.6000\n",
            "Epoch 25/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4649 - acc: 0.8408 \n",
            "Epoch 25: val_acc improved from 0.60000 to 0.60714, saving model to percobaan108_noImgPro/model\\vgg_16_108-saved-model-25-acc-0.61.hdf5\n",
            "4/4 [==============================] - 210s 59s/step - loss: 0.4649 - acc: 0.8408 - val_loss: 1.0327 - val_acc: 0.6071\n",
            "Epoch 26/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4359 - acc: 0.8510 \n",
            "Epoch 26: val_acc improved from 0.60714 to 0.63571, saving model to percobaan108_noImgPro/model\\vgg_16_108-saved-model-26-acc-0.64.hdf5\n",
            "4/4 [==============================] - 208s 55s/step - loss: 0.4359 - acc: 0.8510 - val_loss: 1.0176 - val_acc: 0.6357\n",
            "Epoch 27/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4740 - acc: 0.8429 \n",
            "Epoch 27: val_acc did not improve from 0.63571\n",
            "4/4 [==============================] - 201s 54s/step - loss: 0.4740 - acc: 0.8429 - val_loss: 0.9869 - val_acc: 0.6357\n",
            "Epoch 28/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4565 - acc: 0.8286 \n",
            "Epoch 28: val_acc improved from 0.63571 to 0.67143, saving model to percobaan108_noImgPro/model\\vgg_16_108-saved-model-28-acc-0.67.hdf5\n",
            "4/4 [==============================] - 200s 53s/step - loss: 0.4565 - acc: 0.8286 - val_loss: 0.9523 - val_acc: 0.6714\n",
            "Epoch 29/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4360 - acc: 0.8571 \n",
            "Epoch 29: val_acc improved from 0.67143 to 0.70714, saving model to percobaan108_noImgPro/model\\vgg_16_108-saved-model-29-acc-0.71.hdf5\n",
            "4/4 [==============================] - 200s 56s/step - loss: 0.4360 - acc: 0.8571 - val_loss: 0.9239 - val_acc: 0.7071\n",
            "Epoch 30/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3903 - acc: 0.8571 \n",
            "Epoch 30: val_acc improved from 0.70714 to 0.73571, saving model to percobaan108_noImgPro/model\\vgg_16_108-saved-model-30-acc-0.74.hdf5\n",
            "4/4 [==============================] - 206s 58s/step - loss: 0.3903 - acc: 0.8571 - val_loss: 0.8944 - val_acc: 0.7357\n",
            "Epoch 31/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3870 - acc: 0.8571 \n",
            "Epoch 31: val_acc improved from 0.73571 to 0.76429, saving model to percobaan108_noImgPro/model\\vgg_16_108-saved-model-31-acc-0.76.hdf5\n",
            "4/4 [==============================] - 203s 55s/step - loss: 0.3870 - acc: 0.8571 - val_loss: 0.8580 - val_acc: 0.7643\n",
            "Epoch 32/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4696 - acc: 0.8388 \n",
            "Epoch 32: val_acc did not improve from 0.76429\n",
            "4/4 [==============================] - 193s 52s/step - loss: 0.4696 - acc: 0.8388 - val_loss: 0.8323 - val_acc: 0.7643\n",
            "Epoch 33/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3637 - acc: 0.8796 \n",
            "Epoch 33: val_acc did not improve from 0.76429\n",
            "4/4 [==============================] - 201s 53s/step - loss: 0.3637 - acc: 0.8796 - val_loss: 0.8151 - val_acc: 0.7643\n",
            "Epoch 34/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3876 - acc: 0.8714 \n",
            "Epoch 34: val_acc did not improve from 0.76429\n",
            "4/4 [==============================] - 200s 55s/step - loss: 0.3876 - acc: 0.8714 - val_loss: 0.7955 - val_acc: 0.7571\n",
            "Epoch 35/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3697 - acc: 0.8735 \n",
            "Epoch 35: val_acc did not improve from 0.76429\n",
            "4/4 [==============================] - 193s 53s/step - loss: 0.3697 - acc: 0.8735 - val_loss: 0.7643 - val_acc: 0.7643\n",
            "Epoch 36/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3775 - acc: 0.8755 \n",
            "Epoch 36: val_acc improved from 0.76429 to 0.80000, saving model to percobaan108_noImgPro/model\\vgg_16_108-saved-model-36-acc-0.80.hdf5\n",
            "4/4 [==============================] - 216s 58s/step - loss: 0.3775 - acc: 0.8755 - val_loss: 0.7338 - val_acc: 0.8000\n",
            "Epoch 37/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3873 - acc: 0.8612 \n",
            "Epoch 37: val_acc did not improve from 0.80000\n",
            "4/4 [==============================] - 202s 53s/step - loss: 0.3873 - acc: 0.8612 - val_loss: 0.7144 - val_acc: 0.8000\n",
            "Epoch 38/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3246 - acc: 0.8755 \n",
            "Epoch 38: val_acc did not improve from 0.80000\n",
            "4/4 [==============================] - 198s 56s/step - loss: 0.3246 - acc: 0.8755 - val_loss: 0.7015 - val_acc: 0.7929\n",
            "Epoch 39/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3680 - acc: 0.8633 \n",
            "Epoch 39: val_acc improved from 0.80000 to 0.80714, saving model to percobaan108_noImgPro/model\\vgg_16_108-saved-model-39-acc-0.81.hdf5\n",
            "4/4 [==============================] - 205s 58s/step - loss: 0.3680 - acc: 0.8633 - val_loss: 0.6830 - val_acc: 0.8071\n",
            "Epoch 40/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3242 - acc: 0.9000 \n",
            "Epoch 40: val_acc did not improve from 0.80714\n",
            "4/4 [==============================] - 211s 57s/step - loss: 0.3242 - acc: 0.9000 - val_loss: 0.6599 - val_acc: 0.8071\n",
            "Epoch 41/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3199 - acc: 0.8959 \n",
            "Epoch 41: val_acc improved from 0.80714 to 0.81429, saving model to percobaan108_noImgPro/model\\vgg_16_108-saved-model-41-acc-0.81.hdf5\n",
            "4/4 [==============================] - 199s 54s/step - loss: 0.3199 - acc: 0.8959 - val_loss: 0.6414 - val_acc: 0.8143\n",
            "Epoch 42/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2878 - acc: 0.9102 \n",
            "Epoch 42: val_acc improved from 0.81429 to 0.82143, saving model to percobaan108_noImgPro/model\\vgg_16_108-saved-model-42-acc-0.82.hdf5\n",
            "4/4 [==============================] - 213s 56s/step - loss: 0.2878 - acc: 0.9102 - val_loss: 0.6291 - val_acc: 0.8214\n",
            "Epoch 43/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3061 - acc: 0.9020 \n",
            "Epoch 43: val_acc did not improve from 0.82143\n",
            "4/4 [==============================] - 214s 60s/step - loss: 0.3061 - acc: 0.9020 - val_loss: 0.6190 - val_acc: 0.8214\n",
            "Epoch 44/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3101 - acc: 0.8898 \n",
            "Epoch 44: val_acc improved from 0.82143 to 0.82857, saving model to percobaan108_noImgPro/model\\vgg_16_108-saved-model-44-acc-0.83.hdf5\n",
            "4/4 [==============================] - 197s 53s/step - loss: 0.3101 - acc: 0.8898 - val_loss: 0.6063 - val_acc: 0.8286\n",
            "Epoch 45/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2537 - acc: 0.9061 \n",
            "Epoch 45: val_acc did not improve from 0.82857\n",
            "4/4 [==============================] - 199s 55s/step - loss: 0.2537 - acc: 0.9061 - val_loss: 0.5946 - val_acc: 0.8214\n",
            "Epoch 46/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2458 - acc: 0.9122 \n",
            "Epoch 46: val_acc did not improve from 0.82857\n",
            "4/4 [==============================] - 209s 58s/step - loss: 0.2458 - acc: 0.9122 - val_loss: 0.5902 - val_acc: 0.8071\n",
            "Epoch 47/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2904 - acc: 0.8959 \n",
            "Epoch 47: val_acc did not improve from 0.82857\n",
            "4/4 [==============================] - 205s 57s/step - loss: 0.2904 - acc: 0.8959 - val_loss: 0.5875 - val_acc: 0.8071\n",
            "Epoch 48/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2921 - acc: 0.9041 \n",
            "Epoch 48: val_acc did not improve from 0.82857\n",
            "4/4 [==============================] - 197s 52s/step - loss: 0.2921 - acc: 0.9041 - val_loss: 0.5817 - val_acc: 0.8000\n",
            "Epoch 49/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2647 - acc: 0.8980 \n",
            "Epoch 49: val_acc did not improve from 0.82857\n",
            "4/4 [==============================] - 196s 51s/step - loss: 0.2647 - acc: 0.8980 - val_loss: 0.5729 - val_acc: 0.8214\n",
            "\n",
            "\n",
            "Model Accuracy 0.8285714285714286\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.82      0.90      0.86        10\n",
            "       10000       1.00      0.90      0.95        10\n",
            "      100000       1.00      0.60      0.75        10\n",
            "        2000       0.77      1.00      0.87        10\n",
            "       20000       0.83      0.50      0.62        10\n",
            "        5000       0.75      0.90      0.82        10\n",
            "       50000       0.77      1.00      0.87        10\n",
            "\n",
            "    accuracy                           0.83        70\n",
            "   macro avg       0.85      0.83      0.82        70\n",
            "weighted avg       0.85      0.83      0.82        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 109 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 52\n",
            "learning rate: 0.04395129586826472\n",
            "batch size: 32\n",
            "dropout rate: 0.5472064681544458\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/52\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.7111 - acc: 0.2898\n",
            "Epoch 1: val_acc improved from -inf to 0.18571, saving model to percobaan109_noImgPro/model\\vgg_16_109-saved-model-01-acc-0.19.hdf5\n",
            "16/16 [==============================] - 181s 11s/step - loss: 2.7111 - acc: 0.2898 - val_loss: 7.9736 - val_acc: 0.1857\n",
            "Epoch 2/52\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.6457 - acc: 0.4571\n",
            "Epoch 2: val_acc improved from 0.18571 to 0.38571, saving model to percobaan109_noImgPro/model\\vgg_16_109-saved-model-02-acc-0.39.hdf5\n",
            "16/16 [==============================] - 181s 11s/step - loss: 1.6457 - acc: 0.4571 - val_loss: 4.2416 - val_acc: 0.3857\n",
            "Epoch 3/52\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1335 - acc: 0.6204\n",
            "Epoch 3: val_acc improved from 0.38571 to 0.42143, saving model to percobaan109_noImgPro/model\\vgg_16_109-saved-model-03-acc-0.42.hdf5\n",
            "16/16 [==============================] - 176s 11s/step - loss: 1.1335 - acc: 0.6204 - val_loss: 2.7850 - val_acc: 0.4214\n",
            "Epoch 4/52\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0358 - acc: 0.6571\n",
            "Epoch 4: val_acc did not improve from 0.42143\n",
            "16/16 [==============================] - 180s 11s/step - loss: 1.0358 - acc: 0.6571 - val_loss: 1.8519 - val_acc: 0.4143\n",
            "Epoch 5/52\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8783 - acc: 0.7163\n",
            "Epoch 5: val_acc improved from 0.42143 to 0.50714, saving model to percobaan109_noImgPro/model\\vgg_16_109-saved-model-05-acc-0.51.hdf5\n",
            "16/16 [==============================] - 180s 11s/step - loss: 0.8783 - acc: 0.7163 - val_loss: 1.8068 - val_acc: 0.5071\n",
            "Epoch 6/52\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6713 - acc: 0.7510\n",
            "Epoch 6: val_acc improved from 0.50714 to 0.57143, saving model to percobaan109_noImgPro/model\\vgg_16_109-saved-model-06-acc-0.57.hdf5\n",
            "16/16 [==============================] - 181s 12s/step - loss: 0.6713 - acc: 0.7510 - val_loss: 1.0823 - val_acc: 0.5714\n",
            "Epoch 7/52\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7529 - acc: 0.7327\n",
            "Epoch 7: val_acc improved from 0.57143 to 0.72857, saving model to percobaan109_noImgPro/model\\vgg_16_109-saved-model-07-acc-0.73.hdf5\n",
            "16/16 [==============================] - 181s 11s/step - loss: 0.7529 - acc: 0.7327 - val_loss: 0.8280 - val_acc: 0.7286\n",
            "Epoch 8/52\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7259 - acc: 0.7571\n",
            "Epoch 8: val_acc did not improve from 0.72857\n",
            "16/16 [==============================] - 184s 12s/step - loss: 0.7259 - acc: 0.7571 - val_loss: 0.8529 - val_acc: 0.7214\n",
            "Epoch 9/52\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8949 - acc: 0.7286\n",
            "Epoch 9: val_acc did not improve from 0.72857\n",
            "16/16 [==============================] - 176s 11s/step - loss: 0.8949 - acc: 0.7286 - val_loss: 1.5257 - val_acc: 0.5786\n",
            "Epoch 10/52\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6680 - acc: 0.7653\n",
            "Epoch 10: val_acc did not improve from 0.72857\n",
            "16/16 [==============================] - 180s 11s/step - loss: 0.6680 - acc: 0.7653 - val_loss: 1.5815 - val_acc: 0.6286\n",
            "Epoch 11/52\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6915 - acc: 0.7694\n",
            "Epoch 11: val_acc did not improve from 0.72857\n",
            "16/16 [==============================] - 178s 11s/step - loss: 0.6915 - acc: 0.7694 - val_loss: 1.2360 - val_acc: 0.6357\n",
            "Epoch 12/52\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5299 - acc: 0.8122\n",
            "Epoch 12: val_acc improved from 0.72857 to 0.73571, saving model to percobaan109_noImgPro/model\\vgg_16_109-saved-model-12-acc-0.74.hdf5\n",
            "16/16 [==============================] - 183s 12s/step - loss: 0.5299 - acc: 0.8122 - val_loss: 0.8568 - val_acc: 0.7357\n",
            "\n",
            "\n",
            "Model Accuracy 0.6571428571428571\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.75      0.30      0.43        10\n",
            "       10000       0.80      0.80      0.80        10\n",
            "      100000       1.00      0.80      0.89        10\n",
            "        2000       0.34      1.00      0.51        10\n",
            "       20000       0.83      0.50      0.62        10\n",
            "        5000       1.00      0.50      0.67        10\n",
            "       50000       0.88      0.70      0.78        10\n",
            "\n",
            "    accuracy                           0.66        70\n",
            "   macro avg       0.80      0.66      0.67        70\n",
            "weighted avg       0.80      0.66      0.67        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 110 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 55\n",
            "learning rate: 0.04841137846020006\n",
            "batch size: 32\n",
            "dropout rate: 0.6331927833114149\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/55\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.7373 - acc: 0.3367\n",
            "Epoch 1: val_acc improved from -inf to 0.19286, saving model to percobaan110_noImgPro/model\\vgg_16_110-saved-model-01-acc-0.19.hdf5\n",
            "16/16 [==============================] - 130s 8s/step - loss: 2.7373 - acc: 0.3367 - val_loss: 7.3130 - val_acc: 0.1929\n",
            "Epoch 2/55\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.9004 - acc: 0.4449\n",
            "Epoch 2: val_acc improved from 0.19286 to 0.22857, saving model to percobaan110_noImgPro/model\\vgg_16_110-saved-model-02-acc-0.23.hdf5\n",
            "16/16 [==============================] - 135s 9s/step - loss: 1.9004 - acc: 0.4449 - val_loss: 2.9363 - val_acc: 0.2286\n",
            "Epoch 3/55\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.5316 - acc: 0.5327\n",
            "Epoch 3: val_acc improved from 0.22857 to 0.45000, saving model to percobaan110_noImgPro/model\\vgg_16_110-saved-model-03-acc-0.45.hdf5\n",
            "16/16 [==============================] - 145s 9s/step - loss: 1.5316 - acc: 0.5327 - val_loss: 1.8532 - val_acc: 0.4500\n",
            "Epoch 4/55\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1520 - acc: 0.6000\n",
            "Epoch 4: val_acc did not improve from 0.45000\n",
            "16/16 [==============================] - 146s 9s/step - loss: 1.1520 - acc: 0.6000 - val_loss: 1.9537 - val_acc: 0.4214\n",
            "Epoch 5/55\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0462 - acc: 0.6510\n",
            "Epoch 5: val_acc improved from 0.45000 to 0.68571, saving model to percobaan110_noImgPro/model\\vgg_16_110-saved-model-05-acc-0.69.hdf5\n",
            "16/16 [==============================] - 147s 9s/step - loss: 1.0462 - acc: 0.6510 - val_loss: 0.9736 - val_acc: 0.6857\n",
            "Epoch 6/55\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8183 - acc: 0.7143\n",
            "Epoch 6: val_acc did not improve from 0.68571\n",
            "16/16 [==============================] - 144s 9s/step - loss: 0.8183 - acc: 0.7143 - val_loss: 1.0714 - val_acc: 0.6000\n",
            "Epoch 7/55\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8254 - acc: 0.7163\n",
            "Epoch 7: val_acc did not improve from 0.68571\n",
            "16/16 [==============================] - 146s 10s/step - loss: 0.8254 - acc: 0.7163 - val_loss: 1.6351 - val_acc: 0.5143\n",
            "Epoch 8/55\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8035 - acc: 0.7408\n",
            "Epoch 8: val_acc did not improve from 0.68571\n",
            "16/16 [==============================] - 146s 9s/step - loss: 0.8035 - acc: 0.7408 - val_loss: 1.3424 - val_acc: 0.6214\n",
            "Epoch 9/55\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9115 - acc: 0.6816\n",
            "Epoch 9: val_acc did not improve from 0.68571\n",
            "16/16 [==============================] - 144s 9s/step - loss: 0.9115 - acc: 0.6816 - val_loss: 1.3160 - val_acc: 0.6143\n",
            "Epoch 10/55\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8458 - acc: 0.6857\n",
            "Epoch 10: val_acc did not improve from 0.68571\n",
            "16/16 [==============================] - 145s 9s/step - loss: 0.8458 - acc: 0.6857 - val_loss: 1.0019 - val_acc: 0.6714\n",
            "\n",
            "\n",
            "Model Accuracy 0.6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.58      0.70      0.64        10\n",
            "       10000       0.53      1.00      0.69        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.70      0.70      0.70        10\n",
            "       20000       0.50      0.60      0.55        10\n",
            "        5000       0.58      0.70      0.64        10\n",
            "       50000       1.00      0.50      0.67        10\n",
            "\n",
            "    accuracy                           0.60        70\n",
            "   macro avg       0.56      0.60      0.55        70\n",
            "weighted avg       0.56      0.60      0.55        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 111 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 54\n",
            "learning rate: 0.031191842779565455\n",
            "batch size: 32\n",
            "dropout rate: 0.6909476108881752\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/54\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.9084 - acc: 0.2449\n",
            "Epoch 1: val_acc improved from -inf to 0.22143, saving model to percobaan111_noImgPro/model\\vgg_16_111-saved-model-01-acc-0.22.hdf5\n",
            "16/16 [==============================] - 116s 7s/step - loss: 2.9084 - acc: 0.2449 - val_loss: 5.3182 - val_acc: 0.2214\n",
            "Epoch 2/54\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.9852 - acc: 0.4122\n",
            "Epoch 2: val_acc improved from 0.22143 to 0.35714, saving model to percobaan111_noImgPro/model\\vgg_16_111-saved-model-02-acc-0.36.hdf5\n",
            "16/16 [==============================] - 121s 8s/step - loss: 1.9852 - acc: 0.4122 - val_loss: 2.4884 - val_acc: 0.3571\n",
            "Epoch 3/54\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.6242 - acc: 0.4612\n",
            "Epoch 3: val_acc did not improve from 0.35714\n",
            "16/16 [==============================] - 125s 8s/step - loss: 1.6242 - acc: 0.4612 - val_loss: 2.9262 - val_acc: 0.2286\n",
            "Epoch 4/54\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2211 - acc: 0.5776\n",
            "Epoch 4: val_acc improved from 0.35714 to 0.37857, saving model to percobaan111_noImgPro/model\\vgg_16_111-saved-model-04-acc-0.38.hdf5\n",
            "16/16 [==============================] - 140s 9s/step - loss: 1.2211 - acc: 0.5776 - val_loss: 1.8728 - val_acc: 0.3786\n",
            "Epoch 5/54\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9309 - acc: 0.6714\n",
            "Epoch 5: val_acc improved from 0.37857 to 0.59286, saving model to percobaan111_noImgPro/model\\vgg_16_111-saved-model-05-acc-0.59.hdf5\n",
            "16/16 [==============================] - 139s 9s/step - loss: 0.9309 - acc: 0.6714 - val_loss: 1.1383 - val_acc: 0.5929\n",
            "Epoch 6/54\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8635 - acc: 0.6959\n",
            "Epoch 6: val_acc did not improve from 0.59286\n",
            "16/16 [==============================] - 140s 9s/step - loss: 0.8635 - acc: 0.6959 - val_loss: 1.6685 - val_acc: 0.3143\n",
            "Epoch 7/54\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8753 - acc: 0.7041\n",
            "Epoch 7: val_acc improved from 0.59286 to 0.65000, saving model to percobaan111_noImgPro/model\\vgg_16_111-saved-model-07-acc-0.65.hdf5\n",
            "16/16 [==============================] - 139s 9s/step - loss: 0.8753 - acc: 0.7041 - val_loss: 0.9853 - val_acc: 0.6500\n",
            "Epoch 8/54\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8259 - acc: 0.7245\n",
            "Epoch 8: val_acc did not improve from 0.65000\n",
            "16/16 [==============================] - 140s 9s/step - loss: 0.8259 - acc: 0.7245 - val_loss: 1.0940 - val_acc: 0.6143\n",
            "Epoch 9/54\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7588 - acc: 0.7327\n",
            "Epoch 9: val_acc improved from 0.65000 to 0.70714, saving model to percobaan111_noImgPro/model\\vgg_16_111-saved-model-09-acc-0.71.hdf5\n",
            "16/16 [==============================] - 140s 9s/step - loss: 0.7588 - acc: 0.7327 - val_loss: 0.8391 - val_acc: 0.7071\n",
            "Epoch 10/54\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6977 - acc: 0.7612\n",
            "Epoch 10: val_acc improved from 0.70714 to 0.77143, saving model to percobaan111_noImgPro/model\\vgg_16_111-saved-model-10-acc-0.77.hdf5\n",
            "16/16 [==============================] - 141s 9s/step - loss: 0.6977 - acc: 0.7612 - val_loss: 0.7263 - val_acc: 0.7714\n",
            "Epoch 11/54\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5812 - acc: 0.7959\n",
            "Epoch 11: val_acc did not improve from 0.77143\n",
            "16/16 [==============================] - 140s 9s/step - loss: 0.5812 - acc: 0.7959 - val_loss: 1.0201 - val_acc: 0.6500\n",
            "Epoch 12/54\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5853 - acc: 0.7898\n",
            "Epoch 12: val_acc improved from 0.77143 to 0.77857, saving model to percobaan111_noImgPro/model\\vgg_16_111-saved-model-12-acc-0.78.hdf5\n",
            "16/16 [==============================] - 139s 9s/step - loss: 0.5853 - acc: 0.7898 - val_loss: 0.7796 - val_acc: 0.7786\n",
            "Epoch 13/54\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7892 - acc: 0.7449\n",
            "Epoch 13: val_acc did not improve from 0.77857\n",
            "16/16 [==============================] - 140s 9s/step - loss: 0.7892 - acc: 0.7449 - val_loss: 0.7428 - val_acc: 0.7286\n",
            "Epoch 14/54\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6723 - acc: 0.7796\n",
            "Epoch 14: val_acc improved from 0.77857 to 0.80714, saving model to percobaan111_noImgPro/model\\vgg_16_111-saved-model-14-acc-0.81.hdf5\n",
            "16/16 [==============================] - 138s 9s/step - loss: 0.6723 - acc: 0.7796 - val_loss: 0.5920 - val_acc: 0.8071\n",
            "Epoch 15/54\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6376 - acc: 0.7898\n",
            "Epoch 15: val_acc did not improve from 0.80714\n",
            "16/16 [==============================] - 139s 9s/step - loss: 0.6376 - acc: 0.7898 - val_loss: 0.6858 - val_acc: 0.7929\n",
            "Epoch 16/54\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6604 - acc: 0.7796\n",
            "Epoch 16: val_acc did not improve from 0.80714\n",
            "16/16 [==============================] - 139s 9s/step - loss: 0.6604 - acc: 0.7796 - val_loss: 0.6987 - val_acc: 0.8071\n",
            "Epoch 17/54\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6689 - acc: 0.7694\n",
            "Epoch 17: val_acc did not improve from 0.80714\n",
            "16/16 [==============================] - 139s 9s/step - loss: 0.6689 - acc: 0.7694 - val_loss: 0.7987 - val_acc: 0.7786\n",
            "Epoch 18/54\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6097 - acc: 0.7816\n",
            "Epoch 18: val_acc did not improve from 0.80714\n",
            "16/16 [==============================] - 139s 9s/step - loss: 0.6097 - acc: 0.7816 - val_loss: 0.8551 - val_acc: 0.7429\n",
            "Epoch 19/54\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6710 - acc: 0.7857\n",
            "Epoch 19: val_acc did not improve from 0.80714\n",
            "16/16 [==============================] - 140s 9s/step - loss: 0.6710 - acc: 0.7857 - val_loss: 0.7804 - val_acc: 0.7571\n",
            "\n",
            "\n",
            "Model Accuracy 0.7428571428571429\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.71      1.00      0.83        10\n",
            "       10000       0.77      1.00      0.87        10\n",
            "      100000       1.00      0.50      0.67        10\n",
            "        2000       0.88      0.70      0.78        10\n",
            "       20000       1.00      0.30      0.46        10\n",
            "        5000       1.00      0.70      0.82        10\n",
            "       50000       0.50      1.00      0.67        10\n",
            "\n",
            "    accuracy                           0.74        70\n",
            "   macro avg       0.84      0.74      0.73        70\n",
            "weighted avg       0.84      0.74      0.73        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 112 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 48\n",
            "learning rate: 0.041699533857207274\n",
            "batch size: 32\n",
            "dropout rate: 0.7650192940880949\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 3.5843 - acc: 0.2449\n",
            "Epoch 1: val_acc improved from -inf to 0.14286, saving model to percobaan112_noImgPro/model\\vgg_16_112-saved-model-01-acc-0.14.hdf5\n",
            "16/16 [==============================] - 172s 11s/step - loss: 3.5843 - acc: 0.2449 - val_loss: 12.3211 - val_acc: 0.1429\n",
            "Epoch 2/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.5973 - acc: 0.3327 \n",
            "Epoch 2: val_acc did not improve from 0.14286\n",
            "16/16 [==============================] - 243s 15s/step - loss: 2.5973 - acc: 0.3327 - val_loss: 7.1618 - val_acc: 0.1429\n",
            "Epoch 3/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.8800 - acc: 0.3878 \n",
            "Epoch 3: val_acc improved from 0.14286 to 0.16429, saving model to percobaan112_noImgPro/model\\vgg_16_112-saved-model-03-acc-0.16.hdf5\n",
            "16/16 [==============================] - 249s 16s/step - loss: 1.8800 - acc: 0.3878 - val_loss: 3.8162 - val_acc: 0.1643\n",
            "Epoch 4/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.6360 - acc: 0.4245 \n",
            "Epoch 4: val_acc improved from 0.16429 to 0.20000, saving model to percobaan112_noImgPro/model\\vgg_16_112-saved-model-04-acc-0.20.hdf5\n",
            "16/16 [==============================] - 248s 16s/step - loss: 1.6360 - acc: 0.4245 - val_loss: 3.2737 - val_acc: 0.2000\n",
            "Epoch 5/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3368 - acc: 0.5041 \n",
            "Epoch 5: val_acc improved from 0.20000 to 0.26429, saving model to percobaan112_noImgPro/model\\vgg_16_112-saved-model-05-acc-0.26.hdf5\n",
            "16/16 [==============================] - 248s 16s/step - loss: 1.3368 - acc: 0.5041 - val_loss: 2.0992 - val_acc: 0.2643\n",
            "Epoch 6/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3226 - acc: 0.5286 \n",
            "Epoch 6: val_acc improved from 0.26429 to 0.33571, saving model to percobaan112_noImgPro/model\\vgg_16_112-saved-model-06-acc-0.34.hdf5\n",
            "16/16 [==============================] - 248s 16s/step - loss: 1.3226 - acc: 0.5286 - val_loss: 1.6990 - val_acc: 0.3357\n",
            "Epoch 7/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1067 - acc: 0.6020 \n",
            "Epoch 7: val_acc did not improve from 0.33571\n",
            "16/16 [==============================] - 247s 16s/step - loss: 1.1067 - acc: 0.6020 - val_loss: 2.0098 - val_acc: 0.3286\n",
            "Epoch 8/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0969 - acc: 0.6367 \n",
            "Epoch 8: val_acc improved from 0.33571 to 0.43571, saving model to percobaan112_noImgPro/model\\vgg_16_112-saved-model-08-acc-0.44.hdf5\n",
            "16/16 [==============================] - 248s 16s/step - loss: 1.0969 - acc: 0.6367 - val_loss: 1.5596 - val_acc: 0.4357\n",
            "Epoch 9/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0393 - acc: 0.6122 \n",
            "Epoch 9: val_acc did not improve from 0.43571\n",
            "16/16 [==============================] - 251s 16s/step - loss: 1.0393 - acc: 0.6122 - val_loss: 1.6240 - val_acc: 0.4143\n",
            "Epoch 10/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0871 - acc: 0.6306 \n",
            "Epoch 10: val_acc improved from 0.43571 to 0.62143, saving model to percobaan112_noImgPro/model\\vgg_16_112-saved-model-10-acc-0.62.hdf5\n",
            "16/16 [==============================] - 245s 15s/step - loss: 1.0871 - acc: 0.6306 - val_loss: 1.1081 - val_acc: 0.6214\n",
            "Epoch 11/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0761 - acc: 0.6327 \n",
            "Epoch 11: val_acc improved from 0.62143 to 0.70000, saving model to percobaan112_noImgPro/model\\vgg_16_112-saved-model-11-acc-0.70.hdf5\n",
            "16/16 [==============================] - 243s 15s/step - loss: 1.0761 - acc: 0.6327 - val_loss: 0.9375 - val_acc: 0.7000\n",
            "Epoch 12/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9891 - acc: 0.6408 \n",
            "Epoch 12: val_acc improved from 0.70000 to 0.73571, saving model to percobaan112_noImgPro/model\\vgg_16_112-saved-model-12-acc-0.74.hdf5\n",
            "16/16 [==============================] - 252s 16s/step - loss: 0.9891 - acc: 0.6408 - val_loss: 0.9133 - val_acc: 0.7357\n",
            "Epoch 13/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0063 - acc: 0.6633 \n",
            "Epoch 13: val_acc did not improve from 0.73571\n",
            "16/16 [==============================] - 252s 16s/step - loss: 1.0063 - acc: 0.6633 - val_loss: 0.8324 - val_acc: 0.7143\n",
            "Epoch 14/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9029 - acc: 0.6837 \n",
            "Epoch 14: val_acc improved from 0.73571 to 0.77143, saving model to percobaan112_noImgPro/model\\vgg_16_112-saved-model-14-acc-0.77.hdf5\n",
            "16/16 [==============================] - 249s 16s/step - loss: 0.9029 - acc: 0.6837 - val_loss: 0.7702 - val_acc: 0.7714\n",
            "Epoch 15/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8377 - acc: 0.6980 \n",
            "Epoch 15: val_acc improved from 0.77143 to 0.79286, saving model to percobaan112_noImgPro/model\\vgg_16_112-saved-model-15-acc-0.79.hdf5\n",
            "16/16 [==============================] - 252s 17s/step - loss: 0.8377 - acc: 0.6980 - val_loss: 0.6699 - val_acc: 0.7929\n",
            "Epoch 16/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8100 - acc: 0.7224 \n",
            "Epoch 16: val_acc did not improve from 0.79286\n",
            "16/16 [==============================] - 243s 15s/step - loss: 0.8100 - acc: 0.7224 - val_loss: 0.7621 - val_acc: 0.7286\n",
            "Epoch 17/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8020 - acc: 0.7102 \n",
            "Epoch 17: val_acc did not improve from 0.79286\n",
            "16/16 [==============================] - 222s 14s/step - loss: 0.8020 - acc: 0.7102 - val_loss: 0.6930 - val_acc: 0.7714\n",
            "Epoch 18/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8370 - acc: 0.6980\n",
            "Epoch 18: val_acc improved from 0.79286 to 0.80714, saving model to percobaan112_noImgPro/model\\vgg_16_112-saved-model-18-acc-0.81.hdf5\n",
            "16/16 [==============================] - 198s 12s/step - loss: 0.8370 - acc: 0.6980 - val_loss: 0.7246 - val_acc: 0.8071\n",
            "Epoch 19/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7998 - acc: 0.7286\n",
            "Epoch 19: val_acc did not improve from 0.80714\n",
            "16/16 [==============================] - 185s 12s/step - loss: 0.7998 - acc: 0.7286 - val_loss: 0.6520 - val_acc: 0.7786\n",
            "Epoch 20/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8153 - acc: 0.7245\n",
            "Epoch 20: val_acc did not improve from 0.80714\n",
            "16/16 [==============================] - 186s 12s/step - loss: 0.8153 - acc: 0.7245 - val_loss: 0.6813 - val_acc: 0.7786\n",
            "Epoch 21/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8723 - acc: 0.7265\n",
            "Epoch 21: val_acc improved from 0.80714 to 0.83571, saving model to percobaan112_noImgPro/model\\vgg_16_112-saved-model-21-acc-0.84.hdf5\n",
            "16/16 [==============================] - 186s 12s/step - loss: 0.8723 - acc: 0.7265 - val_loss: 0.5532 - val_acc: 0.8357\n",
            "Epoch 22/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8473 - acc: 0.7347\n",
            "Epoch 22: val_acc did not improve from 0.83571\n",
            "16/16 [==============================] - 187s 12s/step - loss: 0.8473 - acc: 0.7347 - val_loss: 0.7047 - val_acc: 0.7429\n",
            "Epoch 23/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9450 - acc: 0.7204\n",
            "Epoch 23: val_acc did not improve from 0.83571\n",
            "16/16 [==============================] - 188s 12s/step - loss: 0.9450 - acc: 0.7204 - val_loss: 0.6854 - val_acc: 0.8000\n",
            "Epoch 24/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7838 - acc: 0.7510\n",
            "Epoch 24: val_acc did not improve from 0.83571\n",
            "16/16 [==============================] - 186s 12s/step - loss: 0.7838 - acc: 0.7510 - val_loss: 0.6769 - val_acc: 0.7786\n",
            "Epoch 25/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7390 - acc: 0.7531\n",
            "Epoch 25: val_acc did not improve from 0.83571\n",
            "16/16 [==============================] - 189s 12s/step - loss: 0.7390 - acc: 0.7531 - val_loss: 0.8295 - val_acc: 0.7929\n",
            "Epoch 26/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7987 - acc: 0.7510\n",
            "Epoch 26: val_acc did not improve from 0.83571\n",
            "16/16 [==============================] - 189s 12s/step - loss: 0.7987 - acc: 0.7510 - val_loss: 0.6174 - val_acc: 0.8143\n",
            "\n",
            "\n",
            "Model Accuracy 0.8142857142857143\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.70      0.82        10\n",
            "       10000       1.00      0.90      0.95        10\n",
            "      100000       0.90      0.90      0.90        10\n",
            "        2000       0.67      1.00      0.80        10\n",
            "       20000       0.57      0.80      0.67        10\n",
            "        5000       1.00      0.70      0.82        10\n",
            "       50000       0.88      0.70      0.78        10\n",
            "\n",
            "    accuracy                           0.81        70\n",
            "   macro avg       0.86      0.81      0.82        70\n",
            "weighted avg       0.86      0.81      0.82        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 113 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 49\n",
            "learning rate: 0.04317066251482092\n",
            "batch size: 64\n",
            "dropout rate: 0.5717365984376124\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.5123 - acc: 0.3082 \n",
            "Epoch 1: val_acc improved from -inf to 0.30714, saving model to percobaan113_noImgPro/model\\vgg_16_113-saved-model-01-acc-0.31.hdf5\n",
            "8/8 [==============================] - 182s 23s/step - loss: 2.5123 - acc: 0.3082 - val_loss: 5.5707 - val_acc: 0.3071\n",
            "Epoch 2/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5989 - acc: 0.4939 \n",
            "Epoch 2: val_acc did not improve from 0.30714\n",
            "8/8 [==============================] - 182s 23s/step - loss: 1.5989 - acc: 0.4939 - val_loss: 4.2286 - val_acc: 0.2643\n",
            "Epoch 3/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1483 - acc: 0.6245 \n",
            "Epoch 3: val_acc improved from 0.30714 to 0.37143, saving model to percobaan113_noImgPro/model\\vgg_16_113-saved-model-03-acc-0.37.hdf5\n",
            "8/8 [==============================] - 183s 24s/step - loss: 1.1483 - acc: 0.6245 - val_loss: 2.5722 - val_acc: 0.3714\n",
            "Epoch 4/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8525 - acc: 0.6959 \n",
            "Epoch 4: val_acc improved from 0.37143 to 0.54286, saving model to percobaan113_noImgPro/model\\vgg_16_113-saved-model-04-acc-0.54.hdf5\n",
            "8/8 [==============================] - 183s 23s/step - loss: 0.8525 - acc: 0.6959 - val_loss: 1.3297 - val_acc: 0.5429\n",
            "Epoch 5/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7870 - acc: 0.7245 \n",
            "Epoch 5: val_acc did not improve from 0.54286\n",
            "8/8 [==============================] - 183s 24s/step - loss: 0.7870 - acc: 0.7245 - val_loss: 1.8775 - val_acc: 0.4357\n",
            "Epoch 6/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6719 - acc: 0.7755 \n",
            "Epoch 6: val_acc did not improve from 0.54286\n",
            "8/8 [==============================] - 183s 23s/step - loss: 0.6719 - acc: 0.7755 - val_loss: 1.8408 - val_acc: 0.4643\n",
            "Epoch 7/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6081 - acc: 0.7918 \n",
            "Epoch 7: val_acc did not improve from 0.54286\n",
            "8/8 [==============================] - 185s 24s/step - loss: 0.6081 - acc: 0.7918 - val_loss: 1.9086 - val_acc: 0.4071\n",
            "Epoch 8/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5323 - acc: 0.8306 \n",
            "Epoch 8: val_acc did not improve from 0.54286\n",
            "8/8 [==============================] - 184s 24s/step - loss: 0.5323 - acc: 0.8306 - val_loss: 1.9512 - val_acc: 0.3929\n",
            "Epoch 9/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5084 - acc: 0.8388 \n",
            "Epoch 9: val_acc did not improve from 0.54286\n",
            "8/8 [==============================] - 184s 24s/step - loss: 0.5084 - acc: 0.8388 - val_loss: 1.4764 - val_acc: 0.5000\n",
            "\n",
            "\n",
            "Model Accuracy 0.4857142857142857\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.31      1.00      0.48        10\n",
            "       10000       0.86      0.60      0.71        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       1.00      0.10      0.18        10\n",
            "       20000       0.44      0.40      0.42        10\n",
            "        5000       0.75      0.30      0.43        10\n",
            "       50000       0.59      1.00      0.74        10\n",
            "\n",
            "    accuracy                           0.49        70\n",
            "   macro avg       0.56      0.49      0.42        70\n",
            "weighted avg       0.56      0.49      0.42        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 114 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 50\n",
            "learning rate: 0.04569561010812357\n",
            "batch size: 64\n",
            "dropout rate: 0.6367333612981663\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/50\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.6853 - acc: 0.2878 \n",
            "Epoch 1: val_acc improved from -inf to 0.22143, saving model to percobaan114_noImgPro/model\\vgg_16_114-saved-model-01-acc-0.22.hdf5\n",
            "8/8 [==============================] - 180s 24s/step - loss: 2.6853 - acc: 0.2878 - val_loss: 5.3622 - val_acc: 0.2214\n",
            "Epoch 2/50\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.0820 - acc: 0.4184 \n",
            "Epoch 2: val_acc did not improve from 0.22143\n",
            "8/8 [==============================] - 178s 23s/step - loss: 2.0820 - acc: 0.4184 - val_loss: 5.0283 - val_acc: 0.2000\n",
            "Epoch 3/50\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4767 - acc: 0.5265 \n",
            "Epoch 3: val_acc improved from 0.22143 to 0.24286, saving model to percobaan114_noImgPro/model\\vgg_16_114-saved-model-03-acc-0.24.hdf5\n",
            "8/8 [==============================] - 180s 23s/step - loss: 1.4767 - acc: 0.5265 - val_loss: 3.1083 - val_acc: 0.2429\n",
            "Epoch 4/50\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1462 - acc: 0.6061 \n",
            "Epoch 4: val_acc improved from 0.24286 to 0.29286, saving model to percobaan114_noImgPro/model\\vgg_16_114-saved-model-04-acc-0.29.hdf5\n",
            "8/8 [==============================] - 179s 24s/step - loss: 1.1462 - acc: 0.6061 - val_loss: 2.3885 - val_acc: 0.2929\n",
            "Epoch 5/50\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0337 - acc: 0.6224 \n",
            "Epoch 5: val_acc did not improve from 0.29286\n",
            "8/8 [==============================] - 191s 25s/step - loss: 1.0337 - acc: 0.6224 - val_loss: 1.9858 - val_acc: 0.2929\n",
            "Epoch 6/50\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8467 - acc: 0.7000 \n",
            "Epoch 6: val_acc improved from 0.29286 to 0.35000, saving model to percobaan114_noImgPro/model\\vgg_16_114-saved-model-06-acc-0.35.hdf5\n",
            "8/8 [==============================] - 187s 24s/step - loss: 0.8467 - acc: 0.7000 - val_loss: 1.8337 - val_acc: 0.3500\n",
            "Epoch 7/50\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6976 - acc: 0.7510 \n",
            "Epoch 7: val_acc did not improve from 0.35000\n",
            "8/8 [==============================] - 180s 23s/step - loss: 0.6976 - acc: 0.7510 - val_loss: 2.3793 - val_acc: 0.2786\n",
            "Epoch 8/50\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7102 - acc: 0.7429 \n",
            "Epoch 8: val_acc improved from 0.35000 to 0.40000, saving model to percobaan114_noImgPro/model\\vgg_16_114-saved-model-08-acc-0.40.hdf5\n",
            "8/8 [==============================] - 179s 23s/step - loss: 0.7102 - acc: 0.7429 - val_loss: 1.8134 - val_acc: 0.4000\n",
            "Epoch 9/50\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6459 - acc: 0.7694 \n",
            "Epoch 9: val_acc improved from 0.40000 to 0.44286, saving model to percobaan114_noImgPro/model\\vgg_16_114-saved-model-09-acc-0.44.hdf5\n",
            "8/8 [==============================] - 178s 23s/step - loss: 0.6459 - acc: 0.7694 - val_loss: 1.4497 - val_acc: 0.4429\n",
            "Epoch 10/50\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5238 - acc: 0.8224 \n",
            "Epoch 10: val_acc improved from 0.44286 to 0.57143, saving model to percobaan114_noImgPro/model\\vgg_16_114-saved-model-10-acc-0.57.hdf5\n",
            "8/8 [==============================] - 176s 23s/step - loss: 0.5238 - acc: 0.8224 - val_loss: 1.2383 - val_acc: 0.5714\n",
            "Epoch 11/50\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5516 - acc: 0.8184 \n",
            "Epoch 11: val_acc improved from 0.57143 to 0.73571, saving model to percobaan114_noImgPro/model\\vgg_16_114-saved-model-11-acc-0.74.hdf5\n",
            "8/8 [==============================] - 176s 23s/step - loss: 0.5516 - acc: 0.8184 - val_loss: 0.8387 - val_acc: 0.7357\n",
            "Epoch 12/50\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5264 - acc: 0.8143 \n",
            "Epoch 12: val_acc did not improve from 0.73571\n",
            "8/8 [==============================] - 175s 22s/step - loss: 0.5264 - acc: 0.8143 - val_loss: 0.9422 - val_acc: 0.7357\n",
            "Epoch 13/50\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5133 - acc: 0.8408 \n",
            "Epoch 13: val_acc did not improve from 0.73571\n",
            "8/8 [==============================] - 175s 22s/step - loss: 0.5133 - acc: 0.8408 - val_loss: 1.1040 - val_acc: 0.5857\n",
            "Epoch 14/50\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4764 - acc: 0.8490 \n",
            "Epoch 14: val_acc did not improve from 0.73571\n",
            "8/8 [==============================] - 175s 23s/step - loss: 0.4764 - acc: 0.8490 - val_loss: 0.8732 - val_acc: 0.7071\n",
            "Epoch 15/50\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4785 - acc: 0.8531 \n",
            "Epoch 15: val_acc did not improve from 0.73571\n",
            "8/8 [==============================] - 176s 23s/step - loss: 0.4785 - acc: 0.8531 - val_loss: 0.8864 - val_acc: 0.7286\n",
            "Epoch 16/50\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4925 - acc: 0.8367 \n",
            "Epoch 16: val_acc improved from 0.73571 to 0.75714, saving model to percobaan114_noImgPro/model\\vgg_16_114-saved-model-16-acc-0.76.hdf5\n",
            "8/8 [==============================] - 175s 22s/step - loss: 0.4925 - acc: 0.8367 - val_loss: 0.7652 - val_acc: 0.7571\n",
            "Epoch 17/50\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4184 - acc: 0.8551 \n",
            "Epoch 17: val_acc improved from 0.75714 to 0.80714, saving model to percobaan114_noImgPro/model\\vgg_16_114-saved-model-17-acc-0.81.hdf5\n",
            "8/8 [==============================] - 175s 22s/step - loss: 0.4184 - acc: 0.8551 - val_loss: 0.6767 - val_acc: 0.8071\n",
            "Epoch 18/50\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4071 - acc: 0.8531 \n",
            "Epoch 18: val_acc did not improve from 0.80714\n",
            "8/8 [==============================] - 175s 23s/step - loss: 0.4071 - acc: 0.8531 - val_loss: 0.6711 - val_acc: 0.7786\n",
            "Epoch 19/50\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3296 - acc: 0.8653 \n",
            "Epoch 19: val_acc improved from 0.80714 to 0.82143, saving model to percobaan114_noImgPro/model\\vgg_16_114-saved-model-19-acc-0.82.hdf5\n",
            "8/8 [==============================] - 175s 22s/step - loss: 0.3296 - acc: 0.8653 - val_loss: 0.5998 - val_acc: 0.8214\n",
            "Epoch 20/50\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3367 - acc: 0.8878 \n",
            "Epoch 20: val_acc did not improve from 0.82143\n",
            "8/8 [==============================] - 175s 22s/step - loss: 0.3367 - acc: 0.8878 - val_loss: 0.7584 - val_acc: 0.7643\n",
            "Epoch 21/50\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3136 - acc: 0.8816 \n",
            "Epoch 21: val_acc did not improve from 0.82143\n",
            "8/8 [==============================] - 175s 22s/step - loss: 0.3136 - acc: 0.8816 - val_loss: 1.1694 - val_acc: 0.6786\n",
            "Epoch 22/50\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3734 - acc: 0.8816 \n",
            "Epoch 22: val_acc did not improve from 0.82143\n",
            "8/8 [==============================] - 175s 22s/step - loss: 0.3734 - acc: 0.8816 - val_loss: 0.8160 - val_acc: 0.7714\n",
            "Epoch 23/50\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3276 - acc: 0.8857 \n",
            "Epoch 23: val_acc did not improve from 0.82143\n",
            "8/8 [==============================] - 175s 22s/step - loss: 0.3276 - acc: 0.8857 - val_loss: 1.2285 - val_acc: 0.6857\n",
            "Epoch 24/50\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4294 - acc: 0.8694 \n",
            "Epoch 24: val_acc did not improve from 0.82143\n",
            "8/8 [==============================] - 175s 23s/step - loss: 0.4294 - acc: 0.8694 - val_loss: 0.8214 - val_acc: 0.7929\n",
            "\n",
            "\n",
            "Model Accuracy 0.6142857142857143\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.89      0.80      0.84        10\n",
            "       10000       1.00      0.70      0.82        10\n",
            "      100000       1.00      0.20      0.33        10\n",
            "        2000       0.50      0.50      0.50        10\n",
            "       20000       0.80      0.40      0.53        10\n",
            "        5000       0.39      0.90      0.55        10\n",
            "       50000       0.57      0.80      0.67        10\n",
            "\n",
            "    accuracy                           0.61        70\n",
            "   macro avg       0.74      0.61      0.61        70\n",
            "weighted avg       0.74      0.61      0.61        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 115 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 54\n",
            "learning rate: 0.04811879370143828\n",
            "batch size: 64\n",
            "dropout rate: 0.7005657614192409\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 3.0401 - acc: 0.2837 \n",
            "Epoch 1: val_acc improved from -inf to 0.22857, saving model to percobaan115_noImgPro/model\\vgg_16_115-saved-model-01-acc-0.23.hdf5\n",
            "8/8 [==============================] - 169s 22s/step - loss: 3.0401 - acc: 0.2837 - val_loss: 10.1051 - val_acc: 0.2286\n",
            "Epoch 2/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.1723 - acc: 0.3694 \n",
            "Epoch 2: val_acc improved from 0.22857 to 0.27857, saving model to percobaan115_noImgPro/model\\vgg_16_115-saved-model-02-acc-0.28.hdf5\n",
            "8/8 [==============================] - 167s 22s/step - loss: 2.1723 - acc: 0.3694 - val_loss: 4.1738 - val_acc: 0.2786\n",
            "Epoch 3/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6205 - acc: 0.4571 \n",
            "Epoch 3: val_acc did not improve from 0.27857\n",
            "8/8 [==============================] - 167s 21s/step - loss: 1.6205 - acc: 0.4571 - val_loss: 3.9987 - val_acc: 0.1857\n",
            "Epoch 4/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4240 - acc: 0.5245 \n",
            "Epoch 4: val_acc improved from 0.27857 to 0.40000, saving model to percobaan115_noImgPro/model\\vgg_16_115-saved-model-04-acc-0.40.hdf5\n",
            "8/8 [==============================] - 168s 22s/step - loss: 1.4240 - acc: 0.5245 - val_loss: 2.4976 - val_acc: 0.4000\n",
            "Epoch 5/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.2231 - acc: 0.5551 \n",
            "Epoch 5: val_acc did not improve from 0.40000\n",
            "8/8 [==============================] - 167s 22s/step - loss: 1.2231 - acc: 0.5551 - val_loss: 2.1592 - val_acc: 0.3929\n",
            "Epoch 6/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9971 - acc: 0.6469 \n",
            "Epoch 6: val_acc improved from 0.40000 to 0.40714, saving model to percobaan115_noImgPro/model\\vgg_16_115-saved-model-06-acc-0.41.hdf5\n",
            "8/8 [==============================] - 168s 21s/step - loss: 0.9971 - acc: 0.6469 - val_loss: 1.8987 - val_acc: 0.4071\n",
            "Epoch 7/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9679 - acc: 0.6633 \n",
            "Epoch 7: val_acc did not improve from 0.40714\n",
            "8/8 [==============================] - 169s 22s/step - loss: 0.9679 - acc: 0.6633 - val_loss: 2.3080 - val_acc: 0.2643\n",
            "Epoch 8/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8037 - acc: 0.6918 \n",
            "Epoch 8: val_acc did not improve from 0.40714\n",
            "8/8 [==============================] - 168s 22s/step - loss: 0.8037 - acc: 0.6918 - val_loss: 1.9256 - val_acc: 0.3643\n",
            "Epoch 9/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7763 - acc: 0.7082 \n",
            "Epoch 9: val_acc improved from 0.40714 to 0.52143, saving model to percobaan115_noImgPro/model\\vgg_16_115-saved-model-09-acc-0.52.hdf5\n",
            "8/8 [==============================] - 168s 22s/step - loss: 0.7763 - acc: 0.7082 - val_loss: 1.5459 - val_acc: 0.5214\n",
            "Epoch 10/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7277 - acc: 0.7245 \n",
            "Epoch 10: val_acc improved from 0.52143 to 0.55000, saving model to percobaan115_noImgPro/model\\vgg_16_115-saved-model-10-acc-0.55.hdf5\n",
            "8/8 [==============================] - 169s 22s/step - loss: 0.7277 - acc: 0.7245 - val_loss: 1.4190 - val_acc: 0.5500\n",
            "Epoch 11/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6545 - acc: 0.7694 \n",
            "Epoch 11: val_acc improved from 0.55000 to 0.55714, saving model to percobaan115_noImgPro/model\\vgg_16_115-saved-model-11-acc-0.56.hdf5\n",
            "8/8 [==============================] - 168s 21s/step - loss: 0.6545 - acc: 0.7694 - val_loss: 1.1354 - val_acc: 0.5571\n",
            "Epoch 12/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6505 - acc: 0.7612 \n",
            "Epoch 12: val_acc did not improve from 0.55714\n",
            "8/8 [==============================] - 167s 21s/step - loss: 0.6505 - acc: 0.7612 - val_loss: 1.3881 - val_acc: 0.5286\n",
            "Epoch 13/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6031 - acc: 0.7735 \n",
            "Epoch 13: val_acc did not improve from 0.55714\n",
            "8/8 [==============================] - 168s 21s/step - loss: 0.6031 - acc: 0.7735 - val_loss: 1.7371 - val_acc: 0.4429\n",
            "Epoch 14/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6435 - acc: 0.7816 \n",
            "Epoch 14: val_acc did not improve from 0.55714\n",
            "8/8 [==============================] - 167s 21s/step - loss: 0.6435 - acc: 0.7816 - val_loss: 1.6462 - val_acc: 0.4214\n",
            "Epoch 15/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6879 - acc: 0.7612 \n",
            "Epoch 15: val_acc did not improve from 0.55714\n",
            "8/8 [==============================] - 167s 21s/step - loss: 0.6879 - acc: 0.7612 - val_loss: 1.6412 - val_acc: 0.4714\n",
            "Epoch 16/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5245 - acc: 0.7837 \n",
            "Epoch 16: val_acc did not improve from 0.55714\n",
            "8/8 [==============================] - 167s 21s/step - loss: 0.5245 - acc: 0.7837 - val_loss: 1.3976 - val_acc: 0.5571\n",
            "\n",
            "\n",
            "Model Accuracy 0.42857142857142855\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.20      0.33        10\n",
            "       10000       1.00      0.70      0.82        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.46      0.60      0.52        10\n",
            "       20000       0.00      0.00      0.00        10\n",
            "        5000       0.71      0.50      0.59        10\n",
            "       50000       0.24      1.00      0.39        10\n",
            "\n",
            "    accuracy                           0.43        70\n",
            "   macro avg       0.49      0.43      0.38        70\n",
            "weighted avg       0.49      0.43      0.38        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 116 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 53\n",
            "learning rate: 0.04957407700967298\n",
            "batch size: 64\n",
            "dropout rate: 0.7400604825804461\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/53\n",
            "8/8 [==============================] - ETA: 0s - loss: 3.2825 - acc: 0.2592 \n",
            "Epoch 1: val_acc improved from -inf to 0.22143, saving model to percobaan116_noImgPro/model\\vgg_16_116-saved-model-01-acc-0.22.hdf5\n",
            "8/8 [==============================] - 161s 20s/step - loss: 3.2825 - acc: 0.2592 - val_loss: 10.0299 - val_acc: 0.2214\n",
            "Epoch 2/53\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.4967 - acc: 0.3245 \n",
            "Epoch 2: val_acc improved from 0.22143 to 0.22857, saving model to percobaan116_noImgPro/model\\vgg_16_116-saved-model-02-acc-0.23.hdf5\n",
            "8/8 [==============================] - 159s 20s/step - loss: 2.4967 - acc: 0.3245 - val_loss: 4.7962 - val_acc: 0.2286\n",
            "Epoch 3/53\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8224 - acc: 0.4367 \n",
            "Epoch 3: val_acc improved from 0.22857 to 0.28571, saving model to percobaan116_noImgPro/model\\vgg_16_116-saved-model-03-acc-0.29.hdf5\n",
            "8/8 [==============================] - 158s 20s/step - loss: 1.8224 - acc: 0.4367 - val_loss: 2.7713 - val_acc: 0.2857\n",
            "Epoch 4/53\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4960 - acc: 0.5082 \n",
            "Epoch 4: val_acc improved from 0.28571 to 0.37857, saving model to percobaan116_noImgPro/model\\vgg_16_116-saved-model-04-acc-0.38.hdf5\n",
            "8/8 [==============================] - 159s 20s/step - loss: 1.4960 - acc: 0.5082 - val_loss: 1.9957 - val_acc: 0.3786\n",
            "Epoch 5/53\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3396 - acc: 0.4959 \n",
            "Epoch 5: val_acc improved from 0.37857 to 0.49286, saving model to percobaan116_noImgPro/model\\vgg_16_116-saved-model-05-acc-0.49.hdf5\n",
            "8/8 [==============================] - 158s 21s/step - loss: 1.3396 - acc: 0.4959 - val_loss: 1.7967 - val_acc: 0.4929\n",
            "Epoch 6/53\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.2147 - acc: 0.5531 \n",
            "Epoch 6: val_acc did not improve from 0.49286\n",
            "8/8 [==============================] - 158s 20s/step - loss: 1.2147 - acc: 0.5531 - val_loss: 1.7451 - val_acc: 0.3929\n",
            "Epoch 7/53\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0529 - acc: 0.6163 \n",
            "Epoch 7: val_acc improved from 0.49286 to 0.56429, saving model to percobaan116_noImgPro/model\\vgg_16_116-saved-model-07-acc-0.56.hdf5\n",
            "8/8 [==============================] - 159s 20s/step - loss: 1.0529 - acc: 0.6163 - val_loss: 1.4750 - val_acc: 0.5643\n",
            "Epoch 8/53\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9623 - acc: 0.6469 \n",
            "Epoch 8: val_acc did not improve from 0.56429\n",
            "8/8 [==============================] - 158s 20s/step - loss: 0.9623 - acc: 0.6469 - val_loss: 1.4605 - val_acc: 0.4000\n",
            "Epoch 9/53\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9800 - acc: 0.6837 \n",
            "Epoch 9: val_acc did not improve from 0.56429\n",
            "8/8 [==============================] - 158s 21s/step - loss: 0.9800 - acc: 0.6837 - val_loss: 1.7653 - val_acc: 0.3571\n",
            "Epoch 10/53\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8888 - acc: 0.6776 \n",
            "Epoch 10: val_acc did not improve from 0.56429\n",
            "8/8 [==============================] - 158s 20s/step - loss: 0.8888 - acc: 0.6776 - val_loss: 1.2981 - val_acc: 0.5000\n",
            "Epoch 11/53\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6847 - acc: 0.7735 \n",
            "Epoch 11: val_acc did not improve from 0.56429\n",
            "8/8 [==============================] - 159s 20s/step - loss: 0.6847 - acc: 0.7735 - val_loss: 1.3827 - val_acc: 0.4571\n",
            "Epoch 12/53\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7891 - acc: 0.7510 \n",
            "Epoch 12: val_acc did not improve from 0.56429\n",
            "8/8 [==============================] - 158s 20s/step - loss: 0.7891 - acc: 0.7510 - val_loss: 1.5789 - val_acc: 0.3857\n",
            "Epoch 13/53\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7833 - acc: 0.7388 \n",
            "Epoch 13: val_acc improved from 0.56429 to 0.57857, saving model to percobaan116_noImgPro/model\\vgg_16_116-saved-model-13-acc-0.58.hdf5\n",
            "8/8 [==============================] - 158s 20s/step - loss: 0.7833 - acc: 0.7388 - val_loss: 1.1388 - val_acc: 0.5786\n",
            "Epoch 14/53\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7144 - acc: 0.7449 \n",
            "Epoch 14: val_acc did not improve from 0.57857\n",
            "8/8 [==============================] - 158s 20s/step - loss: 0.7144 - acc: 0.7449 - val_loss: 1.1915 - val_acc: 0.5500\n",
            "Epoch 15/53\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7262 - acc: 0.7571 \n",
            "Epoch 15: val_acc improved from 0.57857 to 0.64286, saving model to percobaan116_noImgPro/model\\vgg_16_116-saved-model-15-acc-0.64.hdf5\n",
            "8/8 [==============================] - 158s 20s/step - loss: 0.7262 - acc: 0.7571 - val_loss: 0.9807 - val_acc: 0.6429\n",
            "Epoch 16/53\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6438 - acc: 0.7673 \n",
            "Epoch 16: val_acc did not improve from 0.64286\n",
            "8/8 [==============================] - 157s 20s/step - loss: 0.6438 - acc: 0.7673 - val_loss: 1.1167 - val_acc: 0.6071\n",
            "Epoch 17/53\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6576 - acc: 0.7612 \n",
            "Epoch 17: val_acc improved from 0.64286 to 0.70000, saving model to percobaan116_noImgPro/model\\vgg_16_116-saved-model-17-acc-0.70.hdf5\n",
            "8/8 [==============================] - 158s 20s/step - loss: 0.6576 - acc: 0.7612 - val_loss: 0.8577 - val_acc: 0.7000\n",
            "Epoch 18/53\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7863 - acc: 0.7327 \n",
            "Epoch 18: val_acc did not improve from 0.70000\n",
            "8/8 [==============================] - 159s 20s/step - loss: 0.7863 - acc: 0.7327 - val_loss: 1.1499 - val_acc: 0.6714\n",
            "Epoch 19/53\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6910 - acc: 0.7816 \n",
            "Epoch 19: val_acc did not improve from 0.70000\n",
            "8/8 [==============================] - 158s 20s/step - loss: 0.6910 - acc: 0.7816 - val_loss: 0.9053 - val_acc: 0.6714\n",
            "Epoch 20/53\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6864 - acc: 0.7673 \n",
            "Epoch 20: val_acc did not improve from 0.70000\n",
            "8/8 [==============================] - 158s 21s/step - loss: 0.6864 - acc: 0.7673 - val_loss: 1.1008 - val_acc: 0.6143\n",
            "Epoch 21/53\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6302 - acc: 0.7857 \n",
            "Epoch 21: val_acc improved from 0.70000 to 0.75714, saving model to percobaan116_noImgPro/model\\vgg_16_116-saved-model-21-acc-0.76.hdf5\n",
            "8/8 [==============================] - 158s 20s/step - loss: 0.6302 - acc: 0.7857 - val_loss: 0.7350 - val_acc: 0.7571\n",
            "Epoch 22/53\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5790 - acc: 0.8082 \n",
            "Epoch 22: val_acc improved from 0.75714 to 0.82143, saving model to percobaan116_noImgPro/model\\vgg_16_116-saved-model-22-acc-0.82.hdf5\n",
            "8/8 [==============================] - 159s 21s/step - loss: 0.5790 - acc: 0.8082 - val_loss: 0.6356 - val_acc: 0.8214\n",
            "Epoch 23/53\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6111 - acc: 0.7959 \n",
            "Epoch 23: val_acc did not improve from 0.82143\n",
            "8/8 [==============================] - 159s 20s/step - loss: 0.6111 - acc: 0.7959 - val_loss: 0.8013 - val_acc: 0.7500\n",
            "Epoch 24/53\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5630 - acc: 0.8163 \n",
            "Epoch 24: val_acc did not improve from 0.82143\n",
            "8/8 [==============================] - 160s 21s/step - loss: 0.5630 - acc: 0.8163 - val_loss: 0.7203 - val_acc: 0.7929\n",
            "Epoch 25/53\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4832 - acc: 0.8245 \n",
            "Epoch 25: val_acc did not improve from 0.82143\n",
            "8/8 [==============================] - 161s 21s/step - loss: 0.4832 - acc: 0.8245 - val_loss: 1.0926 - val_acc: 0.6214\n",
            "Epoch 26/53\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5739 - acc: 0.8163 \n",
            "Epoch 26: val_acc did not improve from 0.82143\n",
            "8/8 [==============================] - 162s 22s/step - loss: 0.5739 - acc: 0.8163 - val_loss: 0.6614 - val_acc: 0.8000\n",
            "Epoch 27/53\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5030 - acc: 0.8367 \n",
            "Epoch 27: val_acc did not improve from 0.82143\n",
            "8/8 [==============================] - 164s 21s/step - loss: 0.5030 - acc: 0.8367 - val_loss: 0.6871 - val_acc: 0.7714\n",
            "\n",
            "\n",
            "Model Accuracy 0.7571428571428571\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.71      1.00      0.83        10\n",
            "       10000       0.77      1.00      0.87        10\n",
            "      100000       1.00      0.50      0.67        10\n",
            "        2000       0.82      0.90      0.86        10\n",
            "       20000       0.64      0.70      0.67        10\n",
            "        5000       0.67      0.80      0.73        10\n",
            "       50000       1.00      0.40      0.57        10\n",
            "\n",
            "    accuracy                           0.76        70\n",
            "   macro avg       0.80      0.76      0.74        70\n",
            "weighted avg       0.80      0.76      0.74        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 117 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 51\n",
            "learning rate: 0.04401657219041415\n",
            "batch size: 128\n",
            "dropout rate: 0.5231990849891998\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.4416 - acc: 0.3776 \n",
            "Epoch 1: val_acc improved from -inf to 0.37857, saving model to percobaan117_noImgPro/model\\vgg_16_117-saved-model-01-acc-0.38.hdf5\n",
            "4/4 [==============================] - 157s 43s/step - loss: 2.4416 - acc: 0.3776 - val_loss: 4.6786 - val_acc: 0.3786\n",
            "Epoch 2/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.4029 - acc: 0.5184 \n",
            "Epoch 2: val_acc did not improve from 0.37857\n",
            "4/4 [==============================] - 157s 44s/step - loss: 1.4029 - acc: 0.5184 - val_loss: 14.2091 - val_acc: 0.2143\n",
            "Epoch 3/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0260 - acc: 0.6347 \n",
            "Epoch 3: val_acc did not improve from 0.37857\n",
            "4/4 [==============================] - 157s 42s/step - loss: 1.0260 - acc: 0.6347 - val_loss: 10.5426 - val_acc: 0.1786\n",
            "Epoch 4/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8549 - acc: 0.7020 \n",
            "Epoch 4: val_acc did not improve from 0.37857\n",
            "4/4 [==============================] - 156s 43s/step - loss: 0.8549 - acc: 0.7020 - val_loss: 6.0626 - val_acc: 0.2071\n",
            "Epoch 5/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7105 - acc: 0.7510 \n",
            "Epoch 5: val_acc did not improve from 0.37857\n",
            "4/4 [==============================] - 159s 42s/step - loss: 0.7105 - acc: 0.7510 - val_loss: 6.7862 - val_acc: 0.1857\n",
            "Epoch 6/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6390 - acc: 0.7694 \n",
            "Epoch 6: val_acc did not improve from 0.37857\n",
            "4/4 [==============================] - 157s 43s/step - loss: 0.6390 - acc: 0.7694 - val_loss: 7.1019 - val_acc: 0.1786\n",
            "\n",
            "\n",
            "Model Accuracy 0.15714285714285714\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.10      0.18        10\n",
            "       10000       0.00      0.00      0.00        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.00      0.00      0.00        10\n",
            "       20000       0.14      1.00      0.25        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       0.00      0.00      0.00        10\n",
            "\n",
            "    accuracy                           0.16        70\n",
            "   macro avg       0.16      0.16      0.06        70\n",
            "weighted avg       0.16      0.16      0.06        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 118 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 54\n",
            "learning rate: 0.044304778076834264\n",
            "batch size: 128\n",
            "dropout rate: 0.6319761999927644\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.8287 - acc: 0.2816 \n",
            "Epoch 1: val_acc improved from -inf to 0.25714, saving model to percobaan118_noImgPro/model\\vgg_16_118-saved-model-01-acc-0.26.hdf5\n",
            "4/4 [==============================] - 154s 41s/step - loss: 2.8287 - acc: 0.2816 - val_loss: 5.7856 - val_acc: 0.2571\n",
            "Epoch 2/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.7855 - acc: 0.4265 \n",
            "Epoch 2: val_acc did not improve from 0.25714\n",
            "4/4 [==============================] - 154s 41s/step - loss: 1.7855 - acc: 0.4265 - val_loss: 6.6480 - val_acc: 0.1857\n",
            "Epoch 3/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.3838 - acc: 0.5265 \n",
            "Epoch 3: val_acc improved from 0.25714 to 0.32143, saving model to percobaan118_noImgPro/model\\vgg_16_118-saved-model-03-acc-0.32.hdf5\n",
            "4/4 [==============================] - 151s 40s/step - loss: 1.3838 - acc: 0.5265 - val_loss: 3.1423 - val_acc: 0.3214\n",
            "Epoch 4/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1603 - acc: 0.6122 \n",
            "Epoch 4: val_acc improved from 0.32143 to 0.40000, saving model to percobaan118_noImgPro/model\\vgg_16_118-saved-model-04-acc-0.40.hdf5\n",
            "4/4 [==============================] - 154s 41s/step - loss: 1.1603 - acc: 0.6122 - val_loss: 3.0304 - val_acc: 0.4000\n",
            "Epoch 5/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9886 - acc: 0.6592 \n",
            "Epoch 5: val_acc did not improve from 0.40000\n",
            "4/4 [==============================] - 152s 40s/step - loss: 0.9886 - acc: 0.6592 - val_loss: 3.1984 - val_acc: 0.3214\n",
            "Epoch 6/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7826 - acc: 0.7184 \n",
            "Epoch 6: val_acc did not improve from 0.40000\n",
            "4/4 [==============================] - 151s 42s/step - loss: 0.7826 - acc: 0.7184 - val_loss: 3.6707 - val_acc: 0.3500\n",
            "Epoch 7/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7400 - acc: 0.7265 \n",
            "Epoch 7: val_acc did not improve from 0.40000\n",
            "4/4 [==============================] - 152s 42s/step - loss: 0.7400 - acc: 0.7265 - val_loss: 3.7515 - val_acc: 0.3714\n",
            "Epoch 8/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6676 - acc: 0.7694 \n",
            "Epoch 8: val_acc did not improve from 0.40000\n",
            "4/4 [==============================] - 152s 40s/step - loss: 0.6676 - acc: 0.7694 - val_loss: 3.6022 - val_acc: 0.4000\n",
            "Epoch 9/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5029 - acc: 0.8000 \n",
            "Epoch 9: val_acc improved from 0.40000 to 0.40714, saving model to percobaan118_noImgPro/model\\vgg_16_118-saved-model-09-acc-0.41.hdf5\n",
            "4/4 [==============================] - 154s 41s/step - loss: 0.5029 - acc: 0.8000 - val_loss: 3.4818 - val_acc: 0.4071\n",
            "\n",
            "\n",
            "Model Accuracy 0.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.80      0.40      0.53        10\n",
            "       10000       0.20      1.00      0.34        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       1.00      0.10      0.18        10\n",
            "       20000       0.36      0.50      0.42        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       1.00      0.10      0.18        10\n",
            "\n",
            "    accuracy                           0.30        70\n",
            "   macro avg       0.48      0.30      0.24        70\n",
            "weighted avg       0.48      0.30      0.24        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 119 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 51\n",
            "learning rate: 0.03816398116556126\n",
            "batch size: 128\n",
            "dropout rate: 0.7178631312931926\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.9857 - acc: 0.2653 \n",
            "Epoch 1: val_acc improved from -inf to 0.19286, saving model to percobaan119_noImgPro/model\\vgg_16_119-saved-model-01-acc-0.19.hdf5\n",
            "4/4 [==============================] - 151s 39s/step - loss: 2.9857 - acc: 0.2653 - val_loss: 5.4000 - val_acc: 0.1929\n",
            "Epoch 2/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.6981 - acc: 0.4510 \n",
            "Epoch 2: val_acc improved from 0.19286 to 0.29286, saving model to percobaan119_noImgPro/model\\vgg_16_119-saved-model-02-acc-0.29.hdf5\n",
            "4/4 [==============================] - 152s 40s/step - loss: 1.6981 - acc: 0.4510 - val_loss: 5.3870 - val_acc: 0.2929\n",
            "Epoch 3/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.5137 - acc: 0.4653 \n",
            "Epoch 3: val_acc did not improve from 0.29286\n",
            "4/4 [==============================] - 151s 42s/step - loss: 1.5137 - acc: 0.4653 - val_loss: 5.5585 - val_acc: 0.2571\n",
            "Epoch 4/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.3915 - acc: 0.5245 \n",
            "Epoch 4: val_acc improved from 0.29286 to 0.31429, saving model to percobaan119_noImgPro/model\\vgg_16_119-saved-model-04-acc-0.31.hdf5\n",
            "4/4 [==============================] - 152s 40s/step - loss: 1.3915 - acc: 0.5245 - val_loss: 4.3028 - val_acc: 0.3143\n",
            "Epoch 5/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1815 - acc: 0.5837 \n",
            "Epoch 5: val_acc improved from 0.31429 to 0.37857, saving model to percobaan119_noImgPro/model\\vgg_16_119-saved-model-05-acc-0.38.hdf5\n",
            "4/4 [==============================] - 151s 40s/step - loss: 1.1815 - acc: 0.5837 - val_loss: 3.3262 - val_acc: 0.3786\n",
            "Epoch 6/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9894 - acc: 0.6408 \n",
            "Epoch 6: val_acc did not improve from 0.37857\n",
            "4/4 [==============================] - 151s 40s/step - loss: 0.9894 - acc: 0.6408 - val_loss: 3.1530 - val_acc: 0.3143\n",
            "Epoch 7/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9182 - acc: 0.6939 \n",
            "Epoch 7: val_acc did not improve from 0.37857\n",
            "4/4 [==============================] - 151s 42s/step - loss: 0.9182 - acc: 0.6939 - val_loss: 2.9966 - val_acc: 0.3000\n",
            "Epoch 8/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8685 - acc: 0.7102 \n",
            "Epoch 8: val_acc did not improve from 0.37857\n",
            "4/4 [==============================] - 151s 40s/step - loss: 0.8685 - acc: 0.7102 - val_loss: 3.1645 - val_acc: 0.3143\n",
            "Epoch 9/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8049 - acc: 0.7143 \n",
            "Epoch 9: val_acc did not improve from 0.37857\n",
            "4/4 [==============================] - 152s 40s/step - loss: 0.8049 - acc: 0.7143 - val_loss: 3.9419 - val_acc: 0.2571\n",
            "Epoch 10/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7210 - acc: 0.7490 \n",
            "Epoch 10: val_acc did not improve from 0.37857\n",
            "4/4 [==============================] - 151s 40s/step - loss: 0.7210 - acc: 0.7490 - val_loss: 3.8680 - val_acc: 0.2429\n",
            "Epoch 11/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7387 - acc: 0.7673 \n",
            "Epoch 11: val_acc did not improve from 0.37857\n",
            "4/4 [==============================] - 151s 42s/step - loss: 0.7387 - acc: 0.7673 - val_loss: 3.1369 - val_acc: 0.2786\n",
            "Epoch 12/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5648 - acc: 0.7980 \n",
            "Epoch 12: val_acc did not improve from 0.37857\n",
            "4/4 [==============================] - 152s 42s/step - loss: 0.5648 - acc: 0.7980 - val_loss: 2.9491 - val_acc: 0.3143\n",
            "Epoch 13/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5283 - acc: 0.8102 \n",
            "Epoch 13: val_acc did not improve from 0.37857\n",
            "4/4 [==============================] - 150s 40s/step - loss: 0.5283 - acc: 0.8102 - val_loss: 2.4888 - val_acc: 0.3571\n",
            "Epoch 14/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5140 - acc: 0.8143 \n",
            "Epoch 14: val_acc improved from 0.37857 to 0.40000, saving model to percobaan119_noImgPro/model\\vgg_16_119-saved-model-14-acc-0.40.hdf5\n",
            "4/4 [==============================] - 151s 42s/step - loss: 0.5140 - acc: 0.8143 - val_loss: 2.1876 - val_acc: 0.4000\n",
            "Epoch 15/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4911 - acc: 0.8265 \n",
            "Epoch 15: val_acc improved from 0.40000 to 0.45000, saving model to percobaan119_noImgPro/model\\vgg_16_119-saved-model-15-acc-0.45.hdf5\n",
            "4/4 [==============================] - 152s 40s/step - loss: 0.4911 - acc: 0.8265 - val_loss: 2.0239 - val_acc: 0.4500\n",
            "Epoch 16/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4871 - acc: 0.8143 \n",
            "Epoch 16: val_acc improved from 0.45000 to 0.48571, saving model to percobaan119_noImgPro/model\\vgg_16_119-saved-model-16-acc-0.49.hdf5\n",
            "4/4 [==============================] - 153s 40s/step - loss: 0.4871 - acc: 0.8143 - val_loss: 1.8977 - val_acc: 0.4857\n",
            "Epoch 17/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4314 - acc: 0.8367 \n",
            "Epoch 17: val_acc did not improve from 0.48571\n",
            "4/4 [==============================] - 150s 41s/step - loss: 0.4314 - acc: 0.8367 - val_loss: 2.2388 - val_acc: 0.4071\n",
            "Epoch 18/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4400 - acc: 0.8327 \n",
            "Epoch 18: val_acc did not improve from 0.48571\n",
            "4/4 [==============================] - 152s 40s/step - loss: 0.4400 - acc: 0.8327 - val_loss: 2.4242 - val_acc: 0.3929\n",
            "Epoch 19/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3770 - acc: 0.8714 \n",
            "Epoch 19: val_acc did not improve from 0.48571\n",
            "4/4 [==============================] - 152s 42s/step - loss: 0.3770 - acc: 0.8714 - val_loss: 2.1884 - val_acc: 0.4500\n",
            "Epoch 20/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3591 - acc: 0.8714 \n",
            "Epoch 20: val_acc improved from 0.48571 to 0.54286, saving model to percobaan119_noImgPro/model\\vgg_16_119-saved-model-20-acc-0.54.hdf5\n",
            "4/4 [==============================] - 150s 39s/step - loss: 0.3591 - acc: 0.8714 - val_loss: 1.6259 - val_acc: 0.5429\n",
            "Epoch 21/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3368 - acc: 0.8837 \n",
            "Epoch 21: val_acc improved from 0.54286 to 0.64286, saving model to percobaan119_noImgPro/model\\vgg_16_119-saved-model-21-acc-0.64.hdf5\n",
            "4/4 [==============================] - 150s 41s/step - loss: 0.3368 - acc: 0.8837 - val_loss: 1.2137 - val_acc: 0.6429\n",
            "Epoch 22/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4052 - acc: 0.8551 \n",
            "Epoch 22: val_acc did not improve from 0.64286\n",
            "4/4 [==============================] - 151s 42s/step - loss: 0.4052 - acc: 0.8551 - val_loss: 1.1889 - val_acc: 0.6429\n",
            "Epoch 23/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3036 - acc: 0.8980 \n",
            "Epoch 23: val_acc improved from 0.64286 to 0.65714, saving model to percobaan119_noImgPro/model\\vgg_16_119-saved-model-23-acc-0.66.hdf5\n",
            "4/4 [==============================] - 152s 40s/step - loss: 0.3036 - acc: 0.8980 - val_loss: 1.1168 - val_acc: 0.6571\n",
            "Epoch 24/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3778 - acc: 0.8755 \n",
            "Epoch 24: val_acc improved from 0.65714 to 0.68571, saving model to percobaan119_noImgPro/model\\vgg_16_119-saved-model-24-acc-0.69.hdf5\n",
            "4/4 [==============================] - 151s 40s/step - loss: 0.3778 - acc: 0.8755 - val_loss: 1.0028 - val_acc: 0.6857\n",
            "Epoch 25/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3452 - acc: 0.8918 \n",
            "Epoch 25: val_acc improved from 0.68571 to 0.75000, saving model to percobaan119_noImgPro/model\\vgg_16_119-saved-model-25-acc-0.75.hdf5\n",
            "4/4 [==============================] - 151s 40s/step - loss: 0.3452 - acc: 0.8918 - val_loss: 0.8322 - val_acc: 0.7500\n",
            "Epoch 26/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3504 - acc: 0.8673 \n",
            "Epoch 26: val_acc did not improve from 0.75000\n",
            "4/4 [==============================] - 151s 40s/step - loss: 0.3504 - acc: 0.8673 - val_loss: 0.8518 - val_acc: 0.7500\n",
            "Epoch 27/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3250 - acc: 0.8959 \n",
            "Epoch 27: val_acc did not improve from 0.75000\n",
            "4/4 [==============================] - 151s 42s/step - loss: 0.3250 - acc: 0.8959 - val_loss: 0.9375 - val_acc: 0.7214\n",
            "Epoch 28/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2796 - acc: 0.8939 \n",
            "Epoch 28: val_acc did not improve from 0.75000\n",
            "4/4 [==============================] - 152s 40s/step - loss: 0.2796 - acc: 0.8939 - val_loss: 0.8699 - val_acc: 0.7143\n",
            "Epoch 29/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3221 - acc: 0.8816 \n",
            "Epoch 29: val_acc did not improve from 0.75000\n",
            "4/4 [==============================] - 150s 40s/step - loss: 0.3221 - acc: 0.8816 - val_loss: 1.0808 - val_acc: 0.6643\n",
            "Epoch 30/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2878 - acc: 0.9163 \n",
            "Epoch 30: val_acc did not improve from 0.75000\n",
            "4/4 [==============================] - 152s 40s/step - loss: 0.2878 - acc: 0.9163 - val_loss: 1.1265 - val_acc: 0.6357\n",
            "\n",
            "\n",
            "Model Accuracy 0.5428571428571428\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.83      0.50      0.62        10\n",
            "       10000       0.32      1.00      0.49        10\n",
            "      100000       1.00      0.10      0.18        10\n",
            "        2000       0.71      0.50      0.59        10\n",
            "       20000       1.00      0.40      0.57        10\n",
            "        5000       0.67      0.40      0.50        10\n",
            "       50000       0.60      0.90      0.72        10\n",
            "\n",
            "    accuracy                           0.54        70\n",
            "   macro avg       0.73      0.54      0.52        70\n",
            "weighted avg       0.73      0.54      0.52        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 120 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 54\n",
            "learning rate: 0.030810770023441916\n",
            "batch size: 128\n",
            "dropout rate: 0.7634314000397807\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 3.4478 - acc: 0.2000 \n",
            "Epoch 1: val_acc improved from -inf to 0.15714, saving model to percobaan120_noImgPro/model\\vgg_16_120-saved-model-01-acc-0.16.hdf5\n",
            "4/4 [==============================] - 150s 42s/step - loss: 3.4478 - acc: 0.2000 - val_loss: 7.8292 - val_acc: 0.1571\n",
            "Epoch 2/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.0779 - acc: 0.3571 \n",
            "Epoch 2: val_acc improved from 0.15714 to 0.19286, saving model to percobaan120_noImgPro/model\\vgg_16_120-saved-model-02-acc-0.19.hdf5\n",
            "4/4 [==============================] - 153s 41s/step - loss: 2.0779 - acc: 0.3571 - val_loss: 6.9062 - val_acc: 0.1929\n",
            "Epoch 3/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.9155 - acc: 0.3755 \n",
            "Epoch 3: val_acc did not improve from 0.19286\n",
            "4/4 [==============================] - 153s 40s/step - loss: 1.9155 - acc: 0.3755 - val_loss: 7.3499 - val_acc: 0.1429\n",
            "Epoch 4/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.6006 - acc: 0.4633 \n",
            "Epoch 4: val_acc improved from 0.19286 to 0.20714, saving model to percobaan120_noImgPro/model\\vgg_16_120-saved-model-04-acc-0.21.hdf5\n",
            "4/4 [==============================] - 152s 40s/step - loss: 1.6006 - acc: 0.4633 - val_loss: 4.2019 - val_acc: 0.2071\n",
            "Epoch 5/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.4597 - acc: 0.4816 \n",
            "Epoch 5: val_acc improved from 0.20714 to 0.22857, saving model to percobaan120_noImgPro/model\\vgg_16_120-saved-model-05-acc-0.23.hdf5\n",
            "4/4 [==============================] - 152s 42s/step - loss: 1.4597 - acc: 0.4816 - val_loss: 3.0156 - val_acc: 0.2286\n",
            "Epoch 6/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2498 - acc: 0.5653 \n",
            "Epoch 6: val_acc did not improve from 0.22857\n",
            "4/4 [==============================] - 153s 42s/step - loss: 1.2498 - acc: 0.5653 - val_loss: 3.3299 - val_acc: 0.2286\n",
            "Epoch 7/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1145 - acc: 0.6082 \n",
            "Epoch 7: val_acc did not improve from 0.22857\n",
            "4/4 [==============================] - 154s 41s/step - loss: 1.1145 - acc: 0.6082 - val_loss: 3.9122 - val_acc: 0.1786\n",
            "Epoch 8/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0094 - acc: 0.6612 \n",
            "Epoch 8: val_acc did not improve from 0.22857\n",
            "4/4 [==============================] - 153s 42s/step - loss: 1.0094 - acc: 0.6612 - val_loss: 3.9893 - val_acc: 0.1643\n",
            "Epoch 9/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9462 - acc: 0.6633 \n",
            "Epoch 9: val_acc did not improve from 0.22857\n",
            "4/4 [==============================] - 153s 42s/step - loss: 0.9462 - acc: 0.6633 - val_loss: 3.4482 - val_acc: 0.2286\n",
            "Epoch 10/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9521 - acc: 0.6755 \n",
            "Epoch 10: val_acc improved from 0.22857 to 0.27857, saving model to percobaan120_noImgPro/model\\vgg_16_120-saved-model-10-acc-0.28.hdf5\n",
            "4/4 [==============================] - 152s 40s/step - loss: 0.9521 - acc: 0.6755 - val_loss: 3.3010 - val_acc: 0.2786\n",
            "\n",
            "\n",
            "Model Accuracy 0.24285714285714285\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.10      0.18        10\n",
            "       10000       0.00      0.00      0.00        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.00      0.00      0.00        10\n",
            "       20000       0.15      0.80      0.25        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       0.57      0.80      0.67        10\n",
            "\n",
            "    accuracy                           0.24        70\n",
            "   macro avg       0.25      0.24      0.16        70\n",
            "weighted avg       0.25      0.24      0.16        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 121 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 56\n",
            "learning rate: 0.06782261527805995\n",
            "batch size: 32\n",
            "dropout rate: 0.5261888147347026\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 3.0241 - acc: 0.3000\n",
            "Epoch 1: val_acc improved from -inf to 0.16429, saving model to percobaan121_noImgPro/model\\vgg_16_121-saved-model-01-acc-0.16.hdf5\n",
            "16/16 [==============================] - 154s 10s/step - loss: 3.0241 - acc: 0.3000 - val_loss: 6.2849 - val_acc: 0.1643\n",
            "Epoch 2/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.8203 - acc: 0.4531\n",
            "Epoch 2: val_acc improved from 0.16429 to 0.22857, saving model to percobaan121_noImgPro/model\\vgg_16_121-saved-model-02-acc-0.23.hdf5\n",
            "16/16 [==============================] - 153s 10s/step - loss: 1.8203 - acc: 0.4531 - val_loss: 4.1310 - val_acc: 0.2286\n",
            "Epoch 3/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.4605 - acc: 0.5000\n",
            "Epoch 3: val_acc improved from 0.22857 to 0.24286, saving model to percobaan121_noImgPro/model\\vgg_16_121-saved-model-03-acc-0.24.hdf5\n",
            "16/16 [==============================] - 155s 10s/step - loss: 1.4605 - acc: 0.5000 - val_loss: 4.2988 - val_acc: 0.2429\n",
            "Epoch 4/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2835 - acc: 0.5510\n",
            "Epoch 4: val_acc improved from 0.24286 to 0.31429, saving model to percobaan121_noImgPro/model\\vgg_16_121-saved-model-04-acc-0.31.hdf5\n",
            "16/16 [==============================] - 153s 10s/step - loss: 1.2835 - acc: 0.5510 - val_loss: 2.3078 - val_acc: 0.3143\n",
            "Epoch 5/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0206 - acc: 0.6429\n",
            "Epoch 5: val_acc did not improve from 0.31429\n",
            "16/16 [==============================] - 153s 10s/step - loss: 1.0206 - acc: 0.6429 - val_loss: 2.4444 - val_acc: 0.2500\n",
            "Epoch 6/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9732 - acc: 0.6551\n",
            "Epoch 6: val_acc improved from 0.31429 to 0.55000, saving model to percobaan121_noImgPro/model\\vgg_16_121-saved-model-06-acc-0.55.hdf5\n",
            "16/16 [==============================] - 152s 10s/step - loss: 0.9732 - acc: 0.6551 - val_loss: 1.3661 - val_acc: 0.5500\n",
            "Epoch 7/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8530 - acc: 0.7224\n",
            "Epoch 7: val_acc improved from 0.55000 to 0.60714, saving model to percobaan121_noImgPro/model\\vgg_16_121-saved-model-07-acc-0.61.hdf5\n",
            "16/16 [==============================] - 153s 10s/step - loss: 0.8530 - acc: 0.7224 - val_loss: 1.5828 - val_acc: 0.6071\n",
            "Epoch 8/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9629 - acc: 0.7041\n",
            "Epoch 8: val_acc did not improve from 0.60714\n",
            "16/16 [==============================] - 153s 10s/step - loss: 0.9629 - acc: 0.7041 - val_loss: 2.5517 - val_acc: 0.3429\n",
            "Epoch 9/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7974 - acc: 0.7245\n",
            "Epoch 9: val_acc improved from 0.60714 to 0.62857, saving model to percobaan121_noImgPro/model\\vgg_16_121-saved-model-09-acc-0.63.hdf5\n",
            "16/16 [==============================] - 153s 10s/step - loss: 0.7974 - acc: 0.7245 - val_loss: 1.1992 - val_acc: 0.6286\n",
            "Epoch 10/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8256 - acc: 0.7306\n",
            "Epoch 10: val_acc improved from 0.62857 to 0.67857, saving model to percobaan121_noImgPro/model\\vgg_16_121-saved-model-10-acc-0.68.hdf5\n",
            "16/16 [==============================] - 153s 10s/step - loss: 0.8256 - acc: 0.7306 - val_loss: 1.1534 - val_acc: 0.6786\n",
            "Epoch 11/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8388 - acc: 0.7633\n",
            "Epoch 11: val_acc improved from 0.67857 to 0.73571, saving model to percobaan121_noImgPro/model\\vgg_16_121-saved-model-11-acc-0.74.hdf5\n",
            "16/16 [==============================] - 153s 10s/step - loss: 0.8388 - acc: 0.7633 - val_loss: 0.9275 - val_acc: 0.7357\n",
            "Epoch 12/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0090 - acc: 0.7184\n",
            "Epoch 12: val_acc did not improve from 0.73571\n",
            "16/16 [==============================] - 153s 10s/step - loss: 1.0090 - acc: 0.7184 - val_loss: 1.7049 - val_acc: 0.5857\n",
            "Epoch 13/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8122 - acc: 0.7571\n",
            "Epoch 13: val_acc did not improve from 0.73571\n",
            "16/16 [==============================] - 154s 10s/step - loss: 0.8122 - acc: 0.7571 - val_loss: 1.2462 - val_acc: 0.7071\n",
            "Epoch 14/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7817 - acc: 0.7714\n",
            "Epoch 14: val_acc did not improve from 0.73571\n",
            "16/16 [==============================] - 153s 10s/step - loss: 0.7817 - acc: 0.7714 - val_loss: 4.2362 - val_acc: 0.4000\n",
            "Epoch 15/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7476 - acc: 0.7796\n",
            "Epoch 15: val_acc did not improve from 0.73571\n",
            "16/16 [==============================] - 153s 10s/step - loss: 0.7476 - acc: 0.7796 - val_loss: 2.4610 - val_acc: 0.6286\n",
            "Epoch 16/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8236 - acc: 0.7857\n",
            "Epoch 16: val_acc did not improve from 0.73571\n",
            "16/16 [==============================] - 153s 10s/step - loss: 0.8236 - acc: 0.7857 - val_loss: 3.3801 - val_acc: 0.4500\n",
            "\n",
            "\n",
            "Model Accuracy 0.34285714285714286\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.18      1.00      0.31        10\n",
            "       10000       1.00      0.20      0.33        10\n",
            "      100000       1.00      0.60      0.75        10\n",
            "        2000       1.00      0.20      0.33        10\n",
            "       20000       0.00      0.00      0.00        10\n",
            "        5000       1.00      0.20      0.33        10\n",
            "       50000       1.00      0.20      0.33        10\n",
            "\n",
            "    accuracy                           0.34        70\n",
            "   macro avg       0.74      0.34      0.34        70\n",
            "weighted avg       0.74      0.34      0.34        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 122 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 55\n",
            "learning rate: 0.06509255461204205\n",
            "batch size: 32\n",
            "dropout rate: 0.5898242136919187\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/55\n",
            "16/16 [==============================] - ETA: 0s - loss: 3.1215 - acc: 0.3061\n",
            "Epoch 1: val_acc improved from -inf to 0.22857, saving model to percobaan122_noImgPro/model\\vgg_16_122-saved-model-01-acc-0.23.hdf5\n",
            "16/16 [==============================] - 153s 10s/step - loss: 3.1215 - acc: 0.3061 - val_loss: 9.7068 - val_acc: 0.2286\n",
            "Epoch 2/55\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.1395 - acc: 0.4122\n",
            "Epoch 2: val_acc improved from 0.22857 to 0.37857, saving model to percobaan122_noImgPro/model\\vgg_16_122-saved-model-02-acc-0.38.hdf5\n",
            "16/16 [==============================] - 152s 10s/step - loss: 2.1395 - acc: 0.4122 - val_loss: 3.0190 - val_acc: 0.3786\n",
            "Epoch 3/55\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.7008 - acc: 0.4939\n",
            "Epoch 3: val_acc improved from 0.37857 to 0.49286, saving model to percobaan122_noImgPro/model\\vgg_16_122-saved-model-03-acc-0.49.hdf5\n",
            "16/16 [==============================] - 152s 10s/step - loss: 1.7008 - acc: 0.4939 - val_loss: 1.6164 - val_acc: 0.4929\n",
            "Epoch 4/55\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2242 - acc: 0.5490\n",
            "Epoch 4: val_acc did not improve from 0.49286\n",
            "16/16 [==============================] - 149s 9s/step - loss: 1.2242 - acc: 0.5490 - val_loss: 2.9301 - val_acc: 0.3143\n",
            "Epoch 5/55\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1526 - acc: 0.6163\n",
            "Epoch 5: val_acc did not improve from 0.49286\n",
            "16/16 [==============================] - 152s 10s/step - loss: 1.1526 - acc: 0.6163 - val_loss: 1.5904 - val_acc: 0.4429\n",
            "Epoch 6/55\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1043 - acc: 0.6306\n",
            "Epoch 6: val_acc improved from 0.49286 to 0.52857, saving model to percobaan122_noImgPro/model\\vgg_16_122-saved-model-06-acc-0.53.hdf5\n",
            "16/16 [==============================] - 152s 10s/step - loss: 1.1043 - acc: 0.6306 - val_loss: 1.5388 - val_acc: 0.5286\n",
            "Epoch 7/55\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8996 - acc: 0.6939\n",
            "Epoch 7: val_acc did not improve from 0.52857\n",
            "16/16 [==============================] - 152s 10s/step - loss: 0.8996 - acc: 0.6939 - val_loss: 1.4500 - val_acc: 0.5071\n",
            "Epoch 8/55\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8661 - acc: 0.7020\n",
            "Epoch 8: val_acc improved from 0.52857 to 0.57143, saving model to percobaan122_noImgPro/model\\vgg_16_122-saved-model-08-acc-0.57.hdf5\n",
            "16/16 [==============================] - 152s 10s/step - loss: 0.8661 - acc: 0.7020 - val_loss: 1.2144 - val_acc: 0.5714\n",
            "Epoch 9/55\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6854 - acc: 0.7592\n",
            "Epoch 9: val_acc improved from 0.57143 to 0.57857, saving model to percobaan122_noImgPro/model\\vgg_16_122-saved-model-09-acc-0.58.hdf5\n",
            "16/16 [==============================] - 153s 10s/step - loss: 0.6854 - acc: 0.7592 - val_loss: 1.1987 - val_acc: 0.5786\n",
            "Epoch 10/55\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7979 - acc: 0.7531\n",
            "Epoch 10: val_acc did not improve from 0.57857\n",
            "16/16 [==============================] - 152s 10s/step - loss: 0.7979 - acc: 0.7531 - val_loss: 2.0777 - val_acc: 0.5071\n",
            "Epoch 11/55\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7583 - acc: 0.7592\n",
            "Epoch 11: val_acc improved from 0.57857 to 0.59286, saving model to percobaan122_noImgPro/model\\vgg_16_122-saved-model-11-acc-0.59.hdf5\n",
            "16/16 [==============================] - 152s 10s/step - loss: 0.7583 - acc: 0.7592 - val_loss: 1.5768 - val_acc: 0.5929\n",
            "Epoch 12/55\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9329 - acc: 0.7082\n",
            "Epoch 12: val_acc did not improve from 0.59286\n",
            "16/16 [==============================] - 151s 10s/step - loss: 0.9329 - acc: 0.7082 - val_loss: 2.0417 - val_acc: 0.5286\n",
            "Epoch 13/55\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7945 - acc: 0.7673\n",
            "Epoch 13: val_acc did not improve from 0.59286\n",
            "16/16 [==============================] - 152s 10s/step - loss: 0.7945 - acc: 0.7673 - val_loss: 1.9081 - val_acc: 0.5929\n",
            "Epoch 14/55\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7990 - acc: 0.7673\n",
            "Epoch 14: val_acc improved from 0.59286 to 0.65714, saving model to percobaan122_noImgPro/model\\vgg_16_122-saved-model-14-acc-0.66.hdf5\n",
            "16/16 [==============================] - 152s 10s/step - loss: 0.7990 - acc: 0.7673 - val_loss: 1.1381 - val_acc: 0.6571\n",
            "Epoch 15/55\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6449 - acc: 0.7878\n",
            "Epoch 15: val_acc improved from 0.65714 to 0.80000, saving model to percobaan122_noImgPro/model\\vgg_16_122-saved-model-15-acc-0.80.hdf5\n",
            "16/16 [==============================] - 153s 10s/step - loss: 0.6449 - acc: 0.7878 - val_loss: 0.8303 - val_acc: 0.8000\n",
            "Epoch 16/55\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7126 - acc: 0.7633\n",
            "Epoch 16: val_acc did not improve from 0.80000\n",
            "16/16 [==============================] - 152s 10s/step - loss: 0.7126 - acc: 0.7633 - val_loss: 2.3356 - val_acc: 0.6071\n",
            "Epoch 17/55\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8223 - acc: 0.7714\n",
            "Epoch 17: val_acc did not improve from 0.80000\n",
            "16/16 [==============================] - 151s 10s/step - loss: 0.8223 - acc: 0.7714 - val_loss: 1.6183 - val_acc: 0.7071\n",
            "Epoch 18/55\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9147 - acc: 0.7429\n",
            "Epoch 18: val_acc did not improve from 0.80000\n",
            "16/16 [==============================] - 151s 10s/step - loss: 0.9147 - acc: 0.7429 - val_loss: 1.6764 - val_acc: 0.6857\n",
            "Epoch 19/55\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8494 - acc: 0.7612\n",
            "Epoch 19: val_acc did not improve from 0.80000\n",
            "16/16 [==============================] - 152s 10s/step - loss: 0.8494 - acc: 0.7612 - val_loss: 2.1765 - val_acc: 0.6357\n",
            "Epoch 20/55\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8502 - acc: 0.7510\n",
            "Epoch 20: val_acc did not improve from 0.80000\n",
            "16/16 [==============================] - 151s 10s/step - loss: 0.8502 - acc: 0.7510 - val_loss: 1.5512 - val_acc: 0.7643\n",
            "\n",
            "\n",
            "Model Accuracy 0.6428571428571429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.73      0.80      0.76        10\n",
            "       10000       1.00      0.40      0.57        10\n",
            "      100000       0.62      1.00      0.77        10\n",
            "        2000       0.88      0.70      0.78        10\n",
            "       20000       0.00      0.00      0.00        10\n",
            "        5000       0.45      0.90      0.60        10\n",
            "       50000       0.64      0.70      0.67        10\n",
            "\n",
            "    accuracy                           0.64        70\n",
            "   macro avg       0.62      0.64      0.59        70\n",
            "weighted avg       0.62      0.64      0.59        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 123 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 48\n",
            "learning rate: 0.055269683932900285\n",
            "batch size: 32\n",
            "dropout rate: 0.654674047830431\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 3.4382 - acc: 0.2776 \n",
            "Epoch 1: val_acc improved from -inf to 0.16429, saving model to percobaan123_noImgPro/model\\vgg_16_123-saved-model-01-acc-0.16.hdf5\n",
            "16/16 [==============================] - 225s 14s/step - loss: 3.4382 - acc: 0.2776 - val_loss: 12.1661 - val_acc: 0.1643\n",
            "Epoch 2/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.1831 - acc: 0.3939 \n",
            "Epoch 2: val_acc improved from 0.16429 to 0.33571, saving model to percobaan123_noImgPro/model\\vgg_16_123-saved-model-02-acc-0.34.hdf5\n",
            "16/16 [==============================] - 226s 14s/step - loss: 2.1831 - acc: 0.3939 - val_loss: 3.5748 - val_acc: 0.3357\n",
            "Epoch 3/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.6132 - acc: 0.4673 \n",
            "Epoch 3: val_acc did not improve from 0.33571\n",
            "16/16 [==============================] - 222s 14s/step - loss: 1.6132 - acc: 0.4673 - val_loss: 2.1861 - val_acc: 0.3214\n",
            "Epoch 4/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.4003 - acc: 0.4980 \n",
            "Epoch 4: val_acc improved from 0.33571 to 0.52857, saving model to percobaan123_noImgPro/model\\vgg_16_123-saved-model-04-acc-0.53.hdf5\n",
            "16/16 [==============================] - 223s 14s/step - loss: 1.4003 - acc: 0.4980 - val_loss: 1.3601 - val_acc: 0.5286\n",
            "Epoch 5/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1791 - acc: 0.5755 \n",
            "Epoch 5: val_acc did not improve from 0.52857\n",
            "16/16 [==============================] - 224s 14s/step - loss: 1.1791 - acc: 0.5755 - val_loss: 1.7999 - val_acc: 0.4071\n",
            "Epoch 6/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1225 - acc: 0.6122 \n",
            "Epoch 6: val_acc did not improve from 0.52857\n",
            "16/16 [==============================] - 222s 14s/step - loss: 1.1225 - acc: 0.6122 - val_loss: 1.2768 - val_acc: 0.5286\n",
            "Epoch 7/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0325 - acc: 0.6265 \n",
            "Epoch 7: val_acc improved from 0.52857 to 0.61429, saving model to percobaan123_noImgPro/model\\vgg_16_123-saved-model-07-acc-0.61.hdf5\n",
            "16/16 [==============================] - 225s 14s/step - loss: 1.0325 - acc: 0.6265 - val_loss: 0.9693 - val_acc: 0.6143\n",
            "Epoch 8/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9376 - acc: 0.6837 \n",
            "Epoch 8: val_acc did not improve from 0.61429\n",
            "16/16 [==============================] - 223s 14s/step - loss: 0.9376 - acc: 0.6837 - val_loss: 1.5009 - val_acc: 0.5286\n",
            "Epoch 9/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9630 - acc: 0.6633 \n",
            "Epoch 9: val_acc improved from 0.61429 to 0.75714, saving model to percobaan123_noImgPro/model\\vgg_16_123-saved-model-09-acc-0.76.hdf5\n",
            "16/16 [==============================] - 224s 14s/step - loss: 0.9630 - acc: 0.6633 - val_loss: 0.7868 - val_acc: 0.7571\n",
            "Epoch 10/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8520 - acc: 0.7082 \n",
            "Epoch 10: val_acc did not improve from 0.75714\n",
            "16/16 [==============================] - 224s 14s/step - loss: 0.8520 - acc: 0.7082 - val_loss: 0.9557 - val_acc: 0.6643\n",
            "Epoch 11/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8121 - acc: 0.7224 \n",
            "Epoch 11: val_acc did not improve from 0.75714\n",
            "16/16 [==============================] - 223s 14s/step - loss: 0.8121 - acc: 0.7224 - val_loss: 0.9756 - val_acc: 0.6714\n",
            "Epoch 12/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7011 - acc: 0.7735 \n",
            "Epoch 12: val_acc did not improve from 0.75714\n",
            "16/16 [==============================] - 221s 14s/step - loss: 0.7011 - acc: 0.7735 - val_loss: 1.0029 - val_acc: 0.7286\n",
            "Epoch 13/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7822 - acc: 0.7408 \n",
            "Epoch 13: val_acc did not improve from 0.75714\n",
            "16/16 [==============================] - 226s 14s/step - loss: 0.7822 - acc: 0.7408 - val_loss: 1.1535 - val_acc: 0.6429\n",
            "Epoch 14/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9043 - acc: 0.7245 \n",
            "Epoch 14: val_acc did not improve from 0.75714\n",
            "16/16 [==============================] - 222s 14s/step - loss: 0.9043 - acc: 0.7245 - val_loss: 1.8066 - val_acc: 0.5357\n",
            "\n",
            "\n",
            "Model Accuracy 0.5571428571428572\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.60      0.75        10\n",
            "       10000       0.67      0.80      0.73        10\n",
            "      100000       1.00      0.10      0.18        10\n",
            "        2000       1.00      0.10      0.18        10\n",
            "       20000       0.67      0.40      0.50        10\n",
            "        5000       0.36      1.00      0.53        10\n",
            "       50000       0.56      0.90      0.69        10\n",
            "\n",
            "    accuracy                           0.56        70\n",
            "   macro avg       0.75      0.56      0.51        70\n",
            "weighted avg       0.75      0.56      0.51        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 124 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 56\n",
            "learning rate: 0.055710918136428575\n",
            "batch size: 32\n",
            "dropout rate: 0.7969497869851896\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 4.3947 - acc: 0.1918 \n",
            "Epoch 1: val_acc improved from -inf to 0.17143, saving model to percobaan124_noImgPro/model\\vgg_16_124-saved-model-01-acc-0.17.hdf5\n",
            "16/16 [==============================] - 214s 13s/step - loss: 4.3947 - acc: 0.1918 - val_loss: 11.5709 - val_acc: 0.1714\n",
            "Epoch 2/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 3.0553 - acc: 0.3367 \n",
            "Epoch 2: val_acc did not improve from 0.17143\n",
            "16/16 [==============================] - 215s 14s/step - loss: 3.0553 - acc: 0.3367 - val_loss: 4.7644 - val_acc: 0.1429\n",
            "Epoch 3/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.3066 - acc: 0.2980 \n",
            "Epoch 3: val_acc improved from 0.17143 to 0.32857, saving model to percobaan124_noImgPro/model\\vgg_16_124-saved-model-03-acc-0.33.hdf5\n",
            "16/16 [==============================] - 212s 14s/step - loss: 2.3066 - acc: 0.2980 - val_loss: 2.0702 - val_acc: 0.3286\n",
            "Epoch 4/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.8879 - acc: 0.3061 \n",
            "Epoch 4: val_acc improved from 0.32857 to 0.42143, saving model to percobaan124_noImgPro/model\\vgg_16_124-saved-model-04-acc-0.42.hdf5\n",
            "16/16 [==============================] - 216s 14s/step - loss: 1.8879 - acc: 0.3061 - val_loss: 1.6066 - val_acc: 0.4214\n",
            "Epoch 5/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.7036 - acc: 0.3653 \n",
            "Epoch 5: val_acc improved from 0.42143 to 0.44286, saving model to percobaan124_noImgPro/model\\vgg_16_124-saved-model-05-acc-0.44.hdf5\n",
            "16/16 [==============================] - 216s 14s/step - loss: 1.7036 - acc: 0.3653 - val_loss: 1.5733 - val_acc: 0.4429\n",
            "Epoch 6/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.6042 - acc: 0.4000 \n",
            "Epoch 6: val_acc did not improve from 0.44286\n",
            "16/16 [==============================] - 216s 14s/step - loss: 1.6042 - acc: 0.4000 - val_loss: 1.7021 - val_acc: 0.2286\n",
            "Epoch 7/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.5179 - acc: 0.4510 \n",
            "Epoch 7: val_acc did not improve from 0.44286\n",
            "16/16 [==============================] - 216s 14s/step - loss: 1.5179 - acc: 0.4510 - val_loss: 1.3907 - val_acc: 0.4000\n",
            "Epoch 8/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3917 - acc: 0.4714 \n",
            "Epoch 8: val_acc improved from 0.44286 to 0.49286, saving model to percobaan124_noImgPro/model\\vgg_16_124-saved-model-08-acc-0.49.hdf5\n",
            "16/16 [==============================] - 215s 14s/step - loss: 1.3917 - acc: 0.4714 - val_loss: 1.4064 - val_acc: 0.4929\n",
            "Epoch 9/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3464 - acc: 0.5388 \n",
            "Epoch 9: val_acc improved from 0.49286 to 0.52857, saving model to percobaan124_noImgPro/model\\vgg_16_124-saved-model-09-acc-0.53.hdf5\n",
            "16/16 [==============================] - 216s 14s/step - loss: 1.3464 - acc: 0.5388 - val_loss: 1.1591 - val_acc: 0.5286\n",
            "Epoch 10/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3420 - acc: 0.5429 \n",
            "Epoch 10: val_acc did not improve from 0.52857\n",
            "16/16 [==============================] - 216s 14s/step - loss: 1.3420 - acc: 0.5429 - val_loss: 1.2361 - val_acc: 0.4929\n",
            "Epoch 11/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3425 - acc: 0.5510 \n",
            "Epoch 11: val_acc improved from 0.52857 to 0.67857, saving model to percobaan124_noImgPro/model\\vgg_16_124-saved-model-11-acc-0.68.hdf5\n",
            "16/16 [==============================] - 217s 14s/step - loss: 1.3425 - acc: 0.5510 - val_loss: 0.9842 - val_acc: 0.6786\n",
            "Epoch 12/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2636 - acc: 0.5469 \n",
            "Epoch 12: val_acc did not improve from 0.67857\n",
            "16/16 [==============================] - 217s 14s/step - loss: 1.2636 - acc: 0.5469 - val_loss: 1.2121 - val_acc: 0.6143\n",
            "Epoch 13/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2847 - acc: 0.5490 \n",
            "Epoch 13: val_acc did not improve from 0.67857\n",
            "16/16 [==============================] - 217s 14s/step - loss: 1.2847 - acc: 0.5490 - val_loss: 0.9976 - val_acc: 0.6071\n",
            "Epoch 14/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2963 - acc: 0.5653 \n",
            "Epoch 14: val_acc did not improve from 0.67857\n",
            "16/16 [==============================] - 214s 14s/step - loss: 1.2963 - acc: 0.5653 - val_loss: 1.0942 - val_acc: 0.6786\n",
            "Epoch 15/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3087 - acc: 0.5694 \n",
            "Epoch 15: val_acc improved from 0.67857 to 0.74286, saving model to percobaan124_noImgPro/model\\vgg_16_124-saved-model-15-acc-0.74.hdf5\n",
            "16/16 [==============================] - 217s 14s/step - loss: 1.3087 - acc: 0.5694 - val_loss: 0.9144 - val_acc: 0.7429\n",
            "Epoch 16/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.4310 - acc: 0.5694 \n",
            "Epoch 16: val_acc did not improve from 0.74286\n",
            "16/16 [==============================] - 216s 14s/step - loss: 1.4310 - acc: 0.5694 - val_loss: 0.9567 - val_acc: 0.6857\n",
            "Epoch 17/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2052 - acc: 0.5980 \n",
            "Epoch 17: val_acc did not improve from 0.74286\n",
            "16/16 [==============================] - 216s 14s/step - loss: 1.2052 - acc: 0.5980 - val_loss: 0.9803 - val_acc: 0.6786\n",
            "Epoch 18/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1954 - acc: 0.6163 \n",
            "Epoch 18: val_acc did not improve from 0.74286\n",
            "16/16 [==============================] - 215s 14s/step - loss: 1.1954 - acc: 0.6163 - val_loss: 1.2203 - val_acc: 0.6000\n",
            "Epoch 19/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2079 - acc: 0.6061 \n",
            "Epoch 19: val_acc improved from 0.74286 to 0.81429, saving model to percobaan124_noImgPro/model\\vgg_16_124-saved-model-19-acc-0.81.hdf5\n",
            "16/16 [==============================] - 218s 14s/step - loss: 1.2079 - acc: 0.6061 - val_loss: 0.6435 - val_acc: 0.8143\n",
            "Epoch 20/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1206 - acc: 0.6633 \n",
            "Epoch 20: val_acc did not improve from 0.81429\n",
            "16/16 [==============================] - 216s 14s/step - loss: 1.1206 - acc: 0.6633 - val_loss: 0.7215 - val_acc: 0.8000\n",
            "Epoch 21/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1160 - acc: 0.6388 \n",
            "Epoch 21: val_acc did not improve from 0.81429\n",
            "16/16 [==============================] - 216s 14s/step - loss: 1.1160 - acc: 0.6388 - val_loss: 1.0904 - val_acc: 0.6643\n",
            "Epoch 22/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1791 - acc: 0.6184 \n",
            "Epoch 22: val_acc did not improve from 0.81429\n",
            "16/16 [==============================] - 217s 14s/step - loss: 1.1791 - acc: 0.6184 - val_loss: 0.6922 - val_acc: 0.8000\n",
            "Epoch 23/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1446 - acc: 0.6490 \n",
            "Epoch 23: val_acc did not improve from 0.81429\n",
            "16/16 [==============================] - 214s 14s/step - loss: 1.1446 - acc: 0.6490 - val_loss: 1.0535 - val_acc: 0.7071\n",
            "Epoch 24/56\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2906 - acc: 0.6388 \n",
            "Epoch 24: val_acc did not improve from 0.81429\n",
            "16/16 [==============================] - 221s 14s/step - loss: 1.2906 - acc: 0.6388 - val_loss: 0.9461 - val_acc: 0.7571\n",
            "\n",
            "\n",
            "Model Accuracy 0.7\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.67      0.80      0.73        10\n",
            "       10000       1.00      0.80      0.89        10\n",
            "      100000       1.00      0.90      0.95        10\n",
            "        2000       0.42      1.00      0.59        10\n",
            "       20000       1.00      0.30      0.46        10\n",
            "        5000       1.00      0.40      0.57        10\n",
            "       50000       0.70      0.70      0.70        10\n",
            "\n",
            "    accuracy                           0.70        70\n",
            "   macro avg       0.83      0.70      0.70        70\n",
            "weighted avg       0.83      0.70      0.70        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 125 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 53\n",
            "learning rate: 0.07260925862115301\n",
            "batch size: 64\n",
            "dropout rate: 0.5564430016614522\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/53\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.9162 - acc: 0.2673 \n",
            "Epoch 1: val_acc improved from -inf to 0.14286, saving model to percobaan125_noImgPro/model\\vgg_16_125-saved-model-01-acc-0.14.hdf5\n",
            "8/8 [==============================] - 214s 27s/step - loss: 2.9162 - acc: 0.2673 - val_loss: 25.5496 - val_acc: 0.1429\n",
            "Epoch 2/53\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8607 - acc: 0.4633 \n",
            "Epoch 2: val_acc did not improve from 0.14286\n",
            "8/8 [==============================] - 212s 27s/step - loss: 1.8607 - acc: 0.4633 - val_loss: 7.4326 - val_acc: 0.1429\n",
            "Epoch 3/53\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5515 - acc: 0.5367 \n",
            "Epoch 3: val_acc improved from 0.14286 to 0.30714, saving model to percobaan125_noImgPro/model\\vgg_16_125-saved-model-03-acc-0.31.hdf5\n",
            "8/8 [==============================] - 212s 27s/step - loss: 1.5515 - acc: 0.5367 - val_loss: 3.4369 - val_acc: 0.3071\n",
            "Epoch 4/53\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1482 - acc: 0.5898 \n",
            "Epoch 4: val_acc improved from 0.30714 to 0.42857, saving model to percobaan125_noImgPro/model\\vgg_16_125-saved-model-04-acc-0.43.hdf5\n",
            "8/8 [==============================] - 212s 28s/step - loss: 1.1482 - acc: 0.5898 - val_loss: 1.7277 - val_acc: 0.4286\n",
            "Epoch 5/53\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0672 - acc: 0.6449 \n",
            "Epoch 5: val_acc improved from 0.42857 to 0.43571, saving model to percobaan125_noImgPro/model\\vgg_16_125-saved-model-05-acc-0.44.hdf5\n",
            "8/8 [==============================] - 214s 27s/step - loss: 1.0672 - acc: 0.6449 - val_loss: 1.9062 - val_acc: 0.4357\n",
            "Epoch 6/53\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7764 - acc: 0.7122 \n",
            "Epoch 6: val_acc improved from 0.43571 to 0.64286, saving model to percobaan125_noImgPro/model\\vgg_16_125-saved-model-06-acc-0.64.hdf5\n",
            "8/8 [==============================] - 213s 27s/step - loss: 0.7764 - acc: 0.7122 - val_loss: 1.1219 - val_acc: 0.6429\n",
            "Epoch 7/53\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7225 - acc: 0.7694 \n",
            "Epoch 7: val_acc did not improve from 0.64286\n",
            "8/8 [==============================] - 213s 27s/step - loss: 0.7225 - acc: 0.7694 - val_loss: 1.6637 - val_acc: 0.5214\n",
            "Epoch 8/53\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6119 - acc: 0.7816 \n",
            "Epoch 8: val_acc did not improve from 0.64286\n",
            "8/8 [==============================] - 213s 27s/step - loss: 0.6119 - acc: 0.7816 - val_loss: 1.6921 - val_acc: 0.4357\n",
            "Epoch 9/53\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4953 - acc: 0.8347 \n",
            "Epoch 9: val_acc did not improve from 0.64286\n",
            "8/8 [==============================] - 212s 27s/step - loss: 0.4953 - acc: 0.8347 - val_loss: 2.7997 - val_acc: 0.3214\n",
            "Epoch 10/53\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5236 - acc: 0.8286 \n",
            "Epoch 10: val_acc did not improve from 0.64286\n",
            "8/8 [==============================] - 212s 27s/step - loss: 0.5236 - acc: 0.8286 - val_loss: 3.0504 - val_acc: 0.3214\n",
            "Epoch 11/53\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5087 - acc: 0.8367 \n",
            "Epoch 11: val_acc did not improve from 0.64286\n",
            "8/8 [==============================] - 213s 27s/step - loss: 0.5087 - acc: 0.8367 - val_loss: 1.4366 - val_acc: 0.5071\n",
            "\n",
            "\n",
            "Model Accuracy 0.42857142857142855\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.50      0.67        10\n",
            "       10000       0.50      0.60      0.55        10\n",
            "      100000       1.00      0.40      0.57        10\n",
            "        2000       0.00      0.00      0.00        10\n",
            "       20000       0.00      0.00      0.00        10\n",
            "        5000       0.71      0.50      0.59        10\n",
            "       50000       0.24      1.00      0.38        10\n",
            "\n",
            "    accuracy                           0.43        70\n",
            "   macro avg       0.49      0.43      0.39        70\n",
            "weighted avg       0.49      0.43      0.39        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 126 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 49\n",
            "learning rate: 0.055186017152102924\n",
            "batch size: 64\n",
            "dropout rate: 0.608827586708589\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.9057 - acc: 0.2531 \n",
            "Epoch 1: val_acc improved from -inf to 0.17143, saving model to percobaan126_noImgPro/model\\vgg_16_126-saved-model-01-acc-0.17.hdf5\n",
            "8/8 [==============================] - 206s 26s/step - loss: 2.9057 - acc: 0.2531 - val_loss: 10.4247 - val_acc: 0.1714\n",
            "Epoch 2/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.9976 - acc: 0.4449 \n",
            "Epoch 2: val_acc did not improve from 0.17143\n",
            "8/8 [==============================] - 206s 26s/step - loss: 1.9976 - acc: 0.4449 - val_loss: 9.0559 - val_acc: 0.1714\n",
            "Epoch 3/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3639 - acc: 0.5714 \n",
            "Epoch 3: val_acc improved from 0.17143 to 0.27857, saving model to percobaan126_noImgPro/model\\vgg_16_126-saved-model-03-acc-0.28.hdf5\n",
            "8/8 [==============================] - 206s 26s/step - loss: 1.3639 - acc: 0.5714 - val_loss: 3.8106 - val_acc: 0.2786\n",
            "Epoch 4/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1092 - acc: 0.6551 \n",
            "Epoch 4: val_acc did not improve from 0.27857\n",
            "8/8 [==============================] - 206s 26s/step - loss: 1.1092 - acc: 0.6551 - val_loss: 3.0937 - val_acc: 0.2571\n",
            "Epoch 5/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0461 - acc: 0.6469 \n",
            "Epoch 5: val_acc improved from 0.27857 to 0.32857, saving model to percobaan126_noImgPro/model\\vgg_16_126-saved-model-05-acc-0.33.hdf5\n",
            "8/8 [==============================] - 206s 27s/step - loss: 1.0461 - acc: 0.6469 - val_loss: 2.1805 - val_acc: 0.3286\n",
            "Epoch 6/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8789 - acc: 0.7020 \n",
            "Epoch 6: val_acc improved from 0.32857 to 0.48571, saving model to percobaan126_noImgPro/model\\vgg_16_126-saved-model-06-acc-0.49.hdf5\n",
            "8/8 [==============================] - 205s 26s/step - loss: 0.8789 - acc: 0.7020 - val_loss: 2.1801 - val_acc: 0.4857\n",
            "Epoch 7/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7162 - acc: 0.7449 \n",
            "Epoch 7: val_acc improved from 0.48571 to 0.51429, saving model to percobaan126_noImgPro/model\\vgg_16_126-saved-model-07-acc-0.51.hdf5\n",
            "8/8 [==============================] - 206s 26s/step - loss: 0.7162 - acc: 0.7449 - val_loss: 1.9655 - val_acc: 0.5143\n",
            "Epoch 8/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6383 - acc: 0.7939 \n",
            "Epoch 8: val_acc did not improve from 0.51429\n",
            "8/8 [==============================] - 204s 26s/step - loss: 0.6383 - acc: 0.7939 - val_loss: 1.9017 - val_acc: 0.5071\n",
            "Epoch 9/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6495 - acc: 0.7857 \n",
            "Epoch 9: val_acc improved from 0.51429 to 0.52143, saving model to percobaan126_noImgPro/model\\vgg_16_126-saved-model-09-acc-0.52.hdf5\n",
            "8/8 [==============================] - 204s 27s/step - loss: 0.6495 - acc: 0.7857 - val_loss: 1.6516 - val_acc: 0.5214\n",
            "Epoch 10/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5282 - acc: 0.8184 \n",
            "Epoch 10: val_acc did not improve from 0.52143\n",
            "8/8 [==============================] - 204s 27s/step - loss: 0.5282 - acc: 0.8184 - val_loss: 1.5631 - val_acc: 0.5214\n",
            "Epoch 11/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4777 - acc: 0.8020 \n",
            "Epoch 11: val_acc improved from 0.52143 to 0.59286, saving model to percobaan126_noImgPro/model\\vgg_16_126-saved-model-11-acc-0.59.hdf5\n",
            "8/8 [==============================] - 203s 26s/step - loss: 0.4777 - acc: 0.8020 - val_loss: 1.0471 - val_acc: 0.5929\n",
            "Epoch 12/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4736 - acc: 0.8163 \n",
            "Epoch 12: val_acc improved from 0.59286 to 0.64286, saving model to percobaan126_noImgPro/model\\vgg_16_126-saved-model-12-acc-0.64.hdf5\n",
            "8/8 [==============================] - 203s 26s/step - loss: 0.4736 - acc: 0.8163 - val_loss: 0.9817 - val_acc: 0.6429\n",
            "Epoch 13/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4435 - acc: 0.8510 \n",
            "Epoch 13: val_acc improved from 0.64286 to 0.66429, saving model to percobaan126_noImgPro/model\\vgg_16_126-saved-model-13-acc-0.66.hdf5\n",
            "8/8 [==============================] - 203s 26s/step - loss: 0.4435 - acc: 0.8510 - val_loss: 1.1017 - val_acc: 0.6643\n",
            "Epoch 14/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4915 - acc: 0.8163 \n",
            "Epoch 14: val_acc did not improve from 0.66429\n",
            "8/8 [==============================] - 203s 26s/step - loss: 0.4915 - acc: 0.8163 - val_loss: 1.1855 - val_acc: 0.6357\n",
            "Epoch 15/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4303 - acc: 0.8510 \n",
            "Epoch 15: val_acc did not improve from 0.66429\n",
            "8/8 [==============================] - 203s 27s/step - loss: 0.4303 - acc: 0.8510 - val_loss: 1.2875 - val_acc: 0.6214\n",
            "Epoch 16/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4857 - acc: 0.8265 \n",
            "Epoch 16: val_acc did not improve from 0.66429\n",
            "8/8 [==============================] - 203s 26s/step - loss: 0.4857 - acc: 0.8265 - val_loss: 1.6710 - val_acc: 0.5786\n",
            "Epoch 17/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5331 - acc: 0.8429 \n",
            "Epoch 17: val_acc did not improve from 0.66429\n",
            "8/8 [==============================] - 203s 26s/step - loss: 0.5331 - acc: 0.8429 - val_loss: 0.9309 - val_acc: 0.6571\n",
            "Epoch 18/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4266 - acc: 0.8755 \n",
            "Epoch 18: val_acc improved from 0.66429 to 0.70714, saving model to percobaan126_noImgPro/model\\vgg_16_126-saved-model-18-acc-0.71.hdf5\n",
            "8/8 [==============================] - 203s 26s/step - loss: 0.4266 - acc: 0.8755 - val_loss: 0.8207 - val_acc: 0.7071\n",
            "Epoch 19/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4618 - acc: 0.8388 \n",
            "Epoch 19: val_acc did not improve from 0.70714\n",
            "8/8 [==============================] - 202s 26s/step - loss: 0.4618 - acc: 0.8388 - val_loss: 0.9593 - val_acc: 0.6714\n",
            "Epoch 20/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4032 - acc: 0.8633 \n",
            "Epoch 20: val_acc did not improve from 0.70714\n",
            "8/8 [==============================] - 203s 27s/step - loss: 0.4032 - acc: 0.8633 - val_loss: 0.9109 - val_acc: 0.6714\n",
            "Epoch 21/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4310 - acc: 0.8653 \n",
            "Epoch 21: val_acc improved from 0.70714 to 0.72143, saving model to percobaan126_noImgPro/model\\vgg_16_126-saved-model-21-acc-0.72.hdf5\n",
            "8/8 [==============================] - 203s 26s/step - loss: 0.4310 - acc: 0.8653 - val_loss: 1.0095 - val_acc: 0.7214\n",
            "Epoch 22/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4030 - acc: 0.8551 \n",
            "Epoch 22: val_acc did not improve from 0.72143\n",
            "8/8 [==============================] - 203s 26s/step - loss: 0.4030 - acc: 0.8551 - val_loss: 1.0248 - val_acc: 0.6786\n",
            "Epoch 23/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4782 - acc: 0.8408 \n",
            "Epoch 23: val_acc improved from 0.72143 to 0.78571, saving model to percobaan126_noImgPro/model\\vgg_16_126-saved-model-23-acc-0.79.hdf5\n",
            "8/8 [==============================] - 203s 26s/step - loss: 0.4782 - acc: 0.8408 - val_loss: 0.6426 - val_acc: 0.7857\n",
            "Epoch 24/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3768 - acc: 0.8796 \n",
            "Epoch 24: val_acc did not improve from 0.78571\n",
            "8/8 [==============================] - 203s 26s/step - loss: 0.3768 - acc: 0.8796 - val_loss: 1.0164 - val_acc: 0.7071\n",
            "Epoch 25/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4877 - acc: 0.8510 \n",
            "Epoch 25: val_acc improved from 0.78571 to 0.79286, saving model to percobaan126_noImgPro/model\\vgg_16_126-saved-model-25-acc-0.79.hdf5\n",
            "8/8 [==============================] - 203s 27s/step - loss: 0.4877 - acc: 0.8510 - val_loss: 0.7654 - val_acc: 0.7929\n",
            "Epoch 26/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2704 - acc: 0.9143 \n",
            "Epoch 26: val_acc did not improve from 0.79286\n",
            "8/8 [==============================] - 258s 34s/step - loss: 0.2704 - acc: 0.9143 - val_loss: 0.9687 - val_acc: 0.7500\n",
            "Epoch 27/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3313 - acc: 0.8857 \n",
            "Epoch 27: val_acc did not improve from 0.79286\n",
            "8/8 [==============================] - 281s 36s/step - loss: 0.3313 - acc: 0.8857 - val_loss: 1.6542 - val_acc: 0.6429\n",
            "Epoch 28/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4353 - acc: 0.8837 \n",
            "Epoch 28: val_acc did not improve from 0.79286\n",
            "8/8 [==============================] - 288s 38s/step - loss: 0.4353 - acc: 0.8837 - val_loss: 1.7788 - val_acc: 0.6643\n",
            "\n",
            "\n",
            "Model Accuracy 0.5428571428571428\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.30      0.46        10\n",
            "       10000       0.36      1.00      0.53        10\n",
            "      100000       1.00      0.30      0.46        10\n",
            "        2000       0.80      0.40      0.53        10\n",
            "       20000       0.47      0.70      0.56        10\n",
            "        5000       1.00      0.30      0.46        10\n",
            "       50000       0.62      0.80      0.70        10\n",
            "\n",
            "    accuracy                           0.54        70\n",
            "   macro avg       0.75      0.54      0.53        70\n",
            "weighted avg       0.75      0.54      0.53        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 127 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 55\n",
            "learning rate: 0.06271398281942535\n",
            "batch size: 64\n",
            "dropout rate: 0.6519455118549092\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.9119 - acc: 0.2490 \n",
            "Epoch 1: val_acc improved from -inf to 0.26429, saving model to percobaan127_noImgPro/model\\vgg_16_127-saved-model-01-acc-0.26.hdf5\n",
            "8/8 [==============================] - 266s 34s/step - loss: 2.9119 - acc: 0.2490 - val_loss: 5.6552 - val_acc: 0.2643\n",
            "Epoch 2/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.4860 - acc: 0.3469 \n",
            "Epoch 2: val_acc did not improve from 0.26429\n",
            "8/8 [==============================] - 266s 34s/step - loss: 2.4860 - acc: 0.3469 - val_loss: 7.0200 - val_acc: 0.2214\n",
            "Epoch 3/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6714 - acc: 0.4735 \n",
            "Epoch 3: val_acc improved from 0.26429 to 0.28571, saving model to percobaan127_noImgPro/model\\vgg_16_127-saved-model-03-acc-0.29.hdf5\n",
            "8/8 [==============================] - 266s 34s/step - loss: 1.6714 - acc: 0.4735 - val_loss: 4.1621 - val_acc: 0.2857\n",
            "Epoch 4/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3640 - acc: 0.5163 \n",
            "Epoch 4: val_acc improved from 0.28571 to 0.31429, saving model to percobaan127_noImgPro/model\\vgg_16_127-saved-model-04-acc-0.31.hdf5\n",
            "8/8 [==============================] - 271s 35s/step - loss: 1.3640 - acc: 0.5163 - val_loss: 3.5679 - val_acc: 0.3143\n",
            "Epoch 5/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1007 - acc: 0.5980 \n",
            "Epoch 5: val_acc did not improve from 0.31429\n",
            "8/8 [==============================] - 267s 34s/step - loss: 1.1007 - acc: 0.5980 - val_loss: 2.3961 - val_acc: 0.2571\n",
            "Epoch 6/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9698 - acc: 0.6388 \n",
            "Epoch 6: val_acc improved from 0.31429 to 0.48571, saving model to percobaan127_noImgPro/model\\vgg_16_127-saved-model-06-acc-0.49.hdf5\n",
            "8/8 [==============================] - 267s 35s/step - loss: 0.9698 - acc: 0.6388 - val_loss: 1.7773 - val_acc: 0.4857\n",
            "Epoch 7/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8714 - acc: 0.6918 \n",
            "Epoch 7: val_acc did not improve from 0.48571\n",
            "8/8 [==============================] - 265s 34s/step - loss: 0.8714 - acc: 0.6918 - val_loss: 2.4258 - val_acc: 0.3571\n",
            "Epoch 8/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8016 - acc: 0.7204 \n",
            "Epoch 8: val_acc did not improve from 0.48571\n",
            "8/8 [==============================] - 268s 36s/step - loss: 0.8016 - acc: 0.7204 - val_loss: 1.9898 - val_acc: 0.4571\n",
            "Epoch 9/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7188 - acc: 0.7469 \n",
            "Epoch 9: val_acc improved from 0.48571 to 0.56429, saving model to percobaan127_noImgPro/model\\vgg_16_127-saved-model-09-acc-0.56.hdf5\n",
            "8/8 [==============================] - 272s 35s/step - loss: 0.7188 - acc: 0.7469 - val_loss: 1.5225 - val_acc: 0.5643\n",
            "Epoch 10/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6879 - acc: 0.7571 \n",
            "Epoch 10: val_acc improved from 0.56429 to 0.58571, saving model to percobaan127_noImgPro/model\\vgg_16_127-saved-model-10-acc-0.59.hdf5\n",
            "8/8 [==============================] - 264s 34s/step - loss: 0.6879 - acc: 0.7571 - val_loss: 1.2705 - val_acc: 0.5857\n",
            "Epoch 11/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7043 - acc: 0.7449 \n",
            "Epoch 11: val_acc did not improve from 0.58571\n",
            "8/8 [==============================] - 264s 34s/step - loss: 0.7043 - acc: 0.7449 - val_loss: 1.7325 - val_acc: 0.4571\n",
            "Epoch 12/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5503 - acc: 0.8061 \n",
            "Epoch 12: val_acc improved from 0.58571 to 0.64286, saving model to percobaan127_noImgPro/model\\vgg_16_127-saved-model-12-acc-0.64.hdf5\n",
            "8/8 [==============================] - 259s 33s/step - loss: 0.5503 - acc: 0.8061 - val_loss: 1.1191 - val_acc: 0.6429\n",
            "Epoch 13/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6520 - acc: 0.7918 \n",
            "Epoch 13: val_acc did not improve from 0.64286\n",
            "8/8 [==============================] - 268s 35s/step - loss: 0.6520 - acc: 0.7918 - val_loss: 1.3402 - val_acc: 0.5786\n",
            "Epoch 14/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5773 - acc: 0.7959 \n",
            "Epoch 14: val_acc did not improve from 0.64286\n",
            "8/8 [==============================] - 266s 34s/step - loss: 0.5773 - acc: 0.7959 - val_loss: 1.3580 - val_acc: 0.5714\n",
            "Epoch 15/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5438 - acc: 0.8265 \n",
            "Epoch 15: val_acc did not improve from 0.64286\n",
            "8/8 [==============================] - 269s 35s/step - loss: 0.5438 - acc: 0.8265 - val_loss: 1.7827 - val_acc: 0.5429\n",
            "Epoch 16/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5288 - acc: 0.8204 \n",
            "Epoch 16: val_acc did not improve from 0.64286\n",
            "8/8 [==============================] - 266s 34s/step - loss: 0.5288 - acc: 0.8204 - val_loss: 1.7307 - val_acc: 0.5429\n",
            "Epoch 17/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5108 - acc: 0.8265 \n",
            "Epoch 17: val_acc did not improve from 0.64286\n",
            "8/8 [==============================] - 264s 34s/step - loss: 0.5108 - acc: 0.8265 - val_loss: 1.3525 - val_acc: 0.6143\n",
            "\n",
            "\n",
            "Model Accuracy 0.42857142857142855\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.20      0.33        10\n",
            "       10000       0.89      0.80      0.84        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.43      1.00      0.61        10\n",
            "       20000       0.25      0.10      0.14        10\n",
            "        5000       0.67      0.20      0.31        10\n",
            "       50000       0.24      0.70      0.36        10\n",
            "\n",
            "    accuracy                           0.43        70\n",
            "   macro avg       0.50      0.43      0.37        70\n",
            "weighted avg       0.50      0.43      0.37        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 128 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 48\n",
            "learning rate: 0.05013898013829488\n",
            "batch size: 64\n",
            "dropout rate: 0.772034721313908\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 3.3094 - acc: 0.2163 \n",
            "Epoch 1: val_acc improved from -inf to 0.15000, saving model to percobaan128_noImgPro/model\\vgg_16_128-saved-model-01-acc-0.15.hdf5\n",
            "8/8 [==============================] - 236s 30s/step - loss: 3.3094 - acc: 0.2163 - val_loss: 15.5250 - val_acc: 0.1500\n",
            "Epoch 2/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.7545 - acc: 0.3490 \n",
            "Epoch 2: val_acc improved from 0.15000 to 0.21429, saving model to percobaan128_noImgPro/model\\vgg_16_128-saved-model-02-acc-0.21.hdf5\n",
            "8/8 [==============================] - 239s 31s/step - loss: 2.7545 - acc: 0.3490 - val_loss: 8.9986 - val_acc: 0.2143\n",
            "Epoch 3/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.1720 - acc: 0.3776 \n",
            "Epoch 3: val_acc did not improve from 0.21429\n",
            "8/8 [==============================] - 236s 30s/step - loss: 2.1720 - acc: 0.3776 - val_loss: 5.7352 - val_acc: 0.1429\n",
            "Epoch 4/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7719 - acc: 0.4061 \n",
            "Epoch 4: val_acc did not improve from 0.21429\n",
            "8/8 [==============================] - 222s 28s/step - loss: 1.7719 - acc: 0.4061 - val_loss: 4.3029 - val_acc: 0.1429\n",
            "Epoch 5/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5618 - acc: 0.4122 \n",
            "Epoch 5: val_acc did not improve from 0.21429\n",
            "8/8 [==============================] - 183s 24s/step - loss: 1.5618 - acc: 0.4122 - val_loss: 2.5716 - val_acc: 0.2143\n",
            "Epoch 6/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3050 - acc: 0.5143 \n",
            "Epoch 6: val_acc improved from 0.21429 to 0.26429, saving model to percobaan128_noImgPro/model\\vgg_16_128-saved-model-06-acc-0.26.hdf5\n",
            "8/8 [==============================] - 190s 24s/step - loss: 1.3050 - acc: 0.5143 - val_loss: 2.1832 - val_acc: 0.2643\n",
            "Epoch 7/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.2291 - acc: 0.5367 \n",
            "Epoch 7: val_acc improved from 0.26429 to 0.27143, saving model to percobaan128_noImgPro/model\\vgg_16_128-saved-model-07-acc-0.27.hdf5\n",
            "8/8 [==============================] - 190s 24s/step - loss: 1.2291 - acc: 0.5367 - val_loss: 2.2549 - val_acc: 0.2714\n",
            "Epoch 8/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0924 - acc: 0.5857 \n",
            "Epoch 8: val_acc did not improve from 0.27143\n",
            "8/8 [==============================] - 189s 24s/step - loss: 1.0924 - acc: 0.5857 - val_loss: 2.0408 - val_acc: 0.2429\n",
            "Epoch 9/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0981 - acc: 0.5796 \n",
            "Epoch 9: val_acc improved from 0.27143 to 0.37857, saving model to percobaan128_noImgPro/model\\vgg_16_128-saved-model-09-acc-0.38.hdf5\n",
            "8/8 [==============================] - 189s 24s/step - loss: 1.0981 - acc: 0.5796 - val_loss: 2.3190 - val_acc: 0.3786\n",
            "Epoch 10/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9379 - acc: 0.6490 \n",
            "Epoch 10: val_acc did not improve from 0.37857\n",
            "8/8 [==============================] - 189s 24s/step - loss: 0.9379 - acc: 0.6490 - val_loss: 2.0204 - val_acc: 0.3357\n",
            "Epoch 11/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9722 - acc: 0.6571 \n",
            "Epoch 11: val_acc did not improve from 0.37857\n",
            "8/8 [==============================] - 189s 24s/step - loss: 0.9722 - acc: 0.6571 - val_loss: 1.4765 - val_acc: 0.3643\n",
            "Epoch 12/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8455 - acc: 0.7163 \n",
            "Epoch 12: val_acc improved from 0.37857 to 0.47143, saving model to percobaan128_noImgPro/model\\vgg_16_128-saved-model-12-acc-0.47.hdf5\n",
            "8/8 [==============================] - 190s 25s/step - loss: 0.8455 - acc: 0.7163 - val_loss: 1.1822 - val_acc: 0.4714\n",
            "Epoch 13/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8437 - acc: 0.7020 \n",
            "Epoch 13: val_acc improved from 0.47143 to 0.60714, saving model to percobaan128_noImgPro/model\\vgg_16_128-saved-model-13-acc-0.61.hdf5\n",
            "8/8 [==============================] - 190s 24s/step - loss: 0.8437 - acc: 0.7020 - val_loss: 0.9927 - val_acc: 0.6071\n",
            "Epoch 14/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8517 - acc: 0.6959 \n",
            "Epoch 14: val_acc did not improve from 0.60714\n",
            "8/8 [==============================] - 189s 24s/step - loss: 0.8517 - acc: 0.6959 - val_loss: 1.2676 - val_acc: 0.5500\n",
            "Epoch 15/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7850 - acc: 0.7245 \n",
            "Epoch 15: val_acc did not improve from 0.60714\n",
            "8/8 [==============================] - 189s 24s/step - loss: 0.7850 - acc: 0.7245 - val_loss: 1.5111 - val_acc: 0.5071\n",
            "Epoch 16/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7666 - acc: 0.7327 \n",
            "Epoch 16: val_acc did not improve from 0.60714\n",
            "8/8 [==============================] - 189s 25s/step - loss: 0.7666 - acc: 0.7327 - val_loss: 1.4216 - val_acc: 0.4500\n",
            "Epoch 17/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7071 - acc: 0.7612 \n",
            "Epoch 17: val_acc did not improve from 0.60714\n",
            "8/8 [==============================] - 189s 24s/step - loss: 0.7071 - acc: 0.7612 - val_loss: 1.1402 - val_acc: 0.6071\n",
            "Epoch 18/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7703 - acc: 0.7184 \n",
            "Epoch 18: val_acc did not improve from 0.60714\n",
            "8/8 [==============================] - 189s 24s/step - loss: 0.7703 - acc: 0.7184 - val_loss: 1.4973 - val_acc: 0.5714\n",
            "\n",
            "\n",
            "Model Accuracy 0.4857142857142857\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.10      0.18        10\n",
            "       10000       0.69      0.90      0.78        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.58      0.70      0.64        10\n",
            "       20000       0.29      0.90      0.44        10\n",
            "        5000       0.50      0.10      0.17        10\n",
            "       50000       0.64      0.70      0.67        10\n",
            "\n",
            "    accuracy                           0.49        70\n",
            "   macro avg       0.53      0.49      0.41        70\n",
            "weighted avg       0.53      0.49      0.41        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 129 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 54\n",
            "learning rate: 0.07402448627349667\n",
            "batch size: 128\n",
            "dropout rate: 0.5489698755614442\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.7310 - acc: 0.2898 \n",
            "Epoch 1: val_acc improved from -inf to 0.14286, saving model to percobaan129_noImgPro/model\\vgg_16_129-saved-model-01-acc-0.14.hdf5\n",
            "4/4 [==============================] - 186s 51s/step - loss: 2.7310 - acc: 0.2898 - val_loss: 12.2727 - val_acc: 0.1429\n",
            "Epoch 2/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.7885 - acc: 0.4490 \n",
            "Epoch 2: val_acc improved from 0.14286 to 0.25000, saving model to percobaan129_noImgPro/model\\vgg_16_129-saved-model-02-acc-0.25.hdf5\n",
            "4/4 [==============================] - 185s 49s/step - loss: 1.7885 - acc: 0.4490 - val_loss: 5.8577 - val_acc: 0.2500\n",
            "Epoch 3/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.3052 - acc: 0.5531 \n",
            "Epoch 3: val_acc improved from 0.25000 to 0.44286, saving model to percobaan129_noImgPro/model\\vgg_16_129-saved-model-03-acc-0.44.hdf5\n",
            "4/4 [==============================] - 184s 49s/step - loss: 1.3052 - acc: 0.5531 - val_loss: 2.2198 - val_acc: 0.4429\n",
            "Epoch 4/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1265 - acc: 0.5959 \n",
            "Epoch 4: val_acc improved from 0.44286 to 0.50714, saving model to percobaan129_noImgPro/model\\vgg_16_129-saved-model-04-acc-0.51.hdf5\n",
            "4/4 [==============================] - 184s 49s/step - loss: 1.1265 - acc: 0.5959 - val_loss: 2.2506 - val_acc: 0.5071\n",
            "Epoch 5/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8404 - acc: 0.7020 \n",
            "Epoch 5: val_acc did not improve from 0.50714\n",
            "4/4 [==============================] - 184s 49s/step - loss: 0.8404 - acc: 0.7020 - val_loss: 2.3934 - val_acc: 0.4357\n",
            "Epoch 6/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9040 - acc: 0.6857 \n",
            "Epoch 6: val_acc did not improve from 0.50714\n",
            "4/4 [==============================] - 184s 49s/step - loss: 0.9040 - acc: 0.6857 - val_loss: 3.1087 - val_acc: 0.3429\n",
            "Epoch 7/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7164 - acc: 0.7490 \n",
            "Epoch 7: val_acc did not improve from 0.50714\n",
            "4/4 [==============================] - 185s 49s/step - loss: 0.7164 - acc: 0.7490 - val_loss: 3.6274 - val_acc: 0.3357\n",
            "Epoch 8/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6272 - acc: 0.7878 \n",
            "Epoch 8: val_acc did not improve from 0.50714\n",
            "4/4 [==============================] - 185s 51s/step - loss: 0.6272 - acc: 0.7878 - val_loss: 2.5821 - val_acc: 0.4643\n",
            "\n",
            "\n",
            "Model Accuracy 0.35714285714285715\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.26      1.00      0.41        10\n",
            "       10000       0.24      0.50      0.32        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.00      0.00      0.00        10\n",
            "       20000       1.00      0.60      0.75        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       1.00      0.40      0.57        10\n",
            "\n",
            "    accuracy                           0.36        70\n",
            "   macro avg       0.36      0.36      0.29        70\n",
            "weighted avg       0.36      0.36      0.29        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 130 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 54\n",
            "learning rate: 0.050625503506525074\n",
            "batch size: 128\n",
            "dropout rate: 0.6297935064214283\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.7487 - acc: 0.2735 \n",
            "Epoch 1: val_acc improved from -inf to 0.22857, saving model to percobaan130_noImgPro/model\\vgg_16_130-saved-model-01-acc-0.23.hdf5\n",
            "4/4 [==============================] - 179s 47s/step - loss: 2.7487 - acc: 0.2735 - val_loss: 5.9553 - val_acc: 0.2286\n",
            "Epoch 2/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.6529 - acc: 0.4653 \n",
            "Epoch 2: val_acc did not improve from 0.22857\n",
            "4/4 [==============================] - 178s 47s/step - loss: 1.6529 - acc: 0.4653 - val_loss: 10.8729 - val_acc: 0.1429\n",
            "Epoch 3/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.3921 - acc: 0.5408 \n",
            "Epoch 3: val_acc did not improve from 0.22857\n",
            "4/4 [==============================] - 178s 47s/step - loss: 1.3921 - acc: 0.5408 - val_loss: 7.6262 - val_acc: 0.1857\n",
            "Epoch 4/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1467 - acc: 0.6327 \n",
            "Epoch 4: val_acc improved from 0.22857 to 0.23571, saving model to percobaan130_noImgPro/model\\vgg_16_130-saved-model-04-acc-0.24.hdf5\n",
            "4/4 [==============================] - 177s 49s/step - loss: 1.1467 - acc: 0.6327 - val_loss: 8.1106 - val_acc: 0.2357\n",
            "Epoch 5/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9518 - acc: 0.6714 \n",
            "Epoch 5: val_acc improved from 0.23571 to 0.24286, saving model to percobaan130_noImgPro/model\\vgg_16_130-saved-model-05-acc-0.24.hdf5\n",
            "4/4 [==============================] - 178s 47s/step - loss: 0.9518 - acc: 0.6714 - val_loss: 6.8454 - val_acc: 0.2429\n",
            "Epoch 6/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8716 - acc: 0.7163 \n",
            "Epoch 6: val_acc improved from 0.24286 to 0.25000, saving model to percobaan130_noImgPro/model\\vgg_16_130-saved-model-06-acc-0.25.hdf5\n",
            "4/4 [==============================] - 177s 47s/step - loss: 0.8716 - acc: 0.7163 - val_loss: 5.7438 - val_acc: 0.2500\n",
            "Epoch 7/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6993 - acc: 0.7469 \n",
            "Epoch 7: val_acc did not improve from 0.25000\n",
            "4/4 [==============================] - 178s 47s/step - loss: 0.6993 - acc: 0.7469 - val_loss: 5.4073 - val_acc: 0.2429\n",
            "Epoch 8/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6593 - acc: 0.7735 \n",
            "Epoch 8: val_acc did not improve from 0.25000\n",
            "4/4 [==============================] - 177s 47s/step - loss: 0.6593 - acc: 0.7735 - val_loss: 5.2658 - val_acc: 0.2143\n",
            "Epoch 9/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7267 - acc: 0.7204 \n",
            "Epoch 9: val_acc improved from 0.25000 to 0.26429, saving model to percobaan130_noImgPro/model\\vgg_16_130-saved-model-09-acc-0.26.hdf5\n",
            "4/4 [==============================] - 178s 47s/step - loss: 0.7267 - acc: 0.7204 - val_loss: 3.6368 - val_acc: 0.2643\n",
            "Epoch 10/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6263 - acc: 0.7959 \n",
            "Epoch 10: val_acc improved from 0.26429 to 0.47143, saving model to percobaan130_noImgPro/model\\vgg_16_130-saved-model-10-acc-0.47.hdf5\n",
            "4/4 [==============================] - 178s 49s/step - loss: 0.6263 - acc: 0.7959 - val_loss: 2.1192 - val_acc: 0.4714\n",
            "Epoch 11/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4942 - acc: 0.8286 \n",
            "Epoch 11: val_acc improved from 0.47143 to 0.53571, saving model to percobaan130_noImgPro/model\\vgg_16_130-saved-model-11-acc-0.54.hdf5\n",
            "4/4 [==============================] - 179s 47s/step - loss: 0.4942 - acc: 0.8286 - val_loss: 1.9411 - val_acc: 0.5357\n",
            "Epoch 12/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4559 - acc: 0.8429 \n",
            "Epoch 12: val_acc did not improve from 0.53571\n",
            "4/4 [==============================] - 178s 47s/step - loss: 0.4559 - acc: 0.8429 - val_loss: 2.0470 - val_acc: 0.5143\n",
            "Epoch 13/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4077 - acc: 0.8449 \n",
            "Epoch 13: val_acc did not improve from 0.53571\n",
            "4/4 [==============================] - 178s 49s/step - loss: 0.4077 - acc: 0.8449 - val_loss: 2.2301 - val_acc: 0.5071\n",
            "Epoch 14/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3758 - acc: 0.8653 \n",
            "Epoch 14: val_acc did not improve from 0.53571\n",
            "4/4 [==============================] - 178s 47s/step - loss: 0.3758 - acc: 0.8653 - val_loss: 2.1270 - val_acc: 0.5357\n",
            "Epoch 15/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3775 - acc: 0.8837 \n",
            "Epoch 15: val_acc did not improve from 0.53571\n",
            "4/4 [==============================] - 178s 47s/step - loss: 0.3775 - acc: 0.8837 - val_loss: 2.5984 - val_acc: 0.4571\n",
            "Epoch 16/54\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3917 - acc: 0.8571 \n",
            "Epoch 16: val_acc did not improve from 0.53571\n",
            "4/4 [==============================] - 178s 49s/step - loss: 0.3917 - acc: 0.8571 - val_loss: 2.4033 - val_acc: 0.4500\n",
            "\n",
            "\n",
            "Model Accuracy 0.37142857142857144\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.47      0.90      0.62        10\n",
            "       10000       0.80      0.40      0.53        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       1.00      0.20      0.33        10\n",
            "       20000       1.00      0.10      0.18        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       0.23      1.00      0.38        10\n",
            "\n",
            "    accuracy                           0.37        70\n",
            "   macro avg       0.50      0.37      0.29        70\n",
            "weighted avg       0.50      0.37      0.29        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 131 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 52\n",
            "learning rate: 0.05370374909648124\n",
            "batch size: 128\n",
            "dropout rate: 0.6537029848566485\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.8194 - acc: 0.2551 \n",
            "Epoch 1: val_acc improved from -inf to 0.22143, saving model to percobaan131_noImgPro/model\\vgg_16_131-saved-model-01-acc-0.22.hdf5\n",
            "4/4 [==============================] - 175s 46s/step - loss: 2.8194 - acc: 0.2551 - val_loss: 10.4247 - val_acc: 0.2214\n",
            "Epoch 2/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.9828 - acc: 0.4388 \n",
            "Epoch 2: val_acc improved from 0.22143 to 0.29286, saving model to percobaan131_noImgPro/model\\vgg_16_131-saved-model-02-acc-0.29.hdf5\n",
            "4/4 [==============================] - 174s 46s/step - loss: 1.9828 - acc: 0.4388 - val_loss: 8.9670 - val_acc: 0.2929\n",
            "Epoch 3/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.5800 - acc: 0.4776 \n",
            "Epoch 3: val_acc did not improve from 0.29286\n",
            "4/4 [==============================] - 175s 46s/step - loss: 1.5800 - acc: 0.4776 - val_loss: 10.6769 - val_acc: 0.2143\n",
            "Epoch 4/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1315 - acc: 0.5980 \n",
            "Epoch 4: val_acc did not improve from 0.29286\n",
            "4/4 [==============================] - 174s 46s/step - loss: 1.1315 - acc: 0.5980 - val_loss: 8.9193 - val_acc: 0.2214\n",
            "Epoch 5/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1214 - acc: 0.6306 \n",
            "Epoch 5: val_acc did not improve from 0.29286\n",
            "4/4 [==============================] - 174s 46s/step - loss: 1.1214 - acc: 0.6306 - val_loss: 7.2498 - val_acc: 0.2571\n",
            "Epoch 6/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9173 - acc: 0.6735 \n",
            "Epoch 6: val_acc did not improve from 0.29286\n",
            "4/4 [==============================] - 174s 46s/step - loss: 0.9173 - acc: 0.6735 - val_loss: 6.9243 - val_acc: 0.2643\n",
            "Epoch 7/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7841 - acc: 0.7082 \n",
            "Epoch 7: val_acc did not improve from 0.29286\n",
            "4/4 [==============================] - 174s 48s/step - loss: 0.7841 - acc: 0.7082 - val_loss: 8.6491 - val_acc: 0.2714\n",
            "Epoch 8/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7716 - acc: 0.7408 \n",
            "Epoch 8: val_acc did not improve from 0.29286\n",
            "4/4 [==============================] - 174s 46s/step - loss: 0.7716 - acc: 0.7408 - val_loss: 8.1081 - val_acc: 0.2571\n",
            "Epoch 9/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6995 - acc: 0.7347 \n",
            "Epoch 9: val_acc improved from 0.29286 to 0.32857, saving model to percobaan131_noImgPro/model\\vgg_16_131-saved-model-09-acc-0.33.hdf5\n",
            "4/4 [==============================] - 174s 46s/step - loss: 0.6995 - acc: 0.7347 - val_loss: 6.8563 - val_acc: 0.3286\n",
            "Epoch 10/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6532 - acc: 0.7694 \n",
            "Epoch 10: val_acc did not improve from 0.32857\n",
            "4/4 [==============================] - 174s 46s/step - loss: 0.6532 - acc: 0.7694 - val_loss: 6.0608 - val_acc: 0.3071\n",
            "Epoch 11/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5885 - acc: 0.7755 \n",
            "Epoch 11: val_acc did not improve from 0.32857\n",
            "4/4 [==============================] - 174s 46s/step - loss: 0.5885 - acc: 0.7755 - val_loss: 6.2665 - val_acc: 0.2500\n",
            "Epoch 12/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5572 - acc: 0.7939 \n",
            "Epoch 12: val_acc did not improve from 0.32857\n",
            "4/4 [==============================] - 174s 46s/step - loss: 0.5572 - acc: 0.7939 - val_loss: 6.6006 - val_acc: 0.2000\n",
            "Epoch 13/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5508 - acc: 0.8143 \n",
            "Epoch 13: val_acc did not improve from 0.32857\n",
            "4/4 [==============================] - 174s 46s/step - loss: 0.5508 - acc: 0.8143 - val_loss: 5.9000 - val_acc: 0.2571\n",
            "Epoch 14/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4604 - acc: 0.8367 \n",
            "Epoch 14: val_acc did not improve from 0.32857\n",
            "4/4 [==============================] - 173s 46s/step - loss: 0.4604 - acc: 0.8367 - val_loss: 4.8573 - val_acc: 0.3071\n",
            "Epoch 15/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4526 - acc: 0.8469 \n",
            "Epoch 15: val_acc did not improve from 0.32857\n",
            "4/4 [==============================] - 174s 46s/step - loss: 0.4526 - acc: 0.8469 - val_loss: 4.6189 - val_acc: 0.3143\n",
            "Epoch 16/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4392 - acc: 0.8449 \n",
            "Epoch 16: val_acc improved from 0.32857 to 0.33571, saving model to percobaan131_noImgPro/model\\vgg_16_131-saved-model-16-acc-0.34.hdf5\n",
            "4/4 [==============================] - 173s 46s/step - loss: 0.4392 - acc: 0.8449 - val_loss: 4.1938 - val_acc: 0.3357\n",
            "Epoch 17/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3881 - acc: 0.8714 \n",
            "Epoch 17: val_acc improved from 0.33571 to 0.37857, saving model to percobaan131_noImgPro/model\\vgg_16_131-saved-model-17-acc-0.38.hdf5\n",
            "4/4 [==============================] - 174s 46s/step - loss: 0.3881 - acc: 0.8714 - val_loss: 3.9686 - val_acc: 0.3786\n",
            "Epoch 18/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3879 - acc: 0.8592 \n",
            "Epoch 18: val_acc did not improve from 0.37857\n",
            "4/4 [==============================] - 170s 45s/step - loss: 0.3879 - acc: 0.8592 - val_loss: 4.1921 - val_acc: 0.3286\n",
            "Epoch 19/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2977 - acc: 0.8918 \n",
            "Epoch 19: val_acc did not improve from 0.37857\n",
            "4/4 [==============================] - 167s 44s/step - loss: 0.2977 - acc: 0.8918 - val_loss: 4.3021 - val_acc: 0.2857\n",
            "Epoch 20/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3303 - acc: 0.8878 \n",
            "Epoch 20: val_acc did not improve from 0.37857\n",
            "4/4 [==============================] - 166s 46s/step - loss: 0.3303 - acc: 0.8878 - val_loss: 4.4376 - val_acc: 0.2643\n",
            "Epoch 21/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2718 - acc: 0.8959 \n",
            "Epoch 21: val_acc did not improve from 0.37857\n",
            "4/4 [==============================] - 164s 44s/step - loss: 0.2718 - acc: 0.8959 - val_loss: 3.7232 - val_acc: 0.3571\n",
            "Epoch 22/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3086 - acc: 0.9020 \n",
            "Epoch 22: val_acc improved from 0.37857 to 0.50714, saving model to percobaan131_noImgPro/model\\vgg_16_131-saved-model-22-acc-0.51.hdf5\n",
            "4/4 [==============================] - 162s 43s/step - loss: 0.3086 - acc: 0.9020 - val_loss: 2.9869 - val_acc: 0.5071\n",
            "Epoch 23/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2686 - acc: 0.8980 \n",
            "Epoch 23: val_acc improved from 0.50714 to 0.56429, saving model to percobaan131_noImgPro/model\\vgg_16_131-saved-model-23-acc-0.56.hdf5\n",
            "4/4 [==============================] - 162s 43s/step - loss: 0.2686 - acc: 0.8980 - val_loss: 2.0577 - val_acc: 0.5643\n",
            "Epoch 24/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2079 - acc: 0.9224 \n",
            "Epoch 24: val_acc improved from 0.56429 to 0.62143, saving model to percobaan131_noImgPro/model\\vgg_16_131-saved-model-24-acc-0.62.hdf5\n",
            "4/4 [==============================] - 163s 43s/step - loss: 0.2079 - acc: 0.9224 - val_loss: 1.6618 - val_acc: 0.6214\n",
            "Epoch 25/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3197 - acc: 0.8898 \n",
            "Epoch 25: val_acc did not improve from 0.62143\n",
            "4/4 [==============================] - 181s 49s/step - loss: 0.3197 - acc: 0.8898 - val_loss: 1.9238 - val_acc: 0.5929\n",
            "Epoch 26/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2829 - acc: 0.8980 \n",
            "Epoch 26: val_acc did not improve from 0.62143\n",
            "4/4 [==============================] - 161s 43s/step - loss: 0.2829 - acc: 0.8980 - val_loss: 1.8196 - val_acc: 0.6000\n",
            "Epoch 27/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2442 - acc: 0.9163 \n",
            "Epoch 27: val_acc did not improve from 0.62143\n",
            "4/4 [==============================] - 162s 43s/step - loss: 0.2442 - acc: 0.9163 - val_loss: 1.4152 - val_acc: 0.6143\n",
            "Epoch 28/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3200 - acc: 0.9000 \n",
            "Epoch 28: val_acc improved from 0.62143 to 0.64286, saving model to percobaan131_noImgPro/model\\vgg_16_131-saved-model-28-acc-0.64.hdf5\n",
            "4/4 [==============================] - 159s 42s/step - loss: 0.3200 - acc: 0.9000 - val_loss: 1.1129 - val_acc: 0.6429\n",
            "Epoch 29/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3498 - acc: 0.8959 \n",
            "Epoch 29: val_acc did not improve from 0.64286\n",
            "4/4 [==============================] - 160s 42s/step - loss: 0.3498 - acc: 0.8959 - val_loss: 1.1889 - val_acc: 0.6357\n",
            "Epoch 30/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2534 - acc: 0.9122 \n",
            "Epoch 30: val_acc did not improve from 0.64286\n",
            "4/4 [==============================] - 159s 42s/step - loss: 0.2534 - acc: 0.9122 - val_loss: 1.6584 - val_acc: 0.5286\n",
            "Epoch 31/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2736 - acc: 0.9041 \n",
            "Epoch 31: val_acc did not improve from 0.64286\n",
            "4/4 [==============================] - 159s 42s/step - loss: 0.2736 - acc: 0.9041 - val_loss: 1.9867 - val_acc: 0.5000\n",
            "Epoch 32/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2651 - acc: 0.9102 \n",
            "Epoch 32: val_acc did not improve from 0.64286\n",
            "4/4 [==============================] - 158s 42s/step - loss: 0.2651 - acc: 0.9102 - val_loss: 1.5228 - val_acc: 0.6143\n",
            "Epoch 33/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2841 - acc: 0.9082 \n",
            "Epoch 33: val_acc improved from 0.64286 to 0.65714, saving model to percobaan131_noImgPro/model\\vgg_16_131-saved-model-33-acc-0.66.hdf5\n",
            "4/4 [==============================] - 159s 44s/step - loss: 0.2841 - acc: 0.9082 - val_loss: 1.2967 - val_acc: 0.6571\n",
            "\n",
            "\n",
            "Model Accuracy 0.5714285714285714\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.83      0.50      0.62        10\n",
            "       10000       0.82      0.90      0.86        10\n",
            "      100000       1.00      0.30      0.46        10\n",
            "        2000       0.80      0.40      0.53        10\n",
            "       20000       1.00      0.30      0.46        10\n",
            "        5000       0.86      0.60      0.71        10\n",
            "       50000       0.29      1.00      0.44        10\n",
            "\n",
            "    accuracy                           0.57        70\n",
            "   macro avg       0.80      0.57      0.58        70\n",
            "weighted avg       0.80      0.57      0.58        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 132 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 53\n",
            "learning rate: 0.05996458825950378\n",
            "batch size: 128\n",
            "dropout rate: 0.7697817549092257\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 3.2216 - acc: 0.2184 \n",
            "Epoch 1: val_acc improved from -inf to 0.14286, saving model to percobaan132_noImgPro/model\\vgg_16_132-saved-model-01-acc-0.14.hdf5\n",
            "4/4 [==============================] - 158s 44s/step - loss: 3.2216 - acc: 0.2184 - val_loss: 12.6115 - val_acc: 0.1429\n",
            "Epoch 2/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.6872 - acc: 0.3000 \n",
            "Epoch 2: val_acc improved from 0.14286 to 0.15000, saving model to percobaan132_noImgPro/model\\vgg_16_132-saved-model-02-acc-0.15.hdf5\n",
            "4/4 [==============================] - 161s 43s/step - loss: 2.6872 - acc: 0.3000 - val_loss: 12.0487 - val_acc: 0.1500\n",
            "Epoch 3/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.3737 - acc: 0.3918 \n",
            "Epoch 3: val_acc improved from 0.15000 to 0.17857, saving model to percobaan132_noImgPro/model\\vgg_16_132-saved-model-03-acc-0.18.hdf5\n",
            "4/4 [==============================] - 160s 44s/step - loss: 2.3737 - acc: 0.3918 - val_loss: 7.1927 - val_acc: 0.1786\n",
            "Epoch 4/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.0084 - acc: 0.3776 \n",
            "Epoch 4: val_acc improved from 0.17857 to 0.22143, saving model to percobaan132_noImgPro/model\\vgg_16_132-saved-model-04-acc-0.22.hdf5\n",
            "4/4 [==============================] - 161s 43s/step - loss: 2.0084 - acc: 0.3776 - val_loss: 4.8107 - val_acc: 0.2214\n",
            "Epoch 5/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.6674 - acc: 0.4449 \n",
            "Epoch 5: val_acc improved from 0.22143 to 0.24286, saving model to percobaan132_noImgPro/model\\vgg_16_132-saved-model-05-acc-0.24.hdf5\n",
            "4/4 [==============================] - 161s 43s/step - loss: 1.6674 - acc: 0.4449 - val_loss: 3.7277 - val_acc: 0.2429\n",
            "Epoch 6/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.4788 - acc: 0.4796 \n",
            "Epoch 6: val_acc improved from 0.24286 to 0.36429, saving model to percobaan132_noImgPro/model\\vgg_16_132-saved-model-06-acc-0.36.hdf5\n",
            "4/4 [==============================] - 167s 45s/step - loss: 1.4788 - acc: 0.4796 - val_loss: 2.5048 - val_acc: 0.3643\n",
            "Epoch 7/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.3563 - acc: 0.5286 \n",
            "Epoch 7: val_acc improved from 0.36429 to 0.37857, saving model to percobaan132_noImgPro/model\\vgg_16_132-saved-model-07-acc-0.38.hdf5\n",
            "4/4 [==============================] - 184s 49s/step - loss: 1.3563 - acc: 0.5286 - val_loss: 1.9223 - val_acc: 0.3786\n",
            "Epoch 8/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2801 - acc: 0.5122 \n",
            "Epoch 8: val_acc did not improve from 0.37857\n",
            "4/4 [==============================] - 191s 53s/step - loss: 1.2801 - acc: 0.5122 - val_loss: 1.7553 - val_acc: 0.3071\n",
            "Epoch 9/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2289 - acc: 0.5367 \n",
            "Epoch 9: val_acc did not improve from 0.37857\n",
            "4/4 [==============================] - 185s 49s/step - loss: 1.2289 - acc: 0.5367 - val_loss: 1.5678 - val_acc: 0.2571\n",
            "Epoch 10/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0849 - acc: 0.5898 \n",
            "Epoch 10: val_acc did not improve from 0.37857\n",
            "4/4 [==============================] - 186s 49s/step - loss: 1.0849 - acc: 0.5898 - val_loss: 1.4307 - val_acc: 0.3714\n",
            "Epoch 11/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1049 - acc: 0.5939 \n",
            "Epoch 11: val_acc did not improve from 0.37857\n",
            "4/4 [==============================] - 191s 53s/step - loss: 1.1049 - acc: 0.5939 - val_loss: 1.3741 - val_acc: 0.3786\n",
            "Epoch 12/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9858 - acc: 0.6429 \n",
            "Epoch 12: val_acc improved from 0.37857 to 0.44286, saving model to percobaan132_noImgPro/model\\vgg_16_132-saved-model-12-acc-0.44.hdf5\n",
            "4/4 [==============================] - 189s 50s/step - loss: 0.9858 - acc: 0.6429 - val_loss: 1.2089 - val_acc: 0.4429\n",
            "Epoch 13/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9571 - acc: 0.6612 \n",
            "Epoch 13: val_acc did not improve from 0.44286\n",
            "4/4 [==============================] - 193s 54s/step - loss: 0.9571 - acc: 0.6612 - val_loss: 1.2078 - val_acc: 0.4429\n",
            "Epoch 14/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8958 - acc: 0.6796 \n",
            "Epoch 14: val_acc improved from 0.44286 to 0.49286, saving model to percobaan132_noImgPro/model\\vgg_16_132-saved-model-14-acc-0.49.hdf5\n",
            "4/4 [==============================] - 189s 50s/step - loss: 0.8958 - acc: 0.6796 - val_loss: 1.1905 - val_acc: 0.4929\n",
            "Epoch 15/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8860 - acc: 0.6796 \n",
            "Epoch 15: val_acc improved from 0.49286 to 0.57143, saving model to percobaan132_noImgPro/model\\vgg_16_132-saved-model-15-acc-0.57.hdf5\n",
            "4/4 [==============================] - 190s 51s/step - loss: 0.8860 - acc: 0.6796 - val_loss: 1.1484 - val_acc: 0.5714\n",
            "Epoch 16/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8665 - acc: 0.6796 \n",
            "Epoch 16: val_acc did not improve from 0.57143\n",
            "4/4 [==============================] - 188s 50s/step - loss: 0.8665 - acc: 0.6796 - val_loss: 1.1651 - val_acc: 0.5643\n",
            "Epoch 17/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7832 - acc: 0.7102 \n",
            "Epoch 17: val_acc improved from 0.57143 to 0.62857, saving model to percobaan132_noImgPro/model\\vgg_16_132-saved-model-17-acc-0.63.hdf5\n",
            "4/4 [==============================] - 191s 51s/step - loss: 0.7832 - acc: 0.7102 - val_loss: 1.0331 - val_acc: 0.6286\n",
            "Epoch 18/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8134 - acc: 0.7000 \n",
            "Epoch 18: val_acc did not improve from 0.62857\n",
            "4/4 [==============================] - 189s 50s/step - loss: 0.8134 - acc: 0.7000 - val_loss: 1.0566 - val_acc: 0.6143\n",
            "Epoch 19/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7803 - acc: 0.7184 \n",
            "Epoch 19: val_acc did not improve from 0.62857\n",
            "4/4 [==============================] - 186s 52s/step - loss: 0.7803 - acc: 0.7184 - val_loss: 1.1768 - val_acc: 0.5571\n",
            "Epoch 20/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6696 - acc: 0.7694 \n",
            "Epoch 20: val_acc did not improve from 0.62857\n",
            "4/4 [==============================] - 186s 50s/step - loss: 0.6696 - acc: 0.7694 - val_loss: 1.1959 - val_acc: 0.5571\n",
            "Epoch 21/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6998 - acc: 0.7429 \n",
            "Epoch 21: val_acc did not improve from 0.62857\n",
            "4/4 [==============================] - 187s 50s/step - loss: 0.6998 - acc: 0.7429 - val_loss: 1.6921 - val_acc: 0.4357\n",
            "Epoch 22/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6070 - acc: 0.7857 \n",
            "Epoch 22: val_acc did not improve from 0.62857\n",
            "4/4 [==============================] - 188s 52s/step - loss: 0.6070 - acc: 0.7857 - val_loss: 1.7642 - val_acc: 0.4571\n",
            "\n",
            "\n",
            "Model Accuracy 0.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.10      0.18        10\n",
            "       10000       0.50      0.10      0.17        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.26      1.00      0.41        10\n",
            "       20000       1.00      0.20      0.33        10\n",
            "        5000       0.43      0.90      0.58        10\n",
            "       50000       1.00      0.50      0.67        10\n",
            "\n",
            "    accuracy                           0.40        70\n",
            "   macro avg       0.60      0.40      0.33        70\n",
            "weighted avg       0.60      0.40      0.33        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 133 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 48\n",
            "learning rate: 0.08643874923489848\n",
            "batch size: 32\n",
            "dropout rate: 0.5744305781754937\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 3.7076 - acc: 0.2837\n",
            "Epoch 1: val_acc improved from -inf to 0.22857, saving model to percobaan133_noImgPro/model\\vgg_16_133-saved-model-01-acc-0.23.hdf5\n",
            "16/16 [==============================] - 200s 13s/step - loss: 3.7076 - acc: 0.2837 - val_loss: 11.8143 - val_acc: 0.2286\n",
            "Epoch 2/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.1864 - acc: 0.4041\n",
            "Epoch 2: val_acc did not improve from 0.22857\n",
            "16/16 [==============================] - 194s 12s/step - loss: 2.1864 - acc: 0.4041 - val_loss: 5.3600 - val_acc: 0.1714\n",
            "Epoch 3/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.7514 - acc: 0.4776\n",
            "Epoch 3: val_acc did not improve from 0.22857\n",
            "16/16 [==============================] - 194s 12s/step - loss: 1.7514 - acc: 0.4776 - val_loss: 3.8033 - val_acc: 0.1714\n",
            "Epoch 4/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.4161 - acc: 0.5000\n",
            "Epoch 4: val_acc did not improve from 0.22857\n",
            "16/16 [==============================] - 192s 12s/step - loss: 1.4161 - acc: 0.5000 - val_loss: 3.6679 - val_acc: 0.2143\n",
            "Epoch 5/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2493 - acc: 0.5878\n",
            "Epoch 5: val_acc did not improve from 0.22857\n",
            "16/16 [==============================] - 196s 12s/step - loss: 1.2493 - acc: 0.5878 - val_loss: 3.6365 - val_acc: 0.1786\n",
            "Epoch 6/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1064 - acc: 0.6449\n",
            "Epoch 6: val_acc improved from 0.22857 to 0.26429, saving model to percobaan133_noImgPro/model\\vgg_16_133-saved-model-06-acc-0.26.hdf5\n",
            "16/16 [==============================] - 197s 12s/step - loss: 1.1064 - acc: 0.6449 - val_loss: 4.3758 - val_acc: 0.2643\n",
            "Epoch 7/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0577 - acc: 0.6367\n",
            "Epoch 7: val_acc improved from 0.26429 to 0.30000, saving model to percobaan133_noImgPro/model\\vgg_16_133-saved-model-07-acc-0.30.hdf5\n",
            "16/16 [==============================] - 193s 13s/step - loss: 1.0577 - acc: 0.6367 - val_loss: 3.8390 - val_acc: 0.3000\n",
            "Epoch 8/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0511 - acc: 0.6612\n",
            "Epoch 8: val_acc did not improve from 0.30000\n",
            "16/16 [==============================] - 193s 12s/step - loss: 1.0511 - acc: 0.6612 - val_loss: 6.1131 - val_acc: 0.1429\n",
            "Epoch 9/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0607 - acc: 0.6531\n",
            "Epoch 9: val_acc improved from 0.30000 to 0.42143, saving model to percobaan133_noImgPro/model\\vgg_16_133-saved-model-09-acc-0.42.hdf5\n",
            "16/16 [==============================] - 192s 12s/step - loss: 1.0607 - acc: 0.6531 - val_loss: 2.9862 - val_acc: 0.4214\n",
            "Epoch 10/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9922 - acc: 0.6755\n",
            "Epoch 10: val_acc did not improve from 0.42143\n",
            "16/16 [==============================] - 193s 12s/step - loss: 0.9922 - acc: 0.6755 - val_loss: 4.1027 - val_acc: 0.3643\n",
            "Epoch 11/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0333 - acc: 0.6857\n",
            "Epoch 11: val_acc improved from 0.42143 to 0.44286, saving model to percobaan133_noImgPro/model\\vgg_16_133-saved-model-11-acc-0.44.hdf5\n",
            "16/16 [==============================] - 195s 12s/step - loss: 1.0333 - acc: 0.6857 - val_loss: 2.7053 - val_acc: 0.4429\n",
            "Epoch 12/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9014 - acc: 0.7184\n",
            "Epoch 12: val_acc improved from 0.44286 to 0.51429, saving model to percobaan133_noImgPro/model\\vgg_16_133-saved-model-12-acc-0.51.hdf5\n",
            "16/16 [==============================] - 196s 12s/step - loss: 0.9014 - acc: 0.7184 - val_loss: 1.9922 - val_acc: 0.5143\n",
            "Epoch 13/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9240 - acc: 0.7408\n",
            "Epoch 13: val_acc improved from 0.51429 to 0.59286, saving model to percobaan133_noImgPro/model\\vgg_16_133-saved-model-13-acc-0.59.hdf5\n",
            "16/16 [==============================] - 198s 12s/step - loss: 0.9240 - acc: 0.7408 - val_loss: 1.3211 - val_acc: 0.5929\n",
            "Epoch 14/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9148 - acc: 0.7122\n",
            "Epoch 14: val_acc improved from 0.59286 to 0.67857, saving model to percobaan133_noImgPro/model\\vgg_16_133-saved-model-14-acc-0.68.hdf5\n",
            "16/16 [==============================] - 193s 12s/step - loss: 0.9148 - acc: 0.7122 - val_loss: 1.3708 - val_acc: 0.6786\n",
            "Epoch 15/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9621 - acc: 0.7143\n",
            "Epoch 15: val_acc did not improve from 0.67857\n",
            "16/16 [==============================] - 193s 12s/step - loss: 0.9621 - acc: 0.7143 - val_loss: 7.2880 - val_acc: 0.2857\n",
            "Epoch 16/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8319 - acc: 0.7327\n",
            "Epoch 16: val_acc did not improve from 0.67857\n",
            "16/16 [==============================] - 197s 13s/step - loss: 0.8319 - acc: 0.7327 - val_loss: 7.7204 - val_acc: 0.3643\n",
            "Epoch 17/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1125 - acc: 0.7143\n",
            "Epoch 17: val_acc did not improve from 0.67857\n",
            "16/16 [==============================] - 195s 12s/step - loss: 1.1125 - acc: 0.7143 - val_loss: 3.2513 - val_acc: 0.5214\n",
            "Epoch 18/48\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0631 - acc: 0.6898\n",
            "Epoch 18: val_acc did not improve from 0.67857\n",
            "16/16 [==============================] - 194s 12s/step - loss: 1.0631 - acc: 0.6898 - val_loss: 2.0547 - val_acc: 0.6214\n",
            "\n",
            "\n",
            "Model Accuracy 0.5285714285714286\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.67      0.80      0.73        10\n",
            "       10000       1.00      0.10      0.18        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.80      0.80      0.80        10\n",
            "       20000       0.25      0.20      0.22        10\n",
            "        5000       0.67      0.80      0.73        10\n",
            "       50000       0.37      1.00      0.54        10\n",
            "\n",
            "    accuracy                           0.53        70\n",
            "   macro avg       0.54      0.53      0.46        70\n",
            "weighted avg       0.54      0.53      0.46        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 134 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 50\n",
            "learning rate: 0.09185417623508516\n",
            "batch size: 32\n",
            "dropout rate: 0.5966553703966321\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 4.2564 - acc: 0.2061 \n",
            "Epoch 1: val_acc improved from -inf to 0.15714, saving model to percobaan134_noImgPro/model\\vgg_16_134-saved-model-01-acc-0.16.hdf5\n",
            "16/16 [==============================] - 435s 28s/step - loss: 4.2564 - acc: 0.2061 - val_loss: 12.2888 - val_acc: 0.1571\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.5240 - acc: 0.3184 \n",
            "Epoch 2: val_acc improved from 0.15714 to 0.27857, saving model to percobaan134_noImgPro/model\\vgg_16_134-saved-model-02-acc-0.28.hdf5\n",
            "16/16 [==============================] - 452s 29s/step - loss: 2.5240 - acc: 0.3184 - val_loss: 3.1520 - val_acc: 0.2786\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.8476 - acc: 0.3918 \n",
            "Epoch 3: val_acc did not improve from 0.27857\n",
            "16/16 [==============================] - 432s 28s/step - loss: 1.8476 - acc: 0.3918 - val_loss: 4.2463 - val_acc: 0.2071\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.5947 - acc: 0.4592 \n",
            "Epoch 4: val_acc improved from 0.27857 to 0.40000, saving model to percobaan134_noImgPro/model\\vgg_16_134-saved-model-04-acc-0.40.hdf5\n",
            "16/16 [==============================] - 451s 29s/step - loss: 1.5947 - acc: 0.4592 - val_loss: 2.1796 - val_acc: 0.4000\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2658 - acc: 0.5776 \n",
            "Epoch 5: val_acc improved from 0.40000 to 0.47857, saving model to percobaan134_noImgPro/model\\vgg_16_134-saved-model-05-acc-0.48.hdf5\n",
            "16/16 [==============================] - 448s 28s/step - loss: 1.2658 - acc: 0.5776 - val_loss: 1.4992 - val_acc: 0.4786\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3262 - acc: 0.5612 \n",
            "Epoch 6: val_acc did not improve from 0.47857\n",
            "16/16 [==============================] - 448s 29s/step - loss: 1.3262 - acc: 0.5612 - val_loss: 1.8341 - val_acc: 0.3643\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3214 - acc: 0.5633 \n",
            "Epoch 7: val_acc improved from 0.47857 to 0.52143, saving model to percobaan134_noImgPro/model\\vgg_16_134-saved-model-07-acc-0.52.hdf5\n",
            "16/16 [==============================] - 367s 23s/step - loss: 1.3214 - acc: 0.5633 - val_loss: 1.5856 - val_acc: 0.5214\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1393 - acc: 0.6347 \n",
            "Epoch 8: val_acc improved from 0.52143 to 0.57143, saving model to percobaan134_noImgPro/model\\vgg_16_134-saved-model-08-acc-0.57.hdf5\n",
            "16/16 [==============================] - 434s 28s/step - loss: 1.1393 - acc: 0.6347 - val_loss: 1.3403 - val_acc: 0.5714\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2209 - acc: 0.6306 \n",
            "Epoch 9: val_acc did not improve from 0.57143\n",
            "16/16 [==============================] - 442s 28s/step - loss: 1.2209 - acc: 0.6306 - val_loss: 2.1855 - val_acc: 0.3357\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1944 - acc: 0.6245 \n",
            "Epoch 10: val_acc did not improve from 0.57143\n",
            "16/16 [==============================] - 445s 29s/step - loss: 1.1944 - acc: 0.6245 - val_loss: 3.2183 - val_acc: 0.2143\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1494 - acc: 0.6204 \n",
            "Epoch 11: val_acc did not improve from 0.57143\n",
            "16/16 [==============================] - 446s 28s/step - loss: 1.1494 - acc: 0.6204 - val_loss: 4.9910 - val_acc: 0.2214\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2461 - acc: 0.6143 \n",
            "Epoch 12: val_acc did not improve from 0.57143\n",
            "16/16 [==============================] - 450s 29s/step - loss: 1.2461 - acc: 0.6143 - val_loss: 3.2151 - val_acc: 0.3786\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1339 - acc: 0.6673 \n",
            "Epoch 13: val_acc did not improve from 0.57143\n",
            "16/16 [==============================] - 463s 29s/step - loss: 1.1339 - acc: 0.6673 - val_loss: 1.5376 - val_acc: 0.5429\n",
            "\n",
            "\n",
            "Model Accuracy 0.4714285714285714\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.10      0.18        10\n",
            "       10000       1.00      0.10      0.18        10\n",
            "      100000       0.48      1.00      0.65        10\n",
            "        2000       0.29      1.00      0.45        10\n",
            "       20000       0.00      0.00      0.00        10\n",
            "        5000       1.00      0.60      0.75        10\n",
            "       50000       0.71      0.50      0.59        10\n",
            "\n",
            "    accuracy                           0.47        70\n",
            "   macro avg       0.64      0.47      0.40        70\n",
            "weighted avg       0.64      0.47      0.40        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 135 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 53\n",
            "learning rate: 0.07551021060525145\n",
            "batch size: 32\n",
            "dropout rate: 0.6673321495760528\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/53\n",
            "16/16 [==============================] - ETA: 0s - loss: 3.5598 - acc: 0.2531 \n",
            "Epoch 1: val_acc improved from -inf to 0.26429, saving model to percobaan135_noImgPro/model\\vgg_16_135-saved-model-01-acc-0.26.hdf5\n",
            "16/16 [==============================] - 407s 26s/step - loss: 3.5598 - acc: 0.2531 - val_loss: 6.0438 - val_acc: 0.2643\n",
            "Epoch 2/53\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.7968 - acc: 0.3327 \n",
            "Epoch 2: val_acc did not improve from 0.26429\n",
            "16/16 [==============================] - 416s 26s/step - loss: 2.7968 - acc: 0.3327 - val_loss: 2.9314 - val_acc: 0.2571\n",
            "Epoch 3/53\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.0830 - acc: 0.3490 \n",
            "Epoch 3: val_acc improved from 0.26429 to 0.45714, saving model to percobaan135_noImgPro/model\\vgg_16_135-saved-model-03-acc-0.46.hdf5\n",
            "16/16 [==============================] - 396s 25s/step - loss: 2.0830 - acc: 0.3490 - val_loss: 1.4282 - val_acc: 0.4571\n",
            "Epoch 4/53\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.5927 - acc: 0.4592 \n",
            "Epoch 4: val_acc did not improve from 0.45714\n",
            "16/16 [==============================] - 413s 26s/step - loss: 1.5927 - acc: 0.4592 - val_loss: 2.0169 - val_acc: 0.3571\n",
            "Epoch 5/53\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.5525 - acc: 0.4898 \n",
            "Epoch 5: val_acc improved from 0.45714 to 0.47143, saving model to percobaan135_noImgPro/model\\vgg_16_135-saved-model-05-acc-0.47.hdf5\n",
            "16/16 [==============================] - 389s 25s/step - loss: 1.5525 - acc: 0.4898 - val_loss: 2.0274 - val_acc: 0.4714\n",
            "Epoch 6/53\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3000 - acc: 0.5551 \n",
            "Epoch 6: val_acc did not improve from 0.47143\n",
            "16/16 [==============================] - 405s 26s/step - loss: 1.3000 - acc: 0.5551 - val_loss: 2.2443 - val_acc: 0.4286\n",
            "Epoch 7/53\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1946 - acc: 0.6224 \n",
            "Epoch 7: val_acc improved from 0.47143 to 0.50714, saving model to percobaan135_noImgPro/model\\vgg_16_135-saved-model-07-acc-0.51.hdf5\n",
            "16/16 [==============================] - 413s 26s/step - loss: 1.1946 - acc: 0.6224 - val_loss: 1.6594 - val_acc: 0.5071\n",
            "Epoch 8/53\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1736 - acc: 0.5918 \n",
            "Epoch 8: val_acc improved from 0.50714 to 0.62143, saving model to percobaan135_noImgPro/model\\vgg_16_135-saved-model-08-acc-0.62.hdf5\n",
            "16/16 [==============================] - 398s 25s/step - loss: 1.1736 - acc: 0.5918 - val_loss: 1.0557 - val_acc: 0.6214\n",
            "Epoch 9/53\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1811 - acc: 0.6367 \n",
            "Epoch 9: val_acc did not improve from 0.62143\n",
            "16/16 [==============================] - 400s 26s/step - loss: 1.1811 - acc: 0.6367 - val_loss: 1.1611 - val_acc: 0.5929\n",
            "Epoch 10/53\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0797 - acc: 0.6265 \n",
            "Epoch 10: val_acc did not improve from 0.62143\n",
            "16/16 [==============================] - 405s 26s/step - loss: 1.0797 - acc: 0.6265 - val_loss: 1.4237 - val_acc: 0.5786\n",
            "Epoch 11/53\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1780 - acc: 0.6204 \n",
            "Epoch 11: val_acc improved from 0.62143 to 0.67143, saving model to percobaan135_noImgPro/model\\vgg_16_135-saved-model-11-acc-0.67.hdf5\n",
            "16/16 [==============================] - 411s 26s/step - loss: 1.1780 - acc: 0.6204 - val_loss: 1.1940 - val_acc: 0.6714\n",
            "Epoch 12/53\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2421 - acc: 0.6673 \n",
            "Epoch 12: val_acc did not improve from 0.67143\n",
            "16/16 [==============================] - 379s 24s/step - loss: 1.2421 - acc: 0.6673 - val_loss: 1.3356 - val_acc: 0.6071\n",
            "Epoch 13/53\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1433 - acc: 0.6694 \n",
            "Epoch 13: val_acc did not improve from 0.67143\n",
            "16/16 [==============================] - 406s 26s/step - loss: 1.1433 - acc: 0.6694 - val_loss: 1.4400 - val_acc: 0.5714\n",
            "\n",
            "\n",
            "Model Accuracy 0.45714285714285713\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.40      0.57        10\n",
            "       10000       0.24      1.00      0.39        10\n",
            "      100000       1.00      0.20      0.33        10\n",
            "        2000       0.80      0.40      0.53        10\n",
            "       20000       0.00      0.00      0.00        10\n",
            "        5000       0.58      0.70      0.64        10\n",
            "       50000       0.83      0.50      0.62        10\n",
            "\n",
            "    accuracy                           0.46        70\n",
            "   macro avg       0.64      0.46      0.44        70\n",
            "weighted avg       0.64      0.46      0.44        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 136 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 53\n",
            "learning rate: 0.07919878223900008\n",
            "batch size: 32\n",
            "dropout rate: 0.7726062254152087\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/53\n",
            "16/16 [==============================] - ETA: 0s - loss: 5.0841 - acc: 0.2367 \n",
            "Epoch 1: val_acc improved from -inf to 0.15714, saving model to percobaan136_noImgPro/model\\vgg_16_136-saved-model-01-acc-0.16.hdf5\n",
            "16/16 [==============================] - 351s 22s/step - loss: 5.0841 - acc: 0.2367 - val_loss: 14.5574 - val_acc: 0.1571\n",
            "Epoch 2/53\n",
            "16/16 [==============================] - ETA: 0s - loss: 3.5284 - acc: 0.2367 \n",
            "Epoch 2: val_acc improved from 0.15714 to 0.25000, saving model to percobaan136_noImgPro/model\\vgg_16_136-saved-model-02-acc-0.25.hdf5\n",
            "16/16 [==============================] - 354s 23s/step - loss: 3.5284 - acc: 0.2367 - val_loss: 3.0196 - val_acc: 0.2500\n",
            "Epoch 3/53\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.2500 - acc: 0.2878 \n",
            "Epoch 3: val_acc did not improve from 0.25000\n",
            "16/16 [==============================] - 365s 23s/step - loss: 2.2500 - acc: 0.2878 - val_loss: 3.5901 - val_acc: 0.1500\n",
            "Epoch 4/53\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.1843 - acc: 0.2878 \n",
            "Epoch 4: val_acc did not improve from 0.25000\n",
            "16/16 [==============================] - 370s 24s/step - loss: 2.1843 - acc: 0.2878 - val_loss: 2.2884 - val_acc: 0.2357\n",
            "Epoch 5/53\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.8071 - acc: 0.3980 \n",
            "Epoch 5: val_acc did not improve from 0.25000\n",
            "16/16 [==============================] - 364s 24s/step - loss: 1.8071 - acc: 0.3980 - val_loss: 2.3027 - val_acc: 0.2214\n",
            "Epoch 6/53\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.5380 - acc: 0.4429 \n",
            "Epoch 6: val_acc improved from 0.25000 to 0.33571, saving model to percobaan136_noImgPro/model\\vgg_16_136-saved-model-06-acc-0.34.hdf5\n",
            "16/16 [==============================] - 355s 23s/step - loss: 1.5380 - acc: 0.4429 - val_loss: 1.9073 - val_acc: 0.3357\n",
            "Epoch 7/53\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.6207 - acc: 0.4265 \n",
            "Epoch 7: val_acc improved from 0.33571 to 0.45000, saving model to percobaan136_noImgPro/model\\vgg_16_136-saved-model-07-acc-0.45.hdf5\n",
            "16/16 [==============================] - 358s 23s/step - loss: 1.6207 - acc: 0.4265 - val_loss: 1.4296 - val_acc: 0.4500\n",
            "Epoch 8/53\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.5406 - acc: 0.4653 \n",
            "Epoch 8: val_acc improved from 0.45000 to 0.46429, saving model to percobaan136_noImgPro/model\\vgg_16_136-saved-model-08-acc-0.46.hdf5\n",
            "16/16 [==============================] - 365s 23s/step - loss: 1.5406 - acc: 0.4653 - val_loss: 1.6227 - val_acc: 0.4643\n",
            "Epoch 9/53\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.5256 - acc: 0.4959 \n",
            "Epoch 9: val_acc improved from 0.46429 to 0.50000, saving model to percobaan136_noImgPro/model\\vgg_16_136-saved-model-09-acc-0.50.hdf5\n",
            "16/16 [==============================] - 357s 23s/step - loss: 1.5256 - acc: 0.4959 - val_loss: 1.6646 - val_acc: 0.5000\n",
            "Epoch 10/53\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.6811 - acc: 0.4347 \n",
            "Epoch 10: val_acc improved from 0.50000 to 0.52857, saving model to percobaan136_noImgPro/model\\vgg_16_136-saved-model-10-acc-0.53.hdf5\n",
            "16/16 [==============================] - 357s 23s/step - loss: 1.6811 - acc: 0.4347 - val_loss: 1.3949 - val_acc: 0.5286\n",
            "Epoch 11/53\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.4697 - acc: 0.5061 \n",
            "Epoch 11: val_acc did not improve from 0.52857\n",
            "16/16 [==============================] - 364s 23s/step - loss: 1.4697 - acc: 0.5061 - val_loss: 1.5341 - val_acc: 0.4500\n",
            "Epoch 12/53\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.5124 - acc: 0.5163 \n",
            "Epoch 12: val_acc improved from 0.52857 to 0.71429, saving model to percobaan136_noImgPro/model\\vgg_16_136-saved-model-12-acc-0.71.hdf5\n",
            "16/16 [==============================] - 355s 23s/step - loss: 1.5124 - acc: 0.5163 - val_loss: 0.8930 - val_acc: 0.7143\n",
            "Epoch 13/53\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.5460 - acc: 0.5020 \n",
            "Epoch 13: val_acc did not improve from 0.71429\n",
            "16/16 [==============================] - 366s 23s/step - loss: 1.5460 - acc: 0.5020 - val_loss: 1.5855 - val_acc: 0.4786\n",
            "Epoch 14/53\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.5344 - acc: 0.5163 \n",
            "Epoch 14: val_acc did not improve from 0.71429\n",
            "16/16 [==============================] - 367s 23s/step - loss: 1.5344 - acc: 0.5163 - val_loss: 1.8193 - val_acc: 0.3714\n",
            "Epoch 15/53\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.5754 - acc: 0.5122 \n",
            "Epoch 15: val_acc did not improve from 0.71429\n",
            "16/16 [==============================] - 350s 22s/step - loss: 1.5754 - acc: 0.5122 - val_loss: 1.0513 - val_acc: 0.6500\n",
            "Epoch 16/53\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3996 - acc: 0.5388 \n",
            "Epoch 16: val_acc did not improve from 0.71429\n",
            "16/16 [==============================] - 352s 22s/step - loss: 1.3996 - acc: 0.5388 - val_loss: 1.3199 - val_acc: 0.5857\n",
            "Epoch 17/53\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3891 - acc: 0.5633 \n",
            "Epoch 17: val_acc did not improve from 0.71429\n",
            "16/16 [==============================] - 355s 23s/step - loss: 1.3891 - acc: 0.5633 - val_loss: 1.1822 - val_acc: 0.6500\n",
            "\n",
            "\n",
            "Model Accuracy 0.5571428571428572\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.33      0.90      0.49        10\n",
            "       10000       0.86      0.60      0.71        10\n",
            "      100000       0.88      0.70      0.78        10\n",
            "        2000       1.00      0.20      0.33        10\n",
            "       20000       0.00      0.00      0.00        10\n",
            "        5000       0.54      0.70      0.61        10\n",
            "       50000       0.67      0.80      0.73        10\n",
            "\n",
            "    accuracy                           0.56        70\n",
            "   macro avg       0.61      0.56      0.52        70\n",
            "weighted avg       0.61      0.56      0.52        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 137 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 51\n",
            "learning rate: 0.09037945471736615\n",
            "batch size: 64\n",
            "dropout rate: 0.5594029162553562\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 3.2757 - acc: 0.2306 \n",
            "Epoch 1: val_acc improved from -inf to 0.14286, saving model to percobaan137_noImgPro/model\\vgg_16_137-saved-model-01-acc-0.14.hdf5\n",
            "8/8 [==============================] - 306s 39s/step - loss: 3.2757 - acc: 0.2306 - val_loss: 11.6606 - val_acc: 0.1429\n",
            "Epoch 2/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.1485 - acc: 0.4286 \n",
            "Epoch 2: val_acc improved from 0.14286 to 0.15000, saving model to percobaan137_noImgPro/model\\vgg_16_137-saved-model-02-acc-0.15.hdf5\n",
            "8/8 [==============================] - 310s 40s/step - loss: 2.1485 - acc: 0.4286 - val_loss: 11.4908 - val_acc: 0.1500\n",
            "Epoch 3/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6810 - acc: 0.4694 \n",
            "Epoch 3: val_acc did not improve from 0.15000\n",
            "8/8 [==============================] - 307s 41s/step - loss: 1.6810 - acc: 0.4694 - val_loss: 5.6832 - val_acc: 0.1429\n",
            "Epoch 4/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.2468 - acc: 0.5347 \n",
            "Epoch 4: val_acc did not improve from 0.15000\n",
            "8/8 [==============================] - 306s 40s/step - loss: 1.2468 - acc: 0.5347 - val_loss: 7.6896 - val_acc: 0.1500\n",
            "Epoch 5/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1307 - acc: 0.6429 \n",
            "Epoch 5: val_acc improved from 0.15000 to 0.22143, saving model to percobaan137_noImgPro/model\\vgg_16_137-saved-model-05-acc-0.22.hdf5\n",
            "8/8 [==============================] - 307s 40s/step - loss: 1.1307 - acc: 0.6429 - val_loss: 6.6749 - val_acc: 0.2214\n",
            "Epoch 6/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9571 - acc: 0.6837 \n",
            "Epoch 6: val_acc did not improve from 0.22143\n",
            "8/8 [==============================] - 308s 40s/step - loss: 0.9571 - acc: 0.6837 - val_loss: 5.1056 - val_acc: 0.1929\n",
            "Epoch 7/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7881 - acc: 0.7245 \n",
            "Epoch 7: val_acc improved from 0.22143 to 0.25714, saving model to percobaan137_noImgPro/model\\vgg_16_137-saved-model-07-acc-0.26.hdf5\n",
            "8/8 [==============================] - 211s 27s/step - loss: 0.7881 - acc: 0.7245 - val_loss: 4.0454 - val_acc: 0.2571\n",
            "Epoch 8/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8920 - acc: 0.7020 \n",
            "Epoch 8: val_acc improved from 0.25714 to 0.45714, saving model to percobaan137_noImgPro/model\\vgg_16_137-saved-model-08-acc-0.46.hdf5\n",
            "8/8 [==============================] - 219s 28s/step - loss: 0.8920 - acc: 0.7020 - val_loss: 2.3003 - val_acc: 0.4571\n",
            "Epoch 9/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7105 - acc: 0.7551 \n",
            "Epoch 9: val_acc did not improve from 0.45714\n",
            "8/8 [==============================] - 222s 29s/step - loss: 0.7105 - acc: 0.7551 - val_loss: 2.0561 - val_acc: 0.3929\n",
            "Epoch 10/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7208 - acc: 0.7571 \n",
            "Epoch 10: val_acc improved from 0.45714 to 0.49286, saving model to percobaan137_noImgPro/model\\vgg_16_137-saved-model-10-acc-0.49.hdf5\n",
            "8/8 [==============================] - 224s 29s/step - loss: 0.7208 - acc: 0.7571 - val_loss: 1.7908 - val_acc: 0.4929\n",
            "Epoch 11/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5308 - acc: 0.8143 \n",
            "Epoch 11: val_acc did not improve from 0.49286\n",
            "8/8 [==============================] - 226s 29s/step - loss: 0.5308 - acc: 0.8143 - val_loss: 2.5086 - val_acc: 0.3857\n",
            "Epoch 12/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6021 - acc: 0.7939 \n",
            "Epoch 12: val_acc improved from 0.49286 to 0.60714, saving model to percobaan137_noImgPro/model\\vgg_16_137-saved-model-12-acc-0.61.hdf5\n",
            "8/8 [==============================] - 224s 30s/step - loss: 0.6021 - acc: 0.7939 - val_loss: 1.3239 - val_acc: 0.6071\n",
            "Epoch 13/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5621 - acc: 0.8122 \n",
            "Epoch 13: val_acc did not improve from 0.60714\n",
            "8/8 [==============================] - 225s 29s/step - loss: 0.5621 - acc: 0.8122 - val_loss: 1.8645 - val_acc: 0.5071\n",
            "Epoch 14/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5459 - acc: 0.8265 \n",
            "Epoch 14: val_acc did not improve from 0.60714\n",
            "8/8 [==============================] - 245s 32s/step - loss: 0.5459 - acc: 0.8265 - val_loss: 2.6803 - val_acc: 0.3643\n",
            "Epoch 15/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5482 - acc: 0.8143 \n",
            "Epoch 15: val_acc did not improve from 0.60714\n",
            "8/8 [==============================] - 260s 33s/step - loss: 0.5482 - acc: 0.8143 - val_loss: 1.6437 - val_acc: 0.4786\n",
            "Epoch 16/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5635 - acc: 0.8102 \n",
            "Epoch 16: val_acc did not improve from 0.60714\n",
            "8/8 [==============================] - 261s 34s/step - loss: 0.5635 - acc: 0.8102 - val_loss: 1.5008 - val_acc: 0.4643\n",
            "Epoch 17/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7079 - acc: 0.7776 \n",
            "Epoch 17: val_acc improved from 0.60714 to 0.78571, saving model to percobaan137_noImgPro/model\\vgg_16_137-saved-model-17-acc-0.79.hdf5\n",
            "8/8 [==============================] - 233s 30s/step - loss: 0.7079 - acc: 0.7776 - val_loss: 0.7619 - val_acc: 0.7857\n",
            "Epoch 18/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5428 - acc: 0.8122 \n",
            "Epoch 18: val_acc did not improve from 0.78571\n",
            "8/8 [==============================] - 234s 30s/step - loss: 0.5428 - acc: 0.8122 - val_loss: 2.0542 - val_acc: 0.5500\n",
            "Epoch 19/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5910 - acc: 0.8041 \n",
            "Epoch 19: val_acc did not improve from 0.78571\n",
            "8/8 [==============================] - 234s 30s/step - loss: 0.5910 - acc: 0.8041 - val_loss: 1.6717 - val_acc: 0.5786\n",
            "Epoch 20/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6351 - acc: 0.8020 \n",
            "Epoch 20: val_acc did not improve from 0.78571\n",
            "8/8 [==============================] - 234s 30s/step - loss: 0.6351 - acc: 0.8020 - val_loss: 3.0157 - val_acc: 0.4714\n",
            "Epoch 21/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6725 - acc: 0.7959 \n",
            "Epoch 21: val_acc did not improve from 0.78571\n",
            "8/8 [==============================] - 232s 30s/step - loss: 0.6725 - acc: 0.7959 - val_loss: 1.9020 - val_acc: 0.5643\n",
            "Epoch 22/51\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6790 - acc: 0.8327 \n",
            "Epoch 22: val_acc did not improve from 0.78571\n",
            "8/8 [==============================] - 232s 30s/step - loss: 0.6790 - acc: 0.8327 - val_loss: 1.8956 - val_acc: 0.5929\n",
            "\n",
            "\n",
            "Model Accuracy 0.4857142857142857\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.30      0.46        10\n",
            "       10000       0.34      1.00      0.51        10\n",
            "      100000       1.00      0.30      0.46        10\n",
            "        2000       0.42      0.80      0.55        10\n",
            "       20000       0.00      0.00      0.00        10\n",
            "        5000       1.00      0.10      0.18        10\n",
            "       50000       0.64      0.90      0.75        10\n",
            "\n",
            "    accuracy                           0.49        70\n",
            "   macro avg       0.63      0.49      0.42        70\n",
            "weighted avg       0.63      0.49      0.42        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 138 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 55\n",
            "learning rate: 0.08278317949570832\n",
            "batch size: 64\n",
            "dropout rate: 0.6152115694732275\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 3.3066 - acc: 0.2592 \n",
            "Epoch 1: val_acc improved from -inf to 0.23571, saving model to percobaan138_noImgPro/model\\vgg_16_138-saved-model-01-acc-0.24.hdf5\n",
            "8/8 [==============================] - 223s 28s/step - loss: 3.3066 - acc: 0.2592 - val_loss: 14.9101 - val_acc: 0.2357\n",
            "Epoch 2/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.9157 - acc: 0.4347 \n",
            "Epoch 2: val_acc did not improve from 0.23571\n",
            "8/8 [==============================] - 221s 28s/step - loss: 1.9157 - acc: 0.4347 - val_loss: 8.2805 - val_acc: 0.2000\n",
            "Epoch 3/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7104 - acc: 0.4898 \n",
            "Epoch 3: val_acc did not improve from 0.23571\n",
            "8/8 [==============================] - 223s 29s/step - loss: 1.7104 - acc: 0.4898 - val_loss: 8.0702 - val_acc: 0.2286\n",
            "Epoch 4/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4664 - acc: 0.5388 \n",
            "Epoch 4: val_acc did not improve from 0.23571\n",
            "8/8 [==============================] - 223s 29s/step - loss: 1.4664 - acc: 0.5388 - val_loss: 7.2199 - val_acc: 0.1643\n",
            "Epoch 5/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1879 - acc: 0.5878 \n",
            "Epoch 5: val_acc improved from 0.23571 to 0.32857, saving model to percobaan138_noImgPro/model\\vgg_16_138-saved-model-05-acc-0.33.hdf5\n",
            "8/8 [==============================] - 226s 29s/step - loss: 1.1879 - acc: 0.5878 - val_loss: 3.9334 - val_acc: 0.3286\n",
            "Epoch 6/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0808 - acc: 0.6184 \n",
            "Epoch 6: val_acc improved from 0.32857 to 0.42857, saving model to percobaan138_noImgPro/model\\vgg_16_138-saved-model-06-acc-0.43.hdf5\n",
            "8/8 [==============================] - 223s 29s/step - loss: 1.0808 - acc: 0.6184 - val_loss: 2.6110 - val_acc: 0.4286\n",
            "Epoch 7/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8579 - acc: 0.7000 \n",
            "Epoch 7: val_acc did not improve from 0.42857\n",
            "8/8 [==============================] - 227s 29s/step - loss: 0.8579 - acc: 0.7000 - val_loss: 3.2202 - val_acc: 0.3429\n",
            "Epoch 8/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8514 - acc: 0.7041 \n",
            "Epoch 8: val_acc did not improve from 0.42857\n",
            "8/8 [==============================] - 224s 29s/step - loss: 0.8514 - acc: 0.7041 - val_loss: 2.9163 - val_acc: 0.3357\n",
            "Epoch 9/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7223 - acc: 0.7796 \n",
            "Epoch 9: val_acc improved from 0.42857 to 0.60714, saving model to percobaan138_noImgPro/model\\vgg_16_138-saved-model-09-acc-0.61.hdf5\n",
            "8/8 [==============================] - 226s 29s/step - loss: 0.7223 - acc: 0.7796 - val_loss: 1.3026 - val_acc: 0.6071\n",
            "Epoch 10/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7567 - acc: 0.7531 \n",
            "Epoch 10: val_acc did not improve from 0.60714\n",
            "8/8 [==============================] - 226s 29s/step - loss: 0.7567 - acc: 0.7531 - val_loss: 1.4025 - val_acc: 0.5857\n",
            "Epoch 11/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6596 - acc: 0.7714 \n",
            "Epoch 11: val_acc did not improve from 0.60714\n",
            "8/8 [==============================] - 225s 29s/step - loss: 0.6596 - acc: 0.7714 - val_loss: 1.6862 - val_acc: 0.5643\n",
            "Epoch 12/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7090 - acc: 0.7673 \n",
            "Epoch 12: val_acc did not improve from 0.60714\n",
            "8/8 [==============================] - 226s 29s/step - loss: 0.7090 - acc: 0.7673 - val_loss: 1.7588 - val_acc: 0.5714\n",
            "Epoch 13/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6990 - acc: 0.7673 \n",
            "Epoch 13: val_acc did not improve from 0.60714\n",
            "8/8 [==============================] - 222s 29s/step - loss: 0.6990 - acc: 0.7673 - val_loss: 1.8880 - val_acc: 0.5143\n",
            "Epoch 14/55\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6904 - acc: 0.7857 \n",
            "Epoch 14: val_acc did not improve from 0.60714\n",
            "8/8 [==============================] - 205s 26s/step - loss: 0.6904 - acc: 0.7857 - val_loss: 1.4723 - val_acc: 0.5286\n",
            "\n",
            "\n",
            "Model Accuracy 0.5142857142857142\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.40      0.57        10\n",
            "       10000       0.69      0.90      0.78        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       1.00      0.20      0.33        10\n",
            "       20000       1.00      0.10      0.18        10\n",
            "        5000       0.36      1.00      0.53        10\n",
            "       50000       0.45      1.00      0.62        10\n",
            "\n",
            "    accuracy                           0.51        70\n",
            "   macro avg       0.64      0.51      0.43        70\n",
            "weighted avg       0.64      0.51      0.43        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 139 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 54\n",
            "learning rate: 0.09555647787330854\n",
            "batch size: 64\n",
            "dropout rate: 0.6812347897124326\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 3.7831 - acc: 0.2265 \n",
            "Epoch 1: val_acc improved from -inf to 0.18571, saving model to percobaan139_noImgPro/model\\vgg_16_139-saved-model-01-acc-0.19.hdf5\n",
            "8/8 [==============================] - 195s 25s/step - loss: 3.7831 - acc: 0.2265 - val_loss: 15.2418 - val_acc: 0.1857\n",
            "Epoch 2/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.9785 - acc: 0.3265 \n",
            "Epoch 2: val_acc improved from 0.18571 to 0.29286, saving model to percobaan139_noImgPro/model\\vgg_16_139-saved-model-02-acc-0.29.hdf5\n",
            "8/8 [==============================] - 203s 26s/step - loss: 2.9785 - acc: 0.3265 - val_loss: 3.5855 - val_acc: 0.2929\n",
            "Epoch 3/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.1417 - acc: 0.3388 \n",
            "Epoch 3: val_acc did not improve from 0.29286\n",
            "8/8 [==============================] - 217s 28s/step - loss: 2.1417 - acc: 0.3388 - val_loss: 2.6066 - val_acc: 0.2714\n",
            "Epoch 4/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7586 - acc: 0.3816 \n",
            "Epoch 4: val_acc did not improve from 0.29286\n",
            "8/8 [==============================] - 217s 28s/step - loss: 1.7586 - acc: 0.3816 - val_loss: 5.3489 - val_acc: 0.1500\n",
            "Epoch 5/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5151 - acc: 0.4653 \n",
            "Epoch 5: val_acc did not improve from 0.29286\n",
            "8/8 [==============================] - 217s 28s/step - loss: 1.5151 - acc: 0.4653 - val_loss: 4.0993 - val_acc: 0.2429\n",
            "Epoch 6/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4499 - acc: 0.5245 \n",
            "Epoch 6: val_acc improved from 0.29286 to 0.31429, saving model to percobaan139_noImgPro/model\\vgg_16_139-saved-model-06-acc-0.31.hdf5\n",
            "8/8 [==============================] - 208s 27s/step - loss: 1.4499 - acc: 0.5245 - val_loss: 3.9960 - val_acc: 0.3143\n",
            "Epoch 7/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3324 - acc: 0.5653 \n",
            "Epoch 7: val_acc improved from 0.31429 to 0.34286, saving model to percobaan139_noImgPro/model\\vgg_16_139-saved-model-07-acc-0.34.hdf5\n",
            "8/8 [==============================] - 196s 25s/step - loss: 1.3324 - acc: 0.5653 - val_loss: 2.6316 - val_acc: 0.3429\n",
            "Epoch 8/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1838 - acc: 0.6245 \n",
            "Epoch 8: val_acc did not improve from 0.34286\n",
            "8/8 [==============================] - 197s 25s/step - loss: 1.1838 - acc: 0.6245 - val_loss: 2.3768 - val_acc: 0.3357\n",
            "Epoch 9/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0497 - acc: 0.6531 \n",
            "Epoch 9: val_acc improved from 0.34286 to 0.45000, saving model to percobaan139_noImgPro/model\\vgg_16_139-saved-model-09-acc-0.45.hdf5\n",
            "8/8 [==============================] - 196s 26s/step - loss: 1.0497 - acc: 0.6531 - val_loss: 1.4452 - val_acc: 0.4500\n",
            "Epoch 10/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0133 - acc: 0.6327 \n",
            "Epoch 10: val_acc improved from 0.45000 to 0.60714, saving model to percobaan139_noImgPro/model\\vgg_16_139-saved-model-10-acc-0.61.hdf5\n",
            "8/8 [==============================] - 195s 25s/step - loss: 1.0133 - acc: 0.6327 - val_loss: 1.1382 - val_acc: 0.6071\n",
            "Epoch 11/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9708 - acc: 0.6551 \n",
            "Epoch 11: val_acc did not improve from 0.60714\n",
            "8/8 [==============================] - 193s 25s/step - loss: 0.9708 - acc: 0.6551 - val_loss: 1.3323 - val_acc: 0.6071\n",
            "Epoch 12/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9723 - acc: 0.6959 \n",
            "Epoch 12: val_acc improved from 0.60714 to 0.62857, saving model to percobaan139_noImgPro/model\\vgg_16_139-saved-model-12-acc-0.63.hdf5\n",
            "8/8 [==============================] - 197s 25s/step - loss: 0.9723 - acc: 0.6959 - val_loss: 1.0502 - val_acc: 0.6286\n",
            "Epoch 13/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9253 - acc: 0.6816 \n",
            "Epoch 13: val_acc improved from 0.62857 to 0.65000, saving model to percobaan139_noImgPro/model\\vgg_16_139-saved-model-13-acc-0.65.hdf5\n",
            "8/8 [==============================] - 196s 25s/step - loss: 0.9253 - acc: 0.6816 - val_loss: 1.1229 - val_acc: 0.6500\n",
            "Epoch 14/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0357 - acc: 0.6714 \n",
            "Epoch 14: val_acc did not improve from 0.65000\n",
            "8/8 [==============================] - 198s 25s/step - loss: 1.0357 - acc: 0.6714 - val_loss: 1.2673 - val_acc: 0.6143\n",
            "Epoch 15/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9363 - acc: 0.7204 \n",
            "Epoch 15: val_acc did not improve from 0.65000\n",
            "8/8 [==============================] - 197s 25s/step - loss: 0.9363 - acc: 0.7204 - val_loss: 1.2966 - val_acc: 0.5714\n",
            "Epoch 16/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9366 - acc: 0.7061 \n",
            "Epoch 16: val_acc improved from 0.65000 to 0.67857, saving model to percobaan139_noImgPro/model\\vgg_16_139-saved-model-16-acc-0.68.hdf5\n",
            "8/8 [==============================] - 197s 25s/step - loss: 0.9366 - acc: 0.7061 - val_loss: 1.0132 - val_acc: 0.6786\n",
            "Epoch 17/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8619 - acc: 0.7204 \n",
            "Epoch 17: val_acc improved from 0.67857 to 0.75000, saving model to percobaan139_noImgPro/model\\vgg_16_139-saved-model-17-acc-0.75.hdf5\n",
            "8/8 [==============================] - 196s 25s/step - loss: 0.8619 - acc: 0.7204 - val_loss: 0.8341 - val_acc: 0.7500\n",
            "Epoch 18/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8034 - acc: 0.7327 \n",
            "Epoch 18: val_acc improved from 0.75000 to 0.83571, saving model to percobaan139_noImgPro/model\\vgg_16_139-saved-model-18-acc-0.84.hdf5\n",
            "8/8 [==============================] - 196s 25s/step - loss: 0.8034 - acc: 0.7327 - val_loss: 0.6071 - val_acc: 0.8357\n",
            "Epoch 19/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7839 - acc: 0.7408 \n",
            "Epoch 19: val_acc did not improve from 0.83571\n",
            "8/8 [==============================] - 195s 25s/step - loss: 0.7839 - acc: 0.7408 - val_loss: 0.6927 - val_acc: 0.7643\n",
            "Epoch 20/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7391 - acc: 0.7796 \n",
            "Epoch 20: val_acc did not improve from 0.83571\n",
            "8/8 [==============================] - 200s 25s/step - loss: 0.7391 - acc: 0.7796 - val_loss: 0.6813 - val_acc: 0.8286\n",
            "Epoch 21/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8237 - acc: 0.7510 \n",
            "Epoch 21: val_acc did not improve from 0.83571\n",
            "8/8 [==============================] - 197s 25s/step - loss: 0.8237 - acc: 0.7510 - val_loss: 0.9941 - val_acc: 0.7286\n",
            "Epoch 22/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8658 - acc: 0.7571 \n",
            "Epoch 22: val_acc did not improve from 0.83571\n",
            "8/8 [==============================] - 197s 25s/step - loss: 0.8658 - acc: 0.7571 - val_loss: 1.5989 - val_acc: 0.5357\n",
            "Epoch 23/54\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8213 - acc: 0.7653 \n",
            "Epoch 23: val_acc did not improve from 0.83571\n",
            "8/8 [==============================] - 196s 25s/step - loss: 0.8213 - acc: 0.7653 - val_loss: 0.8092 - val_acc: 0.8143\n",
            "\n",
            "\n",
            "Model Accuracy 0.7285714285714285\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.89      0.80      0.84        10\n",
            "       10000       0.69      0.90      0.78        10\n",
            "      100000       1.00      0.60      0.75        10\n",
            "        2000       0.75      0.60      0.67        10\n",
            "       20000       1.00      0.40      0.57        10\n",
            "        5000       0.50      1.00      0.67        10\n",
            "       50000       0.80      0.80      0.80        10\n",
            "\n",
            "    accuracy                           0.73        70\n",
            "   macro avg       0.80      0.73      0.73        70\n",
            "weighted avg       0.80      0.73      0.73        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 140 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 49\n",
            "learning rate: 0.08492787255187502\n",
            "batch size: 64\n",
            "dropout rate: 0.780123805257467\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 4.1049 - acc: 0.2327 \n",
            "Epoch 1: val_acc improved from -inf to 0.23571, saving model to percobaan140_noImgPro/model\\vgg_16_140-saved-model-01-acc-0.24.hdf5\n",
            "8/8 [==============================] - 189s 24s/step - loss: 4.1049 - acc: 0.2327 - val_loss: 14.3874 - val_acc: 0.2357\n",
            "Epoch 2/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 3.4984 - acc: 0.2592 \n",
            "Epoch 2: val_acc did not improve from 0.23571\n",
            "8/8 [==============================] - 188s 24s/step - loss: 3.4984 - acc: 0.2592 - val_loss: 6.6881 - val_acc: 0.1857\n",
            "Epoch 3/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.3439 - acc: 0.3490 \n",
            "Epoch 3: val_acc did not improve from 0.23571\n",
            "8/8 [==============================] - 189s 24s/step - loss: 2.3439 - acc: 0.3490 - val_loss: 3.0671 - val_acc: 0.1643\n",
            "Epoch 4/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.0884 - acc: 0.3306 \n",
            "Epoch 4: val_acc did not improve from 0.23571\n",
            "8/8 [==============================] - 192s 25s/step - loss: 2.0884 - acc: 0.3306 - val_loss: 3.0208 - val_acc: 0.1429\n",
            "Epoch 5/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8256 - acc: 0.2980 \n",
            "Epoch 5: val_acc did not improve from 0.23571\n",
            "8/8 [==============================] - 189s 24s/step - loss: 1.8256 - acc: 0.2980 - val_loss: 3.0158 - val_acc: 0.1571\n",
            "Epoch 6/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7029 - acc: 0.3469 \n",
            "Epoch 6: val_acc did not improve from 0.23571\n",
            "8/8 [==============================] - 190s 24s/step - loss: 1.7029 - acc: 0.3469 - val_loss: 3.2056 - val_acc: 0.1429\n",
            "Epoch 7/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6663 - acc: 0.4245 \n",
            "Epoch 7: val_acc did not improve from 0.23571\n",
            "8/8 [==============================] - 192s 25s/step - loss: 1.6663 - acc: 0.4245 - val_loss: 2.9697 - val_acc: 0.1714\n",
            "Epoch 8/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4149 - acc: 0.4837 \n",
            "Epoch 8: val_acc did not improve from 0.23571\n",
            "8/8 [==============================] - 192s 25s/step - loss: 1.4149 - acc: 0.4837 - val_loss: 3.1264 - val_acc: 0.1643\n",
            "Epoch 9/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4804 - acc: 0.5143 \n",
            "Epoch 9: val_acc did not improve from 0.23571\n",
            "8/8 [==============================] - 192s 25s/step - loss: 1.4804 - acc: 0.5143 - val_loss: 2.4801 - val_acc: 0.2071\n",
            "Epoch 10/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4355 - acc: 0.4918 \n",
            "Epoch 10: val_acc improved from 0.23571 to 0.32143, saving model to percobaan140_noImgPro/model\\vgg_16_140-saved-model-10-acc-0.32.hdf5\n",
            "8/8 [==============================] - 192s 25s/step - loss: 1.4355 - acc: 0.4918 - val_loss: 2.6085 - val_acc: 0.3214\n",
            "Epoch 11/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4650 - acc: 0.4857 \n",
            "Epoch 11: val_acc did not improve from 0.32143\n",
            "8/8 [==============================] - 191s 25s/step - loss: 1.4650 - acc: 0.4857 - val_loss: 2.3510 - val_acc: 0.2786\n",
            "Epoch 12/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3105 - acc: 0.5061 \n",
            "Epoch 12: val_acc did not improve from 0.32143\n",
            "8/8 [==============================] - 190s 24s/step - loss: 1.3105 - acc: 0.5061 - val_loss: 2.4632 - val_acc: 0.2357\n",
            "Epoch 13/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.2650 - acc: 0.5551 \n",
            "Epoch 13: val_acc did not improve from 0.32143\n",
            "8/8 [==============================] - 192s 25s/step - loss: 1.2650 - acc: 0.5551 - val_loss: 3.0992 - val_acc: 0.2214\n",
            "Epoch 14/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1145 - acc: 0.5857 \n",
            "Epoch 14: val_acc did not improve from 0.32143\n",
            "8/8 [==============================] - 191s 24s/step - loss: 1.1145 - acc: 0.5857 - val_loss: 2.7893 - val_acc: 0.2286\n",
            "Epoch 15/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0919 - acc: 0.6429 \n",
            "Epoch 15: val_acc improved from 0.32143 to 0.41429, saving model to percobaan140_noImgPro/model\\vgg_16_140-saved-model-15-acc-0.41.hdf5\n",
            "8/8 [==============================] - 193s 26s/step - loss: 1.0919 - acc: 0.6429 - val_loss: 2.3149 - val_acc: 0.4143\n",
            "Epoch 16/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1464 - acc: 0.6122 \n",
            "Epoch 16: val_acc improved from 0.41429 to 0.50714, saving model to percobaan140_noImgPro/model\\vgg_16_140-saved-model-16-acc-0.51.hdf5\n",
            "8/8 [==============================] - 193s 25s/step - loss: 1.1464 - acc: 0.6122 - val_loss: 1.6241 - val_acc: 0.5071\n",
            "Epoch 17/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1496 - acc: 0.6388 \n",
            "Epoch 17: val_acc did not improve from 0.50714\n",
            "8/8 [==============================] - 194s 25s/step - loss: 1.1496 - acc: 0.6388 - val_loss: 1.4796 - val_acc: 0.5000\n",
            "Epoch 18/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1015 - acc: 0.6245 \n",
            "Epoch 18: val_acc did not improve from 0.50714\n",
            "8/8 [==============================] - 196s 25s/step - loss: 1.1015 - acc: 0.6245 - val_loss: 1.3914 - val_acc: 0.4929\n",
            "Epoch 19/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1322 - acc: 0.5918 \n",
            "Epoch 19: val_acc did not improve from 0.50714\n",
            "8/8 [==============================] - 196s 26s/step - loss: 1.1322 - acc: 0.5918 - val_loss: 1.2923 - val_acc: 0.5000\n",
            "Epoch 20/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9947 - acc: 0.6694 \n",
            "Epoch 20: val_acc improved from 0.50714 to 0.52857, saving model to percobaan140_noImgPro/model\\vgg_16_140-saved-model-20-acc-0.53.hdf5\n",
            "8/8 [==============================] - 197s 25s/step - loss: 0.9947 - acc: 0.6694 - val_loss: 1.4775 - val_acc: 0.5286\n",
            "Epoch 21/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1102 - acc: 0.6306 \n",
            "Epoch 21: val_acc improved from 0.52857 to 0.62143, saving model to percobaan140_noImgPro/model\\vgg_16_140-saved-model-21-acc-0.62.hdf5\n",
            "8/8 [==============================] - 196s 25s/step - loss: 1.1102 - acc: 0.6306 - val_loss: 1.2083 - val_acc: 0.6214\n",
            "Epoch 22/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1061 - acc: 0.6490 \n",
            "Epoch 22: val_acc did not improve from 0.62143\n",
            "8/8 [==============================] - 198s 25s/step - loss: 1.1061 - acc: 0.6490 - val_loss: 1.5863 - val_acc: 0.5714\n",
            "Epoch 23/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9993 - acc: 0.6735 \n",
            "Epoch 23: val_acc did not improve from 0.62143\n",
            "8/8 [==============================] - 197s 25s/step - loss: 0.9993 - acc: 0.6735 - val_loss: 1.9667 - val_acc: 0.4714\n",
            "Epoch 24/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9454 - acc: 0.6735 \n",
            "Epoch 24: val_acc did not improve from 0.62143\n",
            "8/8 [==============================] - 196s 25s/step - loss: 0.9454 - acc: 0.6735 - val_loss: 1.4380 - val_acc: 0.5357\n",
            "Epoch 25/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0021 - acc: 0.6592 \n",
            "Epoch 25: val_acc did not improve from 0.62143\n",
            "8/8 [==============================] - 195s 25s/step - loss: 1.0021 - acc: 0.6592 - val_loss: 2.0537 - val_acc: 0.5500\n",
            "Epoch 26/49\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9306 - acc: 0.6918 \n",
            "Epoch 26: val_acc did not improve from 0.62143\n",
            "8/8 [==============================] - 197s 25s/step - loss: 0.9306 - acc: 0.6918 - val_loss: 2.8150 - val_acc: 0.4500\n",
            "\n",
            "\n",
            "Model Accuracy 0.32857142857142857\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.30      0.46        10\n",
            "       10000       0.20      1.00      0.33        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.67      0.20      0.31        10\n",
            "       20000       0.55      0.60      0.57        10\n",
            "        5000       0.67      0.20      0.31        10\n",
            "       50000       0.00      0.00      0.00        10\n",
            "\n",
            "    accuracy                           0.33        70\n",
            "   macro avg       0.44      0.33      0.28        70\n",
            "weighted avg       0.44      0.33      0.28        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 141 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 52\n",
            "learning rate: 0.07894636706621386\n",
            "batch size: 128\n",
            "dropout rate: 0.5016180082311374\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.8178 - acc: 0.3082 \n",
            "Epoch 1: val_acc improved from -inf to 0.14286, saving model to percobaan141_noImgPro/model\\vgg_16_141-saved-model-01-acc-0.14.hdf5\n",
            "4/4 [==============================] - 195s 51s/step - loss: 2.8178 - acc: 0.3082 - val_loss: 12.9070 - val_acc: 0.1429\n",
            "Epoch 2/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.6973 - acc: 0.4939 \n",
            "Epoch 2: val_acc improved from 0.14286 to 0.26429, saving model to percobaan141_noImgPro/model\\vgg_16_141-saved-model-02-acc-0.26.hdf5\n",
            "4/4 [==============================] - 193s 53s/step - loss: 1.6973 - acc: 0.4939 - val_loss: 6.0189 - val_acc: 0.2643\n",
            "Epoch 3/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2393 - acc: 0.5673 \n",
            "Epoch 3: val_acc improved from 0.26429 to 0.32857, saving model to percobaan141_noImgPro/model\\vgg_16_141-saved-model-03-acc-0.33.hdf5\n",
            "4/4 [==============================] - 192s 53s/step - loss: 1.2393 - acc: 0.5673 - val_loss: 4.1392 - val_acc: 0.3286\n",
            "Epoch 4/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9508 - acc: 0.6673 \n",
            "Epoch 4: val_acc did not improve from 0.32857\n",
            "4/4 [==============================] - 192s 51s/step - loss: 0.9508 - acc: 0.6673 - val_loss: 8.8382 - val_acc: 0.1857\n",
            "Epoch 5/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8432 - acc: 0.6939 \n",
            "Epoch 5: val_acc did not improve from 0.32857\n",
            "4/4 [==============================] - 194s 51s/step - loss: 0.8432 - acc: 0.6939 - val_loss: 9.2638 - val_acc: 0.2429\n",
            "Epoch 6/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6463 - acc: 0.7898 \n",
            "Epoch 6: val_acc did not improve from 0.32857\n",
            "4/4 [==============================] - 195s 51s/step - loss: 0.6463 - acc: 0.7898 - val_loss: 5.1666 - val_acc: 0.3000\n",
            "Epoch 7/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6286 - acc: 0.7816 \n",
            "Epoch 7: val_acc improved from 0.32857 to 0.40000, saving model to percobaan141_noImgPro/model\\vgg_16_141-saved-model-07-acc-0.40.hdf5\n",
            "4/4 [==============================] - 194s 54s/step - loss: 0.6286 - acc: 0.7816 - val_loss: 3.6402 - val_acc: 0.4000\n",
            "Epoch 8/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5434 - acc: 0.8102 \n",
            "Epoch 8: val_acc improved from 0.40000 to 0.41429, saving model to percobaan141_noImgPro/model\\vgg_16_141-saved-model-08-acc-0.41.hdf5\n",
            "4/4 [==============================] - 193s 51s/step - loss: 0.5434 - acc: 0.8102 - val_loss: 2.9077 - val_acc: 0.4143\n",
            "Epoch 9/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5434 - acc: 0.8224 \n",
            "Epoch 9: val_acc did not improve from 0.41429\n",
            "4/4 [==============================] - 192s 51s/step - loss: 0.5434 - acc: 0.8224 - val_loss: 2.3618 - val_acc: 0.4000\n",
            "Epoch 10/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4248 - acc: 0.8531 \n",
            "Epoch 10: val_acc did not improve from 0.41429\n",
            "4/4 [==============================] - 196s 52s/step - loss: 0.4248 - acc: 0.8531 - val_loss: 2.8326 - val_acc: 0.3786\n",
            "Epoch 11/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4214 - acc: 0.8551 \n",
            "Epoch 11: val_acc did not improve from 0.41429\n",
            "4/4 [==============================] - 192s 51s/step - loss: 0.4214 - acc: 0.8551 - val_loss: 4.3001 - val_acc: 0.2571\n",
            "Epoch 12/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4027 - acc: 0.8449 \n",
            "Epoch 12: val_acc did not improve from 0.41429\n",
            "4/4 [==============================] - 193s 51s/step - loss: 0.4027 - acc: 0.8449 - val_loss: 5.1206 - val_acc: 0.2429\n",
            "Epoch 13/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3479 - acc: 0.8878 \n",
            "Epoch 13: val_acc did not improve from 0.41429\n",
            "4/4 [==============================] - 194s 51s/step - loss: 0.3479 - acc: 0.8878 - val_loss: 4.5878 - val_acc: 0.2714\n",
            "Epoch 14/52\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3109 - acc: 0.8918 \n",
            "Epoch 14: val_acc did not improve from 0.41429\n",
            "4/4 [==============================] - 193s 51s/step - loss: 0.3109 - acc: 0.8918 - val_loss: 3.9186 - val_acc: 0.3214\n",
            "\n",
            "\n",
            "Model Accuracy 0.24285714285714285\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.20      0.33        10\n",
            "       10000       1.00      0.20      0.33        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.50      0.30      0.37        10\n",
            "       20000       0.00      0.00      0.00        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       0.17      1.00      0.29        10\n",
            "\n",
            "    accuracy                           0.24        70\n",
            "   macro avg       0.38      0.24      0.19        70\n",
            "weighted avg       0.38      0.24      0.19        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 142 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 51\n",
            "learning rate: 0.07962391653178104\n",
            "batch size: 128\n",
            "dropout rate: 0.6358311186305512\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.9815 - acc: 0.2449 \n",
            "Epoch 1: val_acc improved from -inf to 0.17857, saving model to percobaan142_noImgPro/model\\vgg_16_142-saved-model-01-acc-0.18.hdf5\n",
            "4/4 [==============================] - 189s 52s/step - loss: 2.9815 - acc: 0.2449 - val_loss: 12.2968 - val_acc: 0.1786\n",
            "Epoch 2/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.2276 - acc: 0.4347 \n",
            "Epoch 2: val_acc improved from 0.17857 to 0.19286, saving model to percobaan142_noImgPro/model\\vgg_16_142-saved-model-02-acc-0.19.hdf5\n",
            "4/4 [==============================] - 188s 53s/step - loss: 2.2276 - acc: 0.4347 - val_loss: 14.7638 - val_acc: 0.1929\n",
            "Epoch 3/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.7446 - acc: 0.5163 \n",
            "Epoch 3: val_acc improved from 0.19286 to 0.20714, saving model to percobaan142_noImgPro/model\\vgg_16_142-saved-model-03-acc-0.21.hdf5\n",
            "4/4 [==============================] - 194s 52s/step - loss: 1.7446 - acc: 0.5163 - val_loss: 9.1686 - val_acc: 0.2071\n",
            "Epoch 4/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.4531 - acc: 0.5449 \n",
            "Epoch 4: val_acc did not improve from 0.20714\n",
            "4/4 [==============================] - 191s 53s/step - loss: 1.4531 - acc: 0.5449 - val_loss: 7.0208 - val_acc: 0.1714\n",
            "Epoch 5/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1116 - acc: 0.6306 \n",
            "Epoch 5: val_acc did not improve from 0.20714\n",
            "4/4 [==============================] - 189s 50s/step - loss: 1.1116 - acc: 0.6306 - val_loss: 5.0890 - val_acc: 0.1500\n",
            "Epoch 6/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0458 - acc: 0.6531 \n",
            "Epoch 6: val_acc improved from 0.20714 to 0.26429, saving model to percobaan142_noImgPro/model\\vgg_16_142-saved-model-06-acc-0.26.hdf5\n",
            "4/4 [==============================] - 192s 51s/step - loss: 1.0458 - acc: 0.6531 - val_loss: 3.0052 - val_acc: 0.2643\n",
            "Epoch 7/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8845 - acc: 0.6796 \n",
            "Epoch 7: val_acc improved from 0.26429 to 0.32143, saving model to percobaan142_noImgPro/model\\vgg_16_142-saved-model-07-acc-0.32.hdf5\n",
            "4/4 [==============================] - 194s 54s/step - loss: 0.8845 - acc: 0.6796 - val_loss: 3.8530 - val_acc: 0.3214\n",
            "Epoch 8/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8417 - acc: 0.6939 \n",
            "Epoch 8: val_acc improved from 0.32143 to 0.39286, saving model to percobaan142_noImgPro/model\\vgg_16_142-saved-model-08-acc-0.39.hdf5\n",
            "4/4 [==============================] - 193s 53s/step - loss: 0.8417 - acc: 0.6939 - val_loss: 3.1970 - val_acc: 0.3929\n",
            "Epoch 9/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7917 - acc: 0.7327 \n",
            "Epoch 9: val_acc did not improve from 0.39286\n",
            "4/4 [==============================] - 193s 53s/step - loss: 0.7917 - acc: 0.7327 - val_loss: 3.4093 - val_acc: 0.3857\n",
            "Epoch 10/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7029 - acc: 0.7531 \n",
            "Epoch 10: val_acc did not improve from 0.39286\n",
            "4/4 [==============================] - 192s 53s/step - loss: 0.7029 - acc: 0.7531 - val_loss: 3.5082 - val_acc: 0.3786\n",
            "Epoch 11/51\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6156 - acc: 0.7918 \n",
            "Epoch 11: val_acc improved from 0.39286 to 0.40714, saving model to percobaan142_noImgPro/model\\vgg_16_142-saved-model-11-acc-0.41.hdf5\n",
            "4/4 [==============================] - 191s 53s/step - loss: 0.6156 - acc: 0.7918 - val_loss: 3.0989 - val_acc: 0.4071\n",
            "\n",
            "\n",
            "Model Accuracy 0.2571428571428571\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.30      0.46        10\n",
            "       10000       0.00      0.00      0.00        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.50      0.10      0.17        10\n",
            "       20000       0.22      0.50      0.30        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       0.21      0.90      0.35        10\n",
            "\n",
            "    accuracy                           0.26        70\n",
            "   macro avg       0.28      0.26      0.18        70\n",
            "weighted avg       0.28      0.26      0.18        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 143 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 49\n",
            "learning rate: 0.07793649304904797\n",
            "batch size: 128\n",
            "dropout rate: 0.6616032968211005\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 3.2243 - acc: 0.2673 \n",
            "Epoch 1: val_acc improved from -inf to 0.22143, saving model to percobaan143_noImgPro/model\\vgg_16_143-saved-model-01-acc-0.22.hdf5\n",
            "4/4 [==============================] - 190s 51s/step - loss: 3.2243 - acc: 0.2673 - val_loss: 5.7669 - val_acc: 0.2214\n",
            "Epoch 2/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.4005 - acc: 0.3245 \n",
            "Epoch 2: val_acc did not improve from 0.22143\n",
            "4/4 [==============================] - 188s 50s/step - loss: 2.4005 - acc: 0.3245 - val_loss: 6.7505 - val_acc: 0.1429\n",
            "Epoch 3/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.8756 - acc: 0.4633 \n",
            "Epoch 3: val_acc improved from 0.22143 to 0.27143, saving model to percobaan143_noImgPro/model\\vgg_16_143-saved-model-03-acc-0.27.hdf5\n",
            "4/4 [==============================] - 187s 52s/step - loss: 1.8756 - acc: 0.4633 - val_loss: 3.3913 - val_acc: 0.2714\n",
            "Epoch 4/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.5228 - acc: 0.4714 \n",
            "Epoch 4: val_acc improved from 0.27143 to 0.30714, saving model to percobaan143_noImgPro/model\\vgg_16_143-saved-model-04-acc-0.31.hdf5\n",
            "4/4 [==============================] - 189s 52s/step - loss: 1.5228 - acc: 0.4714 - val_loss: 2.3407 - val_acc: 0.3071\n",
            "Epoch 5/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2979 - acc: 0.4959 \n",
            "Epoch 5: val_acc did not improve from 0.30714\n",
            "4/4 [==============================] - 191s 51s/step - loss: 1.2979 - acc: 0.4959 - val_loss: 2.9863 - val_acc: 0.2857\n",
            "Epoch 6/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2130 - acc: 0.5714 \n",
            "Epoch 6: val_acc did not improve from 0.30714\n",
            "4/4 [==============================] - 192s 51s/step - loss: 1.2130 - acc: 0.5714 - val_loss: 4.3687 - val_acc: 0.2214\n",
            "Epoch 7/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0924 - acc: 0.6184 \n",
            "Epoch 7: val_acc did not improve from 0.30714\n",
            "4/4 [==============================] - 191s 50s/step - loss: 1.0924 - acc: 0.6184 - val_loss: 5.1596 - val_acc: 0.2500\n",
            "Epoch 8/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9499 - acc: 0.6510 \n",
            "Epoch 8: val_acc did not improve from 0.30714\n",
            "4/4 [==============================] - 191s 51s/step - loss: 0.9499 - acc: 0.6510 - val_loss: 5.8189 - val_acc: 0.1786\n",
            "Epoch 9/49\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9452 - acc: 0.6571 \n",
            "Epoch 9: val_acc did not improve from 0.30714\n",
            "4/4 [==============================] - 191s 51s/step - loss: 0.9452 - acc: 0.6571 - val_loss: 6.3683 - val_acc: 0.2143\n",
            "\n",
            "\n",
            "Model Accuracy 0.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.10      0.18        10\n",
            "       10000       0.00      0.00      0.00        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.00      0.00      0.00        10\n",
            "       20000       0.16      1.00      0.27        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       0.50      0.30      0.37        10\n",
            "\n",
            "    accuracy                           0.20        70\n",
            "   macro avg       0.24      0.20      0.12        70\n",
            "weighted avg       0.24      0.20      0.12        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 144 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 53\n",
            "learning rate: 0.08708020858273174\n",
            "batch size: 128\n",
            "dropout rate: 0.7281884110811517\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 3.3316 - acc: 0.2245 \n",
            "Epoch 1: val_acc improved from -inf to 0.20000, saving model to percobaan144_noImgPro/model\\vgg_16_144-saved-model-01-acc-0.20.hdf5\n",
            "4/4 [==============================] - 189s 52s/step - loss: 3.3316 - acc: 0.2245 - val_loss: 16.2999 - val_acc: 0.2000\n",
            "Epoch 2/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.8069 - acc: 0.3429 \n",
            "Epoch 2: val_acc improved from 0.20000 to 0.24286, saving model to percobaan144_noImgPro/model\\vgg_16_144-saved-model-02-acc-0.24.hdf5\n",
            "4/4 [==============================] - 187s 52s/step - loss: 2.8069 - acc: 0.3429 - val_loss: 15.9943 - val_acc: 0.2429\n",
            "Epoch 3/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.2899 - acc: 0.3551 \n",
            "Epoch 3: val_acc did not improve from 0.24286\n",
            "4/4 [==============================] - 187s 50s/step - loss: 2.2899 - acc: 0.3551 - val_loss: 13.4643 - val_acc: 0.1643\n",
            "Epoch 4/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.9017 - acc: 0.4184 \n",
            "Epoch 4: val_acc did not improve from 0.24286\n",
            "4/4 [==============================] - 187s 49s/step - loss: 1.9017 - acc: 0.4184 - val_loss: 5.2360 - val_acc: 0.2286\n",
            "Epoch 5/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.5957 - acc: 0.4143 \n",
            "Epoch 5: val_acc improved from 0.24286 to 0.25714, saving model to percobaan144_noImgPro/model\\vgg_16_144-saved-model-05-acc-0.26.hdf5\n",
            "4/4 [==============================] - 187s 52s/step - loss: 1.5957 - acc: 0.4143 - val_loss: 4.1451 - val_acc: 0.2571\n",
            "Epoch 6/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.4584 - acc: 0.4510 \n",
            "Epoch 6: val_acc improved from 0.25714 to 0.28571, saving model to percobaan144_noImgPro/model\\vgg_16_144-saved-model-06-acc-0.29.hdf5\n",
            "4/4 [==============================] - 186s 52s/step - loss: 1.4584 - acc: 0.4510 - val_loss: 3.4322 - val_acc: 0.2857\n",
            "Epoch 7/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.3791 - acc: 0.5082 \n",
            "Epoch 7: val_acc improved from 0.28571 to 0.30714, saving model to percobaan144_noImgPro/model\\vgg_16_144-saved-model-07-acc-0.31.hdf5\n",
            "4/4 [==============================] - 187s 49s/step - loss: 1.3791 - acc: 0.5082 - val_loss: 3.5903 - val_acc: 0.3071\n",
            "Epoch 8/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2568 - acc: 0.5163 \n",
            "Epoch 8: val_acc did not improve from 0.30714\n",
            "4/4 [==============================] - 187s 52s/step - loss: 1.2568 - acc: 0.5163 - val_loss: 3.9615 - val_acc: 0.2286\n",
            "Epoch 9/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1491 - acc: 0.5469 \n",
            "Epoch 9: val_acc did not improve from 0.30714\n",
            "4/4 [==============================] - 185s 49s/step - loss: 1.1491 - acc: 0.5469 - val_loss: 3.5702 - val_acc: 0.2786\n",
            "Epoch 10/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0391 - acc: 0.6041 \n",
            "Epoch 10: val_acc improved from 0.30714 to 0.46429, saving model to percobaan144_noImgPro/model\\vgg_16_144-saved-model-10-acc-0.46.hdf5\n",
            "4/4 [==============================] - 186s 49s/step - loss: 1.0391 - acc: 0.6041 - val_loss: 2.7855 - val_acc: 0.4643\n",
            "Epoch 11/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0091 - acc: 0.6551 \n",
            "Epoch 11: val_acc did not improve from 0.46429\n",
            "4/4 [==============================] - 187s 50s/step - loss: 1.0091 - acc: 0.6551 - val_loss: 2.8444 - val_acc: 0.4571\n",
            "Epoch 12/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9483 - acc: 0.6633 \n",
            "Epoch 12: val_acc did not improve from 0.46429\n",
            "4/4 [==============================] - 187s 52s/step - loss: 0.9483 - acc: 0.6633 - val_loss: 2.7660 - val_acc: 0.4143\n",
            "Epoch 13/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9491 - acc: 0.6571 \n",
            "Epoch 13: val_acc did not improve from 0.46429\n",
            "4/4 [==============================] - 184s 49s/step - loss: 0.9491 - acc: 0.6571 - val_loss: 2.2007 - val_acc: 0.4071\n",
            "Epoch 14/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8914 - acc: 0.7082 \n",
            "Epoch 14: val_acc did not improve from 0.46429\n",
            "4/4 [==============================] - 186s 52s/step - loss: 0.8914 - acc: 0.7082 - val_loss: 2.3473 - val_acc: 0.4000\n",
            "Epoch 15/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9461 - acc: 0.6857 \n",
            "Epoch 15: val_acc did not improve from 0.46429\n",
            "4/4 [==============================] - 186s 49s/step - loss: 0.9461 - acc: 0.6857 - val_loss: 2.2868 - val_acc: 0.4571\n",
            "Epoch 16/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7974 - acc: 0.7122 \n",
            "Epoch 16: val_acc improved from 0.46429 to 0.48571, saving model to percobaan144_noImgPro/model\\vgg_16_144-saved-model-16-acc-0.49.hdf5\n",
            "4/4 [==============================] - 184s 51s/step - loss: 0.7974 - acc: 0.7122 - val_loss: 1.9608 - val_acc: 0.4857\n",
            "Epoch 17/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8169 - acc: 0.7408 \n",
            "Epoch 17: val_acc did not improve from 0.48571\n",
            "4/4 [==============================] - 187s 50s/step - loss: 0.8169 - acc: 0.7408 - val_loss: 1.7489 - val_acc: 0.4857\n",
            "Epoch 18/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8145 - acc: 0.7020 \n",
            "Epoch 18: val_acc improved from 0.48571 to 0.53571, saving model to percobaan144_noImgPro/model\\vgg_16_144-saved-model-18-acc-0.54.hdf5\n",
            "4/4 [==============================] - 185s 49s/step - loss: 0.8145 - acc: 0.7020 - val_loss: 1.6499 - val_acc: 0.5357\n",
            "Epoch 19/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8304 - acc: 0.7020 \n",
            "Epoch 19: val_acc did not improve from 0.53571\n",
            "4/4 [==============================] - 186s 50s/step - loss: 0.8304 - acc: 0.7020 - val_loss: 1.3361 - val_acc: 0.5357\n",
            "Epoch 20/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7322 - acc: 0.7347 \n",
            "Epoch 20: val_acc did not improve from 0.53571\n",
            "4/4 [==============================] - 185s 50s/step - loss: 0.7322 - acc: 0.7347 - val_loss: 1.8054 - val_acc: 0.3857\n",
            "Epoch 21/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6859 - acc: 0.7653 \n",
            "Epoch 21: val_acc did not improve from 0.53571\n",
            "4/4 [==============================] - 187s 50s/step - loss: 0.6859 - acc: 0.7653 - val_loss: 1.4609 - val_acc: 0.4786\n",
            "Epoch 22/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6464 - acc: 0.7592 \n",
            "Epoch 22: val_acc improved from 0.53571 to 0.55000, saving model to percobaan144_noImgPro/model\\vgg_16_144-saved-model-22-acc-0.55.hdf5\n",
            "4/4 [==============================] - 187s 49s/step - loss: 0.6464 - acc: 0.7592 - val_loss: 1.3302 - val_acc: 0.5500\n",
            "Epoch 23/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7205 - acc: 0.7429 \n",
            "Epoch 23: val_acc did not improve from 0.55000\n",
            "4/4 [==============================] - 188s 50s/step - loss: 0.7205 - acc: 0.7429 - val_loss: 1.4878 - val_acc: 0.5143\n",
            "Epoch 24/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7319 - acc: 0.7265 \n",
            "Epoch 24: val_acc did not improve from 0.55000\n",
            "4/4 [==============================] - 188s 50s/step - loss: 0.7319 - acc: 0.7265 - val_loss: 1.5612 - val_acc: 0.5286\n",
            "Epoch 25/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5765 - acc: 0.8082 \n",
            "Epoch 25: val_acc did not improve from 0.55000\n",
            "4/4 [==============================] - 187s 50s/step - loss: 0.5765 - acc: 0.8082 - val_loss: 1.3168 - val_acc: 0.5500\n",
            "Epoch 26/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5785 - acc: 0.7755 \n",
            "Epoch 26: val_acc improved from 0.55000 to 0.57143, saving model to percobaan144_noImgPro/model\\vgg_16_144-saved-model-26-acc-0.57.hdf5\n",
            "4/4 [==============================] - 189s 50s/step - loss: 0.5785 - acc: 0.7755 - val_loss: 1.1708 - val_acc: 0.5714\n",
            "Epoch 27/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6132 - acc: 0.8082 \n",
            "Epoch 27: val_acc did not improve from 0.57143\n",
            "4/4 [==============================] - 192s 51s/step - loss: 0.6132 - acc: 0.8082 - val_loss: 1.5493 - val_acc: 0.5286\n",
            "Epoch 28/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6477 - acc: 0.7939 \n",
            "Epoch 28: val_acc did not improve from 0.57143\n",
            "4/4 [==============================] - 191s 50s/step - loss: 0.6477 - acc: 0.7939 - val_loss: 1.6550 - val_acc: 0.5286\n",
            "Epoch 29/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5726 - acc: 0.8020 \n",
            "Epoch 29: val_acc did not improve from 0.57143\n",
            "4/4 [==============================] - 193s 51s/step - loss: 0.5726 - acc: 0.8020 - val_loss: 1.5931 - val_acc: 0.5357\n",
            "Epoch 30/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5791 - acc: 0.8082 \n",
            "Epoch 30: val_acc did not improve from 0.57143\n",
            "4/4 [==============================] - 191s 53s/step - loss: 0.5791 - acc: 0.8082 - val_loss: 2.2077 - val_acc: 0.4714\n",
            "Epoch 31/53\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6010 - acc: 0.7980 \n",
            "Epoch 31: val_acc did not improve from 0.57143\n",
            "4/4 [==============================] - 192s 53s/step - loss: 0.6010 - acc: 0.7980 - val_loss: 1.8896 - val_acc: 0.4786\n",
            "\n",
            "\n",
            "Model Accuracy 0.37142857142857144\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.10      0.18        10\n",
            "       10000       1.00      0.30      0.46        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.31      1.00      0.48        10\n",
            "       20000       0.00      0.00      0.00        10\n",
            "        5000       1.00      0.20      0.33        10\n",
            "       50000       0.31      1.00      0.48        10\n",
            "\n",
            "    accuracy                           0.37        70\n",
            "   macro avg       0.52      0.37      0.28        70\n",
            "weighted avg       0.52      0.37      0.28        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 145 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 62\n",
            "learning rate: 0.005474019439907022\n",
            "batch size: 32\n",
            "dropout rate: 0.5353925263978926\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/62\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.3158 - acc: 0.3163\n",
            "Epoch 1: val_acc improved from -inf to 0.14286, saving model to percobaan145_noImgPro/model\\vgg_16_145-saved-model-01-acc-0.14.hdf5\n",
            "16/16 [==============================] - 188s 12s/step - loss: 2.3158 - acc: 0.3163 - val_loss: 2.2506 - val_acc: 0.1429\n",
            "Epoch 2/62\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1673 - acc: 0.6041\n",
            "Epoch 2: val_acc improved from 0.14286 to 0.34286, saving model to percobaan145_noImgPro/model\\vgg_16_145-saved-model-02-acc-0.34.hdf5\n",
            "16/16 [==============================] - 189s 12s/step - loss: 1.1673 - acc: 0.6041 - val_loss: 1.6941 - val_acc: 0.3429\n",
            "Epoch 3/62\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7936 - acc: 0.7327\n",
            "Epoch 3: val_acc did not improve from 0.34286\n",
            "16/16 [==============================] - 189s 12s/step - loss: 0.7936 - acc: 0.7327 - val_loss: 1.4530 - val_acc: 0.3429\n",
            "Epoch 4/62\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6893 - acc: 0.7633\n",
            "Epoch 4: val_acc improved from 0.34286 to 0.68571, saving model to percobaan145_noImgPro/model\\vgg_16_145-saved-model-04-acc-0.69.hdf5\n",
            "16/16 [==============================] - 190s 12s/step - loss: 0.6893 - acc: 0.7633 - val_loss: 1.0266 - val_acc: 0.6857\n",
            "Epoch 5/62\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5270 - acc: 0.8224\n",
            "Epoch 5: val_acc did not improve from 0.68571\n",
            "16/16 [==============================] - 189s 12s/step - loss: 0.5270 - acc: 0.8224 - val_loss: 0.9803 - val_acc: 0.6643\n",
            "Epoch 6/62\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4557 - acc: 0.8367\n",
            "Epoch 6: val_acc improved from 0.68571 to 0.76429, saving model to percobaan145_noImgPro/model\\vgg_16_145-saved-model-06-acc-0.76.hdf5\n",
            "16/16 [==============================] - 190s 12s/step - loss: 0.4557 - acc: 0.8367 - val_loss: 0.8168 - val_acc: 0.7643\n",
            "Epoch 7/62\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4120 - acc: 0.8571\n",
            "Epoch 7: val_acc did not improve from 0.76429\n",
            "16/16 [==============================] - 190s 12s/step - loss: 0.4120 - acc: 0.8571 - val_loss: 0.7518 - val_acc: 0.7429\n",
            "Epoch 8/62\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4148 - acc: 0.8816\n",
            "Epoch 8: val_acc did not improve from 0.76429\n",
            "16/16 [==============================] - 190s 12s/step - loss: 0.4148 - acc: 0.8816 - val_loss: 0.6958 - val_acc: 0.7643\n",
            "Epoch 9/62\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3608 - acc: 0.8755\n",
            "Epoch 9: val_acc improved from 0.76429 to 0.82143, saving model to percobaan145_noImgPro/model\\vgg_16_145-saved-model-09-acc-0.82.hdf5\n",
            "16/16 [==============================] - 190s 12s/step - loss: 0.3608 - acc: 0.8755 - val_loss: 0.5925 - val_acc: 0.8214\n",
            "Epoch 10/62\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2685 - acc: 0.9122\n",
            "Epoch 10: val_acc improved from 0.82143 to 0.83571, saving model to percobaan145_noImgPro/model\\vgg_16_145-saved-model-10-acc-0.84.hdf5\n",
            "16/16 [==============================] - 186s 12s/step - loss: 0.2685 - acc: 0.9122 - val_loss: 0.5704 - val_acc: 0.8357\n",
            "Epoch 11/62\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3135 - acc: 0.8898\n",
            "Epoch 11: val_acc did not improve from 0.83571\n",
            "16/16 [==============================] - 189s 12s/step - loss: 0.3135 - acc: 0.8898 - val_loss: 0.5416 - val_acc: 0.8143\n",
            "Epoch 12/62\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2596 - acc: 0.9082\n",
            "Epoch 12: val_acc improved from 0.83571 to 0.87143, saving model to percobaan145_noImgPro/model\\vgg_16_145-saved-model-12-acc-0.87.hdf5\n",
            "16/16 [==============================] - 191s 12s/step - loss: 0.2596 - acc: 0.9082 - val_loss: 0.4449 - val_acc: 0.8714\n",
            "Epoch 13/62\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3114 - acc: 0.9061\n",
            "Epoch 13: val_acc improved from 0.87143 to 0.89286, saving model to percobaan145_noImgPro/model\\vgg_16_145-saved-model-13-acc-0.89.hdf5\n",
            "16/16 [==============================] - 190s 12s/step - loss: 0.3114 - acc: 0.9061 - val_loss: 0.4199 - val_acc: 0.8929\n",
            "Epoch 14/62\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2983 - acc: 0.9102\n",
            "Epoch 14: val_acc did not improve from 0.89286\n",
            "16/16 [==============================] - 191s 12s/step - loss: 0.2983 - acc: 0.9102 - val_loss: 0.5031 - val_acc: 0.8429\n",
            "Epoch 15/62\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2504 - acc: 0.9143\n",
            "Epoch 15: val_acc did not improve from 0.89286\n",
            "16/16 [==============================] - 190s 12s/step - loss: 0.2504 - acc: 0.9143 - val_loss: 0.4496 - val_acc: 0.8857\n",
            "Epoch 16/62\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2722 - acc: 0.9020\n",
            "Epoch 16: val_acc improved from 0.89286 to 0.90000, saving model to percobaan145_noImgPro/model\\vgg_16_145-saved-model-16-acc-0.90.hdf5\n",
            "16/16 [==============================] - 190s 12s/step - loss: 0.2722 - acc: 0.9020 - val_loss: 0.3775 - val_acc: 0.9000\n",
            "Epoch 17/62\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2523 - acc: 0.9082\n",
            "Epoch 17: val_acc did not improve from 0.90000\n",
            "16/16 [==============================] - 191s 12s/step - loss: 0.2523 - acc: 0.9082 - val_loss: 0.3831 - val_acc: 0.8571\n",
            "Epoch 18/62\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2202 - acc: 0.9265\n",
            "Epoch 18: val_acc did not improve from 0.90000\n",
            "16/16 [==============================] - 190s 12s/step - loss: 0.2202 - acc: 0.9265 - val_loss: 0.3994 - val_acc: 0.8714\n",
            "Epoch 19/62\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2008 - acc: 0.9245\n",
            "Epoch 19: val_acc did not improve from 0.90000\n",
            "16/16 [==============================] - 193s 12s/step - loss: 0.2008 - acc: 0.9245 - val_loss: 0.4390 - val_acc: 0.8643\n",
            "Epoch 20/62\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.1892 - acc: 0.9306\n",
            "Epoch 20: val_acc did not improve from 0.90000\n",
            "16/16 [==============================] - 190s 12s/step - loss: 0.1892 - acc: 0.9306 - val_loss: 0.5299 - val_acc: 0.8429\n",
            "Epoch 21/62\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2068 - acc: 0.9122\n",
            "Epoch 21: val_acc did not improve from 0.90000\n",
            "16/16 [==============================] - 192s 12s/step - loss: 0.2068 - acc: 0.9122 - val_loss: 0.4699 - val_acc: 0.8714\n",
            "\n",
            "\n",
            "Model Accuracy 0.8571428571428571\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.82      0.90      0.86        10\n",
            "       10000       1.00      0.90      0.95        10\n",
            "      100000       1.00      0.60      0.75        10\n",
            "        2000       0.77      1.00      0.87        10\n",
            "       20000       0.86      0.60      0.71        10\n",
            "        5000       1.00      1.00      1.00        10\n",
            "       50000       0.71      1.00      0.83        10\n",
            "\n",
            "    accuracy                           0.86        70\n",
            "   macro avg       0.88      0.86      0.85        70\n",
            "weighted avg       0.88      0.86      0.85        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 146 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 57\n",
            "learning rate: 0.024042040252672644\n",
            "batch size: 32\n",
            "dropout rate: 0.6287532660921487\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.6300 - acc: 0.2714 \n",
            "Epoch 1: val_acc improved from -inf to 0.22143, saving model to percobaan146_noImgPro/model\\vgg_16_146-saved-model-01-acc-0.22.hdf5\n",
            "16/16 [==============================] - 269s 17s/step - loss: 2.6300 - acc: 0.2714 - val_loss: 6.1988 - val_acc: 0.2214\n",
            "Epoch 2/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.5947 - acc: 0.4449 \n",
            "Epoch 2: val_acc did not improve from 0.22143\n",
            "16/16 [==============================] - 263s 17s/step - loss: 1.5947 - acc: 0.4449 - val_loss: 3.7110 - val_acc: 0.2143\n",
            "Epoch 3/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2594 - acc: 0.5306 \n",
            "Epoch 3: val_acc improved from 0.22143 to 0.35000, saving model to percobaan146_noImgPro/model\\vgg_16_146-saved-model-03-acc-0.35.hdf5\n",
            "16/16 [==============================] - 265s 17s/step - loss: 1.2594 - acc: 0.5306 - val_loss: 2.6572 - val_acc: 0.3500\n",
            "Epoch 4/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1212 - acc: 0.6490 \n",
            "Epoch 4: val_acc improved from 0.35000 to 0.49286, saving model to percobaan146_noImgPro/model\\vgg_16_146-saved-model-04-acc-0.49.hdf5\n",
            "16/16 [==============================] - 269s 17s/step - loss: 1.1212 - acc: 0.6490 - val_loss: 1.3724 - val_acc: 0.4929\n",
            "Epoch 5/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8620 - acc: 0.6878 \n",
            "Epoch 5: val_acc did not improve from 0.49286\n",
            "16/16 [==============================] - 264s 17s/step - loss: 0.8620 - acc: 0.6878 - val_loss: 2.0078 - val_acc: 0.3286\n",
            "Epoch 6/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7246 - acc: 0.7592 \n",
            "Epoch 6: val_acc did not improve from 0.49286\n",
            "16/16 [==============================] - 272s 17s/step - loss: 0.7246 - acc: 0.7592 - val_loss: 1.6596 - val_acc: 0.4571\n",
            "Epoch 7/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7806 - acc: 0.7551 \n",
            "Epoch 7: val_acc improved from 0.49286 to 0.69286, saving model to percobaan146_noImgPro/model\\vgg_16_146-saved-model-07-acc-0.69.hdf5\n",
            "16/16 [==============================] - 271s 17s/step - loss: 0.7806 - acc: 0.7551 - val_loss: 1.0657 - val_acc: 0.6929\n",
            "Epoch 8/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6143 - acc: 0.7776 \n",
            "Epoch 8: val_acc did not improve from 0.69286\n",
            "16/16 [==============================] - 270s 17s/step - loss: 0.6143 - acc: 0.7776 - val_loss: 1.1713 - val_acc: 0.5929\n",
            "Epoch 9/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5644 - acc: 0.8163 \n",
            "Epoch 9: val_acc did not improve from 0.69286\n",
            "16/16 [==============================] - 271s 17s/step - loss: 0.5644 - acc: 0.8163 - val_loss: 1.0523 - val_acc: 0.5786\n",
            "Epoch 10/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5371 - acc: 0.8143 \n",
            "Epoch 10: val_acc improved from 0.69286 to 0.71429, saving model to percobaan146_noImgPro/model\\vgg_16_146-saved-model-10-acc-0.71.hdf5\n",
            "16/16 [==============================] - 268s 18s/step - loss: 0.5371 - acc: 0.8143 - val_loss: 0.9107 - val_acc: 0.7143\n",
            "Epoch 11/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5327 - acc: 0.8306 \n",
            "Epoch 11: val_acc improved from 0.71429 to 0.74286, saving model to percobaan146_noImgPro/model\\vgg_16_146-saved-model-11-acc-0.74.hdf5\n",
            "16/16 [==============================] - 272s 17s/step - loss: 0.5327 - acc: 0.8306 - val_loss: 0.7615 - val_acc: 0.7429\n",
            "Epoch 12/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7427 - acc: 0.7714 \n",
            "Epoch 12: val_acc improved from 0.74286 to 0.78571, saving model to percobaan146_noImgPro/model\\vgg_16_146-saved-model-12-acc-0.79.hdf5\n",
            "16/16 [==============================] - 268s 18s/step - loss: 0.7427 - acc: 0.7714 - val_loss: 0.7217 - val_acc: 0.7857\n",
            "Epoch 13/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5259 - acc: 0.8265 \n",
            "Epoch 13: val_acc did not improve from 0.78571\n",
            "16/16 [==============================] - 272s 17s/step - loss: 0.5259 - acc: 0.8265 - val_loss: 0.8003 - val_acc: 0.7643\n",
            "Epoch 14/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5192 - acc: 0.8184 \n",
            "Epoch 14: val_acc did not improve from 0.78571\n",
            "16/16 [==============================] - 269s 17s/step - loss: 0.5192 - acc: 0.8184 - val_loss: 0.8942 - val_acc: 0.7000\n",
            "Epoch 15/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5616 - acc: 0.8184 \n",
            "Epoch 15: val_acc improved from 0.78571 to 0.82857, saving model to percobaan146_noImgPro/model\\vgg_16_146-saved-model-15-acc-0.83.hdf5\n",
            "16/16 [==============================] - 271s 17s/step - loss: 0.5616 - acc: 0.8184 - val_loss: 0.5970 - val_acc: 0.8286\n",
            "Epoch 16/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4839 - acc: 0.8429 \n",
            "Epoch 16: val_acc did not improve from 0.82857\n",
            "16/16 [==============================] - 271s 17s/step - loss: 0.4839 - acc: 0.8429 - val_loss: 0.6046 - val_acc: 0.8214\n",
            "Epoch 17/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4655 - acc: 0.8347 \n",
            "Epoch 17: val_acc improved from 0.82857 to 0.84286, saving model to percobaan146_noImgPro/model\\vgg_16_146-saved-model-17-acc-0.84.hdf5\n",
            "16/16 [==============================] - 273s 17s/step - loss: 0.4655 - acc: 0.8347 - val_loss: 0.6382 - val_acc: 0.8429\n",
            "Epoch 18/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4369 - acc: 0.8510 \n",
            "Epoch 18: val_acc did not improve from 0.84286\n",
            "16/16 [==============================] - 274s 17s/step - loss: 0.4369 - acc: 0.8510 - val_loss: 0.5916 - val_acc: 0.8214\n",
            "Epoch 19/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4014 - acc: 0.8612 \n",
            "Epoch 19: val_acc did not improve from 0.84286\n",
            "16/16 [==============================] - 274s 17s/step - loss: 0.4014 - acc: 0.8612 - val_loss: 0.8074 - val_acc: 0.7929\n",
            "Epoch 20/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3978 - acc: 0.8857 \n",
            "Epoch 20: val_acc did not improve from 0.84286\n",
            "16/16 [==============================] - 271s 17s/step - loss: 0.3978 - acc: 0.8857 - val_loss: 0.6391 - val_acc: 0.8357\n",
            "Epoch 21/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4623 - acc: 0.8408 \n",
            "Epoch 21: val_acc did not improve from 0.84286\n",
            "16/16 [==============================] - 273s 17s/step - loss: 0.4623 - acc: 0.8408 - val_loss: 0.5429 - val_acc: 0.8357\n",
            "Epoch 22/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4139 - acc: 0.8490 \n",
            "Epoch 22: val_acc improved from 0.84286 to 0.89286, saving model to percobaan146_noImgPro/model\\vgg_16_146-saved-model-22-acc-0.89.hdf5\n",
            "16/16 [==============================] - 270s 18s/step - loss: 0.4139 - acc: 0.8490 - val_loss: 0.4874 - val_acc: 0.8929\n",
            "Epoch 23/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4083 - acc: 0.8898 \n",
            "Epoch 23: val_acc did not improve from 0.89286\n",
            "16/16 [==============================] - 274s 17s/step - loss: 0.4083 - acc: 0.8898 - val_loss: 0.6125 - val_acc: 0.8571\n",
            "Epoch 24/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3764 - acc: 0.8673 \n",
            "Epoch 24: val_acc did not improve from 0.89286\n",
            "16/16 [==============================] - 270s 17s/step - loss: 0.3764 - acc: 0.8673 - val_loss: 0.5335 - val_acc: 0.8786\n",
            "Epoch 25/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3112 - acc: 0.8959 \n",
            "Epoch 25: val_acc did not improve from 0.89286\n",
            "16/16 [==============================] - 273s 17s/step - loss: 0.3112 - acc: 0.8959 - val_loss: 0.7003 - val_acc: 0.8429\n",
            "Epoch 26/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3439 - acc: 0.8796 \n",
            "Epoch 26: val_acc did not improve from 0.89286\n",
            "16/16 [==============================] - 275s 17s/step - loss: 0.3439 - acc: 0.8796 - val_loss: 0.7600 - val_acc: 0.8500\n",
            "Epoch 27/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3672 - acc: 0.8796 \n",
            "Epoch 27: val_acc did not improve from 0.89286\n",
            "16/16 [==============================] - 272s 17s/step - loss: 0.3672 - acc: 0.8796 - val_loss: 0.9627 - val_acc: 0.7929\n",
            "\n",
            "\n",
            "Model Accuracy 0.8428571428571429\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.83      1.00      0.91        10\n",
            "       10000       1.00      0.80      0.89        10\n",
            "      100000       1.00      0.70      0.82        10\n",
            "        2000       0.71      1.00      0.83        10\n",
            "       20000       1.00      0.50      0.67        10\n",
            "        5000       0.77      1.00      0.87        10\n",
            "       50000       0.82      0.90      0.86        10\n",
            "\n",
            "    accuracy                           0.84        70\n",
            "   macro avg       0.88      0.84      0.84        70\n",
            "weighted avg       0.88      0.84      0.84        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 147 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 65\n",
            "learning rate: 0.003436058722402322\n",
            "batch size: 32\n",
            "dropout rate: 0.6808955601109407\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.9804 - acc: 0.2347 \n",
            "Epoch 1: val_acc improved from -inf to 0.20000, saving model to percobaan147_noImgPro/model\\vgg_16_147-saved-model-01-acc-0.20.hdf5\n",
            "16/16 [==============================] - 265s 17s/step - loss: 2.9804 - acc: 0.2347 - val_loss: 2.1727 - val_acc: 0.2000\n",
            "Epoch 2/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.6611 - acc: 0.4816 \n",
            "Epoch 2: val_acc improved from 0.20000 to 0.27857, saving model to percobaan147_noImgPro/model\\vgg_16_147-saved-model-02-acc-0.28.hdf5\n",
            "16/16 [==============================] - 265s 17s/step - loss: 1.6611 - acc: 0.4816 - val_loss: 2.0772 - val_acc: 0.2786\n",
            "Epoch 3/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3484 - acc: 0.5449 \n",
            "Epoch 3: val_acc improved from 0.27857 to 0.35714, saving model to percobaan147_noImgPro/model\\vgg_16_147-saved-model-03-acc-0.36.hdf5\n",
            "16/16 [==============================] - 263s 17s/step - loss: 1.3484 - acc: 0.5449 - val_loss: 1.6021 - val_acc: 0.3571\n",
            "Epoch 4/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0935 - acc: 0.6122 \n",
            "Epoch 4: val_acc improved from 0.35714 to 0.38571, saving model to percobaan147_noImgPro/model\\vgg_16_147-saved-model-04-acc-0.39.hdf5\n",
            "16/16 [==============================] - 263s 17s/step - loss: 1.0935 - acc: 0.6122 - val_loss: 1.4864 - val_acc: 0.3857\n",
            "Epoch 5/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9611 - acc: 0.6571 \n",
            "Epoch 5: val_acc improved from 0.38571 to 0.47143, saving model to percobaan147_noImgPro/model\\vgg_16_147-saved-model-05-acc-0.47.hdf5\n",
            "16/16 [==============================] - 266s 17s/step - loss: 0.9611 - acc: 0.6571 - val_loss: 1.2452 - val_acc: 0.4714\n",
            "Epoch 6/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8940 - acc: 0.6755 \n",
            "Epoch 6: val_acc improved from 0.47143 to 0.60714, saving model to percobaan147_noImgPro/model\\vgg_16_147-saved-model-06-acc-0.61.hdf5\n",
            "16/16 [==============================] - 265s 17s/step - loss: 0.8940 - acc: 0.6755 - val_loss: 1.0515 - val_acc: 0.6071\n",
            "Epoch 7/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8116 - acc: 0.7204 \n",
            "Epoch 7: val_acc improved from 0.60714 to 0.67143, saving model to percobaan147_noImgPro/model\\vgg_16_147-saved-model-07-acc-0.67.hdf5\n",
            "16/16 [==============================] - 270s 18s/step - loss: 0.8116 - acc: 0.7204 - val_loss: 0.9620 - val_acc: 0.6714\n",
            "Epoch 8/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6707 - acc: 0.7816 \n",
            "Epoch 8: val_acc improved from 0.67143 to 0.80000, saving model to percobaan147_noImgPro/model\\vgg_16_147-saved-model-08-acc-0.80.hdf5\n",
            "16/16 [==============================] - 268s 17s/step - loss: 0.6707 - acc: 0.7816 - val_loss: 0.7935 - val_acc: 0.8000\n",
            "Epoch 9/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6613 - acc: 0.7776 \n",
            "Epoch 9: val_acc improved from 0.80000 to 0.80714, saving model to percobaan147_noImgPro/model\\vgg_16_147-saved-model-09-acc-0.81.hdf5\n",
            "16/16 [==============================] - 268s 17s/step - loss: 0.6613 - acc: 0.7776 - val_loss: 0.7352 - val_acc: 0.8071\n",
            "Epoch 10/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5545 - acc: 0.7959 \n",
            "Epoch 10: val_acc improved from 0.80714 to 0.83571, saving model to percobaan147_noImgPro/model\\vgg_16_147-saved-model-10-acc-0.84.hdf5\n",
            "16/16 [==============================] - 267s 17s/step - loss: 0.5545 - acc: 0.7959 - val_loss: 0.6303 - val_acc: 0.8357\n",
            "Epoch 11/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5010 - acc: 0.8286 \n",
            "Epoch 11: val_acc improved from 0.83571 to 0.85000, saving model to percobaan147_noImgPro/model\\vgg_16_147-saved-model-11-acc-0.85.hdf5\n",
            "16/16 [==============================] - 268s 18s/step - loss: 0.5010 - acc: 0.8286 - val_loss: 0.5982 - val_acc: 0.8500\n",
            "Epoch 12/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5256 - acc: 0.8102 \n",
            "Epoch 12: val_acc improved from 0.85000 to 0.85714, saving model to percobaan147_noImgPro/model\\vgg_16_147-saved-model-12-acc-0.86.hdf5\n",
            "16/16 [==============================] - 269s 17s/step - loss: 0.5256 - acc: 0.8102 - val_loss: 0.5669 - val_acc: 0.8571\n",
            "Epoch 13/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4295 - acc: 0.8408 \n",
            "Epoch 13: val_acc improved from 0.85714 to 0.86429, saving model to percobaan147_noImgPro/model\\vgg_16_147-saved-model-13-acc-0.86.hdf5\n",
            "16/16 [==============================] - 269s 17s/step - loss: 0.4295 - acc: 0.8408 - val_loss: 0.5303 - val_acc: 0.8643\n",
            "Epoch 14/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5006 - acc: 0.8286 \n",
            "Epoch 14: val_acc did not improve from 0.86429\n",
            "16/16 [==============================] - 269s 17s/step - loss: 0.5006 - acc: 0.8286 - val_loss: 0.5083 - val_acc: 0.8643\n",
            "Epoch 15/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4849 - acc: 0.8347 \n",
            "Epoch 15: val_acc improved from 0.86429 to 0.87143, saving model to percobaan147_noImgPro/model\\vgg_16_147-saved-model-15-acc-0.87.hdf5\n",
            "16/16 [==============================] - 267s 17s/step - loss: 0.4849 - acc: 0.8347 - val_loss: 0.4884 - val_acc: 0.8714\n",
            "Epoch 16/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5029 - acc: 0.8143 \n",
            "Epoch 16: val_acc improved from 0.87143 to 0.87857, saving model to percobaan147_noImgPro/model\\vgg_16_147-saved-model-16-acc-0.88.hdf5\n",
            "16/16 [==============================] - 266s 17s/step - loss: 0.5029 - acc: 0.8143 - val_loss: 0.4548 - val_acc: 0.8786\n",
            "Epoch 17/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4413 - acc: 0.8592 \n",
            "Epoch 17: val_acc improved from 0.87857 to 0.90000, saving model to percobaan147_noImgPro/model\\vgg_16_147-saved-model-17-acc-0.90.hdf5\n",
            "16/16 [==============================] - 268s 17s/step - loss: 0.4413 - acc: 0.8592 - val_loss: 0.4348 - val_acc: 0.9000\n",
            "Epoch 18/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3749 - acc: 0.8653 \n",
            "Epoch 18: val_acc did not improve from 0.90000\n",
            "16/16 [==============================] - 268s 17s/step - loss: 0.3749 - acc: 0.8653 - val_loss: 0.3991 - val_acc: 0.9000\n",
            "Epoch 19/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4197 - acc: 0.8551 \n",
            "Epoch 19: val_acc did not improve from 0.90000\n",
            "16/16 [==============================] - 268s 17s/step - loss: 0.4197 - acc: 0.8551 - val_loss: 0.4031 - val_acc: 0.9000\n",
            "Epoch 20/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3204 - acc: 0.8918 \n",
            "Epoch 20: val_acc improved from 0.90000 to 0.90714, saving model to percobaan147_noImgPro/model\\vgg_16_147-saved-model-20-acc-0.91.hdf5\n",
            "16/16 [==============================] - 268s 17s/step - loss: 0.3204 - acc: 0.8918 - val_loss: 0.3827 - val_acc: 0.9071\n",
            "Epoch 21/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3548 - acc: 0.8714 \n",
            "Epoch 21: val_acc did not improve from 0.90714\n",
            "16/16 [==============================] - 269s 18s/step - loss: 0.3548 - acc: 0.8714 - val_loss: 0.3646 - val_acc: 0.9071\n",
            "Epoch 22/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3015 - acc: 0.9020 \n",
            "Epoch 22: val_acc did not improve from 0.90714\n",
            "16/16 [==============================] - 267s 17s/step - loss: 0.3015 - acc: 0.9020 - val_loss: 0.3922 - val_acc: 0.8786\n",
            "Epoch 23/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3240 - acc: 0.8878 \n",
            "Epoch 23: val_acc did not improve from 0.90714\n",
            "16/16 [==============================] - 267s 17s/step - loss: 0.3240 - acc: 0.8878 - val_loss: 0.4034 - val_acc: 0.8786\n",
            "Epoch 24/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2897 - acc: 0.9082 \n",
            "Epoch 24: val_acc did not improve from 0.90714\n",
            "16/16 [==============================] - 265s 17s/step - loss: 0.2897 - acc: 0.9082 - val_loss: 0.3970 - val_acc: 0.9071\n",
            "Epoch 25/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2961 - acc: 0.9000 \n",
            "Epoch 25: val_acc did not improve from 0.90714\n",
            "16/16 [==============================] - 269s 17s/step - loss: 0.2961 - acc: 0.9000 - val_loss: 0.4084 - val_acc: 0.8929\n",
            "Epoch 26/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3427 - acc: 0.8918 \n",
            "Epoch 26: val_acc did not improve from 0.90714\n",
            "16/16 [==============================] - 269s 17s/step - loss: 0.3427 - acc: 0.8918 - val_loss: 0.4145 - val_acc: 0.8929\n",
            "\n",
            "\n",
            "Model Accuracy 0.8714285714285714\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.82      0.90      0.86        10\n",
            "       10000       0.90      0.90      0.90        10\n",
            "      100000       1.00      1.00      1.00        10\n",
            "        2000       0.62      1.00      0.77        10\n",
            "       20000       1.00      0.60      0.75        10\n",
            "        5000       1.00      0.90      0.95        10\n",
            "       50000       1.00      0.80      0.89        10\n",
            "\n",
            "    accuracy                           0.87        70\n",
            "   macro avg       0.91      0.87      0.87        70\n",
            "weighted avg       0.91      0.87      0.87        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 148 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 58\n",
            "learning rate: 0.006068814628274338\n",
            "batch size: 32\n",
            "dropout rate: 0.794644326422938\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 3.4203 - acc: 0.2143 \n",
            "Epoch 1: val_acc improved from -inf to 0.29286, saving model to percobaan148_noImgPro/model\\vgg_16_148-saved-model-01-acc-0.29.hdf5\n",
            "16/16 [==============================] - 260s 16s/step - loss: 3.4203 - acc: 0.2143 - val_loss: 1.9517 - val_acc: 0.2929\n",
            "Epoch 2/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.0015 - acc: 0.3816 \n",
            "Epoch 2: val_acc improved from 0.29286 to 0.46429, saving model to percobaan148_noImgPro/model\\vgg_16_148-saved-model-02-acc-0.46.hdf5\n",
            "16/16 [==============================] - 260s 16s/step - loss: 2.0015 - acc: 0.3816 - val_loss: 1.5870 - val_acc: 0.4643\n",
            "Epoch 3/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.7261 - acc: 0.4735 \n",
            "Epoch 3: val_acc did not improve from 0.46429\n",
            "16/16 [==============================] - 258s 16s/step - loss: 1.7261 - acc: 0.4735 - val_loss: 1.4281 - val_acc: 0.4143\n",
            "Epoch 4/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3856 - acc: 0.5122 \n",
            "Epoch 4: val_acc did not improve from 0.46429\n",
            "16/16 [==============================] - 259s 16s/step - loss: 1.3856 - acc: 0.5122 - val_loss: 1.5062 - val_acc: 0.3643\n",
            "Epoch 5/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2459 - acc: 0.5673 \n",
            "Epoch 5: val_acc improved from 0.46429 to 0.48571, saving model to percobaan148_noImgPro/model\\vgg_16_148-saved-model-05-acc-0.49.hdf5\n",
            "16/16 [==============================] - 259s 16s/step - loss: 1.2459 - acc: 0.5673 - val_loss: 1.2613 - val_acc: 0.4857\n",
            "Epoch 6/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1547 - acc: 0.5796 \n",
            "Epoch 6: val_acc improved from 0.48571 to 0.60000, saving model to percobaan148_noImgPro/model\\vgg_16_148-saved-model-06-acc-0.60.hdf5\n",
            "16/16 [==============================] - 263s 17s/step - loss: 1.1547 - acc: 0.5796 - val_loss: 1.1072 - val_acc: 0.6000\n",
            "Epoch 7/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0431 - acc: 0.6449 \n",
            "Epoch 7: val_acc improved from 0.60000 to 0.61429, saving model to percobaan148_noImgPro/model\\vgg_16_148-saved-model-07-acc-0.61.hdf5\n",
            "16/16 [==============================] - 261s 16s/step - loss: 1.0431 - acc: 0.6449 - val_loss: 1.0651 - val_acc: 0.6143\n",
            "Epoch 8/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9399 - acc: 0.6633 \n",
            "Epoch 8: val_acc improved from 0.61429 to 0.72143, saving model to percobaan148_noImgPro/model\\vgg_16_148-saved-model-08-acc-0.72.hdf5\n",
            "16/16 [==============================] - 264s 17s/step - loss: 0.9399 - acc: 0.6633 - val_loss: 0.9041 - val_acc: 0.7214\n",
            "Epoch 9/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8418 - acc: 0.7000 \n",
            "Epoch 9: val_acc improved from 0.72143 to 0.80000, saving model to percobaan148_noImgPro/model\\vgg_16_148-saved-model-09-acc-0.80.hdf5\n",
            "16/16 [==============================] - 262s 17s/step - loss: 0.8418 - acc: 0.7000 - val_loss: 0.8063 - val_acc: 0.8000\n",
            "Epoch 10/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8275 - acc: 0.7061 \n",
            "Epoch 10: val_acc did not improve from 0.80000\n",
            "16/16 [==============================] - 262s 17s/step - loss: 0.8275 - acc: 0.7061 - val_loss: 0.7616 - val_acc: 0.7929\n",
            "Epoch 11/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7205 - acc: 0.7531 \n",
            "Epoch 11: val_acc did not improve from 0.80000\n",
            "16/16 [==============================] - 260s 16s/step - loss: 0.7205 - acc: 0.7531 - val_loss: 0.7317 - val_acc: 0.7857\n",
            "Epoch 12/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7616 - acc: 0.7020 \n",
            "Epoch 12: val_acc improved from 0.80000 to 0.83571, saving model to percobaan148_noImgPro/model\\vgg_16_148-saved-model-12-acc-0.84.hdf5\n",
            "16/16 [==============================] - 260s 16s/step - loss: 0.7616 - acc: 0.7020 - val_loss: 0.6180 - val_acc: 0.8357\n",
            "Epoch 13/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7383 - acc: 0.7490 \n",
            "Epoch 13: val_acc improved from 0.83571 to 0.85714, saving model to percobaan148_noImgPro/model\\vgg_16_148-saved-model-13-acc-0.86.hdf5\n",
            "16/16 [==============================] - 261s 17s/step - loss: 0.7383 - acc: 0.7490 - val_loss: 0.5614 - val_acc: 0.8571\n",
            "Epoch 14/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6801 - acc: 0.7531 \n",
            "Epoch 14: val_acc did not improve from 0.85714\n",
            "16/16 [==============================] - 263s 17s/step - loss: 0.6801 - acc: 0.7531 - val_loss: 0.5284 - val_acc: 0.8429\n",
            "Epoch 15/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6496 - acc: 0.7735 \n",
            "Epoch 15: val_acc improved from 0.85714 to 0.86429, saving model to percobaan148_noImgPro/model\\vgg_16_148-saved-model-15-acc-0.86.hdf5\n",
            "16/16 [==============================] - 262s 17s/step - loss: 0.6496 - acc: 0.7735 - val_loss: 0.5048 - val_acc: 0.8643\n",
            "Epoch 16/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6362 - acc: 0.7673 \n",
            "Epoch 16: val_acc improved from 0.86429 to 0.87857, saving model to percobaan148_noImgPro/model\\vgg_16_148-saved-model-16-acc-0.88.hdf5\n",
            "16/16 [==============================] - 261s 16s/step - loss: 0.6362 - acc: 0.7673 - val_loss: 0.4862 - val_acc: 0.8786\n",
            "Epoch 17/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5582 - acc: 0.8041 \n",
            "Epoch 17: val_acc did not improve from 0.87857\n",
            "16/16 [==============================] - 262s 17s/step - loss: 0.5582 - acc: 0.8041 - val_loss: 0.4863 - val_acc: 0.8429\n",
            "Epoch 18/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5175 - acc: 0.8122 \n",
            "Epoch 18: val_acc did not improve from 0.87857\n",
            "16/16 [==============================] - 261s 16s/step - loss: 0.5175 - acc: 0.8122 - val_loss: 0.4608 - val_acc: 0.8714\n",
            "Epoch 19/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5636 - acc: 0.8000 \n",
            "Epoch 19: val_acc did not improve from 0.87857\n",
            "16/16 [==============================] - 260s 16s/step - loss: 0.5636 - acc: 0.8000 - val_loss: 0.4390 - val_acc: 0.8786\n",
            "Epoch 20/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5137 - acc: 0.8143 \n",
            "Epoch 20: val_acc did not improve from 0.87857\n",
            "16/16 [==============================] - 262s 17s/step - loss: 0.5137 - acc: 0.8143 - val_loss: 0.4462 - val_acc: 0.8643\n",
            "Epoch 21/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5470 - acc: 0.8122 \n",
            "Epoch 21: val_acc improved from 0.87857 to 0.89286, saving model to percobaan148_noImgPro/model\\vgg_16_148-saved-model-21-acc-0.89.hdf5\n",
            "16/16 [==============================] - 260s 16s/step - loss: 0.5470 - acc: 0.8122 - val_loss: 0.4476 - val_acc: 0.8929\n",
            "Epoch 22/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5646 - acc: 0.7898 \n",
            "Epoch 22: val_acc improved from 0.89286 to 0.90000, saving model to percobaan148_noImgPro/model\\vgg_16_148-saved-model-22-acc-0.90.hdf5\n",
            "16/16 [==============================] - 261s 17s/step - loss: 0.5646 - acc: 0.7898 - val_loss: 0.4484 - val_acc: 0.9000\n",
            "Epoch 23/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5228 - acc: 0.8163 \n",
            "Epoch 23: val_acc did not improve from 0.90000\n",
            "16/16 [==============================] - 264s 17s/step - loss: 0.5228 - acc: 0.8163 - val_loss: 0.4529 - val_acc: 0.8714\n",
            "Epoch 24/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5333 - acc: 0.8286 \n",
            "Epoch 24: val_acc did not improve from 0.90000\n",
            "16/16 [==============================] - 262s 17s/step - loss: 0.5333 - acc: 0.8286 - val_loss: 0.4521 - val_acc: 0.8643\n",
            "\n",
            "\n",
            "Model Accuracy 0.9\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.91      1.00      0.95        10\n",
            "       10000       1.00      1.00      1.00        10\n",
            "      100000       1.00      0.90      0.95        10\n",
            "        2000       0.77      1.00      0.87        10\n",
            "       20000       1.00      0.50      0.67        10\n",
            "        5000       0.82      0.90      0.86        10\n",
            "       50000       0.91      1.00      0.95        10\n",
            "\n",
            "    accuracy                           0.90        70\n",
            "   macro avg       0.92      0.90      0.89        70\n",
            "weighted avg       0.92      0.90      0.89        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 149 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 65\n",
            "learning rate: 0.007550927204627761\n",
            "batch size: 64\n",
            "dropout rate: 0.5231260016701382\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.3331 - acc: 0.3265 \n",
            "Epoch 1: val_acc improved from -inf to 0.17857, saving model to percobaan149_noImgPro/model\\vgg_16_149-saved-model-01-acc-0.18.hdf5\n",
            "8/8 [==============================] - 254s 33s/step - loss: 2.3331 - acc: 0.3265 - val_loss: 3.6134 - val_acc: 0.1786\n",
            "Epoch 2/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0417 - acc: 0.6347 \n",
            "Epoch 2: val_acc improved from 0.17857 to 0.26429, saving model to percobaan149_noImgPro/model\\vgg_16_149-saved-model-02-acc-0.26.hdf5\n",
            "8/8 [==============================] - 250s 33s/step - loss: 1.0417 - acc: 0.6347 - val_loss: 3.5888 - val_acc: 0.2643\n",
            "Epoch 3/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8248 - acc: 0.7102 \n",
            "Epoch 3: val_acc did not improve from 0.26429\n",
            "8/8 [==============================] - 253s 32s/step - loss: 0.8248 - acc: 0.7102 - val_loss: 3.2547 - val_acc: 0.2214\n",
            "Epoch 4/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6159 - acc: 0.8000 \n",
            "Epoch 4: val_acc improved from 0.26429 to 0.39286, saving model to percobaan149_noImgPro/model\\vgg_16_149-saved-model-04-acc-0.39.hdf5\n",
            "8/8 [==============================] - 251s 32s/step - loss: 0.6159 - acc: 0.8000 - val_loss: 2.5314 - val_acc: 0.3929\n",
            "Epoch 5/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4930 - acc: 0.8265 \n",
            "Epoch 5: val_acc did not improve from 0.39286\n",
            "8/8 [==============================] - 251s 32s/step - loss: 0.4930 - acc: 0.8265 - val_loss: 2.2171 - val_acc: 0.3929\n",
            "Epoch 6/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4354 - acc: 0.8490 \n",
            "Epoch 6: val_acc improved from 0.39286 to 0.40714, saving model to percobaan149_noImgPro/model\\vgg_16_149-saved-model-06-acc-0.41.hdf5\n",
            "8/8 [==============================] - 254s 33s/step - loss: 0.4354 - acc: 0.8490 - val_loss: 1.9386 - val_acc: 0.4071\n",
            "Epoch 7/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3953 - acc: 0.8714 \n",
            "Epoch 7: val_acc improved from 0.40714 to 0.45000, saving model to percobaan149_noImgPro/model\\vgg_16_149-saved-model-07-acc-0.45.hdf5\n",
            "8/8 [==============================] - 253s 34s/step - loss: 0.3953 - acc: 0.8714 - val_loss: 1.5513 - val_acc: 0.4500\n",
            "Epoch 8/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3077 - acc: 0.8857 \n",
            "Epoch 8: val_acc did not improve from 0.45000\n",
            "8/8 [==============================] - 254s 32s/step - loss: 0.3077 - acc: 0.8857 - val_loss: 1.6764 - val_acc: 0.4071\n",
            "Epoch 9/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2814 - acc: 0.9102 \n",
            "Epoch 9: val_acc improved from 0.45000 to 0.48571, saving model to percobaan149_noImgPro/model\\vgg_16_149-saved-model-09-acc-0.49.hdf5\n",
            "8/8 [==============================] - 252s 32s/step - loss: 0.2814 - acc: 0.9102 - val_loss: 1.3812 - val_acc: 0.4857\n",
            "Epoch 10/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2657 - acc: 0.9102 \n",
            "Epoch 10: val_acc improved from 0.48571 to 0.63571, saving model to percobaan149_noImgPro/model\\vgg_16_149-saved-model-10-acc-0.64.hdf5\n",
            "8/8 [==============================] - 254s 33s/step - loss: 0.2657 - acc: 0.9102 - val_loss: 1.0359 - val_acc: 0.6357\n",
            "Epoch 11/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2164 - acc: 0.9327 \n",
            "Epoch 11: val_acc did not improve from 0.63571\n",
            "8/8 [==============================] - 252s 32s/step - loss: 0.2164 - acc: 0.9327 - val_loss: 1.0017 - val_acc: 0.6286\n",
            "Epoch 12/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2391 - acc: 0.9327 \n",
            "Epoch 12: val_acc did not improve from 0.63571\n",
            "8/8 [==============================] - 253s 32s/step - loss: 0.2391 - acc: 0.9327 - val_loss: 0.9787 - val_acc: 0.6214\n",
            "Epoch 13/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2217 - acc: 0.9265 \n",
            "Epoch 13: val_acc improved from 0.63571 to 0.70000, saving model to percobaan149_noImgPro/model\\vgg_16_149-saved-model-13-acc-0.70.hdf5\n",
            "8/8 [==============================] - 254s 33s/step - loss: 0.2217 - acc: 0.9265 - val_loss: 0.8333 - val_acc: 0.7000\n",
            "Epoch 14/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1740 - acc: 0.9408 \n",
            "Epoch 14: val_acc did not improve from 0.70000\n",
            "8/8 [==============================] - 252s 32s/step - loss: 0.1740 - acc: 0.9408 - val_loss: 0.8239 - val_acc: 0.7000\n",
            "Epoch 15/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1697 - acc: 0.9429 \n",
            "Epoch 15: val_acc improved from 0.70000 to 0.72143, saving model to percobaan149_noImgPro/model\\vgg_16_149-saved-model-15-acc-0.72.hdf5\n",
            "8/8 [==============================] - 255s 33s/step - loss: 0.1697 - acc: 0.9429 - val_loss: 0.8052 - val_acc: 0.7214\n",
            "Epoch 16/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1682 - acc: 0.9469 \n",
            "Epoch 16: val_acc improved from 0.72143 to 0.74286, saving model to percobaan149_noImgPro/model\\vgg_16_149-saved-model-16-acc-0.74.hdf5\n",
            "8/8 [==============================] - 254s 34s/step - loss: 0.1682 - acc: 0.9469 - val_loss: 0.7414 - val_acc: 0.7429\n",
            "Epoch 17/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1710 - acc: 0.9490 \n",
            "Epoch 17: val_acc improved from 0.74286 to 0.77143, saving model to percobaan149_noImgPro/model\\vgg_16_149-saved-model-17-acc-0.77.hdf5\n",
            "8/8 [==============================] - 253s 33s/step - loss: 0.1710 - acc: 0.9490 - val_loss: 0.6536 - val_acc: 0.7714\n",
            "Epoch 18/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1390 - acc: 0.9592 \n",
            "Epoch 18: val_acc did not improve from 0.77143\n",
            "8/8 [==============================] - 253s 32s/step - loss: 0.1390 - acc: 0.9592 - val_loss: 0.6758 - val_acc: 0.7429\n",
            "Epoch 19/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1052 - acc: 0.9633 \n",
            "Epoch 19: val_acc did not improve from 0.77143\n",
            "8/8 [==============================] - 366s 49s/step - loss: 0.1052 - acc: 0.9633 - val_loss: 0.6653 - val_acc: 0.7500\n",
            "Epoch 20/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1540 - acc: 0.9531 \n",
            "Epoch 20: val_acc improved from 0.77143 to 0.77857, saving model to percobaan149_noImgPro/model\\vgg_16_149-saved-model-20-acc-0.78.hdf5\n",
            "8/8 [==============================] - 441s 58s/step - loss: 0.1540 - acc: 0.9531 - val_loss: 0.6436 - val_acc: 0.7786\n",
            "Epoch 21/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1243 - acc: 0.9551 \n",
            "Epoch 21: val_acc did not improve from 0.77857\n",
            "8/8 [==============================] - 457s 60s/step - loss: 0.1243 - acc: 0.9551 - val_loss: 0.6383 - val_acc: 0.7643\n",
            "Epoch 22/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1089 - acc: 0.9694 \n",
            "Epoch 22: val_acc did not improve from 0.77857\n",
            "8/8 [==============================] - 426s 54s/step - loss: 0.1089 - acc: 0.9694 - val_loss: 0.6093 - val_acc: 0.7571\n",
            "Epoch 23/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1550 - acc: 0.9388 \n",
            "Epoch 23: val_acc did not improve from 0.77857\n",
            "8/8 [==============================] - 463s 60s/step - loss: 0.1550 - acc: 0.9388 - val_loss: 0.6372 - val_acc: 0.7500\n",
            "Epoch 24/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1766 - acc: 0.9469 \n",
            "Epoch 24: val_acc improved from 0.77857 to 0.80000, saving model to percobaan149_noImgPro/model\\vgg_16_149-saved-model-24-acc-0.80.hdf5\n",
            "8/8 [==============================] - 437s 59s/step - loss: 0.1766 - acc: 0.9469 - val_loss: 0.5757 - val_acc: 0.8000\n",
            "Epoch 25/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1238 - acc: 0.9571 \n",
            "Epoch 25: val_acc improved from 0.80000 to 0.82857, saving model to percobaan149_noImgPro/model\\vgg_16_149-saved-model-25-acc-0.83.hdf5\n",
            "8/8 [==============================] - 450s 59s/step - loss: 0.1238 - acc: 0.9571 - val_loss: 0.5354 - val_acc: 0.8286\n",
            "Epoch 26/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1008 - acc: 0.9694 \n",
            "Epoch 26: val_acc improved from 0.82857 to 0.85714, saving model to percobaan149_noImgPro/model\\vgg_16_149-saved-model-26-acc-0.86.hdf5\n",
            "8/8 [==============================] - 460s 59s/step - loss: 0.1008 - acc: 0.9694 - val_loss: 0.4968 - val_acc: 0.8571\n",
            "Epoch 27/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1275 - acc: 0.9449 \n",
            "Epoch 27: val_acc improved from 0.85714 to 0.86429, saving model to percobaan149_noImgPro/model\\vgg_16_149-saved-model-27-acc-0.86.hdf5\n",
            "8/8 [==============================] - 454s 59s/step - loss: 0.1275 - acc: 0.9449 - val_loss: 0.5064 - val_acc: 0.8643\n",
            "Epoch 28/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1268 - acc: 0.9571 \n",
            "Epoch 28: val_acc did not improve from 0.86429\n",
            "8/8 [==============================] - 440s 59s/step - loss: 0.1268 - acc: 0.9571 - val_loss: 0.5230 - val_acc: 0.8286\n",
            "Epoch 29/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0888 - acc: 0.9714 \n",
            "Epoch 29: val_acc did not improve from 0.86429\n",
            "8/8 [==============================] - 460s 61s/step - loss: 0.0888 - acc: 0.9714 - val_loss: 0.4903 - val_acc: 0.8571\n",
            "Epoch 30/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1335 - acc: 0.9531 \n",
            "Epoch 30: val_acc did not improve from 0.86429\n",
            "8/8 [==============================] - 434s 57s/step - loss: 0.1335 - acc: 0.9531 - val_loss: 0.4637 - val_acc: 0.8571\n",
            "Epoch 31/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1462 - acc: 0.9531 \n",
            "Epoch 31: val_acc did not improve from 0.86429\n",
            "8/8 [==============================] - 445s 58s/step - loss: 0.1462 - acc: 0.9531 - val_loss: 0.4981 - val_acc: 0.8429\n",
            "Epoch 32/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1375 - acc: 0.9510 \n",
            "Epoch 32: val_acc did not improve from 0.86429\n",
            "8/8 [==============================] - 431s 55s/step - loss: 0.1375 - acc: 0.9510 - val_loss: 0.5003 - val_acc: 0.8286\n",
            "Epoch 33/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1303 - acc: 0.9612 \n",
            "Epoch 33: val_acc did not improve from 0.86429\n",
            "8/8 [==============================] - 442s 58s/step - loss: 0.1303 - acc: 0.9612 - val_loss: 0.4461 - val_acc: 0.8429\n",
            "Epoch 34/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0665 - acc: 0.9816 \n",
            "Epoch 34: val_acc did not improve from 0.86429\n",
            "8/8 [==============================] - 445s 57s/step - loss: 0.0665 - acc: 0.9816 - val_loss: 0.4798 - val_acc: 0.8500\n",
            "Epoch 35/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0882 - acc: 0.9673 \n",
            "Epoch 35: val_acc did not improve from 0.86429\n",
            "8/8 [==============================] - 452s 59s/step - loss: 0.0882 - acc: 0.9673 - val_loss: 0.5276 - val_acc: 0.8357\n",
            "Epoch 36/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1089 - acc: 0.9735 \n",
            "Epoch 36: val_acc did not improve from 0.86429\n",
            "8/8 [==============================] - 298s 37s/step - loss: 0.1089 - acc: 0.9735 - val_loss: 0.5278 - val_acc: 0.8429\n",
            "Epoch 37/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1276 - acc: 0.9633 \n",
            "Epoch 37: val_acc did not improve from 0.86429\n",
            "8/8 [==============================] - 253s 33s/step - loss: 0.1276 - acc: 0.9633 - val_loss: 0.5099 - val_acc: 0.8500\n",
            "Epoch 38/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1014 - acc: 0.9714 \n",
            "Epoch 38: val_acc did not improve from 0.86429\n",
            "8/8 [==============================] - 255s 33s/step - loss: 0.1014 - acc: 0.9714 - val_loss: 0.5748 - val_acc: 0.8357\n",
            "\n",
            "\n",
            "Model Accuracy 0.8571428571428571\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.82      0.90      0.86        10\n",
            "       10000       1.00      0.90      0.95        10\n",
            "      100000       1.00      0.80      0.89        10\n",
            "        2000       0.77      1.00      0.87        10\n",
            "       20000       1.00      0.40      0.57        10\n",
            "        5000       0.83      1.00      0.91        10\n",
            "       50000       0.77      1.00      0.87        10\n",
            "\n",
            "    accuracy                           0.86        70\n",
            "   macro avg       0.88      0.86      0.84        70\n",
            "weighted avg       0.88      0.86      0.84        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 150 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 61\n",
            "learning rate: 0.01965596470354793\n",
            "batch size: 64\n",
            "dropout rate: 0.6428328881507777\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/61\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.4566 - acc: 0.3531 \n",
            "Epoch 1: val_acc improved from -inf to 0.16429, saving model to percobaan150_noImgPro/model\\vgg_16_150-saved-model-01-acc-0.16.hdf5\n",
            "8/8 [==============================] - 243s 31s/step - loss: 2.4566 - acc: 0.3531 - val_loss: 5.3060 - val_acc: 0.1643\n",
            "Epoch 2/61\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4585 - acc: 0.4776 \n",
            "Epoch 2: val_acc improved from 0.16429 to 0.25714, saving model to percobaan150_noImgPro/model\\vgg_16_150-saved-model-02-acc-0.26.hdf5\n",
            "8/8 [==============================] - 242s 31s/step - loss: 1.4585 - acc: 0.4776 - val_loss: 4.5108 - val_acc: 0.2571\n",
            "Epoch 3/61\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.2174 - acc: 0.5755 \n",
            "Epoch 3: val_acc improved from 0.25714 to 0.27143, saving model to percobaan150_noImgPro/model\\vgg_16_150-saved-model-03-acc-0.27.hdf5\n",
            "8/8 [==============================] - 243s 31s/step - loss: 1.2174 - acc: 0.5755 - val_loss: 2.7492 - val_acc: 0.2714\n",
            "Epoch 4/61\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9281 - acc: 0.6755 \n",
            "Epoch 4: val_acc improved from 0.27143 to 0.35000, saving model to percobaan150_noImgPro/model\\vgg_16_150-saved-model-04-acc-0.35.hdf5\n",
            "8/8 [==============================] - 246s 31s/step - loss: 0.9281 - acc: 0.6755 - val_loss: 1.9217 - val_acc: 0.3500\n",
            "Epoch 5/61\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7980 - acc: 0.7286 \n",
            "Epoch 5: val_acc improved from 0.35000 to 0.47857, saving model to percobaan150_noImgPro/model\\vgg_16_150-saved-model-05-acc-0.48.hdf5\n",
            "8/8 [==============================] - 246s 32s/step - loss: 0.7980 - acc: 0.7286 - val_loss: 1.7278 - val_acc: 0.4786\n",
            "Epoch 6/61\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6180 - acc: 0.7939 \n",
            "Epoch 6: val_acc did not improve from 0.47857\n",
            "8/8 [==============================] - 246s 33s/step - loss: 0.6180 - acc: 0.7939 - val_loss: 1.9208 - val_acc: 0.3786\n",
            "Epoch 7/61\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5703 - acc: 0.7878 \n",
            "Epoch 7: val_acc improved from 0.47857 to 0.57857, saving model to percobaan150_noImgPro/model\\vgg_16_150-saved-model-07-acc-0.58.hdf5\n",
            "8/8 [==============================] - 245s 31s/step - loss: 0.5703 - acc: 0.7878 - val_loss: 1.2560 - val_acc: 0.5786\n",
            "Epoch 8/61\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5331 - acc: 0.8286 \n",
            "Epoch 8: val_acc did not improve from 0.57857\n",
            "8/8 [==============================] - 248s 32s/step - loss: 0.5331 - acc: 0.8286 - val_loss: 1.4263 - val_acc: 0.5214\n",
            "Epoch 9/61\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4643 - acc: 0.8653 \n",
            "Epoch 9: val_acc did not improve from 0.57857\n",
            "8/8 [==============================] - 246s 32s/step - loss: 0.4643 - acc: 0.8653 - val_loss: 1.6212 - val_acc: 0.4571\n",
            "Epoch 10/61\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4117 - acc: 0.8510 \n",
            "Epoch 10: val_acc did not improve from 0.57857\n",
            "8/8 [==============================] - 247s 32s/step - loss: 0.4117 - acc: 0.8510 - val_loss: 1.8033 - val_acc: 0.4071\n",
            "Epoch 11/61\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4306 - acc: 0.8633 \n",
            "Epoch 11: val_acc did not improve from 0.57857\n",
            "8/8 [==============================] - 244s 31s/step - loss: 0.4306 - acc: 0.8633 - val_loss: 1.7521 - val_acc: 0.3786\n",
            "Epoch 12/61\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4434 - acc: 0.8592 \n",
            "Epoch 12: val_acc improved from 0.57857 to 0.62857, saving model to percobaan150_noImgPro/model\\vgg_16_150-saved-model-12-acc-0.63.hdf5\n",
            "8/8 [==============================] - 242s 31s/step - loss: 0.4434 - acc: 0.8592 - val_loss: 1.1957 - val_acc: 0.6286\n",
            "Epoch 13/61\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3558 - acc: 0.8857 \n",
            "Epoch 13: val_acc improved from 0.62857 to 0.70714, saving model to percobaan150_noImgPro/model\\vgg_16_150-saved-model-13-acc-0.71.hdf5\n",
            "8/8 [==============================] - 245s 31s/step - loss: 0.3558 - acc: 0.8857 - val_loss: 0.9111 - val_acc: 0.7071\n",
            "Epoch 14/61\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4129 - acc: 0.8510 \n",
            "Epoch 14: val_acc did not improve from 0.70714\n",
            "8/8 [==============================] - 243s 31s/step - loss: 0.4129 - acc: 0.8510 - val_loss: 0.9699 - val_acc: 0.6286\n",
            "Epoch 15/61\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3790 - acc: 0.8673 \n",
            "Epoch 15: val_acc did not improve from 0.70714\n",
            "8/8 [==============================] - 244s 33s/step - loss: 0.3790 - acc: 0.8673 - val_loss: 0.8268 - val_acc: 0.6929\n",
            "Epoch 16/61\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3284 - acc: 0.8918 \n",
            "Epoch 16: val_acc did not improve from 0.70714\n",
            "8/8 [==============================] - 247s 32s/step - loss: 0.3284 - acc: 0.8918 - val_loss: 0.9900 - val_acc: 0.6286\n",
            "Epoch 17/61\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3356 - acc: 0.8837 \n",
            "Epoch 17: val_acc did not improve from 0.70714\n",
            "8/8 [==============================] - 243s 31s/step - loss: 0.3356 - acc: 0.8837 - val_loss: 1.0195 - val_acc: 0.6500\n",
            "Epoch 18/61\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3361 - acc: 0.8694 \n",
            "Epoch 18: val_acc improved from 0.70714 to 0.72857, saving model to percobaan150_noImgPro/model\\vgg_16_150-saved-model-18-acc-0.73.hdf5\n",
            "8/8 [==============================] - 245s 33s/step - loss: 0.3361 - acc: 0.8694 - val_loss: 0.8752 - val_acc: 0.7286\n",
            "Epoch 19/61\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2720 - acc: 0.9061 \n",
            "Epoch 19: val_acc did not improve from 0.72857\n",
            "8/8 [==============================] - 246s 33s/step - loss: 0.2720 - acc: 0.9061 - val_loss: 0.9987 - val_acc: 0.7071\n",
            "Epoch 20/61\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2233 - acc: 0.9143 \n",
            "Epoch 20: val_acc did not improve from 0.72857\n",
            "8/8 [==============================] - 245s 31s/step - loss: 0.2233 - acc: 0.9143 - val_loss: 0.9958 - val_acc: 0.7000\n",
            "\n",
            "\n",
            "Model Accuracy 0.5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.80      0.40      0.53        10\n",
            "       10000       0.50      0.80      0.62        10\n",
            "      100000       0.83      0.50      0.62        10\n",
            "        2000       0.67      0.20      0.31        10\n",
            "       20000       1.00      0.10      0.18        10\n",
            "        5000       1.00      0.50      0.67        10\n",
            "       50000       0.29      1.00      0.45        10\n",
            "\n",
            "    accuracy                           0.50        70\n",
            "   macro avg       0.73      0.50      0.48        70\n",
            "weighted avg       0.73      0.50      0.48        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 151 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 63\n",
            "learning rate: 0.014390826789828734\n",
            "batch size: 64\n",
            "dropout rate: 0.6646285506512308\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.6962 - acc: 0.3020 \n",
            "Epoch 1: val_acc improved from -inf to 0.17857, saving model to percobaan151_noImgPro/model\\vgg_16_151-saved-model-01-acc-0.18.hdf5\n",
            "8/8 [==============================] - 235s 30s/step - loss: 2.6962 - acc: 0.3020 - val_loss: 3.8433 - val_acc: 0.1786\n",
            "Epoch 2/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4859 - acc: 0.5000 \n",
            "Epoch 2: val_acc did not improve from 0.17857\n",
            "8/8 [==============================] - 232s 30s/step - loss: 1.4859 - acc: 0.5000 - val_loss: 5.5298 - val_acc: 0.1786\n",
            "Epoch 3/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1095 - acc: 0.5918 \n",
            "Epoch 3: val_acc improved from 0.17857 to 0.21429, saving model to percobaan151_noImgPro/model\\vgg_16_151-saved-model-03-acc-0.21.hdf5\n",
            "8/8 [==============================] - 235s 30s/step - loss: 1.1095 - acc: 0.5918 - val_loss: 3.8361 - val_acc: 0.2143\n",
            "Epoch 4/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0020 - acc: 0.6551 \n",
            "Epoch 4: val_acc improved from 0.21429 to 0.31429, saving model to percobaan151_noImgPro/model\\vgg_16_151-saved-model-04-acc-0.31.hdf5\n",
            "8/8 [==============================] - 232s 30s/step - loss: 1.0020 - acc: 0.6551 - val_loss: 2.2678 - val_acc: 0.3143\n",
            "Epoch 5/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7972 - acc: 0.6959 \n",
            "Epoch 5: val_acc did not improve from 0.31429\n",
            "8/8 [==============================] - 236s 30s/step - loss: 0.7972 - acc: 0.6959 - val_loss: 2.2086 - val_acc: 0.2929\n",
            "Epoch 6/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7197 - acc: 0.7449 \n",
            "Epoch 6: val_acc did not improve from 0.31429\n",
            "8/8 [==============================] - 235s 30s/step - loss: 0.7197 - acc: 0.7449 - val_loss: 2.2011 - val_acc: 0.2571\n",
            "Epoch 7/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5532 - acc: 0.8020 \n",
            "Epoch 7: val_acc improved from 0.31429 to 0.40714, saving model to percobaan151_noImgPro/model\\vgg_16_151-saved-model-07-acc-0.41.hdf5\n",
            "8/8 [==============================] - 233s 30s/step - loss: 0.5532 - acc: 0.8020 - val_loss: 1.7783 - val_acc: 0.4071\n",
            "Epoch 8/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5111 - acc: 0.8245 \n",
            "Epoch 8: val_acc improved from 0.40714 to 0.42143, saving model to percobaan151_noImgPro/model\\vgg_16_151-saved-model-08-acc-0.42.hdf5\n",
            "8/8 [==============================] - 234s 30s/step - loss: 0.5111 - acc: 0.8245 - val_loss: 1.5200 - val_acc: 0.4214\n",
            "Epoch 9/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4880 - acc: 0.8122 \n",
            "Epoch 9: val_acc improved from 0.42143 to 0.57857, saving model to percobaan151_noImgPro/model\\vgg_16_151-saved-model-09-acc-0.58.hdf5\n",
            "8/8 [==============================] - 238s 30s/step - loss: 0.4880 - acc: 0.8122 - val_loss: 1.1959 - val_acc: 0.5786\n",
            "Epoch 10/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4148 - acc: 0.8429 \n",
            "Epoch 10: val_acc improved from 0.57857 to 0.62143, saving model to percobaan151_noImgPro/model\\vgg_16_151-saved-model-10-acc-0.62.hdf5\n",
            "8/8 [==============================] - 233s 30s/step - loss: 0.4148 - acc: 0.8429 - val_loss: 1.0773 - val_acc: 0.6214\n",
            "Epoch 11/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4380 - acc: 0.8388 \n",
            "Epoch 11: val_acc did not improve from 0.62143\n",
            "8/8 [==============================] - 234s 30s/step - loss: 0.4380 - acc: 0.8388 - val_loss: 1.0339 - val_acc: 0.6000\n",
            "Epoch 12/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4111 - acc: 0.8653 \n",
            "Epoch 12: val_acc improved from 0.62143 to 0.66429, saving model to percobaan151_noImgPro/model\\vgg_16_151-saved-model-12-acc-0.66.hdf5\n",
            "8/8 [==============================] - 236s 30s/step - loss: 0.4111 - acc: 0.8653 - val_loss: 0.9330 - val_acc: 0.6643\n",
            "Epoch 13/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3461 - acc: 0.8653 \n",
            "Epoch 13: val_acc improved from 0.66429 to 0.73571, saving model to percobaan151_noImgPro/model\\vgg_16_151-saved-model-13-acc-0.74.hdf5\n",
            "8/8 [==============================] - 233s 30s/step - loss: 0.3461 - acc: 0.8653 - val_loss: 0.7677 - val_acc: 0.7357\n",
            "Epoch 14/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3718 - acc: 0.8735 \n",
            "Epoch 14: val_acc improved from 0.73571 to 0.75714, saving model to percobaan151_noImgPro/model\\vgg_16_151-saved-model-14-acc-0.76.hdf5\n",
            "8/8 [==============================] - 233s 30s/step - loss: 0.3718 - acc: 0.8735 - val_loss: 0.7352 - val_acc: 0.7571\n",
            "Epoch 15/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2785 - acc: 0.9082 \n",
            "Epoch 15: val_acc did not improve from 0.75714\n",
            "8/8 [==============================] - 235s 30s/step - loss: 0.2785 - acc: 0.9082 - val_loss: 0.7494 - val_acc: 0.7571\n",
            "Epoch 16/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3415 - acc: 0.8857 \n",
            "Epoch 16: val_acc did not improve from 0.75714\n",
            "8/8 [==============================] - 237s 32s/step - loss: 0.3415 - acc: 0.8857 - val_loss: 0.8103 - val_acc: 0.7214\n",
            "Epoch 17/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3779 - acc: 0.8694 \n",
            "Epoch 17: val_acc did not improve from 0.75714\n",
            "8/8 [==============================] - 236s 30s/step - loss: 0.3779 - acc: 0.8694 - val_loss: 0.7691 - val_acc: 0.7357\n",
            "Epoch 18/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3284 - acc: 0.9000 \n",
            "Epoch 18: val_acc improved from 0.75714 to 0.77857, saving model to percobaan151_noImgPro/model\\vgg_16_151-saved-model-18-acc-0.78.hdf5\n",
            "8/8 [==============================] - 235s 30s/step - loss: 0.3284 - acc: 0.9000 - val_loss: 0.6690 - val_acc: 0.7786\n",
            "Epoch 19/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2936 - acc: 0.9061 \n",
            "Epoch 19: val_acc improved from 0.77857 to 0.82857, saving model to percobaan151_noImgPro/model\\vgg_16_151-saved-model-19-acc-0.83.hdf5\n",
            "8/8 [==============================] - 233s 31s/step - loss: 0.2936 - acc: 0.9061 - val_loss: 0.5864 - val_acc: 0.8286\n",
            "Epoch 20/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3022 - acc: 0.9102 \n",
            "Epoch 20: val_acc did not improve from 0.82857\n",
            "8/8 [==============================] - 233s 30s/step - loss: 0.3022 - acc: 0.9102 - val_loss: 0.5856 - val_acc: 0.8143\n",
            "Epoch 21/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2733 - acc: 0.9020 \n",
            "Epoch 21: val_acc did not improve from 0.82857\n",
            "8/8 [==============================] - 236s 30s/step - loss: 0.2733 - acc: 0.9020 - val_loss: 0.6677 - val_acc: 0.7857\n",
            "Epoch 22/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2892 - acc: 0.8939 \n",
            "Epoch 22: val_acc did not improve from 0.82857\n",
            "8/8 [==============================] - 234s 30s/step - loss: 0.2892 - acc: 0.8939 - val_loss: 0.7002 - val_acc: 0.7571\n",
            "Epoch 23/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3000 - acc: 0.8959 \n",
            "Epoch 23: val_acc did not improve from 0.82857\n",
            "8/8 [==============================] - 236s 30s/step - loss: 0.3000 - acc: 0.8959 - val_loss: 0.7426 - val_acc: 0.7786\n",
            "Epoch 24/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2865 - acc: 0.9143 \n",
            "Epoch 24: val_acc did not improve from 0.82857\n",
            "8/8 [==============================] - 236s 30s/step - loss: 0.2865 - acc: 0.9143 - val_loss: 0.7086 - val_acc: 0.7857\n",
            "Epoch 25/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2466 - acc: 0.9286 \n",
            "Epoch 25: val_acc did not improve from 0.82857\n",
            "8/8 [==============================] - 235s 30s/step - loss: 0.2466 - acc: 0.9286 - val_loss: 0.6112 - val_acc: 0.8286\n",
            "\n",
            "\n",
            "Model Accuracy 0.8142857142857143\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.83      1.00      0.91        10\n",
            "       10000       0.88      0.70      0.78        10\n",
            "      100000       1.00      0.50      0.67        10\n",
            "        2000       0.82      0.90      0.86        10\n",
            "       20000       0.88      0.70      0.78        10\n",
            "        5000       0.64      0.90      0.75        10\n",
            "       50000       0.83      1.00      0.91        10\n",
            "\n",
            "    accuracy                           0.81        70\n",
            "   macro avg       0.84      0.81      0.81        70\n",
            "weighted avg       0.84      0.81      0.81        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 152 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 65\n",
            "learning rate: 0.02334095125890999\n",
            "batch size: 64\n",
            "dropout rate: 0.7715818783688897\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 3.2413 - acc: 0.2163 \n",
            "Epoch 1: val_acc improved from -inf to 0.14286, saving model to percobaan152_noImgPro/model\\vgg_16_152-saved-model-01-acc-0.14.hdf5\n",
            "8/8 [==============================] - 228s 29s/step - loss: 3.2413 - acc: 0.2163 - val_loss: 10.1185 - val_acc: 0.1429\n",
            "Epoch 2/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.0885 - acc: 0.3776 \n",
            "Epoch 2: val_acc improved from 0.14286 to 0.25000, saving model to percobaan152_noImgPro/model\\vgg_16_152-saved-model-02-acc-0.25.hdf5\n",
            "8/8 [==============================] - 223s 30s/step - loss: 2.0885 - acc: 0.3776 - val_loss: 4.4780 - val_acc: 0.2500\n",
            "Epoch 3/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7455 - acc: 0.4469 \n",
            "Epoch 3: val_acc did not improve from 0.25000\n",
            "8/8 [==============================] - 225s 29s/step - loss: 1.7455 - acc: 0.4469 - val_loss: 2.7898 - val_acc: 0.2500\n",
            "Epoch 4/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4597 - acc: 0.4980 \n",
            "Epoch 4: val_acc improved from 0.25000 to 0.29286, saving model to percobaan152_noImgPro/model\\vgg_16_152-saved-model-04-acc-0.29.hdf5\n",
            "8/8 [==============================] - 226s 29s/step - loss: 1.4597 - acc: 0.4980 - val_loss: 2.4722 - val_acc: 0.2929\n",
            "Epoch 5/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3256 - acc: 0.4959 \n",
            "Epoch 5: val_acc did not improve from 0.29286\n",
            "8/8 [==============================] - 227s 29s/step - loss: 1.3256 - acc: 0.4959 - val_loss: 2.7235 - val_acc: 0.2000\n",
            "Epoch 6/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.2618 - acc: 0.5633 \n",
            "Epoch 6: val_acc did not improve from 0.29286\n",
            "8/8 [==============================] - 228s 29s/step - loss: 1.2618 - acc: 0.5633 - val_loss: 2.1570 - val_acc: 0.2786\n",
            "Epoch 7/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9853 - acc: 0.6490 \n",
            "Epoch 7: val_acc did not improve from 0.29286\n",
            "8/8 [==============================] - 228s 29s/step - loss: 0.9853 - acc: 0.6490 - val_loss: 1.8905 - val_acc: 0.2929\n",
            "Epoch 8/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9443 - acc: 0.6469 \n",
            "Epoch 8: val_acc improved from 0.29286 to 0.36429, saving model to percobaan152_noImgPro/model\\vgg_16_152-saved-model-08-acc-0.36.hdf5\n",
            "8/8 [==============================] - 228s 29s/step - loss: 0.9443 - acc: 0.6469 - val_loss: 1.7281 - val_acc: 0.3643\n",
            "Epoch 9/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8387 - acc: 0.7204 \n",
            "Epoch 9: val_acc improved from 0.36429 to 0.42857, saving model to percobaan152_noImgPro/model\\vgg_16_152-saved-model-09-acc-0.43.hdf5\n",
            "8/8 [==============================] - 227s 29s/step - loss: 0.8387 - acc: 0.7204 - val_loss: 1.5082 - val_acc: 0.4286\n",
            "Epoch 10/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7941 - acc: 0.7020 \n",
            "Epoch 10: val_acc did not improve from 0.42857\n",
            "8/8 [==============================] - 232s 30s/step - loss: 0.7941 - acc: 0.7020 - val_loss: 1.4784 - val_acc: 0.4071\n",
            "Epoch 11/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7573 - acc: 0.7286 \n",
            "Epoch 11: val_acc improved from 0.42857 to 0.45000, saving model to percobaan152_noImgPro/model\\vgg_16_152-saved-model-11-acc-0.45.hdf5\n",
            "8/8 [==============================] - 229s 30s/step - loss: 0.7573 - acc: 0.7286 - val_loss: 1.4756 - val_acc: 0.4500\n",
            "Epoch 12/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7825 - acc: 0.7265 \n",
            "Epoch 12: val_acc improved from 0.45000 to 0.54286, saving model to percobaan152_noImgPro/model\\vgg_16_152-saved-model-12-acc-0.54.hdf5\n",
            "8/8 [==============================] - 228s 29s/step - loss: 0.7825 - acc: 0.7265 - val_loss: 1.3283 - val_acc: 0.5429\n",
            "Epoch 13/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7306 - acc: 0.7510 \n",
            "Epoch 13: val_acc improved from 0.54286 to 0.55000, saving model to percobaan152_noImgPro/model\\vgg_16_152-saved-model-13-acc-0.55.hdf5\n",
            "8/8 [==============================] - 228s 30s/step - loss: 0.7306 - acc: 0.7510 - val_loss: 1.2201 - val_acc: 0.5500\n",
            "Epoch 14/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6053 - acc: 0.7714 \n",
            "Epoch 14: val_acc improved from 0.55000 to 0.67857, saving model to percobaan152_noImgPro/model\\vgg_16_152-saved-model-14-acc-0.68.hdf5\n",
            "8/8 [==============================] - 228s 29s/step - loss: 0.6053 - acc: 0.7714 - val_loss: 0.9602 - val_acc: 0.6786\n",
            "Epoch 15/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6597 - acc: 0.7694 \n",
            "Epoch 15: val_acc did not improve from 0.67857\n",
            "8/8 [==============================] - 228s 29s/step - loss: 0.6597 - acc: 0.7694 - val_loss: 0.9603 - val_acc: 0.6571\n",
            "Epoch 16/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6294 - acc: 0.7918 \n",
            "Epoch 16: val_acc did not improve from 0.67857\n",
            "8/8 [==============================] - 229s 29s/step - loss: 0.6294 - acc: 0.7918 - val_loss: 0.8878 - val_acc: 0.6786\n",
            "Epoch 17/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5934 - acc: 0.7816 \n",
            "Epoch 17: val_acc improved from 0.67857 to 0.72857, saving model to percobaan152_noImgPro/model\\vgg_16_152-saved-model-17-acc-0.73.hdf5\n",
            "8/8 [==============================] - 229s 29s/step - loss: 0.5934 - acc: 0.7816 - val_loss: 0.8472 - val_acc: 0.7286\n",
            "Epoch 18/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5571 - acc: 0.8061 \n",
            "Epoch 18: val_acc did not improve from 0.72857\n",
            "8/8 [==============================] - 227s 29s/step - loss: 0.5571 - acc: 0.8061 - val_loss: 0.8820 - val_acc: 0.7214\n",
            "Epoch 19/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5412 - acc: 0.8122 \n",
            "Epoch 19: val_acc did not improve from 0.72857\n",
            "8/8 [==============================] - 227s 30s/step - loss: 0.5412 - acc: 0.8122 - val_loss: 1.0614 - val_acc: 0.6714\n",
            "Epoch 20/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4990 - acc: 0.8163 \n",
            "Epoch 20: val_acc did not improve from 0.72857\n",
            "8/8 [==============================] - 228s 29s/step - loss: 0.4990 - acc: 0.8163 - val_loss: 1.0757 - val_acc: 0.6357\n",
            "Epoch 21/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5321 - acc: 0.8184 \n",
            "Epoch 21: val_acc improved from 0.72857 to 0.75000, saving model to percobaan152_noImgPro/model\\vgg_16_152-saved-model-21-acc-0.75.hdf5\n",
            "8/8 [==============================] - 227s 29s/step - loss: 0.5321 - acc: 0.8184 - val_loss: 0.8086 - val_acc: 0.7500\n",
            "Epoch 22/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4960 - acc: 0.8245 \n",
            "Epoch 22: val_acc improved from 0.75000 to 0.77143, saving model to percobaan152_noImgPro/model\\vgg_16_152-saved-model-22-acc-0.77.hdf5\n",
            "8/8 [==============================] - 228s 29s/step - loss: 0.4960 - acc: 0.8245 - val_loss: 0.7068 - val_acc: 0.7714\n",
            "Epoch 23/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5006 - acc: 0.8102 \n",
            "Epoch 23: val_acc improved from 0.77143 to 0.80000, saving model to percobaan152_noImgPro/model\\vgg_16_152-saved-model-23-acc-0.80.hdf5\n",
            "8/8 [==============================] - 229s 29s/step - loss: 0.5006 - acc: 0.8102 - val_loss: 0.6687 - val_acc: 0.8000\n",
            "Epoch 24/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4828 - acc: 0.8388 \n",
            "Epoch 24: val_acc improved from 0.80000 to 0.81429, saving model to percobaan152_noImgPro/model\\vgg_16_152-saved-model-24-acc-0.81.hdf5\n",
            "8/8 [==============================] - 228s 29s/step - loss: 0.4828 - acc: 0.8388 - val_loss: 0.6473 - val_acc: 0.8143\n",
            "Epoch 25/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5126 - acc: 0.8265 \n",
            "Epoch 25: val_acc did not improve from 0.81429\n",
            "8/8 [==============================] - 227s 29s/step - loss: 0.5126 - acc: 0.8265 - val_loss: 0.7154 - val_acc: 0.7643\n",
            "Epoch 26/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4552 - acc: 0.8367 \n",
            "Epoch 26: val_acc did not improve from 0.81429\n",
            "8/8 [==============================] - 229s 29s/step - loss: 0.4552 - acc: 0.8367 - val_loss: 0.6879 - val_acc: 0.7857\n",
            "Epoch 27/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4272 - acc: 0.8306 \n",
            "Epoch 27: val_acc did not improve from 0.81429\n",
            "8/8 [==============================] - 228s 30s/step - loss: 0.4272 - acc: 0.8306 - val_loss: 0.6699 - val_acc: 0.8000\n",
            "Epoch 28/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3641 - acc: 0.8633 \n",
            "Epoch 28: val_acc improved from 0.81429 to 0.83571, saving model to percobaan152_noImgPro/model\\vgg_16_152-saved-model-28-acc-0.84.hdf5\n",
            "8/8 [==============================] - 228s 29s/step - loss: 0.3641 - acc: 0.8633 - val_loss: 0.5623 - val_acc: 0.8357\n",
            "Epoch 29/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4533 - acc: 0.8429 \n",
            "Epoch 29: val_acc improved from 0.83571 to 0.85714, saving model to percobaan152_noImgPro/model\\vgg_16_152-saved-model-29-acc-0.86.hdf5\n",
            "8/8 [==============================] - 227s 29s/step - loss: 0.4533 - acc: 0.8429 - val_loss: 0.5441 - val_acc: 0.8571\n",
            "Epoch 30/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3205 - acc: 0.8796 \n",
            "Epoch 30: val_acc did not improve from 0.85714\n",
            "8/8 [==============================] - 227s 29s/step - loss: 0.3205 - acc: 0.8796 - val_loss: 0.5247 - val_acc: 0.8500\n",
            "Epoch 31/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4168 - acc: 0.8551 \n",
            "Epoch 31: val_acc did not improve from 0.85714\n",
            "8/8 [==============================] - 230s 29s/step - loss: 0.4168 - acc: 0.8551 - val_loss: 0.5567 - val_acc: 0.8357\n",
            "Epoch 32/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3908 - acc: 0.8571 \n",
            "Epoch 32: val_acc did not improve from 0.85714\n",
            "8/8 [==============================] - 228s 29s/step - loss: 0.3908 - acc: 0.8571 - val_loss: 0.5960 - val_acc: 0.8286\n",
            "Epoch 33/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4063 - acc: 0.8531 \n",
            "Epoch 33: val_acc did not improve from 0.85714\n",
            "8/8 [==============================] - 226s 29s/step - loss: 0.4063 - acc: 0.8531 - val_loss: 0.6408 - val_acc: 0.8000\n",
            "Epoch 34/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4396 - acc: 0.8531 \n",
            "Epoch 34: val_acc did not improve from 0.85714\n",
            "8/8 [==============================] - 228s 29s/step - loss: 0.4396 - acc: 0.8531 - val_loss: 0.5581 - val_acc: 0.8357\n",
            "Epoch 35/65\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3821 - acc: 0.8653 \n",
            "Epoch 35: val_acc did not improve from 0.85714\n",
            "8/8 [==============================] - 228s 29s/step - loss: 0.3821 - acc: 0.8653 - val_loss: 0.5709 - val_acc: 0.8429\n",
            "\n",
            "\n",
            "Model Accuracy 0.8\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.90      0.90      0.90        10\n",
            "       10000       1.00      0.90      0.95        10\n",
            "      100000       1.00      0.40      0.57        10\n",
            "        2000       0.77      1.00      0.87        10\n",
            "       20000       0.86      0.60      0.71        10\n",
            "        5000       0.56      1.00      0.71        10\n",
            "       50000       0.89      0.80      0.84        10\n",
            "\n",
            "    accuracy                           0.80        70\n",
            "   macro avg       0.85      0.80      0.79        70\n",
            "weighted avg       0.85      0.80      0.79        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 153 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 58\n",
            "learning rate: 0.0015143797566057565\n",
            "batch size: 128\n",
            "dropout rate: 0.5717586508280008\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 3.0616 - acc: 0.2102 \n",
            "Epoch 1: val_acc improved from -inf to 0.18571, saving model to percobaan153_noImgPro/model\\vgg_16_153-saved-model-01-acc-0.19.hdf5\n",
            "4/4 [==============================] - 221s 58s/step - loss: 3.0616 - acc: 0.2102 - val_loss: 2.0933 - val_acc: 0.1857\n",
            "Epoch 2/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.4139 - acc: 0.2959 \n",
            "Epoch 2: val_acc did not improve from 0.18571\n",
            "4/4 [==============================] - 220s 59s/step - loss: 2.4139 - acc: 0.2959 - val_loss: 1.9712 - val_acc: 0.1786\n",
            "Epoch 3/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.8358 - acc: 0.3980 \n",
            "Epoch 3: val_acc improved from 0.18571 to 0.20714, saving model to percobaan153_noImgPro/model\\vgg_16_153-saved-model-03-acc-0.21.hdf5\n",
            "4/4 [==============================] - 220s 58s/step - loss: 1.8358 - acc: 0.3980 - val_loss: 1.8251 - val_acc: 0.2071\n",
            "Epoch 4/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.5290 - acc: 0.4878 \n",
            "Epoch 4: val_acc improved from 0.20714 to 0.30000, saving model to percobaan153_noImgPro/model\\vgg_16_153-saved-model-04-acc-0.30.hdf5\n",
            "4/4 [==============================] - 220s 58s/step - loss: 1.5290 - acc: 0.4878 - val_loss: 1.7036 - val_acc: 0.3000\n",
            "Epoch 5/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.3625 - acc: 0.5306 \n",
            "Epoch 5: val_acc improved from 0.30000 to 0.33571, saving model to percobaan153_noImgPro/model\\vgg_16_153-saved-model-05-acc-0.34.hdf5\n",
            "4/4 [==============================] - 221s 58s/step - loss: 1.3625 - acc: 0.5306 - val_loss: 1.6093 - val_acc: 0.3357\n",
            "Epoch 6/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0977 - acc: 0.6163 \n",
            "Epoch 6: val_acc did not improve from 0.33571\n",
            "4/4 [==============================] - 222s 59s/step - loss: 1.0977 - acc: 0.6163 - val_loss: 1.5683 - val_acc: 0.3357\n",
            "Epoch 7/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9707 - acc: 0.6714 \n",
            "Epoch 7: val_acc did not improve from 0.33571\n",
            "4/4 [==============================] - 220s 59s/step - loss: 0.9707 - acc: 0.6714 - val_loss: 1.5510 - val_acc: 0.3357\n",
            "Epoch 8/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8783 - acc: 0.6918 \n",
            "Epoch 8: val_acc did not improve from 0.33571\n",
            "4/4 [==============================] - 220s 58s/step - loss: 0.8783 - acc: 0.6918 - val_loss: 1.5292 - val_acc: 0.3357\n",
            "Epoch 9/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8328 - acc: 0.6980 \n",
            "Epoch 9: val_acc improved from 0.33571 to 0.35000, saving model to percobaan153_noImgPro/model\\vgg_16_153-saved-model-09-acc-0.35.hdf5\n",
            "4/4 [==============================] - 221s 59s/step - loss: 0.8328 - acc: 0.6980 - val_loss: 1.4793 - val_acc: 0.3500\n",
            "Epoch 10/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7105 - acc: 0.7347 \n",
            "Epoch 10: val_acc improved from 0.35000 to 0.40714, saving model to percobaan153_noImgPro/model\\vgg_16_153-saved-model-10-acc-0.41.hdf5\n",
            "4/4 [==============================] - 223s 59s/step - loss: 0.7105 - acc: 0.7347 - val_loss: 1.4297 - val_acc: 0.4071\n",
            "Epoch 11/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6521 - acc: 0.7878 \n",
            "Epoch 11: val_acc improved from 0.40714 to 0.45714, saving model to percobaan153_noImgPro/model\\vgg_16_153-saved-model-11-acc-0.46.hdf5\n",
            "4/4 [==============================] - 222s 59s/step - loss: 0.6521 - acc: 0.7878 - val_loss: 1.3675 - val_acc: 0.4571\n",
            "Epoch 12/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5543 - acc: 0.8163 \n",
            "Epoch 12: val_acc improved from 0.45714 to 0.50714, saving model to percobaan153_noImgPro/model\\vgg_16_153-saved-model-12-acc-0.51.hdf5\n",
            "4/4 [==============================] - 222s 59s/step - loss: 0.5543 - acc: 0.8163 - val_loss: 1.3094 - val_acc: 0.5071\n",
            "Epoch 13/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4929 - acc: 0.8327 \n",
            "Epoch 13: val_acc improved from 0.50714 to 0.54286, saving model to percobaan153_noImgPro/model\\vgg_16_153-saved-model-13-acc-0.54.hdf5\n",
            "4/4 [==============================] - 221s 59s/step - loss: 0.4929 - acc: 0.8327 - val_loss: 1.2482 - val_acc: 0.5429\n",
            "Epoch 14/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5424 - acc: 0.8184 \n",
            "Epoch 14: val_acc improved from 0.54286 to 0.59286, saving model to percobaan153_noImgPro/model\\vgg_16_153-saved-model-14-acc-0.59.hdf5\n",
            "4/4 [==============================] - 222s 59s/step - loss: 0.5424 - acc: 0.8184 - val_loss: 1.1924 - val_acc: 0.5929\n",
            "Epoch 15/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5067 - acc: 0.8327 \n",
            "Epoch 15: val_acc did not improve from 0.59286\n",
            "4/4 [==============================] - 221s 59s/step - loss: 0.5067 - acc: 0.8327 - val_loss: 1.1597 - val_acc: 0.5929\n",
            "Epoch 16/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4714 - acc: 0.8286 \n",
            "Epoch 16: val_acc did not improve from 0.59286\n",
            "4/4 [==============================] - 220s 58s/step - loss: 0.4714 - acc: 0.8286 - val_loss: 1.1514 - val_acc: 0.5929\n",
            "Epoch 17/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3935 - acc: 0.8714 \n",
            "Epoch 17: val_acc did not improve from 0.59286\n",
            "4/4 [==============================] - 219s 61s/step - loss: 0.3935 - acc: 0.8714 - val_loss: 1.1390 - val_acc: 0.5929\n",
            "Epoch 18/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4183 - acc: 0.8490 \n",
            "Epoch 18: val_acc did not improve from 0.59286\n",
            "4/4 [==============================] - 222s 59s/step - loss: 0.4183 - acc: 0.8490 - val_loss: 1.1144 - val_acc: 0.5857\n",
            "Epoch 19/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3517 - acc: 0.8959 \n",
            "Epoch 19: val_acc improved from 0.59286 to 0.62143, saving model to percobaan153_noImgPro/model\\vgg_16_153-saved-model-19-acc-0.62.hdf5\n",
            "4/4 [==============================] - 220s 59s/step - loss: 0.3517 - acc: 0.8959 - val_loss: 1.0848 - val_acc: 0.6214\n",
            "Epoch 20/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3619 - acc: 0.8816 \n",
            "Epoch 20: val_acc improved from 0.62143 to 0.65714, saving model to percobaan153_noImgPro/model\\vgg_16_153-saved-model-20-acc-0.66.hdf5\n",
            "4/4 [==============================] - 220s 61s/step - loss: 0.3619 - acc: 0.8816 - val_loss: 1.0576 - val_acc: 0.6571\n",
            "Epoch 21/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3449 - acc: 0.8837 \n",
            "Epoch 21: val_acc did not improve from 0.65714\n",
            "4/4 [==============================] - 222s 59s/step - loss: 0.3449 - acc: 0.8837 - val_loss: 1.0373 - val_acc: 0.6571\n",
            "Epoch 22/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3400 - acc: 0.9061 \n",
            "Epoch 22: val_acc improved from 0.65714 to 0.69286, saving model to percobaan153_noImgPro/model\\vgg_16_153-saved-model-22-acc-0.69.hdf5\n",
            "4/4 [==============================] - 219s 58s/step - loss: 0.3400 - acc: 0.9061 - val_loss: 1.0054 - val_acc: 0.6929\n",
            "Epoch 23/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3397 - acc: 0.9041 \n",
            "Epoch 23: val_acc improved from 0.69286 to 0.70714, saving model to percobaan153_noImgPro/model\\vgg_16_153-saved-model-23-acc-0.71.hdf5\n",
            "4/4 [==============================] - 218s 58s/step - loss: 0.3397 - acc: 0.9041 - val_loss: 0.9711 - val_acc: 0.7071\n",
            "Epoch 24/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3100 - acc: 0.9000 \n",
            "Epoch 24: val_acc improved from 0.70714 to 0.72857, saving model to percobaan153_noImgPro/model\\vgg_16_153-saved-model-24-acc-0.73.hdf5\n",
            "4/4 [==============================] - 223s 59s/step - loss: 0.3100 - acc: 0.9000 - val_loss: 0.9376 - val_acc: 0.7286\n",
            "Epoch 25/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2836 - acc: 0.9143 \n",
            "Epoch 25: val_acc improved from 0.72857 to 0.75000, saving model to percobaan153_noImgPro/model\\vgg_16_153-saved-model-25-acc-0.75.hdf5\n",
            "4/4 [==============================] - 221s 59s/step - loss: 0.2836 - acc: 0.9143 - val_loss: 0.9099 - val_acc: 0.7500\n",
            "Epoch 26/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2934 - acc: 0.8980 \n",
            "Epoch 26: val_acc did not improve from 0.75000\n",
            "4/4 [==============================] - 221s 59s/step - loss: 0.2934 - acc: 0.8980 - val_loss: 0.8824 - val_acc: 0.7500\n",
            "Epoch 27/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2994 - acc: 0.9000 \n",
            "Epoch 27: val_acc improved from 0.75000 to 0.77143, saving model to percobaan153_noImgPro/model\\vgg_16_153-saved-model-27-acc-0.77.hdf5\n",
            "4/4 [==============================] - 219s 58s/step - loss: 0.2994 - acc: 0.9000 - val_loss: 0.8582 - val_acc: 0.7714\n",
            "Epoch 28/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2550 - acc: 0.9163 \n",
            "Epoch 28: val_acc did not improve from 0.77143\n",
            "4/4 [==============================] - 222s 59s/step - loss: 0.2550 - acc: 0.9163 - val_loss: 0.8335 - val_acc: 0.7500\n",
            "Epoch 29/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2273 - acc: 0.9347 \n",
            "Epoch 29: val_acc did not improve from 0.77143\n",
            "4/4 [==============================] - 224s 62s/step - loss: 0.2273 - acc: 0.9347 - val_loss: 0.8163 - val_acc: 0.7571\n",
            "Epoch 30/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2572 - acc: 0.9000 \n",
            "Epoch 30: val_acc did not improve from 0.77143\n",
            "4/4 [==============================] - 221s 59s/step - loss: 0.2572 - acc: 0.9000 - val_loss: 0.7898 - val_acc: 0.7643\n",
            "Epoch 31/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2372 - acc: 0.9102 \n",
            "Epoch 31: val_acc did not improve from 0.77143\n",
            "4/4 [==============================] - 220s 59s/step - loss: 0.2372 - acc: 0.9102 - val_loss: 0.7632 - val_acc: 0.7714\n",
            "Epoch 32/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2183 - acc: 0.9429 \n",
            "Epoch 32: val_acc improved from 0.77143 to 0.81429, saving model to percobaan153_noImgPro/model\\vgg_16_153-saved-model-32-acc-0.81.hdf5\n",
            "4/4 [==============================] - 223s 59s/step - loss: 0.2183 - acc: 0.9429 - val_loss: 0.7315 - val_acc: 0.8143\n",
            "Epoch 33/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2253 - acc: 0.9286 \n",
            "Epoch 33: val_acc improved from 0.81429 to 0.82143, saving model to percobaan153_noImgPro/model\\vgg_16_153-saved-model-33-acc-0.82.hdf5\n",
            "4/4 [==============================] - 221s 61s/step - loss: 0.2253 - acc: 0.9286 - val_loss: 0.7067 - val_acc: 0.8214\n",
            "Epoch 34/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2107 - acc: 0.9367 \n",
            "Epoch 34: val_acc did not improve from 0.82143\n",
            "4/4 [==============================] - 219s 58s/step - loss: 0.2107 - acc: 0.9367 - val_loss: 0.6903 - val_acc: 0.8143\n",
            "Epoch 35/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2165 - acc: 0.9347 \n",
            "Epoch 35: val_acc improved from 0.82143 to 0.82857, saving model to percobaan153_noImgPro/model\\vgg_16_153-saved-model-35-acc-0.83.hdf5\n",
            "4/4 [==============================] - 220s 59s/step - loss: 0.2165 - acc: 0.9347 - val_loss: 0.6836 - val_acc: 0.8286\n",
            "Epoch 36/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1998 - acc: 0.9408 \n",
            "Epoch 36: val_acc did not improve from 0.82857\n",
            "4/4 [==============================] - 220s 61s/step - loss: 0.1998 - acc: 0.9408 - val_loss: 0.6793 - val_acc: 0.8071\n",
            "Epoch 37/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2142 - acc: 0.9388 \n",
            "Epoch 37: val_acc did not improve from 0.82857\n",
            "4/4 [==============================] - 220s 59s/step - loss: 0.2142 - acc: 0.9388 - val_loss: 0.6718 - val_acc: 0.8143\n",
            "Epoch 38/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1953 - acc: 0.9408 \n",
            "Epoch 38: val_acc did not improve from 0.82857\n",
            "4/4 [==============================] - 221s 59s/step - loss: 0.1953 - acc: 0.9408 - val_loss: 0.6652 - val_acc: 0.7929\n",
            "Epoch 39/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1826 - acc: 0.9347 \n",
            "Epoch 39: val_acc did not improve from 0.82857\n",
            "4/4 [==============================] - 220s 58s/step - loss: 0.1826 - acc: 0.9347 - val_loss: 0.6511 - val_acc: 0.8143\n",
            "Epoch 40/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1391 - acc: 0.9551 \n",
            "Epoch 40: val_acc did not improve from 0.82857\n",
            "4/4 [==============================] - 222s 59s/step - loss: 0.1391 - acc: 0.9551 - val_loss: 0.6322 - val_acc: 0.8143\n",
            "Epoch 41/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1660 - acc: 0.9510 \n",
            "Epoch 41: val_acc improved from 0.82857 to 0.83571, saving model to percobaan153_noImgPro/model\\vgg_16_153-saved-model-41-acc-0.84.hdf5\n",
            "4/4 [==============================] - 219s 58s/step - loss: 0.1660 - acc: 0.9510 - val_loss: 0.6125 - val_acc: 0.8357\n",
            "Epoch 42/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1880 - acc: 0.9347 \n",
            "Epoch 42: val_acc did not improve from 0.83571\n",
            "4/4 [==============================] - 219s 58s/step - loss: 0.1880 - acc: 0.9347 - val_loss: 0.5980 - val_acc: 0.8357\n",
            "Epoch 43/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1617 - acc: 0.9551 \n",
            "Epoch 43: val_acc improved from 0.83571 to 0.85000, saving model to percobaan153_noImgPro/model\\vgg_16_153-saved-model-43-acc-0.85.hdf5\n",
            "4/4 [==============================] - 219s 58s/step - loss: 0.1617 - acc: 0.9551 - val_loss: 0.5839 - val_acc: 0.8500\n",
            "Epoch 44/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1525 - acc: 0.9510 \n",
            "Epoch 44: val_acc did not improve from 0.85000\n",
            "4/4 [==============================] - 223s 59s/step - loss: 0.1525 - acc: 0.9510 - val_loss: 0.5740 - val_acc: 0.8357\n",
            "Epoch 45/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1571 - acc: 0.9510 \n",
            "Epoch 45: val_acc improved from 0.85000 to 0.85714, saving model to percobaan153_noImgPro/model\\vgg_16_153-saved-model-45-acc-0.86.hdf5\n",
            "4/4 [==============================] - 222s 61s/step - loss: 0.1571 - acc: 0.9510 - val_loss: 0.5637 - val_acc: 0.8571\n",
            "Epoch 46/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1326 - acc: 0.9694 \n",
            "Epoch 46: val_acc did not improve from 0.85714\n",
            "4/4 [==============================] - 222s 62s/step - loss: 0.1326 - acc: 0.9694 - val_loss: 0.5573 - val_acc: 0.8500\n",
            "Epoch 47/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1315 - acc: 0.9571 \n",
            "Epoch 47: val_acc did not improve from 0.85714\n",
            "4/4 [==============================] - 220s 61s/step - loss: 0.1315 - acc: 0.9571 - val_loss: 0.5511 - val_acc: 0.8500\n",
            "Epoch 48/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1579 - acc: 0.9388 \n",
            "Epoch 48: val_acc did not improve from 0.85714\n",
            "4/4 [==============================] - 220s 59s/step - loss: 0.1579 - acc: 0.9388 - val_loss: 0.5377 - val_acc: 0.8500\n",
            "Epoch 49/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1427 - acc: 0.9551 \n",
            "Epoch 49: val_acc did not improve from 0.85714\n",
            "4/4 [==============================] - 218s 60s/step - loss: 0.1427 - acc: 0.9551 - val_loss: 0.5263 - val_acc: 0.8571\n",
            "Epoch 50/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1202 - acc: 0.9816 \n",
            "Epoch 50: val_acc improved from 0.85714 to 0.87143, saving model to percobaan153_noImgPro/model\\vgg_16_153-saved-model-50-acc-0.87.hdf5\n",
            "4/4 [==============================] - 223s 59s/step - loss: 0.1202 - acc: 0.9816 - val_loss: 0.5175 - val_acc: 0.8714\n",
            "Epoch 51/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1326 - acc: 0.9633 \n",
            "Epoch 51: val_acc improved from 0.87143 to 0.87857, saving model to percobaan153_noImgPro/model\\vgg_16_153-saved-model-51-acc-0.88.hdf5\n",
            "4/4 [==============================] - 222s 59s/step - loss: 0.1326 - acc: 0.9633 - val_loss: 0.5140 - val_acc: 0.8786\n",
            "Epoch 52/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1487 - acc: 0.9510 \n",
            "Epoch 52: val_acc improved from 0.87857 to 0.88571, saving model to percobaan153_noImgPro/model\\vgg_16_153-saved-model-52-acc-0.89.hdf5\n",
            "4/4 [==============================] - 220s 58s/step - loss: 0.1487 - acc: 0.9510 - val_loss: 0.5115 - val_acc: 0.8857\n",
            "Epoch 53/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1504 - acc: 0.9469 \n",
            "Epoch 53: val_acc improved from 0.88571 to 0.89286, saving model to percobaan153_noImgPro/model\\vgg_16_153-saved-model-53-acc-0.89.hdf5\n",
            "4/4 [==============================] - 222s 59s/step - loss: 0.1504 - acc: 0.9469 - val_loss: 0.5037 - val_acc: 0.8929\n",
            "Epoch 54/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1558 - acc: 0.9633 \n",
            "Epoch 54: val_acc did not improve from 0.89286\n",
            "4/4 [==============================] - 220s 58s/step - loss: 0.1558 - acc: 0.9633 - val_loss: 0.4889 - val_acc: 0.8857\n",
            "Epoch 55/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1230 - acc: 0.9571 \n",
            "Epoch 55: val_acc did not improve from 0.89286\n",
            "4/4 [==============================] - 220s 58s/step - loss: 0.1230 - acc: 0.9571 - val_loss: 0.4756 - val_acc: 0.8857\n",
            "Epoch 56/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1264 - acc: 0.9673 \n",
            "Epoch 56: val_acc did not improve from 0.89286\n",
            "4/4 [==============================] - 220s 58s/step - loss: 0.1264 - acc: 0.9673 - val_loss: 0.4634 - val_acc: 0.8786\n",
            "Epoch 57/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0969 - acc: 0.9755 \n",
            "Epoch 57: val_acc did not improve from 0.89286\n",
            "4/4 [==============================] - 221s 62s/step - loss: 0.0969 - acc: 0.9755 - val_loss: 0.4528 - val_acc: 0.8857\n",
            "Epoch 58/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1336 - acc: 0.9592 \n",
            "Epoch 58: val_acc did not improve from 0.89286\n",
            "4/4 [==============================] - 220s 61s/step - loss: 0.1336 - acc: 0.9592 - val_loss: 0.4469 - val_acc: 0.8857\n",
            "\n",
            "\n",
            "Model Accuracy 0.8142857142857143\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.75      0.90      0.82        10\n",
            "       10000       1.00      0.90      0.95        10\n",
            "      100000       1.00      0.80      0.89        10\n",
            "        2000       0.75      0.90      0.82        10\n",
            "       20000       1.00      0.30      0.46        10\n",
            "        5000       0.90      0.90      0.90        10\n",
            "       50000       0.62      1.00      0.77        10\n",
            "\n",
            "    accuracy                           0.81        70\n",
            "   macro avg       0.86      0.81      0.80        70\n",
            "weighted avg       0.86      0.81      0.80        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 154 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 58\n",
            "learning rate: 0.0024309678834137935\n",
            "batch size: 128\n",
            "dropout rate: 0.617415284972867\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 3.0105 - acc: 0.1939 \n",
            "Epoch 1: val_acc improved from -inf to 0.14286, saving model to percobaan154_noImgPro/model\\vgg_16_154-saved-model-01-acc-0.14.hdf5\n",
            "4/4 [==============================] - 220s 60s/step - loss: 3.0105 - acc: 0.1939 - val_loss: 2.3077 - val_acc: 0.1429\n",
            "Epoch 2/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.0286 - acc: 0.3571 \n",
            "Epoch 2: val_acc did not improve from 0.14286\n",
            "4/4 [==============================] - 217s 58s/step - loss: 2.0286 - acc: 0.3571 - val_loss: 2.6494 - val_acc: 0.1429\n",
            "Epoch 3/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.7114 - acc: 0.4449 \n",
            "Epoch 3: val_acc did not improve from 0.14286\n",
            "4/4 [==============================] - 221s 59s/step - loss: 1.7114 - acc: 0.4449 - val_loss: 2.6414 - val_acc: 0.1429\n",
            "Epoch 4/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.3749 - acc: 0.5041 \n",
            "Epoch 4: val_acc improved from 0.14286 to 0.15000, saving model to percobaan154_noImgPro/model\\vgg_16_154-saved-model-04-acc-0.15.hdf5\n",
            "4/4 [==============================] - 221s 59s/step - loss: 1.3749 - acc: 0.5041 - val_loss: 2.4802 - val_acc: 0.1500\n",
            "Epoch 5/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1304 - acc: 0.6000 \n",
            "Epoch 5: val_acc improved from 0.15000 to 0.16429, saving model to percobaan154_noImgPro/model\\vgg_16_154-saved-model-05-acc-0.16.hdf5\n",
            "4/4 [==============================] - 220s 58s/step - loss: 1.1304 - acc: 0.6000 - val_loss: 2.2461 - val_acc: 0.1643\n",
            "Epoch 6/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8752 - acc: 0.7061 \n",
            "Epoch 6: val_acc improved from 0.16429 to 0.19286, saving model to percobaan154_noImgPro/model\\vgg_16_154-saved-model-06-acc-0.19.hdf5\n",
            "4/4 [==============================] - 217s 58s/step - loss: 0.8752 - acc: 0.7061 - val_loss: 2.0738 - val_acc: 0.1929\n",
            "Epoch 7/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8196 - acc: 0.7143 \n",
            "Epoch 7: val_acc improved from 0.19286 to 0.22857, saving model to percobaan154_noImgPro/model\\vgg_16_154-saved-model-07-acc-0.23.hdf5\n",
            "4/4 [==============================] - 219s 58s/step - loss: 0.8196 - acc: 0.7143 - val_loss: 1.9627 - val_acc: 0.2286\n",
            "Epoch 8/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7631 - acc: 0.7347 \n",
            "Epoch 8: val_acc improved from 0.22857 to 0.24286, saving model to percobaan154_noImgPro/model\\vgg_16_154-saved-model-08-acc-0.24.hdf5\n",
            "4/4 [==============================] - 219s 58s/step - loss: 0.7631 - acc: 0.7347 - val_loss: 1.8863 - val_acc: 0.2429\n",
            "Epoch 9/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6771 - acc: 0.7653 \n",
            "Epoch 9: val_acc improved from 0.24286 to 0.25000, saving model to percobaan154_noImgPro/model\\vgg_16_154-saved-model-09-acc-0.25.hdf5\n",
            "4/4 [==============================] - 222s 59s/step - loss: 0.6771 - acc: 0.7653 - val_loss: 1.8338 - val_acc: 0.2500\n",
            "Epoch 10/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5613 - acc: 0.8122 \n",
            "Epoch 10: val_acc improved from 0.25000 to 0.30000, saving model to percobaan154_noImgPro/model\\vgg_16_154-saved-model-10-acc-0.30.hdf5\n",
            "4/4 [==============================] - 220s 59s/step - loss: 0.5613 - acc: 0.8122 - val_loss: 1.7969 - val_acc: 0.3000\n",
            "Epoch 11/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5095 - acc: 0.8224 \n",
            "Epoch 11: val_acc improved from 0.30000 to 0.31429, saving model to percobaan154_noImgPro/model\\vgg_16_154-saved-model-11-acc-0.31.hdf5\n",
            "4/4 [==============================] - 221s 61s/step - loss: 0.5095 - acc: 0.8224 - val_loss: 1.7760 - val_acc: 0.3143\n",
            "Epoch 12/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5248 - acc: 0.8327 \n",
            "Epoch 12: val_acc improved from 0.31429 to 0.32857, saving model to percobaan154_noImgPro/model\\vgg_16_154-saved-model-12-acc-0.33.hdf5\n",
            "4/4 [==============================] - 218s 60s/step - loss: 0.5248 - acc: 0.8327 - val_loss: 1.7252 - val_acc: 0.3286\n",
            "Epoch 13/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5104 - acc: 0.8204 \n",
            "Epoch 13: val_acc improved from 0.32857 to 0.33571, saving model to percobaan154_noImgPro/model\\vgg_16_154-saved-model-13-acc-0.34.hdf5\n",
            "4/4 [==============================] - 218s 58s/step - loss: 0.5104 - acc: 0.8204 - val_loss: 1.6404 - val_acc: 0.3357\n",
            "Epoch 14/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4381 - acc: 0.8367 \n",
            "Epoch 14: val_acc improved from 0.33571 to 0.34286, saving model to percobaan154_noImgPro/model\\vgg_16_154-saved-model-14-acc-0.34.hdf5\n",
            "4/4 [==============================] - 220s 58s/step - loss: 0.4381 - acc: 0.8367 - val_loss: 1.5651 - val_acc: 0.3429\n",
            "Epoch 15/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4141 - acc: 0.8551 \n",
            "Epoch 15: val_acc improved from 0.34286 to 0.37143, saving model to percobaan154_noImgPro/model\\vgg_16_154-saved-model-15-acc-0.37.hdf5\n",
            "4/4 [==============================] - 223s 59s/step - loss: 0.4141 - acc: 0.8551 - val_loss: 1.4859 - val_acc: 0.3714\n",
            "Epoch 16/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3703 - acc: 0.8755 \n",
            "Epoch 16: val_acc improved from 0.37143 to 0.44286, saving model to percobaan154_noImgPro/model\\vgg_16_154-saved-model-16-acc-0.44.hdf5\n",
            "4/4 [==============================] - 219s 61s/step - loss: 0.3703 - acc: 0.8755 - val_loss: 1.3846 - val_acc: 0.4429\n",
            "Epoch 17/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3442 - acc: 0.8918 \n",
            "Epoch 17: val_acc improved from 0.44286 to 0.47143, saving model to percobaan154_noImgPro/model\\vgg_16_154-saved-model-17-acc-0.47.hdf5\n",
            "4/4 [==============================] - 220s 59s/step - loss: 0.3442 - acc: 0.8918 - val_loss: 1.3014 - val_acc: 0.4714\n",
            "Epoch 18/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3035 - acc: 0.9143 \n",
            "Epoch 18: val_acc improved from 0.47143 to 0.50000, saving model to percobaan154_noImgPro/model\\vgg_16_154-saved-model-18-acc-0.50.hdf5\n",
            "4/4 [==============================] - 218s 58s/step - loss: 0.3035 - acc: 0.9143 - val_loss: 1.2353 - val_acc: 0.5000\n",
            "Epoch 19/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2945 - acc: 0.9122 \n",
            "Epoch 19: val_acc improved from 0.50000 to 0.53571, saving model to percobaan154_noImgPro/model\\vgg_16_154-saved-model-19-acc-0.54.hdf5\n",
            "4/4 [==============================] - 219s 61s/step - loss: 0.2945 - acc: 0.9122 - val_loss: 1.1756 - val_acc: 0.5357\n",
            "Epoch 20/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2528 - acc: 0.9224 \n",
            "Epoch 20: val_acc improved from 0.53571 to 0.57143, saving model to percobaan154_noImgPro/model\\vgg_16_154-saved-model-20-acc-0.57.hdf5\n",
            "4/4 [==============================] - 219s 60s/step - loss: 0.2528 - acc: 0.9224 - val_loss: 1.1244 - val_acc: 0.5714\n",
            "Epoch 21/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3178 - acc: 0.9061 \n",
            "Epoch 21: val_acc improved from 0.57143 to 0.62857, saving model to percobaan154_noImgPro/model\\vgg_16_154-saved-model-21-acc-0.63.hdf5\n",
            "4/4 [==============================] - 219s 58s/step - loss: 0.3178 - acc: 0.9061 - val_loss: 1.0584 - val_acc: 0.6286\n",
            "Epoch 22/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2205 - acc: 0.9306 \n",
            "Epoch 22: val_acc improved from 0.62857 to 0.65714, saving model to percobaan154_noImgPro/model\\vgg_16_154-saved-model-22-acc-0.66.hdf5\n",
            "4/4 [==============================] - 220s 58s/step - loss: 0.2205 - acc: 0.9306 - val_loss: 1.0160 - val_acc: 0.6571\n",
            "Epoch 23/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2702 - acc: 0.9143 \n",
            "Epoch 23: val_acc improved from 0.65714 to 0.67857, saving model to percobaan154_noImgPro/model\\vgg_16_154-saved-model-23-acc-0.68.hdf5\n",
            "4/4 [==============================] - 221s 59s/step - loss: 0.2702 - acc: 0.9143 - val_loss: 0.9723 - val_acc: 0.6786\n",
            "Epoch 24/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2566 - acc: 0.9184 \n",
            "Epoch 24: val_acc improved from 0.67857 to 0.68571, saving model to percobaan154_noImgPro/model\\vgg_16_154-saved-model-24-acc-0.69.hdf5\n",
            "4/4 [==============================] - 219s 58s/step - loss: 0.2566 - acc: 0.9184 - val_loss: 0.9576 - val_acc: 0.6857\n",
            "Epoch 25/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2460 - acc: 0.9306 \n",
            "Epoch 25: val_acc did not improve from 0.68571\n",
            "4/4 [==============================] - 220s 58s/step - loss: 0.2460 - acc: 0.9306 - val_loss: 0.9503 - val_acc: 0.6857\n",
            "Epoch 26/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2444 - acc: 0.9163 \n",
            "Epoch 26: val_acc did not improve from 0.68571\n",
            "4/4 [==============================] - 221s 58s/step - loss: 0.2444 - acc: 0.9163 - val_loss: 0.9390 - val_acc: 0.6857\n",
            "Epoch 27/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2301 - acc: 0.9306 \n",
            "Epoch 27: val_acc did not improve from 0.68571\n",
            "4/4 [==============================] - 215s 59s/step - loss: 0.2301 - acc: 0.9306 - val_loss: 0.9206 - val_acc: 0.6857\n",
            "Epoch 28/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2032 - acc: 0.9449 \n",
            "Epoch 28: val_acc improved from 0.68571 to 0.70000, saving model to percobaan154_noImgPro/model\\vgg_16_154-saved-model-28-acc-0.70.hdf5\n",
            "4/4 [==============================] - 220s 58s/step - loss: 0.2032 - acc: 0.9449 - val_loss: 0.9009 - val_acc: 0.7000\n",
            "Epoch 29/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1986 - acc: 0.9429 \n",
            "Epoch 29: val_acc did not improve from 0.70000\n",
            "4/4 [==============================] - 220s 61s/step - loss: 0.1986 - acc: 0.9429 - val_loss: 0.8784 - val_acc: 0.7000\n",
            "Epoch 30/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2510 - acc: 0.9102 \n",
            "Epoch 30: val_acc improved from 0.70000 to 0.71429, saving model to percobaan154_noImgPro/model\\vgg_16_154-saved-model-30-acc-0.71.hdf5\n",
            "4/4 [==============================] - 217s 58s/step - loss: 0.2510 - acc: 0.9102 - val_loss: 0.8483 - val_acc: 0.7143\n",
            "Epoch 31/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2238 - acc: 0.9367 \n",
            "Epoch 31: val_acc improved from 0.71429 to 0.74286, saving model to percobaan154_noImgPro/model\\vgg_16_154-saved-model-31-acc-0.74.hdf5\n",
            "4/4 [==============================] - 221s 59s/step - loss: 0.2238 - acc: 0.9367 - val_loss: 0.8239 - val_acc: 0.7429\n",
            "Epoch 32/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2088 - acc: 0.9449 \n",
            "Epoch 32: val_acc improved from 0.74286 to 0.75000, saving model to percobaan154_noImgPro/model\\vgg_16_154-saved-model-32-acc-0.75.hdf5\n",
            "4/4 [==============================] - 217s 58s/step - loss: 0.2088 - acc: 0.9449 - val_loss: 0.8056 - val_acc: 0.7500\n",
            "Epoch 33/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1604 - acc: 0.9592 \n",
            "Epoch 33: val_acc did not improve from 0.75000\n",
            "4/4 [==============================] - 218s 58s/step - loss: 0.1604 - acc: 0.9592 - val_loss: 0.7904 - val_acc: 0.7500\n",
            "Epoch 34/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2045 - acc: 0.9327 \n",
            "Epoch 34: val_acc did not improve from 0.75000\n",
            "4/4 [==============================] - 216s 57s/step - loss: 0.2045 - acc: 0.9327 - val_loss: 0.7707 - val_acc: 0.7500\n",
            "Epoch 35/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1773 - acc: 0.9388 \n",
            "Epoch 35: val_acc improved from 0.75000 to 0.76429, saving model to percobaan154_noImgPro/model\\vgg_16_154-saved-model-35-acc-0.76.hdf5\n",
            "4/4 [==============================] - 220s 58s/step - loss: 0.1773 - acc: 0.9388 - val_loss: 0.7480 - val_acc: 0.7643\n",
            "Epoch 36/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1704 - acc: 0.9367 \n",
            "Epoch 36: val_acc improved from 0.76429 to 0.77857, saving model to percobaan154_noImgPro/model\\vgg_16_154-saved-model-36-acc-0.78.hdf5\n",
            "4/4 [==============================] - 221s 61s/step - loss: 0.1704 - acc: 0.9367 - val_loss: 0.7186 - val_acc: 0.7786\n",
            "Epoch 37/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1763 - acc: 0.9510 \n",
            "Epoch 37: val_acc did not improve from 0.77857\n",
            "4/4 [==============================] - 220s 59s/step - loss: 0.1763 - acc: 0.9510 - val_loss: 0.6944 - val_acc: 0.7714\n",
            "Epoch 38/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2074 - acc: 0.9367 \n",
            "Epoch 38: val_acc improved from 0.77857 to 0.78571, saving model to percobaan154_noImgPro/model\\vgg_16_154-saved-model-38-acc-0.79.hdf5\n",
            "4/4 [==============================] - 222s 61s/step - loss: 0.2074 - acc: 0.9367 - val_loss: 0.6768 - val_acc: 0.7857\n",
            "Epoch 39/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1694 - acc: 0.9531 \n",
            "Epoch 39: val_acc did not improve from 0.78571\n",
            "4/4 [==============================] - 221s 59s/step - loss: 0.1694 - acc: 0.9531 - val_loss: 0.6649 - val_acc: 0.7786\n",
            "Epoch 40/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1774 - acc: 0.9367 \n",
            "Epoch 40: val_acc improved from 0.78571 to 0.79286, saving model to percobaan154_noImgPro/model\\vgg_16_154-saved-model-40-acc-0.79.hdf5\n",
            "4/4 [==============================] - 223s 59s/step - loss: 0.1774 - acc: 0.9367 - val_loss: 0.6557 - val_acc: 0.7929\n",
            "Epoch 41/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1611 - acc: 0.9469 \n",
            "Epoch 41: val_acc improved from 0.79286 to 0.80000, saving model to percobaan154_noImgPro/model\\vgg_16_154-saved-model-41-acc-0.80.hdf5\n",
            "4/4 [==============================] - 224s 59s/step - loss: 0.1611 - acc: 0.9469 - val_loss: 0.6449 - val_acc: 0.8000\n",
            "Epoch 42/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1181 - acc: 0.9694 \n",
            "Epoch 42: val_acc did not improve from 0.80000\n",
            "4/4 [==============================] - 221s 59s/step - loss: 0.1181 - acc: 0.9694 - val_loss: 0.6299 - val_acc: 0.8000\n",
            "Epoch 43/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1301 - acc: 0.9694 \n",
            "Epoch 43: val_acc did not improve from 0.80000\n",
            "4/4 [==============================] - 222s 59s/step - loss: 0.1301 - acc: 0.9694 - val_loss: 0.6197 - val_acc: 0.8000\n",
            "Epoch 44/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1272 - acc: 0.9612 \n",
            "Epoch 44: val_acc improved from 0.80000 to 0.80714, saving model to percobaan154_noImgPro/model\\vgg_16_154-saved-model-44-acc-0.81.hdf5\n",
            "4/4 [==============================] - 221s 59s/step - loss: 0.1272 - acc: 0.9612 - val_loss: 0.6101 - val_acc: 0.8071\n",
            "Epoch 45/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1270 - acc: 0.9633 \n",
            "Epoch 45: val_acc improved from 0.80714 to 0.81429, saving model to percobaan154_noImgPro/model\\vgg_16_154-saved-model-45-acc-0.81.hdf5\n",
            "4/4 [==============================] - 223s 59s/step - loss: 0.1270 - acc: 0.9633 - val_loss: 0.6013 - val_acc: 0.8143\n",
            "Epoch 46/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1120 - acc: 0.9673 \n",
            "Epoch 46: val_acc did not improve from 0.81429\n",
            "4/4 [==============================] - 223s 59s/step - loss: 0.1120 - acc: 0.9673 - val_loss: 0.5884 - val_acc: 0.8143\n",
            "Epoch 47/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1648 - acc: 0.9449 \n",
            "Epoch 47: val_acc did not improve from 0.81429\n",
            "4/4 [==============================] - 223s 59s/step - loss: 0.1648 - acc: 0.9449 - val_loss: 0.5838 - val_acc: 0.8071\n",
            "Epoch 48/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1286 - acc: 0.9633 \n",
            "Epoch 48: val_acc did not improve from 0.81429\n",
            "4/4 [==============================] - 221s 59s/step - loss: 0.1286 - acc: 0.9633 - val_loss: 0.5805 - val_acc: 0.8071\n",
            "Epoch 49/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0972 - acc: 0.9694 \n",
            "Epoch 49: val_acc improved from 0.81429 to 0.82143, saving model to percobaan154_noImgPro/model\\vgg_16_154-saved-model-49-acc-0.82.hdf5\n",
            "4/4 [==============================] - 223s 59s/step - loss: 0.0972 - acc: 0.9694 - val_loss: 0.5733 - val_acc: 0.8214\n",
            "Epoch 50/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1730 - acc: 0.9469 \n",
            "Epoch 50: val_acc did not improve from 0.82143\n",
            "4/4 [==============================] - 220s 58s/step - loss: 0.1730 - acc: 0.9469 - val_loss: 0.5559 - val_acc: 0.8214\n",
            "Epoch 51/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1160 - acc: 0.9653 \n",
            "Epoch 51: val_acc did not improve from 0.82143\n",
            "4/4 [==============================] - 223s 61s/step - loss: 0.1160 - acc: 0.9653 - val_loss: 0.5418 - val_acc: 0.8214\n",
            "Epoch 52/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1042 - acc: 0.9673 \n",
            "Epoch 52: val_acc did not improve from 0.82143\n",
            "4/4 [==============================] - 222s 59s/step - loss: 0.1042 - acc: 0.9673 - val_loss: 0.5328 - val_acc: 0.8214\n",
            "Epoch 53/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1347 - acc: 0.9490 \n",
            "Epoch 53: val_acc improved from 0.82143 to 0.82857, saving model to percobaan154_noImgPro/model\\vgg_16_154-saved-model-53-acc-0.83.hdf5\n",
            "4/4 [==============================] - 223s 61s/step - loss: 0.1347 - acc: 0.9490 - val_loss: 0.5257 - val_acc: 0.8286\n",
            "Epoch 54/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1155 - acc: 0.9694 \n",
            "Epoch 54: val_acc improved from 0.82857 to 0.84286, saving model to percobaan154_noImgPro/model\\vgg_16_154-saved-model-54-acc-0.84.hdf5\n",
            "4/4 [==============================] - 223s 62s/step - loss: 0.1155 - acc: 0.9694 - val_loss: 0.5193 - val_acc: 0.8429\n",
            "Epoch 55/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1084 - acc: 0.9755 \n",
            "Epoch 55: val_acc did not improve from 0.84286\n",
            "4/4 [==============================] - 224s 59s/step - loss: 0.1084 - acc: 0.9755 - val_loss: 0.5103 - val_acc: 0.8429\n",
            "Epoch 56/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0741 - acc: 0.9837 \n",
            "Epoch 56: val_acc improved from 0.84286 to 0.85000, saving model to percobaan154_noImgPro/model\\vgg_16_154-saved-model-56-acc-0.85.hdf5\n",
            "4/4 [==============================] - 222s 59s/step - loss: 0.0741 - acc: 0.9837 - val_loss: 0.5018 - val_acc: 0.8500\n",
            "Epoch 57/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1133 - acc: 0.9633 \n",
            "Epoch 57: val_acc improved from 0.85000 to 0.85714, saving model to percobaan154_noImgPro/model\\vgg_16_154-saved-model-57-acc-0.86.hdf5\n",
            "4/4 [==============================] - 223s 62s/step - loss: 0.1133 - acc: 0.9633 - val_loss: 0.4916 - val_acc: 0.8571\n",
            "Epoch 58/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1019 - acc: 0.9592 \n",
            "Epoch 58: val_acc did not improve from 0.85714\n",
            "4/4 [==============================] - 221s 59s/step - loss: 0.1019 - acc: 0.9592 - val_loss: 0.4891 - val_acc: 0.8571\n",
            "\n",
            "\n",
            "Model Accuracy 0.9\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.91      1.00      0.95        10\n",
            "       10000       1.00      1.00      1.00        10\n",
            "      100000       1.00      0.90      0.95        10\n",
            "        2000       0.83      1.00      0.91        10\n",
            "       20000       1.00      0.50      0.67        10\n",
            "        5000       1.00      0.90      0.95        10\n",
            "       50000       0.71      1.00      0.83        10\n",
            "\n",
            "    accuracy                           0.90        70\n",
            "   macro avg       0.92      0.90      0.89        70\n",
            "weighted avg       0.92      0.90      0.89        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 155 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 64\n",
            "learning rate: 0.02284962000435188\n",
            "batch size: 128\n",
            "dropout rate: 0.6805051049151487\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.7900 - acc: 0.2592 \n",
            "Epoch 1: val_acc improved from -inf to 0.23571, saving model to percobaan155_noImgPro/model\\vgg_16_155-saved-model-01-acc-0.24.hdf5\n",
            "4/4 [==============================] - 223s 62s/step - loss: 2.7900 - acc: 0.2592 - val_loss: 2.8449 - val_acc: 0.2357\n",
            "Epoch 2/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.5463 - acc: 0.4735 \n",
            "Epoch 2: val_acc improved from 0.23571 to 0.27143, saving model to percobaan155_noImgPro/model\\vgg_16_155-saved-model-02-acc-0.27.hdf5\n",
            "4/4 [==============================] - 219s 58s/step - loss: 1.5463 - acc: 0.4735 - val_loss: 3.5542 - val_acc: 0.2714\n",
            "Epoch 3/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2646 - acc: 0.5490 \n",
            "Epoch 3: val_acc improved from 0.27143 to 0.36429, saving model to percobaan155_noImgPro/model\\vgg_16_155-saved-model-03-acc-0.36.hdf5\n",
            "4/4 [==============================] - 223s 59s/step - loss: 1.2646 - acc: 0.5490 - val_loss: 2.8590 - val_acc: 0.3643\n",
            "Epoch 4/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1284 - acc: 0.5918 \n",
            "Epoch 4: val_acc did not improve from 0.36429\n",
            "4/4 [==============================] - 222s 59s/step - loss: 1.1284 - acc: 0.5918 - val_loss: 2.8549 - val_acc: 0.3643\n",
            "Epoch 5/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9249 - acc: 0.6694 \n",
            "Epoch 5: val_acc improved from 0.36429 to 0.38571, saving model to percobaan155_noImgPro/model\\vgg_16_155-saved-model-05-acc-0.39.hdf5\n",
            "4/4 [==============================] - 223s 60s/step - loss: 0.9249 - acc: 0.6694 - val_loss: 2.2967 - val_acc: 0.3857\n",
            "Epoch 6/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8591 - acc: 0.6918 \n",
            "Epoch 6: val_acc improved from 0.38571 to 0.48571, saving model to percobaan155_noImgPro/model\\vgg_16_155-saved-model-06-acc-0.49.hdf5\n",
            "4/4 [==============================] - 222s 59s/step - loss: 0.8591 - acc: 0.6918 - val_loss: 2.1684 - val_acc: 0.4857\n",
            "Epoch 7/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7952 - acc: 0.7367 \n",
            "Epoch 7: val_acc did not improve from 0.48571\n",
            "4/4 [==============================] - 222s 59s/step - loss: 0.7952 - acc: 0.7367 - val_loss: 1.9975 - val_acc: 0.4643\n",
            "Epoch 8/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6281 - acc: 0.7796 \n",
            "Epoch 8: val_acc did not improve from 0.48571\n",
            "4/4 [==============================] - 220s 61s/step - loss: 0.6281 - acc: 0.7796 - val_loss: 2.0809 - val_acc: 0.4143\n",
            "Epoch 9/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5953 - acc: 0.7857 \n",
            "Epoch 9: val_acc did not improve from 0.48571\n",
            "4/4 [==============================] - 220s 58s/step - loss: 0.5953 - acc: 0.7857 - val_loss: 2.1696 - val_acc: 0.4143\n",
            "Epoch 10/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5162 - acc: 0.8306 \n",
            "Epoch 10: val_acc did not improve from 0.48571\n",
            "4/4 [==============================] - 220s 58s/step - loss: 0.5162 - acc: 0.8306 - val_loss: 1.9538 - val_acc: 0.4786\n",
            "Epoch 11/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4573 - acc: 0.8306 \n",
            "Epoch 11: val_acc did not improve from 0.48571\n",
            "4/4 [==============================] - 219s 58s/step - loss: 0.4573 - acc: 0.8306 - val_loss: 1.8087 - val_acc: 0.4857\n",
            "Epoch 12/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4112 - acc: 0.8551 \n",
            "Epoch 12: val_acc improved from 0.48571 to 0.55714, saving model to percobaan155_noImgPro/model\\vgg_16_155-saved-model-12-acc-0.56.hdf5\n",
            "4/4 [==============================] - 220s 58s/step - loss: 0.4112 - acc: 0.8551 - val_loss: 1.6783 - val_acc: 0.5571\n",
            "Epoch 13/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3975 - acc: 0.8633 \n",
            "Epoch 13: val_acc did not improve from 0.55714\n",
            "4/4 [==============================] - 223s 59s/step - loss: 0.3975 - acc: 0.8633 - val_loss: 1.5882 - val_acc: 0.5429\n",
            "Epoch 14/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3623 - acc: 0.8776 \n",
            "Epoch 14: val_acc did not improve from 0.55714\n",
            "4/4 [==============================] - 221s 59s/step - loss: 0.3623 - acc: 0.8776 - val_loss: 1.4085 - val_acc: 0.5429\n",
            "Epoch 15/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3352 - acc: 0.8755 \n",
            "Epoch 15: val_acc improved from 0.55714 to 0.57143, saving model to percobaan155_noImgPro/model\\vgg_16_155-saved-model-15-acc-0.57.hdf5\n",
            "4/4 [==============================] - 221s 58s/step - loss: 0.3352 - acc: 0.8755 - val_loss: 1.2312 - val_acc: 0.5714\n",
            "Epoch 16/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3555 - acc: 0.8694 \n",
            "Epoch 16: val_acc improved from 0.57143 to 0.58571, saving model to percobaan155_noImgPro/model\\vgg_16_155-saved-model-16-acc-0.59.hdf5\n",
            "4/4 [==============================] - 222s 59s/step - loss: 0.3555 - acc: 0.8694 - val_loss: 1.2044 - val_acc: 0.5857\n",
            "Epoch 17/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2705 - acc: 0.9143 \n",
            "Epoch 17: val_acc improved from 0.58571 to 0.59286, saving model to percobaan155_noImgPro/model\\vgg_16_155-saved-model-17-acc-0.59.hdf5\n",
            "4/4 [==============================] - 220s 58s/step - loss: 0.2705 - acc: 0.9143 - val_loss: 1.1935 - val_acc: 0.5929\n",
            "Epoch 18/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2533 - acc: 0.9061 \n",
            "Epoch 18: val_acc improved from 0.59286 to 0.64286, saving model to percobaan155_noImgPro/model\\vgg_16_155-saved-model-18-acc-0.64.hdf5\n",
            "4/4 [==============================] - 223s 60s/step - loss: 0.2533 - acc: 0.9061 - val_loss: 1.0566 - val_acc: 0.6429\n",
            "Epoch 19/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2611 - acc: 0.9102 \n",
            "Epoch 19: val_acc improved from 0.64286 to 0.73571, saving model to percobaan155_noImgPro/model\\vgg_16_155-saved-model-19-acc-0.74.hdf5\n",
            "4/4 [==============================] - 222s 59s/step - loss: 0.2611 - acc: 0.9102 - val_loss: 0.8786 - val_acc: 0.7357\n",
            "Epoch 20/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3003 - acc: 0.8939 \n",
            "Epoch 20: val_acc improved from 0.73571 to 0.77857, saving model to percobaan155_noImgPro/model\\vgg_16_155-saved-model-20-acc-0.78.hdf5\n",
            "4/4 [==============================] - 222s 62s/step - loss: 0.3003 - acc: 0.8939 - val_loss: 0.7326 - val_acc: 0.7786\n",
            "Epoch 21/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2429 - acc: 0.9184 \n",
            "Epoch 21: val_acc did not improve from 0.77857\n",
            "4/4 [==============================] - 222s 59s/step - loss: 0.2429 - acc: 0.9184 - val_loss: 0.7918 - val_acc: 0.7500\n",
            "Epoch 22/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2395 - acc: 0.9102 \n",
            "Epoch 22: val_acc did not improve from 0.77857\n",
            "4/4 [==============================] - 223s 59s/step - loss: 0.2395 - acc: 0.9102 - val_loss: 0.8429 - val_acc: 0.7143\n",
            "Epoch 23/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3002 - acc: 0.9102 \n",
            "Epoch 23: val_acc did not improve from 0.77857\n",
            "4/4 [==============================] - 221s 61s/step - loss: 0.3002 - acc: 0.9102 - val_loss: 0.9535 - val_acc: 0.6786\n",
            "Epoch 24/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2289 - acc: 0.9204 \n",
            "Epoch 24: val_acc did not improve from 0.77857\n",
            "4/4 [==============================] - 222s 59s/step - loss: 0.2289 - acc: 0.9204 - val_loss: 1.0911 - val_acc: 0.6071\n",
            "Epoch 25/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2713 - acc: 0.9082 \n",
            "Epoch 25: val_acc did not improve from 0.77857\n",
            "4/4 [==============================] - 221s 61s/step - loss: 0.2713 - acc: 0.9082 - val_loss: 1.2275 - val_acc: 0.6000\n",
            "\n",
            "\n",
            "Model Accuracy 0.5285714285714286\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.88      0.70      0.78        10\n",
            "       10000       0.64      0.90      0.75        10\n",
            "      100000       1.00      0.20      0.33        10\n",
            "        2000       0.80      0.40      0.53        10\n",
            "       20000       1.00      0.10      0.18        10\n",
            "        5000       1.00      0.40      0.57        10\n",
            "       50000       0.28      1.00      0.43        10\n",
            "\n",
            "    accuracy                           0.53        70\n",
            "   macro avg       0.80      0.53      0.51        70\n",
            "weighted avg       0.80      0.53      0.51        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 156 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 60\n",
            "learning rate: 0.013638250265064664\n",
            "batch size: 128\n",
            "dropout rate: 0.797531568730455\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 3.6185 - acc: 0.2408 \n",
            "Epoch 1: val_acc improved from -inf to 0.20714, saving model to percobaan156_noImgPro/model\\vgg_16_156-saved-model-01-acc-0.21.hdf5\n",
            "4/4 [==============================] - 217s 60s/step - loss: 3.6185 - acc: 0.2408 - val_loss: 3.1011 - val_acc: 0.2071\n",
            "Epoch 2/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.1363 - acc: 0.3816 \n",
            "Epoch 2: val_acc did not improve from 0.20714\n",
            "4/4 [==============================] - 218s 58s/step - loss: 2.1363 - acc: 0.3816 - val_loss: 3.1139 - val_acc: 0.1643\n",
            "Epoch 3/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.9671 - acc: 0.3837 \n",
            "Epoch 3: val_acc did not improve from 0.20714\n",
            "4/4 [==============================] - 218s 57s/step - loss: 1.9671 - acc: 0.3837 - val_loss: 3.4399 - val_acc: 0.1714\n",
            "Epoch 4/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.5709 - acc: 0.4776 \n",
            "Epoch 4: val_acc did not improve from 0.20714\n",
            "4/4 [==============================] - 220s 59s/step - loss: 1.5709 - acc: 0.4776 - val_loss: 2.9054 - val_acc: 0.1929\n",
            "Epoch 5/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.3321 - acc: 0.5367 \n",
            "Epoch 5: val_acc improved from 0.20714 to 0.22857, saving model to percobaan156_noImgPro/model\\vgg_16_156-saved-model-05-acc-0.23.hdf5\n",
            "4/4 [==============================] - 218s 58s/step - loss: 1.3321 - acc: 0.5367 - val_loss: 2.4395 - val_acc: 0.2286\n",
            "Epoch 6/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2001 - acc: 0.5612 \n",
            "Epoch 6: val_acc improved from 0.22857 to 0.25000, saving model to percobaan156_noImgPro/model\\vgg_16_156-saved-model-06-acc-0.25.hdf5\n",
            "4/4 [==============================] - 219s 61s/step - loss: 1.2001 - acc: 0.5612 - val_loss: 2.2420 - val_acc: 0.2500\n",
            "Epoch 7/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1225 - acc: 0.5857 \n",
            "Epoch 7: val_acc did not improve from 0.25000\n",
            "4/4 [==============================] - 219s 61s/step - loss: 1.1225 - acc: 0.5857 - val_loss: 2.2120 - val_acc: 0.2286\n",
            "Epoch 8/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0757 - acc: 0.6184 \n",
            "Epoch 8: val_acc did not improve from 0.25000\n",
            "4/4 [==============================] - 219s 61s/step - loss: 1.0757 - acc: 0.6184 - val_loss: 2.0595 - val_acc: 0.2500\n",
            "Epoch 9/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9830 - acc: 0.6551 \n",
            "Epoch 9: val_acc improved from 0.25000 to 0.27143, saving model to percobaan156_noImgPro/model\\vgg_16_156-saved-model-09-acc-0.27.hdf5\n",
            "4/4 [==============================] - 220s 61s/step - loss: 0.9830 - acc: 0.6551 - val_loss: 1.9133 - val_acc: 0.2714\n",
            "Epoch 10/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8836 - acc: 0.6878 \n",
            "Epoch 10: val_acc improved from 0.27143 to 0.28571, saving model to percobaan156_noImgPro/model\\vgg_16_156-saved-model-10-acc-0.29.hdf5\n",
            "4/4 [==============================] - 220s 61s/step - loss: 0.8836 - acc: 0.6878 - val_loss: 1.8449 - val_acc: 0.2857\n",
            "Epoch 11/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7655 - acc: 0.7143 \n",
            "Epoch 11: val_acc improved from 0.28571 to 0.35000, saving model to percobaan156_noImgPro/model\\vgg_16_156-saved-model-11-acc-0.35.hdf5\n",
            "4/4 [==============================] - 217s 58s/step - loss: 0.7655 - acc: 0.7143 - val_loss: 1.6932 - val_acc: 0.3500\n",
            "Epoch 12/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7749 - acc: 0.7265 \n",
            "Epoch 12: val_acc improved from 0.35000 to 0.42857, saving model to percobaan156_noImgPro/model\\vgg_16_156-saved-model-12-acc-0.43.hdf5\n",
            "4/4 [==============================] - 220s 59s/step - loss: 0.7749 - acc: 0.7265 - val_loss: 1.5048 - val_acc: 0.4286\n",
            "Epoch 13/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7396 - acc: 0.7408 \n",
            "Epoch 13: val_acc improved from 0.42857 to 0.48571, saving model to percobaan156_noImgPro/model\\vgg_16_156-saved-model-13-acc-0.49.hdf5\n",
            "4/4 [==============================] - 218s 58s/step - loss: 0.7396 - acc: 0.7408 - val_loss: 1.4038 - val_acc: 0.4857\n",
            "Epoch 14/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5990 - acc: 0.7980 \n",
            "Epoch 14: val_acc improved from 0.48571 to 0.52857, saving model to percobaan156_noImgPro/model\\vgg_16_156-saved-model-14-acc-0.53.hdf5\n",
            "4/4 [==============================] - 220s 59s/step - loss: 0.5990 - acc: 0.7980 - val_loss: 1.3695 - val_acc: 0.5286\n",
            "Epoch 15/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6328 - acc: 0.7959 \n",
            "Epoch 15: val_acc improved from 0.52857 to 0.55000, saving model to percobaan156_noImgPro/model\\vgg_16_156-saved-model-15-acc-0.55.hdf5\n",
            "4/4 [==============================] - 222s 59s/step - loss: 0.6328 - acc: 0.7959 - val_loss: 1.2988 - val_acc: 0.5500\n",
            "Epoch 16/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6051 - acc: 0.7898 \n",
            "Epoch 16: val_acc improved from 0.55000 to 0.56429, saving model to percobaan156_noImgPro/model\\vgg_16_156-saved-model-16-acc-0.56.hdf5\n",
            "4/4 [==============================] - 220s 59s/step - loss: 0.6051 - acc: 0.7898 - val_loss: 1.2405 - val_acc: 0.5643\n",
            "Epoch 17/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5737 - acc: 0.8041 \n",
            "Epoch 17: val_acc improved from 0.56429 to 0.59286, saving model to percobaan156_noImgPro/model\\vgg_16_156-saved-model-17-acc-0.59.hdf5\n",
            "4/4 [==============================] - 216s 57s/step - loss: 0.5737 - acc: 0.8041 - val_loss: 1.1533 - val_acc: 0.5929\n",
            "Epoch 18/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5867 - acc: 0.7898 \n",
            "Epoch 18: val_acc improved from 0.59286 to 0.60714, saving model to percobaan156_noImgPro/model\\vgg_16_156-saved-model-18-acc-0.61.hdf5\n",
            "4/4 [==============================] - 220s 59s/step - loss: 0.5867 - acc: 0.7898 - val_loss: 1.0851 - val_acc: 0.6071\n",
            "Epoch 19/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5099 - acc: 0.8286 \n",
            "Epoch 19: val_acc did not improve from 0.60714\n",
            "4/4 [==============================] - 218s 60s/step - loss: 0.5099 - acc: 0.8286 - val_loss: 1.0556 - val_acc: 0.6000\n",
            "Epoch 20/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4901 - acc: 0.8367 \n",
            "Epoch 20: val_acc improved from 0.60714 to 0.64286, saving model to percobaan156_noImgPro/model\\vgg_16_156-saved-model-20-acc-0.64.hdf5\n",
            "4/4 [==============================] - 219s 58s/step - loss: 0.4901 - acc: 0.8367 - val_loss: 0.9958 - val_acc: 0.6429\n",
            "Epoch 21/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5175 - acc: 0.8327 \n",
            "Epoch 21: val_acc did not improve from 0.64286\n",
            "4/4 [==============================] - 219s 58s/step - loss: 0.5175 - acc: 0.8327 - val_loss: 0.9895 - val_acc: 0.6429\n",
            "Epoch 22/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5223 - acc: 0.8245 \n",
            "Epoch 22: val_acc did not improve from 0.64286\n",
            "4/4 [==============================] - 219s 58s/step - loss: 0.5223 - acc: 0.8245 - val_loss: 1.0291 - val_acc: 0.6429\n",
            "Epoch 23/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4949 - acc: 0.8122 \n",
            "Epoch 23: val_acc did not improve from 0.64286\n",
            "4/4 [==============================] - 220s 58s/step - loss: 0.4949 - acc: 0.8122 - val_loss: 1.0496 - val_acc: 0.6357\n",
            "Epoch 24/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4101 - acc: 0.8531 \n",
            "Epoch 24: val_acc did not improve from 0.64286\n",
            "4/4 [==============================] - 220s 58s/step - loss: 0.4101 - acc: 0.8531 - val_loss: 1.0777 - val_acc: 0.6214\n",
            "Epoch 25/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4391 - acc: 0.8429 \n",
            "Epoch 25: val_acc did not improve from 0.64286\n",
            "4/4 [==============================] - 219s 58s/step - loss: 0.4391 - acc: 0.8429 - val_loss: 1.0523 - val_acc: 0.6429\n",
            "Epoch 26/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3842 - acc: 0.8673 \n",
            "Epoch 26: val_acc improved from 0.64286 to 0.67143, saving model to percobaan156_noImgPro/model\\vgg_16_156-saved-model-26-acc-0.67.hdf5\n",
            "4/4 [==============================] - 220s 58s/step - loss: 0.3842 - acc: 0.8673 - val_loss: 0.9693 - val_acc: 0.6714\n",
            "Epoch 27/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3705 - acc: 0.8469 \n",
            "Epoch 27: val_acc improved from 0.67143 to 0.69286, saving model to percobaan156_noImgPro/model\\vgg_16_156-saved-model-27-acc-0.69.hdf5\n",
            "4/4 [==============================] - 221s 59s/step - loss: 0.3705 - acc: 0.8469 - val_loss: 0.8518 - val_acc: 0.6929\n",
            "Epoch 28/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4364 - acc: 0.8469 \n",
            "Epoch 28: val_acc improved from 0.69286 to 0.75000, saving model to percobaan156_noImgPro/model\\vgg_16_156-saved-model-28-acc-0.75.hdf5\n",
            "4/4 [==============================] - 220s 58s/step - loss: 0.4364 - acc: 0.8469 - val_loss: 0.7952 - val_acc: 0.7500\n",
            "Epoch 29/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3866 - acc: 0.8633 \n",
            "Epoch 29: val_acc did not improve from 0.75000\n",
            "4/4 [==============================] - 218s 58s/step - loss: 0.3866 - acc: 0.8633 - val_loss: 0.7820 - val_acc: 0.7286\n",
            "Epoch 30/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3383 - acc: 0.8837 \n",
            "Epoch 30: val_acc did not improve from 0.75000\n",
            "4/4 [==============================] - 219s 58s/step - loss: 0.3383 - acc: 0.8837 - val_loss: 0.8159 - val_acc: 0.7214\n",
            "Epoch 31/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3919 - acc: 0.8633 \n",
            "Epoch 31: val_acc did not improve from 0.75000\n",
            "4/4 [==============================] - 220s 58s/step - loss: 0.3919 - acc: 0.8633 - val_loss: 0.8837 - val_acc: 0.6571\n",
            "Epoch 32/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4074 - acc: 0.8633 \n",
            "Epoch 32: val_acc did not improve from 0.75000\n",
            "4/4 [==============================] - 217s 58s/step - loss: 0.4074 - acc: 0.8633 - val_loss: 0.9251 - val_acc: 0.6929\n",
            "Epoch 33/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3574 - acc: 0.8816 \n",
            "Epoch 33: val_acc did not improve from 0.75000\n",
            "4/4 [==============================] - 216s 57s/step - loss: 0.3574 - acc: 0.8816 - val_loss: 0.9224 - val_acc: 0.6929\n",
            "Epoch 34/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3467 - acc: 0.8857 \n",
            "Epoch 34: val_acc did not improve from 0.75000\n",
            "4/4 [==============================] - 219s 58s/step - loss: 0.3467 - acc: 0.8857 - val_loss: 0.8745 - val_acc: 0.7214\n",
            "\n",
            "\n",
            "Model Accuracy 0.6\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.78      0.70      0.74        10\n",
            "       10000       0.56      1.00      0.71        10\n",
            "      100000       1.00      0.20      0.33        10\n",
            "        2000       0.75      0.60      0.67        10\n",
            "       20000       0.50      0.40      0.44        10\n",
            "        5000       1.00      0.40      0.57        10\n",
            "       50000       0.43      0.90      0.58        10\n",
            "\n",
            "    accuracy                           0.60        70\n",
            "   macro avg       0.72      0.60      0.58        70\n",
            "weighted avg       0.72      0.60      0.58        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 157 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 65\n",
            "learning rate: 0.04224055109201187\n",
            "batch size: 32\n",
            "dropout rate: 0.5468000660550598\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.5023 - acc: 0.3327 \n",
            "Epoch 1: val_acc improved from -inf to 0.30714, saving model to percobaan157_noImgPro/model\\vgg_16_157-saved-model-01-acc-0.31.hdf5\n",
            "16/16 [==============================] - 216s 14s/step - loss: 2.5023 - acc: 0.3327 - val_loss: 4.0628 - val_acc: 0.3071\n",
            "Epoch 2/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.6062 - acc: 0.5000 \n",
            "Epoch 2: val_acc did not improve from 0.30714\n",
            "16/16 [==============================] - 218s 14s/step - loss: 1.6062 - acc: 0.5000 - val_loss: 5.4894 - val_acc: 0.2286\n",
            "Epoch 3/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1127 - acc: 0.6612 \n",
            "Epoch 3: val_acc improved from 0.30714 to 0.37143, saving model to percobaan157_noImgPro/model\\vgg_16_157-saved-model-03-acc-0.37.hdf5\n",
            "16/16 [==============================] - 213s 14s/step - loss: 1.1127 - acc: 0.6612 - val_loss: 2.6405 - val_acc: 0.3714\n",
            "Epoch 4/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9482 - acc: 0.6490 \n",
            "Epoch 4: val_acc did not improve from 0.37143\n",
            "16/16 [==============================] - 217s 14s/step - loss: 0.9482 - acc: 0.6490 - val_loss: 2.5305 - val_acc: 0.3071\n",
            "Epoch 5/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9907 - acc: 0.6714 \n",
            "Epoch 5: val_acc improved from 0.37143 to 0.52857, saving model to percobaan157_noImgPro/model\\vgg_16_157-saved-model-05-acc-0.53.hdf5\n",
            "16/16 [==============================] - 214s 14s/step - loss: 0.9907 - acc: 0.6714 - val_loss: 1.8628 - val_acc: 0.5286\n",
            "Epoch 6/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7527 - acc: 0.7551 \n",
            "Epoch 6: val_acc improved from 0.52857 to 0.65000, saving model to percobaan157_noImgPro/model\\vgg_16_157-saved-model-06-acc-0.65.hdf5\n",
            "16/16 [==============================] - 216s 14s/step - loss: 0.7527 - acc: 0.7551 - val_loss: 1.2860 - val_acc: 0.6500\n",
            "Epoch 7/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7157 - acc: 0.7653 \n",
            "Epoch 7: val_acc improved from 0.65000 to 0.68571, saving model to percobaan157_noImgPro/model\\vgg_16_157-saved-model-07-acc-0.69.hdf5\n",
            "16/16 [==============================] - 215s 14s/step - loss: 0.7157 - acc: 0.7653 - val_loss: 1.1039 - val_acc: 0.6857\n",
            "Epoch 8/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7073 - acc: 0.7633 \n",
            "Epoch 8: val_acc did not improve from 0.68571\n",
            "16/16 [==============================] - 217s 14s/step - loss: 0.7073 - acc: 0.7633 - val_loss: 1.0726 - val_acc: 0.6714\n",
            "Epoch 9/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5389 - acc: 0.8082 \n",
            "Epoch 9: val_acc did not improve from 0.68571\n",
            "16/16 [==============================] - 216s 14s/step - loss: 0.5389 - acc: 0.8082 - val_loss: 1.2728 - val_acc: 0.6286\n",
            "Epoch 10/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5004 - acc: 0.8245 \n",
            "Epoch 10: val_acc improved from 0.68571 to 0.70000, saving model to percobaan157_noImgPro/model\\vgg_16_157-saved-model-10-acc-0.70.hdf5\n",
            "16/16 [==============================] - 216s 14s/step - loss: 0.5004 - acc: 0.8245 - val_loss: 0.9485 - val_acc: 0.7000\n",
            "Epoch 11/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5687 - acc: 0.8122 \n",
            "Epoch 11: val_acc improved from 0.70000 to 0.77143, saving model to percobaan157_noImgPro/model\\vgg_16_157-saved-model-11-acc-0.77.hdf5\n",
            "16/16 [==============================] - 214s 14s/step - loss: 0.5687 - acc: 0.8122 - val_loss: 0.8472 - val_acc: 0.7714\n",
            "Epoch 12/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4479 - acc: 0.8510 \n",
            "Epoch 12: val_acc did not improve from 0.77143\n",
            "16/16 [==============================] - 217s 14s/step - loss: 0.4479 - acc: 0.8510 - val_loss: 0.8455 - val_acc: 0.7500\n",
            "Epoch 13/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6416 - acc: 0.8061 \n",
            "Epoch 13: val_acc did not improve from 0.77143\n",
            "16/16 [==============================] - 217s 14s/step - loss: 0.6416 - acc: 0.8061 - val_loss: 0.8996 - val_acc: 0.7214\n",
            "Epoch 14/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4118 - acc: 0.8633 \n",
            "Epoch 14: val_acc improved from 0.77143 to 0.79286, saving model to percobaan157_noImgPro/model\\vgg_16_157-saved-model-14-acc-0.79.hdf5\n",
            "16/16 [==============================] - 216s 14s/step - loss: 0.4118 - acc: 0.8633 - val_loss: 0.7175 - val_acc: 0.7929\n",
            "Epoch 15/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4143 - acc: 0.8612 \n",
            "Epoch 15: val_acc improved from 0.79286 to 0.85714, saving model to percobaan157_noImgPro/model\\vgg_16_157-saved-model-15-acc-0.86.hdf5\n",
            "16/16 [==============================] - 217s 14s/step - loss: 0.4143 - acc: 0.8612 - val_loss: 0.6324 - val_acc: 0.8571\n",
            "Epoch 16/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4795 - acc: 0.8469 \n",
            "Epoch 16: val_acc did not improve from 0.85714\n",
            "16/16 [==============================] - 217s 14s/step - loss: 0.4795 - acc: 0.8469 - val_loss: 0.8000 - val_acc: 0.7643\n",
            "Epoch 17/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4460 - acc: 0.8592 \n",
            "Epoch 17: val_acc did not improve from 0.85714\n",
            "16/16 [==============================] - 217s 14s/step - loss: 0.4460 - acc: 0.8592 - val_loss: 0.8313 - val_acc: 0.8143\n",
            "Epoch 18/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5145 - acc: 0.8367 \n",
            "Epoch 18: val_acc did not improve from 0.85714\n",
            "16/16 [==============================] - 216s 14s/step - loss: 0.5145 - acc: 0.8367 - val_loss: 0.6990 - val_acc: 0.8214\n",
            "Epoch 19/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5600 - acc: 0.8265 \n",
            "Epoch 19: val_acc did not improve from 0.85714\n",
            "16/16 [==============================] - 217s 14s/step - loss: 0.5600 - acc: 0.8265 - val_loss: 1.0391 - val_acc: 0.7429\n",
            "Epoch 20/65\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4833 - acc: 0.8510 \n",
            "Epoch 20: val_acc did not improve from 0.85714\n",
            "16/16 [==============================] - 217s 14s/step - loss: 0.4833 - acc: 0.8510 - val_loss: 0.7984 - val_acc: 0.7857\n",
            "\n",
            "\n",
            "Model Accuracy 0.8\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.90      0.90      0.90        10\n",
            "       10000       0.89      0.80      0.84        10\n",
            "      100000       1.00      0.70      0.82        10\n",
            "        2000       0.53      1.00      0.69        10\n",
            "       20000       0.71      0.50      0.59        10\n",
            "        5000       0.91      1.00      0.95        10\n",
            "       50000       1.00      0.70      0.82        10\n",
            "\n",
            "    accuracy                           0.80        70\n",
            "   macro avg       0.85      0.80      0.80        70\n",
            "weighted avg       0.85      0.80      0.80        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 158 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 57\n",
            "learning rate: 0.029049540950222837\n",
            "batch size: 32\n",
            "dropout rate: 0.6006520602412639\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.5730 - acc: 0.2878\n",
            "Epoch 1: val_acc improved from -inf to 0.17857, saving model to percobaan158_noImgPro/model\\vgg_16_158-saved-model-01-acc-0.18.hdf5\n",
            "16/16 [==============================] - 209s 13s/step - loss: 2.5730 - acc: 0.2878 - val_loss: 5.9996 - val_acc: 0.1786\n",
            "Epoch 2/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.7571 - acc: 0.4735 \n",
            "Epoch 2: val_acc improved from 0.17857 to 0.27857, saving model to percobaan158_noImgPro/model\\vgg_16_158-saved-model-02-acc-0.28.hdf5\n",
            "16/16 [==============================] - 207s 14s/step - loss: 1.7571 - acc: 0.4735 - val_loss: 3.1853 - val_acc: 0.2786\n",
            "Epoch 3/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2157 - acc: 0.5714\n",
            "Epoch 3: val_acc improved from 0.27857 to 0.34286, saving model to percobaan158_noImgPro/model\\vgg_16_158-saved-model-03-acc-0.34.hdf5\n",
            "16/16 [==============================] - 207s 13s/step - loss: 1.2157 - acc: 0.5714 - val_loss: 2.5727 - val_acc: 0.3429\n",
            "Epoch 4/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0288 - acc: 0.6592 \n",
            "Epoch 4: val_acc improved from 0.34286 to 0.38571, saving model to percobaan158_noImgPro/model\\vgg_16_158-saved-model-04-acc-0.39.hdf5\n",
            "16/16 [==============================] - 210s 14s/step - loss: 1.0288 - acc: 0.6592 - val_loss: 2.7441 - val_acc: 0.3857\n",
            "Epoch 5/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8285 - acc: 0.7000\n",
            "Epoch 5: val_acc improved from 0.38571 to 0.52143, saving model to percobaan158_noImgPro/model\\vgg_16_158-saved-model-05-acc-0.52.hdf5\n",
            "16/16 [==============================] - 210s 13s/step - loss: 0.8285 - acc: 0.7000 - val_loss: 1.7347 - val_acc: 0.5214\n",
            "Epoch 6/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7065 - acc: 0.7653\n",
            "Epoch 6: val_acc improved from 0.52143 to 0.58571, saving model to percobaan158_noImgPro/model\\vgg_16_158-saved-model-06-acc-0.59.hdf5\n",
            "16/16 [==============================] - 210s 13s/step - loss: 0.7065 - acc: 0.7653 - val_loss: 1.5702 - val_acc: 0.5857\n",
            "Epoch 7/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6290 - acc: 0.7816\n",
            "Epoch 7: val_acc did not improve from 0.58571\n",
            "16/16 [==============================] - 211s 13s/step - loss: 0.6290 - acc: 0.7816 - val_loss: 1.8017 - val_acc: 0.4929\n",
            "Epoch 8/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5692 - acc: 0.8041\n",
            "Epoch 8: val_acc improved from 0.58571 to 0.64286, saving model to percobaan158_noImgPro/model\\vgg_16_158-saved-model-08-acc-0.64.hdf5\n",
            "16/16 [==============================] - 211s 13s/step - loss: 0.5692 - acc: 0.8041 - val_loss: 1.1246 - val_acc: 0.6429\n",
            "Epoch 9/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5864 - acc: 0.8041\n",
            "Epoch 9: val_acc did not improve from 0.64286\n",
            "16/16 [==============================] - 210s 13s/step - loss: 0.5864 - acc: 0.8041 - val_loss: 1.2351 - val_acc: 0.5929\n",
            "Epoch 10/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5233 - acc: 0.8061 \n",
            "Epoch 10: val_acc did not improve from 0.64286\n",
            "16/16 [==============================] - 211s 13s/step - loss: 0.5233 - acc: 0.8061 - val_loss: 1.0551 - val_acc: 0.6214\n",
            "Epoch 11/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4847 - acc: 0.8265 \n",
            "Epoch 11: val_acc improved from 0.64286 to 0.67857, saving model to percobaan158_noImgPro/model\\vgg_16_158-saved-model-11-acc-0.68.hdf5\n",
            "16/16 [==============================] - 209s 14s/step - loss: 0.4847 - acc: 0.8265 - val_loss: 1.1398 - val_acc: 0.6786\n",
            "Epoch 12/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6438 - acc: 0.7878\n",
            "Epoch 12: val_acc improved from 0.67857 to 0.72143, saving model to percobaan158_noImgPro/model\\vgg_16_158-saved-model-12-acc-0.72.hdf5\n",
            "16/16 [==============================] - 210s 13s/step - loss: 0.6438 - acc: 0.7878 - val_loss: 0.7213 - val_acc: 0.7214\n",
            "Epoch 13/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5020 - acc: 0.8204\n",
            "Epoch 13: val_acc did not improve from 0.72143\n",
            "16/16 [==============================] - 210s 13s/step - loss: 0.5020 - acc: 0.8204 - val_loss: 1.0962 - val_acc: 0.6571\n",
            "Epoch 14/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4986 - acc: 0.8265\n",
            "Epoch 14: val_acc improved from 0.72143 to 0.75000, saving model to percobaan158_noImgPro/model\\vgg_16_158-saved-model-14-acc-0.75.hdf5\n",
            "16/16 [==============================] - 210s 13s/step - loss: 0.4986 - acc: 0.8265 - val_loss: 0.7817 - val_acc: 0.7500\n",
            "Epoch 15/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5498 - acc: 0.8061\n",
            "Epoch 15: val_acc improved from 0.75000 to 0.79286, saving model to percobaan158_noImgPro/model\\vgg_16_158-saved-model-15-acc-0.79.hdf5\n",
            "16/16 [==============================] - 210s 13s/step - loss: 0.5498 - acc: 0.8061 - val_loss: 0.7049 - val_acc: 0.7929\n",
            "Epoch 16/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4980 - acc: 0.8449\n",
            "Epoch 16: val_acc did not improve from 0.79286\n",
            "16/16 [==============================] - 210s 13s/step - loss: 0.4980 - acc: 0.8449 - val_loss: 1.1516 - val_acc: 0.6857\n",
            "Epoch 17/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5516 - acc: 0.8388\n",
            "Epoch 17: val_acc did not improve from 0.79286\n",
            "16/16 [==============================] - 211s 13s/step - loss: 0.5516 - acc: 0.8388 - val_loss: 1.0011 - val_acc: 0.7143\n",
            "Epoch 18/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5267 - acc: 0.8367 \n",
            "Epoch 18: val_acc did not improve from 0.79286\n",
            "16/16 [==============================] - 211s 13s/step - loss: 0.5267 - acc: 0.8367 - val_loss: 1.0426 - val_acc: 0.7286\n",
            "Epoch 19/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4256 - acc: 0.8653\n",
            "Epoch 19: val_acc did not improve from 0.79286\n",
            "16/16 [==============================] - 210s 13s/step - loss: 0.4256 - acc: 0.8653 - val_loss: 1.2479 - val_acc: 0.6929\n",
            "Epoch 20/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4813 - acc: 0.8286\n",
            "Epoch 20: val_acc did not improve from 0.79286\n",
            "16/16 [==============================] - 208s 13s/step - loss: 0.4813 - acc: 0.8286 - val_loss: 0.7736 - val_acc: 0.7571\n",
            "\n",
            "\n",
            "Model Accuracy 0.8\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.89      0.80      0.84        10\n",
            "       10000       0.91      1.00      0.95        10\n",
            "      100000       1.00      0.60      0.75        10\n",
            "        2000       0.67      1.00      0.80        10\n",
            "       20000       0.83      0.50      0.62        10\n",
            "        5000       0.62      1.00      0.77        10\n",
            "       50000       1.00      0.70      0.82        10\n",
            "\n",
            "    accuracy                           0.80        70\n",
            "   macro avg       0.85      0.80      0.79        70\n",
            "weighted avg       0.85      0.80      0.79        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 159 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 58\n",
            "learning rate: 0.04615978699268203\n",
            "batch size: 32\n",
            "dropout rate: 0.6575955479058637\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.9467 - acc: 0.2510 \n",
            "Epoch 1: val_acc improved from -inf to 0.20000, saving model to percobaan159_noImgPro/model\\vgg_16_159-saved-model-01-acc-0.20.hdf5\n",
            "16/16 [==============================] - 286s 18s/step - loss: 2.9467 - acc: 0.2510 - val_loss: 9.5293 - val_acc: 0.2000\n",
            "Epoch 2/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.2479 - acc: 0.4041 \n",
            "Epoch 2: val_acc did not improve from 0.20000\n",
            "16/16 [==============================] - 278s 18s/step - loss: 2.2479 - acc: 0.4041 - val_loss: 6.4364 - val_acc: 0.1429\n",
            "Epoch 3/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.5885 - acc: 0.4898 \n",
            "Epoch 3: val_acc improved from 0.20000 to 0.25000, saving model to percobaan159_noImgPro/model\\vgg_16_159-saved-model-03-acc-0.25.hdf5\n",
            "16/16 [==============================] - 280s 18s/step - loss: 1.5885 - acc: 0.4898 - val_loss: 2.9409 - val_acc: 0.2500\n",
            "Epoch 4/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2597 - acc: 0.5653 \n",
            "Epoch 4: val_acc improved from 0.25000 to 0.52143, saving model to percobaan159_noImgPro/model\\vgg_16_159-saved-model-04-acc-0.52.hdf5\n",
            "16/16 [==============================] - 281s 18s/step - loss: 1.2597 - acc: 0.5653 - val_loss: 1.3699 - val_acc: 0.5214\n",
            "Epoch 5/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1058 - acc: 0.6000 \n",
            "Epoch 5: val_acc did not improve from 0.52143\n",
            "16/16 [==============================] - 281s 18s/step - loss: 1.1058 - acc: 0.6000 - val_loss: 1.6964 - val_acc: 0.4286\n",
            "Epoch 6/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9745 - acc: 0.7082 \n",
            "Epoch 6: val_acc improved from 0.52143 to 0.58571, saving model to percobaan159_noImgPro/model\\vgg_16_159-saved-model-06-acc-0.59.hdf5\n",
            "16/16 [==============================] - 284s 18s/step - loss: 0.9745 - acc: 0.7082 - val_loss: 1.1178 - val_acc: 0.5857\n",
            "Epoch 7/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0734 - acc: 0.6224 \n",
            "Epoch 7: val_acc did not improve from 0.58571\n",
            "16/16 [==============================] - 283s 18s/step - loss: 1.0734 - acc: 0.6224 - val_loss: 1.3627 - val_acc: 0.5286\n",
            "Epoch 8/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8469 - acc: 0.7000 \n",
            "Epoch 8: val_acc did not improve from 0.58571\n",
            "16/16 [==============================] - 285s 18s/step - loss: 0.8469 - acc: 0.7000 - val_loss: 1.2924 - val_acc: 0.5500\n",
            "Epoch 9/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8405 - acc: 0.7265 \n",
            "Epoch 9: val_acc did not improve from 0.58571\n",
            "16/16 [==============================] - 314s 20s/step - loss: 0.8405 - acc: 0.7265 - val_loss: 1.3172 - val_acc: 0.5571\n",
            "Epoch 10/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8453 - acc: 0.7163 \n",
            "Epoch 10: val_acc improved from 0.58571 to 0.63571, saving model to percobaan159_noImgPro/model\\vgg_16_159-saved-model-10-acc-0.64.hdf5\n",
            "16/16 [==============================] - 310s 20s/step - loss: 0.8453 - acc: 0.7163 - val_loss: 1.1666 - val_acc: 0.6357\n",
            "Epoch 11/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7689 - acc: 0.7449 \n",
            "Epoch 11: val_acc improved from 0.63571 to 0.71429, saving model to percobaan159_noImgPro/model\\vgg_16_159-saved-model-11-acc-0.71.hdf5\n",
            "16/16 [==============================] - 298s 19s/step - loss: 0.7689 - acc: 0.7449 - val_loss: 0.8229 - val_acc: 0.7143\n",
            "Epoch 12/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7908 - acc: 0.7245 \n",
            "Epoch 12: val_acc improved from 0.71429 to 0.74286, saving model to percobaan159_noImgPro/model\\vgg_16_159-saved-model-12-acc-0.74.hdf5\n",
            "16/16 [==============================] - 296s 19s/step - loss: 0.7908 - acc: 0.7245 - val_loss: 0.8804 - val_acc: 0.7429\n",
            "Epoch 13/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7463 - acc: 0.7347 \n",
            "Epoch 13: val_acc improved from 0.74286 to 0.80000, saving model to percobaan159_noImgPro/model\\vgg_16_159-saved-model-13-acc-0.80.hdf5\n",
            "16/16 [==============================] - 296s 19s/step - loss: 0.7463 - acc: 0.7347 - val_loss: 0.6996 - val_acc: 0.8000\n",
            "Epoch 14/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6600 - acc: 0.7755 \n",
            "Epoch 14: val_acc did not improve from 0.80000\n",
            "16/16 [==============================] - 298s 19s/step - loss: 0.6600 - acc: 0.7755 - val_loss: 0.7200 - val_acc: 0.7857\n",
            "Epoch 15/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7420 - acc: 0.7408 \n",
            "Epoch 15: val_acc did not improve from 0.80000\n",
            "16/16 [==============================] - 296s 19s/step - loss: 0.7420 - acc: 0.7408 - val_loss: 0.7059 - val_acc: 0.7714\n",
            "Epoch 16/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6567 - acc: 0.7694 \n",
            "Epoch 16: val_acc did not improve from 0.80000\n",
            "16/16 [==============================] - 297s 19s/step - loss: 0.6567 - acc: 0.7694 - val_loss: 0.7614 - val_acc: 0.7357\n",
            "Epoch 17/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6772 - acc: 0.7776 \n",
            "Epoch 17: val_acc improved from 0.80000 to 0.84286, saving model to percobaan159_noImgPro/model\\vgg_16_159-saved-model-17-acc-0.84.hdf5\n",
            "16/16 [==============================] - 298s 19s/step - loss: 0.6772 - acc: 0.7776 - val_loss: 0.5113 - val_acc: 0.8429\n",
            "Epoch 18/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6269 - acc: 0.7857 \n",
            "Epoch 18: val_acc did not improve from 0.84286\n",
            "16/16 [==============================] - 296s 19s/step - loss: 0.6269 - acc: 0.7857 - val_loss: 0.6967 - val_acc: 0.7786\n",
            "Epoch 19/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6960 - acc: 0.7612 \n",
            "Epoch 19: val_acc did not improve from 0.84286\n",
            "16/16 [==============================] - 295s 19s/step - loss: 0.6960 - acc: 0.7612 - val_loss: 0.7929 - val_acc: 0.8000\n",
            "Epoch 20/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7169 - acc: 0.7714 \n",
            "Epoch 20: val_acc did not improve from 0.84286\n",
            "16/16 [==============================] - 295s 19s/step - loss: 0.7169 - acc: 0.7714 - val_loss: 0.8520 - val_acc: 0.8000\n",
            "Epoch 21/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7515 - acc: 0.7755 \n",
            "Epoch 21: val_acc did not improve from 0.84286\n",
            "16/16 [==============================] - 298s 19s/step - loss: 0.7515 - acc: 0.7755 - val_loss: 1.1233 - val_acc: 0.7143\n",
            "Epoch 22/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7255 - acc: 0.7653 \n",
            "Epoch 22: val_acc did not improve from 0.84286\n",
            "16/16 [==============================] - 295s 19s/step - loss: 0.7255 - acc: 0.7653 - val_loss: 0.6736 - val_acc: 0.8214\n",
            "\n",
            "\n",
            "Model Accuracy 0.7857142857142857\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.80      0.89        10\n",
            "       10000       0.73      0.80      0.76        10\n",
            "      100000       1.00      0.90      0.95        10\n",
            "        2000       0.80      0.80      0.80        10\n",
            "       20000       0.53      0.80      0.64        10\n",
            "        5000       0.75      0.90      0.82        10\n",
            "       50000       1.00      0.50      0.67        10\n",
            "\n",
            "    accuracy                           0.79        70\n",
            "   macro avg       0.83      0.79      0.79        70\n",
            "weighted avg       0.83      0.79      0.79        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 160 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 60\n",
            "learning rate: 0.026275711131477048\n",
            "batch size: 32\n",
            "dropout rate: 0.7713083901588229\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "16/16 [==============================] - ETA: 0s - loss: 3.2511 - acc: 0.2571 \n",
            "Epoch 1: val_acc improved from -inf to 0.23571, saving model to percobaan160_noImgPro/model\\vgg_16_160-saved-model-01-acc-0.24.hdf5\n",
            "16/16 [==============================] - 288s 18s/step - loss: 3.2511 - acc: 0.2571 - val_loss: 3.6255 - val_acc: 0.2357\n",
            "Epoch 2/60\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.5706 - acc: 0.3122 \n",
            "Epoch 2: val_acc improved from 0.23571 to 0.33571, saving model to percobaan160_noImgPro/model\\vgg_16_160-saved-model-02-acc-0.34.hdf5\n",
            "16/16 [==============================] - 285s 18s/step - loss: 2.5706 - acc: 0.3122 - val_loss: 2.4945 - val_acc: 0.3357\n",
            "Epoch 3/60\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.7609 - acc: 0.4367 \n",
            "Epoch 3: val_acc did not improve from 0.33571\n",
            "16/16 [==============================] - 286s 18s/step - loss: 1.7609 - acc: 0.4367 - val_loss: 2.9041 - val_acc: 0.3000\n",
            "Epoch 4/60\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.4931 - acc: 0.4837 \n",
            "Epoch 4: val_acc did not improve from 0.33571\n",
            "16/16 [==============================] - 286s 18s/step - loss: 1.4931 - acc: 0.4837 - val_loss: 1.9049 - val_acc: 0.2714\n",
            "Epoch 5/60\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.4170 - acc: 0.5122 \n",
            "Epoch 5: val_acc improved from 0.33571 to 0.35714, saving model to percobaan160_noImgPro/model\\vgg_16_160-saved-model-05-acc-0.36.hdf5\n",
            "16/16 [==============================] - 287s 18s/step - loss: 1.4170 - acc: 0.5122 - val_loss: 1.6838 - val_acc: 0.3571\n",
            "Epoch 6/60\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1450 - acc: 0.5857 \n",
            "Epoch 6: val_acc improved from 0.35714 to 0.50000, saving model to percobaan160_noImgPro/model\\vgg_16_160-saved-model-06-acc-0.50.hdf5\n",
            "16/16 [==============================] - 274s 17s/step - loss: 1.1450 - acc: 0.5857 - val_loss: 1.3927 - val_acc: 0.5000\n",
            "Epoch 7/60\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0053 - acc: 0.6408 \n",
            "Epoch 7: val_acc did not improve from 0.50000\n",
            "16/16 [==============================] - 269s 17s/step - loss: 1.0053 - acc: 0.6408 - val_loss: 1.3785 - val_acc: 0.4643\n",
            "Epoch 8/60\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9604 - acc: 0.6653 \n",
            "Epoch 8: val_acc improved from 0.50000 to 0.62857, saving model to percobaan160_noImgPro/model\\vgg_16_160-saved-model-08-acc-0.63.hdf5\n",
            "16/16 [==============================] - 265s 17s/step - loss: 0.9604 - acc: 0.6653 - val_loss: 1.1619 - val_acc: 0.6286\n",
            "Epoch 9/60\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0622 - acc: 0.6204 \n",
            "Epoch 9: val_acc did not improve from 0.62857\n",
            "16/16 [==============================] - 275s 17s/step - loss: 1.0622 - acc: 0.6204 - val_loss: 1.0650 - val_acc: 0.5857\n",
            "Epoch 10/60\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8989 - acc: 0.6939 \n",
            "Epoch 10: val_acc improved from 0.62857 to 0.70000, saving model to percobaan160_noImgPro/model\\vgg_16_160-saved-model-10-acc-0.70.hdf5\n",
            "16/16 [==============================] - 284s 19s/step - loss: 0.8989 - acc: 0.6939 - val_loss: 0.9763 - val_acc: 0.7000\n",
            "Epoch 11/60\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8974 - acc: 0.6755 \n",
            "Epoch 11: val_acc improved from 0.70000 to 0.72143, saving model to percobaan160_noImgPro/model\\vgg_16_160-saved-model-11-acc-0.72.hdf5\n",
            "16/16 [==============================] - 285s 18s/step - loss: 0.8974 - acc: 0.6755 - val_loss: 0.9155 - val_acc: 0.7214\n",
            "Epoch 12/60\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8485 - acc: 0.6735 \n",
            "Epoch 12: val_acc did not improve from 0.72143\n",
            "16/16 [==============================] - 290s 18s/step - loss: 0.8485 - acc: 0.6735 - val_loss: 0.8846 - val_acc: 0.7000\n",
            "Epoch 13/60\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8678 - acc: 0.6776 \n",
            "Epoch 13: val_acc did not improve from 0.72143\n",
            "16/16 [==============================] - 289s 18s/step - loss: 0.8678 - acc: 0.6776 - val_loss: 0.9389 - val_acc: 0.7000\n",
            "Epoch 14/60\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7504 - acc: 0.7327 \n",
            "Epoch 14: val_acc improved from 0.72143 to 0.81429, saving model to percobaan160_noImgPro/model\\vgg_16_160-saved-model-14-acc-0.81.hdf5\n",
            "16/16 [==============================] - 290s 18s/step - loss: 0.7504 - acc: 0.7327 - val_loss: 0.5549 - val_acc: 0.8143\n",
            "Epoch 15/60\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8802 - acc: 0.7061 \n",
            "Epoch 15: val_acc improved from 0.81429 to 0.83571, saving model to percobaan160_noImgPro/model\\vgg_16_160-saved-model-15-acc-0.84.hdf5\n",
            "16/16 [==============================] - 289s 18s/step - loss: 0.8802 - acc: 0.7061 - val_loss: 0.5407 - val_acc: 0.8357\n",
            "Epoch 16/60\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7352 - acc: 0.7510 \n",
            "Epoch 16: val_acc did not improve from 0.83571\n",
            "16/16 [==============================] - 289s 18s/step - loss: 0.7352 - acc: 0.7510 - val_loss: 0.5672 - val_acc: 0.8214\n",
            "Epoch 17/60\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6893 - acc: 0.7612 \n",
            "Epoch 17: val_acc did not improve from 0.83571\n",
            "16/16 [==============================] - 289s 18s/step - loss: 0.6893 - acc: 0.7612 - val_loss: 0.5515 - val_acc: 0.8357\n",
            "Epoch 18/60\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6523 - acc: 0.7673 \n",
            "Epoch 18: val_acc improved from 0.83571 to 0.86429, saving model to percobaan160_noImgPro/model\\vgg_16_160-saved-model-18-acc-0.86.hdf5\n",
            "16/16 [==============================] - 290s 18s/step - loss: 0.6523 - acc: 0.7673 - val_loss: 0.5104 - val_acc: 0.8643\n",
            "Epoch 19/60\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7000 - acc: 0.7755 \n",
            "Epoch 19: val_acc did not improve from 0.86429\n",
            "16/16 [==============================] - 289s 18s/step - loss: 0.7000 - acc: 0.7755 - val_loss: 0.6259 - val_acc: 0.8286\n",
            "Epoch 20/60\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6710 - acc: 0.7735 \n",
            "Epoch 20: val_acc did not improve from 0.86429\n",
            "16/16 [==============================] - 287s 19s/step - loss: 0.6710 - acc: 0.7735 - val_loss: 0.5784 - val_acc: 0.8643\n",
            "Epoch 21/60\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7995 - acc: 0.7327 \n",
            "Epoch 21: val_acc did not improve from 0.86429\n",
            "16/16 [==============================] - 289s 18s/step - loss: 0.7995 - acc: 0.7327 - val_loss: 0.5604 - val_acc: 0.8500\n",
            "Epoch 22/60\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7563 - acc: 0.7265 \n",
            "Epoch 22: val_acc did not improve from 0.86429\n",
            "16/16 [==============================] - 288s 18s/step - loss: 0.7563 - acc: 0.7265 - val_loss: 0.5560 - val_acc: 0.8500\n",
            "Epoch 23/60\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6257 - acc: 0.7898 \n",
            "Epoch 23: val_acc did not improve from 0.86429\n",
            "16/16 [==============================] - 290s 18s/step - loss: 0.6257 - acc: 0.7898 - val_loss: 0.5474 - val_acc: 0.8286\n",
            "\n",
            "\n",
            "Model Accuracy 0.7428571428571429\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.88      0.70      0.78        10\n",
            "       10000       0.88      0.70      0.78        10\n",
            "      100000       1.00      0.90      0.95        10\n",
            "        2000       0.43      1.00      0.61        10\n",
            "       20000       0.86      0.60      0.71        10\n",
            "        5000       0.83      0.50      0.62        10\n",
            "       50000       0.89      0.80      0.84        10\n",
            "\n",
            "    accuracy                           0.74        70\n",
            "   macro avg       0.82      0.74      0.75        70\n",
            "weighted avg       0.82      0.74      0.75        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 161 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 57\n",
            "learning rate: 0.0392772309817598\n",
            "batch size: 64\n",
            "dropout rate: 0.5651239451152208\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2348\\3527758676.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.4431 - acc: 0.3347 \n",
            "Epoch 1: val_acc improved from -inf to 0.27143, saving model to percobaan161_noImgPro/model\\vgg_16_161-saved-model-01-acc-0.27.hdf5\n",
            "8/8 [==============================] - 281s 36s/step - loss: 2.4431 - acc: 0.3347 - val_loss: 5.8221 - val_acc: 0.2714\n",
            "Epoch 2/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4118 - acc: 0.5204 \n",
            "Epoch 2: val_acc did not improve from 0.27143\n",
            "8/8 [==============================] - 278s 36s/step - loss: 1.4118 - acc: 0.5204 - val_loss: 4.6113 - val_acc: 0.2357\n",
            "Epoch 3/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1772 - acc: 0.5939 \n",
            "Epoch 3: val_acc did not improve from 0.27143\n",
            "8/8 [==============================] - 276s 35s/step - loss: 1.1772 - acc: 0.5939 - val_loss: 2.8980 - val_acc: 0.2643\n",
            "Epoch 4/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9931 - acc: 0.6367 \n",
            "Epoch 4: val_acc improved from 0.27143 to 0.40000, saving model to percobaan161_noImgPro/model\\vgg_16_161-saved-model-04-acc-0.40.hdf5\n",
            "8/8 [==============================] - 278s 37s/step - loss: 0.9931 - acc: 0.6367 - val_loss: 2.4802 - val_acc: 0.4000\n",
            "Epoch 5/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7330 - acc: 0.7347 \n",
            "Epoch 5: val_acc did not improve from 0.40000\n",
            "8/8 [==============================] - 279s 36s/step - loss: 0.7330 - acc: 0.7347 - val_loss: 3.5335 - val_acc: 0.3143\n",
            "Epoch 6/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6209 - acc: 0.7776 \n",
            "Epoch 6: val_acc did not improve from 0.40000\n",
            "8/8 [==============================] - 278s 36s/step - loss: 0.6209 - acc: 0.7776 - val_loss: 3.5282 - val_acc: 0.2929\n",
            "Epoch 7/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5345 - acc: 0.8061 \n",
            "Epoch 7: val_acc did not improve from 0.40000\n",
            "8/8 [==============================] - 273s 36s/step - loss: 0.5345 - acc: 0.8061 - val_loss: 3.0176 - val_acc: 0.3571\n",
            "Epoch 8/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4793 - acc: 0.8122 \n",
            "Epoch 8: val_acc did not improve from 0.40000\n",
            "8/8 [==============================] - 264s 34s/step - loss: 0.4793 - acc: 0.8122 - val_loss: 1.8836 - val_acc: 0.3500\n",
            "Epoch 9/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4975 - acc: 0.8408 \n",
            "Epoch 9: val_acc improved from 0.40000 to 0.51429, saving model to percobaan161_noImgPro/model\\vgg_16_161-saved-model-09-acc-0.51.hdf5\n",
            "8/8 [==============================] - 257s 33s/step - loss: 0.4975 - acc: 0.8408 - val_loss: 1.4514 - val_acc: 0.5143\n",
            "Epoch 10/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3832 - acc: 0.8551 \n",
            "Epoch 10: val_acc did not improve from 0.51429\n",
            "8/8 [==============================] - 255s 33s/step - loss: 0.3832 - acc: 0.8551 - val_loss: 1.6681 - val_acc: 0.4500\n",
            "Epoch 11/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3728 - acc: 0.8755 \n",
            "Epoch 11: val_acc did not improve from 0.51429\n",
            "8/8 [==============================] - 255s 33s/step - loss: 0.3728 - acc: 0.8755 - val_loss: 1.6842 - val_acc: 0.4500\n",
            "Epoch 12/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3558 - acc: 0.8612 \n",
            "Epoch 12: val_acc improved from 0.51429 to 0.56429, saving model to percobaan161_noImgPro/model\\vgg_16_161-saved-model-12-acc-0.56.hdf5\n",
            "8/8 [==============================] - 254s 33s/step - loss: 0.3558 - acc: 0.8612 - val_loss: 1.5258 - val_acc: 0.5643\n",
            "Epoch 13/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2767 - acc: 0.9041 \n",
            "Epoch 13: val_acc did not improve from 0.56429\n",
            "8/8 [==============================] - 256s 34s/step - loss: 0.2767 - acc: 0.9041 - val_loss: 1.3349 - val_acc: 0.5429\n",
            "Epoch 14/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3664 - acc: 0.8673 \n",
            "Epoch 14: val_acc improved from 0.56429 to 0.65000, saving model to percobaan161_noImgPro/model\\vgg_16_161-saved-model-14-acc-0.65.hdf5\n",
            "8/8 [==============================] - 256s 33s/step - loss: 0.3664 - acc: 0.8673 - val_loss: 1.2191 - val_acc: 0.6500\n",
            "Epoch 15/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3322 - acc: 0.8959 \n",
            "Epoch 15: val_acc did not improve from 0.65000\n",
            "8/8 [==============================] - 256s 33s/step - loss: 0.3322 - acc: 0.8959 - val_loss: 1.4962 - val_acc: 0.5857\n",
            "Epoch 16/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3617 - acc: 0.8898 \n",
            "Epoch 16: val_acc did not improve from 0.65000\n",
            "8/8 [==============================] - 255s 33s/step - loss: 0.3617 - acc: 0.8898 - val_loss: 1.6959 - val_acc: 0.5857\n",
            "Epoch 17/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3185 - acc: 0.9102 \n",
            "Epoch 17: val_acc did not improve from 0.65000\n",
            "8/8 [==============================] - 253s 33s/step - loss: 0.3185 - acc: 0.9102 - val_loss: 1.3213 - val_acc: 0.5643\n",
            "Epoch 18/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3428 - acc: 0.8878 \n",
            "Epoch 18: val_acc improved from 0.65000 to 0.72857, saving model to percobaan161_noImgPro/model\\vgg_16_161-saved-model-18-acc-0.73.hdf5\n",
            "8/8 [==============================] - 255s 33s/step - loss: 0.3428 - acc: 0.8878 - val_loss: 0.8148 - val_acc: 0.7286\n",
            "Epoch 19/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2843 - acc: 0.9122 \n",
            "Epoch 19: val_acc improved from 0.72857 to 0.77143, saving model to percobaan161_noImgPro/model\\vgg_16_161-saved-model-19-acc-0.77.hdf5\n",
            "8/8 [==============================] - 257s 33s/step - loss: 0.2843 - acc: 0.9122 - val_loss: 0.7356 - val_acc: 0.7714\n",
            "Epoch 20/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2090 - acc: 0.9265 \n",
            "Epoch 20: val_acc did not improve from 0.77143\n",
            "8/8 [==============================] - 256s 33s/step - loss: 0.2090 - acc: 0.9265 - val_loss: 1.1995 - val_acc: 0.6500\n",
            "Epoch 21/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2812 - acc: 0.8959 \n",
            "Epoch 21: val_acc did not improve from 0.77143\n",
            "8/8 [==============================] - 255s 33s/step - loss: 0.2812 - acc: 0.8959 - val_loss: 1.0109 - val_acc: 0.6786\n",
            "Epoch 22/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2332 - acc: 0.9122 \n",
            "Epoch 22: val_acc did not improve from 0.77143\n",
            "8/8 [==============================] - 254s 34s/step - loss: 0.2332 - acc: 0.9122 - val_loss: 0.8085 - val_acc: 0.7286\n",
            "Epoch 23/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3111 - acc: 0.8980 \n",
            "Epoch 23: val_acc improved from 0.77143 to 0.81429, saving model to percobaan161_noImgPro/model\\vgg_16_161-saved-model-23-acc-0.81.hdf5\n",
            "8/8 [==============================] - 253s 32s/step - loss: 0.3111 - acc: 0.8980 - val_loss: 0.6913 - val_acc: 0.8143\n",
            "Epoch 24/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2459 - acc: 0.9041 \n",
            "Epoch 24: val_acc improved from 0.81429 to 0.82857, saving model to percobaan161_noImgPro/model\\vgg_16_161-saved-model-24-acc-0.83.hdf5\n",
            "8/8 [==============================] - 255s 33s/step - loss: 0.2459 - acc: 0.9041 - val_loss: 0.7144 - val_acc: 0.8286\n",
            "Epoch 25/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2246 - acc: 0.9184 \n",
            "Epoch 25: val_acc did not improve from 0.82857\n",
            "8/8 [==============================] - 256s 33s/step - loss: 0.2246 - acc: 0.9184 - val_loss: 1.1273 - val_acc: 0.7143\n",
            "Epoch 26/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2690 - acc: 0.9041 \n",
            "Epoch 26: val_acc improved from 0.82857 to 0.83571, saving model to percobaan161_noImgPro/model\\vgg_16_161-saved-model-26-acc-0.84.hdf5\n",
            "8/8 [==============================] - 267s 34s/step - loss: 0.2690 - acc: 0.9041 - val_loss: 0.6084 - val_acc: 0.8357\n",
            "Epoch 27/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3404 - acc: 0.9020 "
          ]
        }
      ],
      "source": [
        "j = 8\n",
        "for i in range (j,len(parameter)):\n",
        "#for i in range (0,10): #aslinya in range len(parameter) tapi kalau mau coba per sedikit2 ya gini deh\n",
        "  vgg_epoch = (parameter[i][0])\n",
        "  learning_rate = (parameter[i][1])\n",
        "  batch_size = (parameter[i][2])\n",
        "  dropout_rate = (parameter[i][3])\n",
        "  i=i+1\n",
        "  savePercobaan(i)\n",
        "  print(\"Percobaan ke-\",i,\"↓\")\n",
        "  print(\"HYPERPARAMETER\".center(100,\"─\"))\n",
        "  print(\"vgg epoch:\",vgg_epoch)\n",
        "  print(\"learning rate:\",learning_rate)\n",
        "  print(\"batch size:\",batch_size)\n",
        "  print(\"dropout rate:\",dropout_rate)\n",
        "  print(\"\".center(100,\"─\"))\n",
        "  vgg16_training(i, vgg_epoch, learning_rate, batch_size, dropout_rate)\n",
        "  new_row = {'Epoch': vgg_epoch, 'Learning Rate': learning_rate, 'Batch Size': batch_size, 'Dropout Rate': dropout_rate, 'Accuracy': arr_accuracy16[-1]}\n",
        "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n",
        "  hasilTabel.index = hasilTabel.index + (j+1)\n",
        "  hasilTabel.to_excel(\"hasilTabel.xlsx\")\n",
        "  print(\"\".center(100,\"─\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percobaan ke- 161 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 62\n",
            "learning rate: 0.030324927544112847\n",
            "batch size: 64\n",
            "dropout rate: 0.5494962491831858\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/62\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.1281 - acc: 0.3816\n",
            "Epoch 1: val_acc improved from -inf to 0.25000, saving model to percobaan161_noImgPro/model\\vgg_16_161-saved-model-01-acc-0.25.hdf5\n",
            "8/8 [==============================] - 35s 4s/step - loss: 2.1281 - acc: 0.3816 - val_loss: 4.3536 - val_acc: 0.2500\n",
            "Epoch 2/62\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4128 - acc: 0.5204\n",
            "Epoch 2: val_acc did not improve from 0.25000\n",
            "8/8 [==============================] - 33s 4s/step - loss: 1.4128 - acc: 0.5204 - val_loss: 7.3806 - val_acc: 0.2214\n",
            "Epoch 3/62\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0200 - acc: 0.6551\n",
            "Epoch 3: val_acc did not improve from 0.25000\n",
            "8/8 [==============================] - 32s 4s/step - loss: 1.0200 - acc: 0.6551 - val_loss: 7.5023 - val_acc: 0.1929\n",
            "Epoch 4/62\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8671 - acc: 0.6857\n",
            "Epoch 4: val_acc did not improve from 0.25000\n",
            "8/8 [==============================] - 32s 4s/step - loss: 0.8671 - acc: 0.6857 - val_loss: 5.4776 - val_acc: 0.2214\n",
            "Epoch 5/62\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5755 - acc: 0.7816\n",
            "Epoch 5: val_acc did not improve from 0.25000\n",
            "8/8 [==============================] - 32s 4s/step - loss: 0.5755 - acc: 0.7816 - val_loss: 4.7289 - val_acc: 0.2500\n",
            "Epoch 6/62\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6225 - acc: 0.7959\n",
            "Epoch 6: val_acc improved from 0.25000 to 0.37857, saving model to percobaan161_noImgPro/model\\vgg_16_161-saved-model-06-acc-0.38.hdf5\n",
            "8/8 [==============================] - 32s 4s/step - loss: 0.6225 - acc: 0.7959 - val_loss: 2.6332 - val_acc: 0.3786\n",
            "Epoch 7/62\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4542 - acc: 0.8531\n",
            "Epoch 7: val_acc improved from 0.37857 to 0.38571, saving model to percobaan161_noImgPro/model\\vgg_16_161-saved-model-07-acc-0.39.hdf5\n",
            "8/8 [==============================] - 32s 4s/step - loss: 0.4542 - acc: 0.8531 - val_loss: 2.6973 - val_acc: 0.3857\n",
            "Epoch 8/62\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4191 - acc: 0.8653\n",
            "Epoch 8: val_acc improved from 0.38571 to 0.43571, saving model to percobaan161_noImgPro/model\\vgg_16_161-saved-model-08-acc-0.44.hdf5\n",
            "8/8 [==============================] - 32s 4s/step - loss: 0.4191 - acc: 0.8653 - val_loss: 2.4728 - val_acc: 0.4357\n",
            "Epoch 9/62\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3483 - acc: 0.8755\n",
            "Epoch 9: val_acc improved from 0.43571 to 0.52143, saving model to percobaan161_noImgPro/model\\vgg_16_161-saved-model-09-acc-0.52.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.3483 - acc: 0.8755 - val_loss: 1.5801 - val_acc: 0.5214\n",
            "Epoch 10/62\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3526 - acc: 0.8694\n",
            "Epoch 10: val_acc improved from 0.52143 to 0.65714, saving model to percobaan161_noImgPro/model\\vgg_16_161-saved-model-10-acc-0.66.hdf5\n",
            "8/8 [==============================] - 32s 4s/step - loss: 0.3526 - acc: 0.8694 - val_loss: 1.0868 - val_acc: 0.6571\n",
            "Epoch 11/62\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4060 - acc: 0.8469\n",
            "Epoch 11: val_acc did not improve from 0.65714\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.4060 - acc: 0.8469 - val_loss: 0.9587 - val_acc: 0.6357\n",
            "Epoch 12/62\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3373 - acc: 0.8776\n",
            "Epoch 12: val_acc did not improve from 0.65714\n",
            "8/8 [==============================] - 37s 5s/step - loss: 0.3373 - acc: 0.8776 - val_loss: 0.9120 - val_acc: 0.6143\n",
            "Epoch 13/62\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2875 - acc: 0.9143\n",
            "Epoch 13: val_acc did not improve from 0.65714\n",
            "8/8 [==============================] - 32s 4s/step - loss: 0.2875 - acc: 0.9143 - val_loss: 0.9528 - val_acc: 0.6143\n",
            "Epoch 14/62\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3001 - acc: 0.8939\n",
            "Epoch 14: val_acc improved from 0.65714 to 0.72857, saving model to percobaan161_noImgPro/model\\vgg_16_161-saved-model-14-acc-0.73.hdf5\n",
            "8/8 [==============================] - 38s 4s/step - loss: 0.3001 - acc: 0.8939 - val_loss: 0.6597 - val_acc: 0.7286\n",
            "Epoch 15/62\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1711 - acc: 0.9449\n",
            "Epoch 15: val_acc improved from 0.72857 to 0.74286, saving model to percobaan161_noImgPro/model\\vgg_16_161-saved-model-15-acc-0.74.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.1711 - acc: 0.9449 - val_loss: 0.6550 - val_acc: 0.7429\n",
            "Epoch 16/62\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2550 - acc: 0.9082\n",
            "Epoch 16: val_acc improved from 0.74286 to 0.82143, saving model to percobaan161_noImgPro/model\\vgg_16_161-saved-model-16-acc-0.82.hdf5\n",
            "8/8 [==============================] - 38s 4s/step - loss: 0.2550 - acc: 0.9082 - val_loss: 0.5693 - val_acc: 0.8214\n",
            "Epoch 17/62\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3024 - acc: 0.8959\n",
            "Epoch 17: val_acc did not improve from 0.82143\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.3024 - acc: 0.8959 - val_loss: 0.5082 - val_acc: 0.8214\n",
            "Epoch 18/62\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3006 - acc: 0.8898\n",
            "Epoch 18: val_acc did not improve from 0.82143\n",
            "8/8 [==============================] - 38s 4s/step - loss: 0.3006 - acc: 0.8898 - val_loss: 0.6420 - val_acc: 0.7643\n",
            "Epoch 19/62\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2133 - acc: 0.9224\n",
            "Epoch 19: val_acc did not improve from 0.82143\n",
            "8/8 [==============================] - 44s 5s/step - loss: 0.2133 - acc: 0.9224 - val_loss: 0.8669 - val_acc: 0.7143\n",
            "Epoch 20/62\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2230 - acc: 0.9224\n",
            "Epoch 20: val_acc did not improve from 0.82143\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.2230 - acc: 0.9224 - val_loss: 0.9737 - val_acc: 0.7286\n",
            "Epoch 21/62\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2468 - acc: 0.9184\n",
            "Epoch 21: val_acc did not improve from 0.82143\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.2468 - acc: 0.9184 - val_loss: 1.0383 - val_acc: 0.7000\n",
            "Epoch 22/62\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2775 - acc: 0.8918\n",
            "Epoch 22: val_acc did not improve from 0.82143\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.2775 - acc: 0.8918 - val_loss: 0.7422 - val_acc: 0.7643\n",
            "\n",
            "\n",
            "Model Accuracy 0.6857142857142857\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.71      1.00      0.83        10\n",
            "       10000       0.90      0.90      0.90        10\n",
            "      100000       1.00      0.30      0.46        10\n",
            "        2000       0.90      0.90      0.90        10\n",
            "       20000       1.00      0.20      0.33        10\n",
            "        5000       1.00      0.50      0.67        10\n",
            "       50000       0.38      1.00      0.56        10\n",
            "\n",
            "    accuracy                           0.69        70\n",
            "   macro avg       0.84      0.69      0.66        70\n",
            "weighted avg       0.84      0.69      0.66        70\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_57148\\3902733085.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 162 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 63\n",
            "learning rate: 0.048297728483626234\n",
            "batch size: 64\n",
            "dropout rate: 0.6330239662804152\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.9065 - acc: 0.2816\n",
            "Epoch 1: val_acc improved from -inf to 0.14286, saving model to percobaan162_noImgPro/model\\vgg_16_162-saved-model-01-acc-0.14.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 2.9065 - acc: 0.2816 - val_loss: 19.8436 - val_acc: 0.1429\n",
            "Epoch 2/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.0369 - acc: 0.4000\n",
            "Epoch 2: val_acc improved from 0.14286 to 0.22143, saving model to percobaan162_noImgPro/model\\vgg_16_162-saved-model-02-acc-0.22.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 2.0369 - acc: 0.4000 - val_loss: 6.4675 - val_acc: 0.2214\n",
            "Epoch 3/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5485 - acc: 0.4959\n",
            "Epoch 3: val_acc did not improve from 0.22143\n",
            "8/8 [==============================] - 38s 5s/step - loss: 1.5485 - acc: 0.4959 - val_loss: 5.1115 - val_acc: 0.1929\n",
            "Epoch 4/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1421 - acc: 0.5796\n",
            "Epoch 4: val_acc did not improve from 0.22143\n",
            "8/8 [==============================] - 38s 5s/step - loss: 1.1421 - acc: 0.5796 - val_loss: 6.5413 - val_acc: 0.1429\n",
            "Epoch 5/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0259 - acc: 0.6469\n",
            "Epoch 5: val_acc did not improve from 0.22143\n",
            "8/8 [==============================] - 38s 5s/step - loss: 1.0259 - acc: 0.6469 - val_loss: 5.0203 - val_acc: 0.1786\n",
            "Epoch 6/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8402 - acc: 0.7184\n",
            "Epoch 6: val_acc improved from 0.22143 to 0.34286, saving model to percobaan162_noImgPro/model\\vgg_16_162-saved-model-06-acc-0.34.hdf5\n",
            "8/8 [==============================] - 37s 5s/step - loss: 0.8402 - acc: 0.7184 - val_loss: 2.4994 - val_acc: 0.3429\n",
            "Epoch 7/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7544 - acc: 0.7204\n",
            "Epoch 7: val_acc did not improve from 0.34286\n",
            "8/8 [==============================] - 44s 5s/step - loss: 0.7544 - acc: 0.7204 - val_loss: 3.2333 - val_acc: 0.2571\n",
            "Epoch 8/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7136 - acc: 0.7327\n",
            "Epoch 8: val_acc did not improve from 0.34286\n",
            "8/8 [==============================] - 37s 5s/step - loss: 0.7136 - acc: 0.7327 - val_loss: 3.1451 - val_acc: 0.3143\n",
            "Epoch 9/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5556 - acc: 0.8000\n",
            "Epoch 9: val_acc improved from 0.34286 to 0.42857, saving model to percobaan162_noImgPro/model\\vgg_16_162-saved-model-09-acc-0.43.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.5556 - acc: 0.8000 - val_loss: 2.1487 - val_acc: 0.4286\n",
            "Epoch 10/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6051 - acc: 0.7980\n",
            "Epoch 10: val_acc improved from 0.42857 to 0.57857, saving model to percobaan162_noImgPro/model\\vgg_16_162-saved-model-10-acc-0.58.hdf5\n",
            "8/8 [==============================] - 42s 5s/step - loss: 0.6051 - acc: 0.7980 - val_loss: 1.2762 - val_acc: 0.5786\n",
            "Epoch 11/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5717 - acc: 0.7898\n",
            "Epoch 11: val_acc did not improve from 0.57857\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.5717 - acc: 0.7898 - val_loss: 1.1600 - val_acc: 0.5714\n",
            "Epoch 12/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4748 - acc: 0.8408\n",
            "Epoch 12: val_acc did not improve from 0.57857\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.4748 - acc: 0.8408 - val_loss: 1.9911 - val_acc: 0.4143\n",
            "Epoch 13/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4776 - acc: 0.8429\n",
            "Epoch 13: val_acc improved from 0.57857 to 0.60000, saving model to percobaan162_noImgPro/model\\vgg_16_162-saved-model-13-acc-0.60.hdf5\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.4776 - acc: 0.8429 - val_loss: 1.3806 - val_acc: 0.6000\n",
            "Epoch 14/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3762 - acc: 0.8796\n",
            "Epoch 14: val_acc did not improve from 0.60000\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.3762 - acc: 0.8796 - val_loss: 1.5049 - val_acc: 0.5571\n",
            "Epoch 15/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5021 - acc: 0.8429\n",
            "Epoch 15: val_acc did not improve from 0.60000\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.5021 - acc: 0.8429 - val_loss: 2.3868 - val_acc: 0.3857\n",
            "Epoch 16/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3807 - acc: 0.8653\n",
            "Epoch 16: val_acc did not improve from 0.60000\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.3807 - acc: 0.8653 - val_loss: 2.0567 - val_acc: 0.3786\n",
            "\n",
            "\n",
            "Model Accuracy 0.35714285714285715\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_57148\\3902733085.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.40      0.57        10\n",
            "       10000       1.00      0.40      0.57        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.00      0.00      0.00        10\n",
            "       20000       0.00      0.00      0.00        10\n",
            "        5000       0.41      0.70      0.52        10\n",
            "       50000       0.22      1.00      0.36        10\n",
            "\n",
            "    accuracy                           0.36        70\n",
            "   macro avg       0.38      0.36      0.29        70\n",
            "weighted avg       0.38      0.36      0.29        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 163 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 59\n",
            "learning rate: 0.046236619243689284\n",
            "batch size: 64\n",
            "dropout rate: 0.6616692794468843\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/59\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.7933 - acc: 0.2878\n",
            "Epoch 1: val_acc improved from -inf to 0.35714, saving model to percobaan163_noImgPro/model\\vgg_16_163-saved-model-01-acc-0.36.hdf5\n",
            "8/8 [==============================] - 46s 5s/step - loss: 2.7933 - acc: 0.2878 - val_loss: 6.1501 - val_acc: 0.3571\n",
            "Epoch 2/59\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.1029 - acc: 0.4286\n",
            "Epoch 2: val_acc did not improve from 0.35714\n",
            "8/8 [==============================] - 40s 5s/step - loss: 2.1029 - acc: 0.4286 - val_loss: 5.0799 - val_acc: 0.3071\n",
            "Epoch 3/59\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4260 - acc: 0.5061\n",
            "Epoch 3: val_acc did not improve from 0.35714\n",
            "8/8 [==============================] - 39s 5s/step - loss: 1.4260 - acc: 0.5061 - val_loss: 4.2428 - val_acc: 0.2071\n",
            "Epoch 4/59\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.2408 - acc: 0.5551\n",
            "Epoch 4: val_acc did not improve from 0.35714\n",
            "8/8 [==============================] - 45s 6s/step - loss: 1.2408 - acc: 0.5551 - val_loss: 3.6490 - val_acc: 0.1643\n",
            "Epoch 5/59\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9904 - acc: 0.6551\n",
            "Epoch 5: val_acc did not improve from 0.35714\n",
            "8/8 [==============================] - 40s 5s/step - loss: 0.9904 - acc: 0.6551 - val_loss: 3.0169 - val_acc: 0.2500\n",
            "Epoch 6/59\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8597 - acc: 0.6939\n",
            "Epoch 6: val_acc did not improve from 0.35714\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.8597 - acc: 0.6939 - val_loss: 2.0641 - val_acc: 0.3214\n",
            "Epoch 7/59\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8321 - acc: 0.6837\n",
            "Epoch 7: val_acc improved from 0.35714 to 0.40000, saving model to percobaan163_noImgPro/model\\vgg_16_163-saved-model-07-acc-0.40.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.8321 - acc: 0.6837 - val_loss: 2.0063 - val_acc: 0.4000\n",
            "Epoch 8/59\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6132 - acc: 0.7735\n",
            "Epoch 8: val_acc improved from 0.40000 to 0.50000, saving model to percobaan163_noImgPro/model\\vgg_16_163-saved-model-08-acc-0.50.hdf5\n",
            "8/8 [==============================] - 45s 6s/step - loss: 0.6132 - acc: 0.7735 - val_loss: 1.5102 - val_acc: 0.5000\n",
            "Epoch 9/59\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6445 - acc: 0.7571\n",
            "Epoch 9: val_acc improved from 0.50000 to 0.61429, saving model to percobaan163_noImgPro/model\\vgg_16_163-saved-model-09-acc-0.61.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.6445 - acc: 0.7571 - val_loss: 1.2258 - val_acc: 0.6143\n",
            "Epoch 10/59\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6378 - acc: 0.7653\n",
            "Epoch 10: val_acc did not improve from 0.61429\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.6378 - acc: 0.7653 - val_loss: 1.3988 - val_acc: 0.5286\n",
            "Epoch 11/59\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6214 - acc: 0.7878\n",
            "Epoch 11: val_acc did not improve from 0.61429\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.6214 - acc: 0.7878 - val_loss: 1.5951 - val_acc: 0.4571\n",
            "Epoch 12/59\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5971 - acc: 0.7980\n",
            "Epoch 12: val_acc did not improve from 0.61429\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.5971 - acc: 0.7980 - val_loss: 1.6450 - val_acc: 0.5143\n",
            "Epoch 13/59\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5251 - acc: 0.8041\n",
            "Epoch 13: val_acc did not improve from 0.61429\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.5251 - acc: 0.8041 - val_loss: 1.9202 - val_acc: 0.5286\n",
            "Epoch 14/59\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5496 - acc: 0.8020\n",
            "Epoch 14: val_acc did not improve from 0.61429\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.5496 - acc: 0.8020 - val_loss: 3.1656 - val_acc: 0.3214\n",
            "\n",
            "\n",
            "Model Accuracy 0.2857142857142857\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_57148\\3902733085.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.10      0.18        10\n",
            "       10000       1.00      0.20      0.33        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.00      0.00      0.00        10\n",
            "       20000       0.18      0.80      0.29        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       0.41      0.90      0.56        10\n",
            "\n",
            "    accuracy                           0.29        70\n",
            "   macro avg       0.37      0.29      0.20        70\n",
            "weighted avg       0.37      0.29      0.20        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 164 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 63\n",
            "learning rate: 0.037022438462023556\n",
            "batch size: 64\n",
            "dropout rate: 0.7434844176372062\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 3.2066 - acc: 0.2367\n",
            "Epoch 1: val_acc improved from -inf to 0.21429, saving model to percobaan164_noImgPro/model\\vgg_16_164-saved-model-01-acc-0.21.hdf5\n",
            "8/8 [==============================] - 45s 5s/step - loss: 3.2066 - acc: 0.2367 - val_loss: 6.2414 - val_acc: 0.2143\n",
            "Epoch 2/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.2379 - acc: 0.3571\n",
            "Epoch 2: val_acc improved from 0.21429 to 0.25714, saving model to percobaan164_noImgPro/model\\vgg_16_164-saved-model-02-acc-0.26.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 2.2379 - acc: 0.3571 - val_loss: 4.6540 - val_acc: 0.2571\n",
            "Epoch 3/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7732 - acc: 0.4143\n",
            "Epoch 3: val_acc did not improve from 0.25714\n",
            "8/8 [==============================] - 37s 5s/step - loss: 1.7732 - acc: 0.4143 - val_loss: 4.8763 - val_acc: 0.1429\n",
            "Epoch 4/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5689 - acc: 0.4714\n",
            "Epoch 4: val_acc did not improve from 0.25714\n",
            "8/8 [==============================] - 43s 5s/step - loss: 1.5689 - acc: 0.4714 - val_loss: 3.1498 - val_acc: 0.1929\n",
            "Epoch 5/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.2745 - acc: 0.5327\n",
            "Epoch 5: val_acc did not improve from 0.25714\n",
            "8/8 [==============================] - 37s 5s/step - loss: 1.2745 - acc: 0.5327 - val_loss: 2.8524 - val_acc: 0.2500\n",
            "Epoch 6/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0847 - acc: 0.6245\n",
            "Epoch 6: val_acc did not improve from 0.25714\n",
            "8/8 [==============================] - 43s 6s/step - loss: 1.0847 - acc: 0.6245 - val_loss: 2.5286 - val_acc: 0.2214\n",
            "Epoch 7/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0429 - acc: 0.6408\n",
            "Epoch 7: val_acc improved from 0.25714 to 0.37143, saving model to percobaan164_noImgPro/model\\vgg_16_164-saved-model-07-acc-0.37.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 1.0429 - acc: 0.6408 - val_loss: 2.0386 - val_acc: 0.3714\n",
            "Epoch 8/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9511 - acc: 0.6735\n",
            "Epoch 8: val_acc improved from 0.37143 to 0.42143, saving model to percobaan164_noImgPro/model\\vgg_16_164-saved-model-08-acc-0.42.hdf5\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.9511 - acc: 0.6735 - val_loss: 1.6477 - val_acc: 0.4214\n",
            "Epoch 9/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8923 - acc: 0.6694\n",
            "Epoch 9: val_acc improved from 0.42143 to 0.43571, saving model to percobaan164_noImgPro/model\\vgg_16_164-saved-model-09-acc-0.44.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.8923 - acc: 0.6694 - val_loss: 1.6026 - val_acc: 0.4357\n",
            "Epoch 10/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8927 - acc: 0.6939\n",
            "Epoch 10: val_acc improved from 0.43571 to 0.47143, saving model to percobaan164_noImgPro/model\\vgg_16_164-saved-model-10-acc-0.47.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.8927 - acc: 0.6939 - val_loss: 1.4499 - val_acc: 0.4714\n",
            "Epoch 11/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7546 - acc: 0.7306\n",
            "Epoch 11: val_acc improved from 0.47143 to 0.57143, saving model to percobaan164_noImgPro/model\\vgg_16_164-saved-model-11-acc-0.57.hdf5\n",
            "8/8 [==============================] - 44s 5s/step - loss: 0.7546 - acc: 0.7306 - val_loss: 1.0906 - val_acc: 0.5714\n",
            "Epoch 12/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6751 - acc: 0.7551\n",
            "Epoch 12: val_acc did not improve from 0.57143\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.6751 - acc: 0.7551 - val_loss: 1.3767 - val_acc: 0.4714\n",
            "Epoch 13/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7795 - acc: 0.7429\n",
            "Epoch 13: val_acc did not improve from 0.57143\n",
            "8/8 [==============================] - 42s 5s/step - loss: 0.7795 - acc: 0.7429 - val_loss: 1.5852 - val_acc: 0.5000\n",
            "Epoch 14/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7180 - acc: 0.7408\n",
            "Epoch 14: val_acc did not improve from 0.57143\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.7180 - acc: 0.7408 - val_loss: 1.4909 - val_acc: 0.5286\n",
            "Epoch 15/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6303 - acc: 0.7735\n",
            "Epoch 15: val_acc did not improve from 0.57143\n",
            "8/8 [==============================] - 43s 5s/step - loss: 0.6303 - acc: 0.7735 - val_loss: 1.7454 - val_acc: 0.4500\n",
            "Epoch 16/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6880 - acc: 0.7612\n",
            "Epoch 16: val_acc did not improve from 0.57143\n",
            "8/8 [==============================] - 37s 5s/step - loss: 0.6880 - acc: 0.7612 - val_loss: 1.9479 - val_acc: 0.4500\n",
            "\n",
            "\n",
            "Model Accuracy 0.37142857142857144\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.25      1.00      0.40        10\n",
            "       10000       0.00      0.00      0.00        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.00      0.00      0.00        10\n",
            "       20000       0.50      0.70      0.58        10\n",
            "        5000       0.67      0.20      0.31        10\n",
            "       50000       0.54      0.70      0.61        10\n",
            "\n",
            "    accuracy                           0.37        70\n",
            "   macro avg       0.28      0.37      0.27        70\n",
            "weighted avg       0.28      0.37      0.27        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 165 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 65\n",
            "learning rate: 0.042248219486144656\n",
            "batch size: 128\n",
            "dropout rate: 0.515611349147933\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_57148\\3902733085.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/65\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.4764 - acc: 0.3429\n",
            "Epoch 1: val_acc improved from -inf to 0.19286, saving model to percobaan165_noImgPro/model\\vgg_16_165-saved-model-01-acc-0.19.hdf5\n",
            "4/4 [==============================] - 40s 11s/step - loss: 2.4764 - acc: 0.3429 - val_loss: 6.3207 - val_acc: 0.1929\n",
            "Epoch 2/65\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2880 - acc: 0.5796\n",
            "Epoch 2: val_acc did not improve from 0.19286\n",
            "4/4 [==============================] - 39s 10s/step - loss: 1.2880 - acc: 0.5796 - val_loss: 6.9069 - val_acc: 0.1929\n",
            "Epoch 3/65\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9885 - acc: 0.6755\n",
            "Epoch 3: val_acc did not improve from 0.19286\n",
            "4/4 [==============================] - 43s 10s/step - loss: 0.9885 - acc: 0.6755 - val_loss: 8.3299 - val_acc: 0.1429\n",
            "Epoch 4/65\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7723 - acc: 0.7449\n",
            "Epoch 4: val_acc did not improve from 0.19286\n",
            "4/4 [==============================] - 38s 11s/step - loss: 0.7723 - acc: 0.7449 - val_loss: 8.8509 - val_acc: 0.1571\n",
            "Epoch 5/65\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6863 - acc: 0.7551\n",
            "Epoch 5: val_acc did not improve from 0.19286\n",
            "4/4 [==============================] - 44s 10s/step - loss: 0.6863 - acc: 0.7551 - val_loss: 7.2988 - val_acc: 0.1857\n",
            "Epoch 6/65\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4834 - acc: 0.8327\n",
            "Epoch 6: val_acc did not improve from 0.19286\n",
            "4/4 [==============================] - 38s 11s/step - loss: 0.4834 - acc: 0.8327 - val_loss: 7.1773 - val_acc: 0.1643\n",
            "\n",
            "\n",
            "Model Accuracy 0.14285714285714285\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_57148\\3902733085.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.00      0.00      0.00        10\n",
            "       10000       0.00      0.00      0.00        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.00      0.00      0.00        10\n",
            "       20000       0.14      1.00      0.25        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       0.00      0.00      0.00        10\n",
            "\n",
            "    accuracy                           0.14        70\n",
            "   macro avg       0.02      0.14      0.04        70\n",
            "weighted avg       0.02      0.14      0.04        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 166 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 64\n",
            "learning rate: 0.02963298827365965\n",
            "batch size: 128\n",
            "dropout rate: 0.6393601825452988\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.7408 - acc: 0.2796\n",
            "Epoch 1: val_acc improved from -inf to 0.14286, saving model to percobaan166_noImgPro/model\\vgg_16_166-saved-model-01-acc-0.14.hdf5\n",
            "4/4 [==============================] - 40s 11s/step - loss: 2.7408 - acc: 0.2796 - val_loss: 7.2967 - val_acc: 0.1429\n",
            "Epoch 2/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.5471 - acc: 0.5041\n",
            "Epoch 2: val_acc did not improve from 0.14286\n",
            "4/4 [==============================] - 38s 11s/step - loss: 1.5471 - acc: 0.5041 - val_loss: 10.7931 - val_acc: 0.1429\n",
            "Epoch 3/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2832 - acc: 0.5510\n",
            "Epoch 3: val_acc improved from 0.14286 to 0.18571, saving model to percobaan166_noImgPro/model\\vgg_16_166-saved-model-03-acc-0.19.hdf5\n",
            "4/4 [==============================] - 45s 11s/step - loss: 1.2832 - acc: 0.5510 - val_loss: 7.8604 - val_acc: 0.1857\n",
            "Epoch 4/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0463 - acc: 0.6286\n",
            "Epoch 4: val_acc did not improve from 0.18571\n",
            "4/4 [==============================] - 41s 11s/step - loss: 1.0463 - acc: 0.6286 - val_loss: 7.9719 - val_acc: 0.1429\n",
            "Epoch 5/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8193 - acc: 0.7245\n",
            "Epoch 5: val_acc did not improve from 0.18571\n",
            "4/4 [==============================] - 45s 11s/step - loss: 0.8193 - acc: 0.7245 - val_loss: 7.6686 - val_acc: 0.1429\n",
            "Epoch 6/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6984 - acc: 0.7531\n",
            "Epoch 6: val_acc did not improve from 0.18571\n",
            "4/4 [==============================] - 38s 10s/step - loss: 0.6984 - acc: 0.7531 - val_loss: 5.9878 - val_acc: 0.1571\n",
            "Epoch 7/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6570 - acc: 0.7755\n",
            "Epoch 7: val_acc did not improve from 0.18571\n",
            "4/4 [==============================] - 44s 10s/step - loss: 0.6570 - acc: 0.7755 - val_loss: 5.7027 - val_acc: 0.1571\n",
            "Epoch 8/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5879 - acc: 0.7857\n",
            "Epoch 8: val_acc did not improve from 0.18571\n",
            "4/4 [==============================] - 38s 11s/step - loss: 0.5879 - acc: 0.7857 - val_loss: 4.5671 - val_acc: 0.1786\n",
            "Epoch 9/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4877 - acc: 0.8265\n",
            "Epoch 9: val_acc improved from 0.18571 to 0.33571, saving model to percobaan166_noImgPro/model\\vgg_16_166-saved-model-09-acc-0.34.hdf5\n",
            "4/4 [==============================] - 44s 11s/step - loss: 0.4877 - acc: 0.8265 - val_loss: 3.4832 - val_acc: 0.3357\n",
            "Epoch 10/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4032 - acc: 0.8490\n",
            "Epoch 10: val_acc improved from 0.33571 to 0.41429, saving model to percobaan166_noImgPro/model\\vgg_16_166-saved-model-10-acc-0.41.hdf5\n",
            "4/4 [==============================] - 38s 11s/step - loss: 0.4032 - acc: 0.8490 - val_loss: 3.0249 - val_acc: 0.4143\n",
            "Epoch 11/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4588 - acc: 0.8367\n",
            "Epoch 11: val_acc did not improve from 0.41429\n",
            "4/4 [==============================] - 44s 11s/step - loss: 0.4588 - acc: 0.8367 - val_loss: 3.0084 - val_acc: 0.3429\n",
            "Epoch 12/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4232 - acc: 0.8633\n",
            "Epoch 12: val_acc did not improve from 0.41429\n",
            "4/4 [==============================] - 39s 11s/step - loss: 0.4232 - acc: 0.8633 - val_loss: 3.2049 - val_acc: 0.2857\n",
            "Epoch 13/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3864 - acc: 0.8714\n",
            "Epoch 13: val_acc did not improve from 0.41429\n",
            "4/4 [==============================] - 44s 11s/step - loss: 0.3864 - acc: 0.8714 - val_loss: 2.8677 - val_acc: 0.3214\n",
            "Epoch 14/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3687 - acc: 0.8592\n",
            "Epoch 14: val_acc did not improve from 0.41429\n",
            "4/4 [==============================] - 38s 10s/step - loss: 0.3687 - acc: 0.8592 - val_loss: 2.2877 - val_acc: 0.3500\n",
            "Epoch 15/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3655 - acc: 0.8878\n",
            "Epoch 15: val_acc did not improve from 0.41429\n",
            "4/4 [==============================] - 44s 13s/step - loss: 0.3655 - acc: 0.8878 - val_loss: 1.9427 - val_acc: 0.3571\n",
            "Epoch 16/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2716 - acc: 0.9041\n",
            "Epoch 16: val_acc did not improve from 0.41429\n",
            "4/4 [==============================] - 39s 11s/step - loss: 0.2716 - acc: 0.9041 - val_loss: 1.9300 - val_acc: 0.3714\n",
            "Epoch 17/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2719 - acc: 0.8918\n",
            "Epoch 17: val_acc improved from 0.41429 to 0.43571, saving model to percobaan166_noImgPro/model\\vgg_16_166-saved-model-17-acc-0.44.hdf5\n",
            "4/4 [==============================] - 38s 11s/step - loss: 0.2719 - acc: 0.8918 - val_loss: 1.7516 - val_acc: 0.4357\n",
            "Epoch 18/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2932 - acc: 0.9082\n",
            "Epoch 18: val_acc improved from 0.43571 to 0.49286, saving model to percobaan166_noImgPro/model\\vgg_16_166-saved-model-18-acc-0.49.hdf5\n",
            "4/4 [==============================] - 44s 11s/step - loss: 0.2932 - acc: 0.9082 - val_loss: 1.6635 - val_acc: 0.4929\n",
            "Epoch 19/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2566 - acc: 0.8959\n",
            "Epoch 19: val_acc improved from 0.49286 to 0.57857, saving model to percobaan166_noImgPro/model\\vgg_16_166-saved-model-19-acc-0.58.hdf5\n",
            "4/4 [==============================] - 38s 11s/step - loss: 0.2566 - acc: 0.8959 - val_loss: 1.3977 - val_acc: 0.5786\n",
            "Epoch 20/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2682 - acc: 0.9082\n",
            "Epoch 20: val_acc improved from 0.57857 to 0.62143, saving model to percobaan166_noImgPro/model\\vgg_16_166-saved-model-20-acc-0.62.hdf5\n",
            "4/4 [==============================] - 44s 11s/step - loss: 0.2682 - acc: 0.9082 - val_loss: 1.2157 - val_acc: 0.6214\n",
            "Epoch 21/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2966 - acc: 0.9020\n",
            "Epoch 21: val_acc did not improve from 0.62143\n",
            "4/4 [==============================] - 39s 11s/step - loss: 0.2966 - acc: 0.9020 - val_loss: 1.4730 - val_acc: 0.6000\n",
            "Epoch 22/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2360 - acc: 0.9122\n",
            "Epoch 22: val_acc did not improve from 0.62143\n",
            "4/4 [==============================] - 39s 11s/step - loss: 0.2360 - acc: 0.9122 - val_loss: 1.5872 - val_acc: 0.5357\n",
            "Epoch 23/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2280 - acc: 0.9265\n",
            "Epoch 23: val_acc did not improve from 0.62143\n",
            "4/4 [==============================] - 44s 11s/step - loss: 0.2280 - acc: 0.9265 - val_loss: 1.5585 - val_acc: 0.5357\n",
            "Epoch 24/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2001 - acc: 0.9184\n",
            "Epoch 24: val_acc did not improve from 0.62143\n",
            "4/4 [==============================] - 44s 13s/step - loss: 0.2001 - acc: 0.9184 - val_loss: 1.2447 - val_acc: 0.5857\n",
            "Epoch 25/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2565 - acc: 0.9265\n",
            "Epoch 25: val_acc improved from 0.62143 to 0.66429, saving model to percobaan166_noImgPro/model\\vgg_16_166-saved-model-25-acc-0.66.hdf5\n",
            "4/4 [==============================] - 39s 11s/step - loss: 0.2565 - acc: 0.9265 - val_loss: 1.0191 - val_acc: 0.6643\n",
            "Epoch 26/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2120 - acc: 0.9245\n",
            "Epoch 26: val_acc improved from 0.66429 to 0.72857, saving model to percobaan166_noImgPro/model\\vgg_16_166-saved-model-26-acc-0.73.hdf5\n",
            "4/4 [==============================] - 44s 11s/step - loss: 0.2120 - acc: 0.9245 - val_loss: 0.8260 - val_acc: 0.7286\n",
            "Epoch 27/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1972 - acc: 0.9327\n",
            "Epoch 27: val_acc did not improve from 0.72857\n",
            "4/4 [==============================] - 38s 10s/step - loss: 0.1972 - acc: 0.9327 - val_loss: 0.8405 - val_acc: 0.7286\n",
            "Epoch 28/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1920 - acc: 0.9327\n",
            "Epoch 28: val_acc improved from 0.72857 to 0.73571, saving model to percobaan166_noImgPro/model\\vgg_16_166-saved-model-28-acc-0.74.hdf5\n",
            "4/4 [==============================] - 45s 11s/step - loss: 0.1920 - acc: 0.9327 - val_loss: 0.8018 - val_acc: 0.7357\n",
            "Epoch 29/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1910 - acc: 0.9327\n",
            "Epoch 29: val_acc did not improve from 0.73571\n",
            "4/4 [==============================] - 38s 11s/step - loss: 0.1910 - acc: 0.9327 - val_loss: 0.8231 - val_acc: 0.7357\n",
            "Epoch 30/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1643 - acc: 0.9347\n",
            "Epoch 30: val_acc did not improve from 0.73571\n",
            "4/4 [==============================] - 44s 11s/step - loss: 0.1643 - acc: 0.9347 - val_loss: 0.7740 - val_acc: 0.7357\n",
            "Epoch 31/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1917 - acc: 0.9388\n",
            "Epoch 31: val_acc improved from 0.73571 to 0.80000, saving model to percobaan166_noImgPro/model\\vgg_16_166-saved-model-31-acc-0.80.hdf5\n",
            "4/4 [==============================] - 39s 11s/step - loss: 0.1917 - acc: 0.9388 - val_loss: 0.5995 - val_acc: 0.8000\n",
            "Epoch 32/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1885 - acc: 0.9388\n",
            "Epoch 32: val_acc improved from 0.80000 to 0.82857, saving model to percobaan166_noImgPro/model\\vgg_16_166-saved-model-32-acc-0.83.hdf5\n",
            "4/4 [==============================] - 45s 11s/step - loss: 0.1885 - acc: 0.9388 - val_loss: 0.5769 - val_acc: 0.8286\n",
            "Epoch 33/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1947 - acc: 0.9327\n",
            "Epoch 33: val_acc did not improve from 0.82857\n",
            "4/4 [==============================] - 38s 11s/step - loss: 0.1947 - acc: 0.9327 - val_loss: 0.6562 - val_acc: 0.8143\n",
            "Epoch 34/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1842 - acc: 0.9245\n",
            "Epoch 34: val_acc did not improve from 0.82857\n",
            "4/4 [==============================] - 44s 11s/step - loss: 0.1842 - acc: 0.9245 - val_loss: 0.8025 - val_acc: 0.7500\n",
            "Epoch 35/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1706 - acc: 0.9449\n",
            "Epoch 35: val_acc did not improve from 0.82857\n",
            "4/4 [==============================] - 38s 11s/step - loss: 0.1706 - acc: 0.9449 - val_loss: 0.8216 - val_acc: 0.7857\n",
            "Epoch 36/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1777 - acc: 0.9367\n",
            "Epoch 36: val_acc did not improve from 0.82857\n",
            "4/4 [==============================] - 44s 11s/step - loss: 0.1777 - acc: 0.9367 - val_loss: 0.7326 - val_acc: 0.7857\n",
            "Epoch 37/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1482 - acc: 0.9469\n",
            "Epoch 37: val_acc did not improve from 0.82857\n",
            "4/4 [==============================] - 38s 11s/step - loss: 0.1482 - acc: 0.9469 - val_loss: 0.6198 - val_acc: 0.8071\n",
            "\n",
            "\n",
            "Model Accuracy 0.7714285714285715\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.70      0.82        10\n",
            "       10000       1.00      0.90      0.95        10\n",
            "      100000       1.00      0.60      0.75        10\n",
            "        2000       0.59      1.00      0.74        10\n",
            "       20000       1.00      0.40      0.57        10\n",
            "        5000       1.00      0.80      0.89        10\n",
            "       50000       0.53      1.00      0.69        10\n",
            "\n",
            "    accuracy                           0.77        70\n",
            "   macro avg       0.87      0.77      0.77        70\n",
            "weighted avg       0.87      0.77      0.77        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 167 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 58\n",
            "learning rate: 0.030268571799246496\n",
            "batch size: 128\n",
            "dropout rate: 0.6708258446606795\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_57148\\3902733085.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.7818 - acc: 0.2918\n",
            "Epoch 1: val_acc improved from -inf to 0.24286, saving model to percobaan167_noImgPro/model\\vgg_16_167-saved-model-01-acc-0.24.hdf5\n",
            "4/4 [==============================] - 40s 11s/step - loss: 2.7818 - acc: 0.2918 - val_loss: 4.7731 - val_acc: 0.2429\n",
            "Epoch 2/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.6736 - acc: 0.4347\n",
            "Epoch 2: val_acc did not improve from 0.24286\n",
            "4/4 [==============================] - 44s 12s/step - loss: 1.6736 - acc: 0.4347 - val_loss: 5.9443 - val_acc: 0.1857\n",
            "Epoch 3/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2988 - acc: 0.5306\n",
            "Epoch 3: val_acc did not improve from 0.24286\n",
            "4/4 [==============================] - 39s 11s/step - loss: 1.2988 - acc: 0.5306 - val_loss: 10.1627 - val_acc: 0.1429\n",
            "Epoch 4/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2065 - acc: 0.5612\n",
            "Epoch 4: val_acc did not improve from 0.24286\n",
            "4/4 [==============================] - 44s 11s/step - loss: 1.2065 - acc: 0.5612 - val_loss: 5.9083 - val_acc: 0.1714\n",
            "Epoch 5/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9226 - acc: 0.6510\n",
            "Epoch 5: val_acc improved from 0.24286 to 0.29286, saving model to percobaan167_noImgPro/model\\vgg_16_167-saved-model-05-acc-0.29.hdf5\n",
            "4/4 [==============================] - 38s 11s/step - loss: 0.9226 - acc: 0.6510 - val_loss: 4.4348 - val_acc: 0.2929\n",
            "Epoch 6/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8335 - acc: 0.6980\n",
            "Epoch 6: val_acc did not improve from 0.29286\n",
            "4/4 [==============================] - 44s 11s/step - loss: 0.8335 - acc: 0.6980 - val_loss: 4.4545 - val_acc: 0.2786\n",
            "Epoch 7/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7538 - acc: 0.7204\n",
            "Epoch 7: val_acc did not improve from 0.29286\n",
            "4/4 [==============================] - 39s 11s/step - loss: 0.7538 - acc: 0.7204 - val_loss: 4.8251 - val_acc: 0.2214\n",
            "Epoch 8/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7143 - acc: 0.7204\n",
            "Epoch 8: val_acc did not improve from 0.29286\n",
            "4/4 [==============================] - 44s 11s/step - loss: 0.7143 - acc: 0.7204 - val_loss: 5.3852 - val_acc: 0.1571\n",
            "Epoch 9/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6659 - acc: 0.7837\n",
            "Epoch 9: val_acc did not improve from 0.29286\n",
            "4/4 [==============================] - 39s 11s/step - loss: 0.6659 - acc: 0.7837 - val_loss: 4.8750 - val_acc: 0.1786\n",
            "Epoch 10/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5135 - acc: 0.8020\n",
            "Epoch 10: val_acc did not improve from 0.29286\n",
            "4/4 [==============================] - 44s 11s/step - loss: 0.5135 - acc: 0.8020 - val_loss: 3.6726 - val_acc: 0.2929\n",
            "Epoch 11/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4957 - acc: 0.8367\n",
            "Epoch 11: val_acc improved from 0.29286 to 0.38571, saving model to percobaan167_noImgPro/model\\vgg_16_167-saved-model-11-acc-0.39.hdf5\n",
            "4/4 [==============================] - 39s 11s/step - loss: 0.4957 - acc: 0.8367 - val_loss: 2.8850 - val_acc: 0.3857\n",
            "Epoch 12/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4596 - acc: 0.8286\n",
            "Epoch 12: val_acc improved from 0.38571 to 0.46429, saving model to percobaan167_noImgPro/model\\vgg_16_167-saved-model-12-acc-0.46.hdf5\n",
            "4/4 [==============================] - 45s 11s/step - loss: 0.4596 - acc: 0.8286 - val_loss: 2.5017 - val_acc: 0.4643\n",
            "Epoch 13/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3649 - acc: 0.8735\n",
            "Epoch 13: val_acc improved from 0.46429 to 0.50714, saving model to percobaan167_noImgPro/model\\vgg_16_167-saved-model-13-acc-0.51.hdf5\n",
            "4/4 [==============================] - 39s 11s/step - loss: 0.3649 - acc: 0.8735 - val_loss: 2.3436 - val_acc: 0.5071\n",
            "Epoch 14/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4572 - acc: 0.8449\n",
            "Epoch 14: val_acc improved from 0.50714 to 0.54286, saving model to percobaan167_noImgPro/model\\vgg_16_167-saved-model-14-acc-0.54.hdf5\n",
            "4/4 [==============================] - 45s 11s/step - loss: 0.4572 - acc: 0.8449 - val_loss: 2.1835 - val_acc: 0.5429\n",
            "Epoch 15/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4007 - acc: 0.8490\n",
            "Epoch 15: val_acc improved from 0.54286 to 0.56429, saving model to percobaan167_noImgPro/model\\vgg_16_167-saved-model-15-acc-0.56.hdf5\n",
            "4/4 [==============================] - 39s 11s/step - loss: 0.4007 - acc: 0.8490 - val_loss: 1.9314 - val_acc: 0.5643\n",
            "Epoch 16/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3413 - acc: 0.8816\n",
            "Epoch 16: val_acc did not improve from 0.56429\n",
            "4/4 [==============================] - 44s 11s/step - loss: 0.3413 - acc: 0.8816 - val_loss: 1.6766 - val_acc: 0.5500\n",
            "Epoch 17/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3160 - acc: 0.9143\n",
            "Epoch 17: val_acc improved from 0.56429 to 0.60000, saving model to percobaan167_noImgPro/model\\vgg_16_167-saved-model-17-acc-0.60.hdf5\n",
            "4/4 [==============================] - 39s 11s/step - loss: 0.3160 - acc: 0.9143 - val_loss: 1.4641 - val_acc: 0.6000\n",
            "Epoch 18/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3175 - acc: 0.8837\n",
            "Epoch 18: val_acc improved from 0.60000 to 0.60714, saving model to percobaan167_noImgPro/model\\vgg_16_167-saved-model-18-acc-0.61.hdf5\n",
            "4/4 [==============================] - 45s 11s/step - loss: 0.3175 - acc: 0.8837 - val_loss: 1.4940 - val_acc: 0.6071\n",
            "Epoch 19/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3440 - acc: 0.8857\n",
            "Epoch 19: val_acc did not improve from 0.60714\n",
            "4/4 [==============================] - 39s 11s/step - loss: 0.3440 - acc: 0.8857 - val_loss: 1.7050 - val_acc: 0.5286\n",
            "Epoch 20/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3031 - acc: 0.8918\n",
            "Epoch 20: val_acc did not improve from 0.60714\n",
            "4/4 [==============================] - 44s 13s/step - loss: 0.3031 - acc: 0.8918 - val_loss: 1.7366 - val_acc: 0.5214\n",
            "Epoch 21/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2543 - acc: 0.9102\n",
            "Epoch 21: val_acc did not improve from 0.60714\n",
            "4/4 [==============================] - 39s 11s/step - loss: 0.2543 - acc: 0.9102 - val_loss: 1.7137 - val_acc: 0.5214\n",
            "Epoch 22/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2897 - acc: 0.9082\n",
            "Epoch 22: val_acc did not improve from 0.60714\n",
            "4/4 [==============================] - 45s 11s/step - loss: 0.2897 - acc: 0.9082 - val_loss: 1.6899 - val_acc: 0.4571\n",
            "\n",
            "\n",
            "Model Accuracy 0.2857142857142857\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_57148\\3902733085.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.67      0.20      0.31        10\n",
            "       10000       0.64      0.70      0.67        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.00      0.00      0.00        10\n",
            "       20000       0.00      0.00      0.00        10\n",
            "        5000       0.50      0.10      0.17        10\n",
            "       50000       0.19      1.00      0.31        10\n",
            "\n",
            "    accuracy                           0.29        70\n",
            "   macro avg       0.28      0.29      0.21        70\n",
            "weighted avg       0.28      0.29      0.21        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 168 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 64\n",
            "learning rate: 0.049939702056216326\n",
            "batch size: 128\n",
            "dropout rate: 0.7684764099507231\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 3.4780 - acc: 0.1939\n",
            "Epoch 1: val_acc improved from -inf to 0.18571, saving model to percobaan168_noImgPro/model\\vgg_16_168-saved-model-01-acc-0.19.hdf5\n",
            "4/4 [==============================] - 43s 12s/step - loss: 3.4780 - acc: 0.1939 - val_loss: 11.8229 - val_acc: 0.1857\n",
            "Epoch 2/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.7520 - acc: 0.2592\n",
            "Epoch 2: val_acc did not improve from 0.18571\n",
            "4/4 [==============================] - 46s 11s/step - loss: 2.7520 - acc: 0.2592 - val_loss: 9.4884 - val_acc: 0.1500\n",
            "Epoch 3/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.1560 - acc: 0.3571\n",
            "Epoch 3: val_acc did not improve from 0.18571\n",
            "4/4 [==============================] - 43s 12s/step - loss: 2.1560 - acc: 0.3571 - val_loss: 10.3848 - val_acc: 0.1429\n",
            "Epoch 4/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.7072 - acc: 0.4082\n",
            "Epoch 4: val_acc did not improve from 0.18571\n",
            "4/4 [==============================] - 48s 12s/step - loss: 1.7072 - acc: 0.4082 - val_loss: 7.3856 - val_acc: 0.1857\n",
            "Epoch 5/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.5657 - acc: 0.4714\n",
            "Epoch 5: val_acc improved from 0.18571 to 0.20000, saving model to percobaan168_noImgPro/model\\vgg_16_168-saved-model-05-acc-0.20.hdf5\n",
            "4/4 [==============================] - 49s 11s/step - loss: 1.5657 - acc: 0.4714 - val_loss: 5.1309 - val_acc: 0.2000\n",
            "Epoch 6/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.3499 - acc: 0.5265\n",
            "Epoch 6: val_acc did not improve from 0.20000\n",
            "4/4 [==============================] - 40s 11s/step - loss: 1.3499 - acc: 0.5265 - val_loss: 4.3852 - val_acc: 0.1786\n",
            "Epoch 7/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2567 - acc: 0.5388\n",
            "Epoch 7: val_acc did not improve from 0.20000\n",
            "4/4 [==============================] - 46s 11s/step - loss: 1.2567 - acc: 0.5388 - val_loss: 5.2071 - val_acc: 0.1429\n",
            "Epoch 8/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2170 - acc: 0.5327\n",
            "Epoch 8: val_acc did not improve from 0.20000\n",
            "4/4 [==============================] - 40s 11s/step - loss: 1.2170 - acc: 0.5327 - val_loss: 5.0951 - val_acc: 0.1500\n",
            "Epoch 9/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1288 - acc: 0.5796\n",
            "Epoch 9: val_acc did not improve from 0.20000\n",
            "4/4 [==============================] - 47s 11s/step - loss: 1.1288 - acc: 0.5796 - val_loss: 4.0879 - val_acc: 0.1714\n",
            "Epoch 10/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0339 - acc: 0.6388\n",
            "Epoch 10: val_acc did not improve from 0.20000\n",
            "4/4 [==============================] - 40s 11s/step - loss: 1.0339 - acc: 0.6388 - val_loss: 3.6920 - val_acc: 0.2000\n",
            "Epoch 11/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0309 - acc: 0.6061\n",
            "Epoch 11: val_acc improved from 0.20000 to 0.30000, saving model to percobaan168_noImgPro/model\\vgg_16_168-saved-model-11-acc-0.30.hdf5\n",
            "4/4 [==============================] - 47s 11s/step - loss: 1.0309 - acc: 0.6061 - val_loss: 3.4210 - val_acc: 0.3000\n",
            "Epoch 12/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8847 - acc: 0.6816\n",
            "Epoch 12: val_acc improved from 0.30000 to 0.32143, saving model to percobaan168_noImgPro/model\\vgg_16_168-saved-model-12-acc-0.32.hdf5\n",
            "4/4 [==============================] - 40s 11s/step - loss: 0.8847 - acc: 0.6816 - val_loss: 2.6288 - val_acc: 0.3214\n",
            "Epoch 13/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8975 - acc: 0.6816\n",
            "Epoch 13: val_acc improved from 0.32143 to 0.41429, saving model to percobaan168_noImgPro/model\\vgg_16_168-saved-model-13-acc-0.41.hdf5\n",
            "4/4 [==============================] - 47s 12s/step - loss: 0.8975 - acc: 0.6816 - val_loss: 2.1791 - val_acc: 0.4143\n",
            "Epoch 14/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8288 - acc: 0.6939\n",
            "Epoch 14: val_acc improved from 0.41429 to 0.44286, saving model to percobaan168_noImgPro/model\\vgg_16_168-saved-model-14-acc-0.44.hdf5\n",
            "4/4 [==============================] - 41s 11s/step - loss: 0.8288 - acc: 0.6939 - val_loss: 2.0489 - val_acc: 0.4429\n",
            "Epoch 15/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7645 - acc: 0.7327\n",
            "Epoch 15: val_acc did not improve from 0.44286\n",
            "4/4 [==============================] - 47s 11s/step - loss: 0.7645 - acc: 0.7327 - val_loss: 2.0033 - val_acc: 0.4429\n",
            "Epoch 16/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7140 - acc: 0.7408\n",
            "Epoch 16: val_acc improved from 0.44286 to 0.46429, saving model to percobaan168_noImgPro/model\\vgg_16_168-saved-model-16-acc-0.46.hdf5\n",
            "4/4 [==============================] - 41s 11s/step - loss: 0.7140 - acc: 0.7408 - val_loss: 1.8607 - val_acc: 0.4643\n",
            "Epoch 17/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7145 - acc: 0.7327\n",
            "Epoch 17: val_acc did not improve from 0.46429\n",
            "4/4 [==============================] - 46s 12s/step - loss: 0.7145 - acc: 0.7327 - val_loss: 1.9933 - val_acc: 0.4643\n",
            "Epoch 18/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6764 - acc: 0.7571\n",
            "Epoch 18: val_acc did not improve from 0.46429\n",
            "4/4 [==============================] - 40s 11s/step - loss: 0.6764 - acc: 0.7571 - val_loss: 2.2519 - val_acc: 0.3857\n",
            "Epoch 19/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7376 - acc: 0.7429\n",
            "Epoch 19: val_acc did not improve from 0.46429\n",
            "4/4 [==============================] - 47s 12s/step - loss: 0.7376 - acc: 0.7429 - val_loss: 2.2125 - val_acc: 0.3857\n",
            "Epoch 20/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6412 - acc: 0.7510\n",
            "Epoch 20: val_acc improved from 0.46429 to 0.47857, saving model to percobaan168_noImgPro/model\\vgg_16_168-saved-model-20-acc-0.48.hdf5\n",
            "4/4 [==============================] - 42s 11s/step - loss: 0.6412 - acc: 0.7510 - val_loss: 1.7259 - val_acc: 0.4786\n",
            "Epoch 21/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5777 - acc: 0.7980\n",
            "Epoch 21: val_acc improved from 0.47857 to 0.65714, saving model to percobaan168_noImgPro/model\\vgg_16_168-saved-model-21-acc-0.66.hdf5\n",
            "4/4 [==============================] - 47s 12s/step - loss: 0.5777 - acc: 0.7980 - val_loss: 1.4830 - val_acc: 0.6571\n",
            "Epoch 22/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6681 - acc: 0.7673\n",
            "Epoch 22: val_acc did not improve from 0.65714\n",
            "4/4 [==============================] - 40s 11s/step - loss: 0.6681 - acc: 0.7673 - val_loss: 1.5356 - val_acc: 0.6143\n",
            "Epoch 23/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5650 - acc: 0.7776\n",
            "Epoch 23: val_acc did not improve from 0.65714\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.5650 - acc: 0.7776 - val_loss: 2.0585 - val_acc: 0.4429\n",
            "Epoch 24/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5341 - acc: 0.8082\n",
            "Epoch 24: val_acc did not improve from 0.65714\n",
            "4/4 [==============================] - 40s 11s/step - loss: 0.5341 - acc: 0.8082 - val_loss: 2.0482 - val_acc: 0.4571\n",
            "Epoch 25/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5745 - acc: 0.7959\n",
            "Epoch 25: val_acc did not improve from 0.65714\n",
            "4/4 [==============================] - 46s 11s/step - loss: 0.5745 - acc: 0.7959 - val_loss: 1.8255 - val_acc: 0.4429\n",
            "Epoch 26/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5564 - acc: 0.7980\n",
            "Epoch 26: val_acc did not improve from 0.65714\n",
            "4/4 [==============================] - 40s 11s/step - loss: 0.5564 - acc: 0.7980 - val_loss: 2.1978 - val_acc: 0.3500\n",
            "\n",
            "\n",
            "Model Accuracy 0.2571428571428571\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_57148\\3902733085.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.10      0.18        10\n",
            "       10000       1.00      0.40      0.57        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.00      0.00      0.00        10\n",
            "       20000       0.75      0.30      0.43        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       0.17      1.00      0.29        10\n",
            "\n",
            "    accuracy                           0.26        70\n",
            "   macro avg       0.42      0.26      0.21        70\n",
            "weighted avg       0.42      0.26      0.21        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 169 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 63\n",
            "learning rate: 0.06551402354795599\n",
            "batch size: 32\n",
            "dropout rate: 0.5108836130015687\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.8554 - acc: 0.3245\n",
            "Epoch 1: val_acc improved from -inf to 0.14286, saving model to percobaan169_noImgPro/model\\vgg_16_169-saved-model-01-acc-0.14.hdf5\n",
            "16/16 [==============================] - 43s 3s/step - loss: 2.8554 - acc: 0.3245 - val_loss: 14.2962 - val_acc: 0.1429\n",
            "Epoch 2/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.9155 - acc: 0.4551\n",
            "Epoch 2: val_acc improved from 0.14286 to 0.25714, saving model to percobaan169_noImgPro/model\\vgg_16_169-saved-model-02-acc-0.26.hdf5\n",
            "16/16 [==============================] - 40s 3s/step - loss: 1.9155 - acc: 0.4551 - val_loss: 3.6688 - val_acc: 0.2571\n",
            "Epoch 3/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3042 - acc: 0.5612\n",
            "Epoch 3: val_acc improved from 0.25714 to 0.37143, saving model to percobaan169_noImgPro/model\\vgg_16_169-saved-model-03-acc-0.37.hdf5\n",
            "16/16 [==============================] - 47s 3s/step - loss: 1.3042 - acc: 0.5612 - val_loss: 2.2799 - val_acc: 0.3714\n",
            "Epoch 4/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9999 - acc: 0.6612\n",
            "Epoch 4: val_acc improved from 0.37143 to 0.42857, saving model to percobaan169_noImgPro/model\\vgg_16_169-saved-model-04-acc-0.43.hdf5\n",
            "16/16 [==============================] - 40s 3s/step - loss: 0.9999 - acc: 0.6612 - val_loss: 2.3320 - val_acc: 0.4286\n",
            "Epoch 5/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0531 - acc: 0.6510\n",
            "Epoch 5: val_acc did not improve from 0.42857\n",
            "16/16 [==============================] - 46s 3s/step - loss: 1.0531 - acc: 0.6510 - val_loss: 2.0130 - val_acc: 0.3714\n",
            "Epoch 6/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8724 - acc: 0.6980\n",
            "Epoch 6: val_acc did not improve from 0.42857\n",
            "16/16 [==============================] - 42s 3s/step - loss: 0.8724 - acc: 0.6980 - val_loss: 2.5632 - val_acc: 0.3357\n",
            "Epoch 7/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7859 - acc: 0.7408\n",
            "Epoch 7: val_acc improved from 0.42857 to 0.43571, saving model to percobaan169_noImgPro/model\\vgg_16_169-saved-model-07-acc-0.44.hdf5\n",
            "16/16 [==============================] - 43s 3s/step - loss: 0.7859 - acc: 0.7408 - val_loss: 1.9390 - val_acc: 0.4357\n",
            "Epoch 8/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8434 - acc: 0.7327\n",
            "Epoch 8: val_acc improved from 0.43571 to 0.55000, saving model to percobaan169_noImgPro/model\\vgg_16_169-saved-model-08-acc-0.55.hdf5\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.8434 - acc: 0.7327 - val_loss: 1.7127 - val_acc: 0.5500\n",
            "Epoch 9/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9109 - acc: 0.7163\n",
            "Epoch 9: val_acc did not improve from 0.55000\n",
            "16/16 [==============================] - 40s 3s/step - loss: 0.9109 - acc: 0.7163 - val_loss: 1.8546 - val_acc: 0.4500\n",
            "Epoch 10/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8169 - acc: 0.7306\n",
            "Epoch 10: val_acc improved from 0.55000 to 0.60714, saving model to percobaan169_noImgPro/model\\vgg_16_169-saved-model-10-acc-0.61.hdf5\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.8169 - acc: 0.7306 - val_loss: 1.5821 - val_acc: 0.6071\n",
            "Epoch 11/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8591 - acc: 0.7143\n",
            "Epoch 11: val_acc did not improve from 0.60714\n",
            "16/16 [==============================] - 41s 3s/step - loss: 0.8591 - acc: 0.7143 - val_loss: 2.2251 - val_acc: 0.4714\n",
            "Epoch 12/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6820 - acc: 0.7714\n",
            "Epoch 12: val_acc did not improve from 0.60714\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.6820 - acc: 0.7714 - val_loss: 2.0685 - val_acc: 0.5286\n",
            "Epoch 13/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7824 - acc: 0.7531\n",
            "Epoch 13: val_acc did not improve from 0.60714\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.7824 - acc: 0.7531 - val_loss: 1.8573 - val_acc: 0.5357\n",
            "Epoch 14/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7747 - acc: 0.7653\n",
            "Epoch 14: val_acc did not improve from 0.60714\n",
            "16/16 [==============================] - 40s 3s/step - loss: 0.7747 - acc: 0.7653 - val_loss: 1.6136 - val_acc: 0.5429\n",
            "Epoch 15/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7130 - acc: 0.7714\n",
            "Epoch 15: val_acc did not improve from 0.60714\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.7130 - acc: 0.7714 - val_loss: 1.5762 - val_acc: 0.6071\n",
            "Epoch 16/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6019 - acc: 0.7980\n",
            "Epoch 16: val_acc improved from 0.60714 to 0.66429, saving model to percobaan169_noImgPro/model\\vgg_16_169-saved-model-16-acc-0.66.hdf5\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.6019 - acc: 0.7980 - val_loss: 1.4821 - val_acc: 0.6643\n",
            "Epoch 17/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8522 - acc: 0.7653\n",
            "Epoch 17: val_acc did not improve from 0.66429\n",
            "16/16 [==============================] - 40s 3s/step - loss: 0.8522 - acc: 0.7653 - val_loss: 1.6862 - val_acc: 0.6286\n",
            "Epoch 18/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6492 - acc: 0.7633\n",
            "Epoch 18: val_acc improved from 0.66429 to 0.70714, saving model to percobaan169_noImgPro/model\\vgg_16_169-saved-model-18-acc-0.71.hdf5\n",
            "16/16 [==============================] - 48s 3s/step - loss: 0.6492 - acc: 0.7633 - val_loss: 1.3521 - val_acc: 0.7071\n",
            "Epoch 19/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6412 - acc: 0.7959\n",
            "Epoch 19: val_acc did not improve from 0.70714\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.6412 - acc: 0.7959 - val_loss: 1.6631 - val_acc: 0.6714\n",
            "Epoch 20/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6994 - acc: 0.8102\n",
            "Epoch 20: val_acc improved from 0.70714 to 0.78571, saving model to percobaan169_noImgPro/model\\vgg_16_169-saved-model-20-acc-0.79.hdf5\n",
            "16/16 [==============================] - 40s 3s/step - loss: 0.6994 - acc: 0.8102 - val_loss: 0.9754 - val_acc: 0.7857\n",
            "Epoch 21/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6106 - acc: 0.8265\n",
            "Epoch 21: val_acc did not improve from 0.78571\n",
            "16/16 [==============================] - 45s 3s/step - loss: 0.6106 - acc: 0.8265 - val_loss: 2.0097 - val_acc: 0.6143\n",
            "Epoch 22/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7474 - acc: 0.7857\n",
            "Epoch 22: val_acc did not improve from 0.78571\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.7474 - acc: 0.7857 - val_loss: 1.5649 - val_acc: 0.6643\n",
            "Epoch 23/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7017 - acc: 0.7776\n",
            "Epoch 23: val_acc did not improve from 0.78571\n",
            "16/16 [==============================] - 40s 3s/step - loss: 0.7017 - acc: 0.7776 - val_loss: 2.1223 - val_acc: 0.6500\n",
            "Epoch 24/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6905 - acc: 0.8061\n",
            "Epoch 24: val_acc did not improve from 0.78571\n",
            "16/16 [==============================] - 48s 3s/step - loss: 0.6905 - acc: 0.8061 - val_loss: 1.5786 - val_acc: 0.7143\n",
            "Epoch 25/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5914 - acc: 0.8286\n",
            "Epoch 25: val_acc did not improve from 0.78571\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.5914 - acc: 0.8286 - val_loss: 1.5064 - val_acc: 0.7857\n",
            "\n",
            "\n",
            "Model Accuracy 0.7285714285714285\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.62      1.00      0.77        10\n",
            "       10000       0.77      1.00      0.87        10\n",
            "      100000       1.00      0.70      0.82        10\n",
            "        2000       1.00      0.30      0.46        10\n",
            "       20000       0.83      0.50      0.62        10\n",
            "        5000       0.57      0.80      0.67        10\n",
            "       50000       0.73      0.80      0.76        10\n",
            "\n",
            "    accuracy                           0.73        70\n",
            "   macro avg       0.79      0.73      0.71        70\n",
            "weighted avg       0.79      0.73      0.71        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 170 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 63\n",
            "learning rate: 0.05942649675134498\n",
            "batch size: 32\n",
            "dropout rate: 0.591078396457584\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_57148\\3902733085.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 3.2478 - acc: 0.2449\n",
            "Epoch 1: val_acc improved from -inf to 0.16429, saving model to percobaan170_noImgPro/model\\vgg_16_170-saved-model-01-acc-0.16.hdf5\n",
            "16/16 [==============================] - 41s 3s/step - loss: 3.2478 - acc: 0.2449 - val_loss: 9.5206 - val_acc: 0.1643\n",
            "Epoch 2/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.2404 - acc: 0.3633\n",
            "Epoch 2: val_acc improved from 0.16429 to 0.33571, saving model to percobaan170_noImgPro/model\\vgg_16_170-saved-model-02-acc-0.34.hdf5\n",
            "16/16 [==============================] - 45s 3s/step - loss: 2.2404 - acc: 0.3633 - val_loss: 2.0098 - val_acc: 0.3357\n",
            "Epoch 3/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.5933 - acc: 0.4571\n",
            "Epoch 3: val_acc improved from 0.33571 to 0.57143, saving model to percobaan170_noImgPro/model\\vgg_16_170-saved-model-03-acc-0.57.hdf5\n",
            "16/16 [==============================] - 39s 3s/step - loss: 1.5933 - acc: 0.4571 - val_loss: 1.2528 - val_acc: 0.5714\n",
            "Epoch 4/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2377 - acc: 0.5592\n",
            "Epoch 4: val_acc did not improve from 0.57143\n",
            "16/16 [==============================] - 45s 3s/step - loss: 1.2377 - acc: 0.5592 - val_loss: 1.3695 - val_acc: 0.4500\n",
            "Epoch 5/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0839 - acc: 0.6245\n",
            "Epoch 5: val_acc did not improve from 0.57143\n",
            "16/16 [==============================] - 46s 3s/step - loss: 1.0839 - acc: 0.6245 - val_loss: 1.8986 - val_acc: 0.3500\n",
            "Epoch 6/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0107 - acc: 0.6469\n",
            "Epoch 6: val_acc did not improve from 0.57143\n",
            "16/16 [==============================] - 39s 2s/step - loss: 1.0107 - acc: 0.6469 - val_loss: 1.3361 - val_acc: 0.5143\n",
            "Epoch 7/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9259 - acc: 0.6755\n",
            "Epoch 7: val_acc improved from 0.57143 to 0.59286, saving model to percobaan170_noImgPro/model\\vgg_16_170-saved-model-07-acc-0.59.hdf5\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.9259 - acc: 0.6755 - val_loss: 1.2058 - val_acc: 0.5929\n",
            "Epoch 8/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8617 - acc: 0.6918\n",
            "Epoch 8: val_acc improved from 0.59286 to 0.64286, saving model to percobaan170_noImgPro/model\\vgg_16_170-saved-model-08-acc-0.64.hdf5\n",
            "16/16 [==============================] - 39s 3s/step - loss: 0.8617 - acc: 0.6918 - val_loss: 0.9827 - val_acc: 0.6429\n",
            "Epoch 9/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8272 - acc: 0.7020\n",
            "Epoch 9: val_acc did not improve from 0.64286\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.8272 - acc: 0.7020 - val_loss: 1.8625 - val_acc: 0.4357\n",
            "Epoch 10/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8587 - acc: 0.7143\n",
            "Epoch 10: val_acc did not improve from 0.64286\n",
            "16/16 [==============================] - 45s 3s/step - loss: 0.8587 - acc: 0.7143 - val_loss: 1.7452 - val_acc: 0.4643\n",
            "Epoch 11/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9736 - acc: 0.6776\n",
            "Epoch 11: val_acc improved from 0.64286 to 0.67143, saving model to percobaan170_noImgPro/model\\vgg_16_170-saved-model-11-acc-0.67.hdf5\n",
            "16/16 [==============================] - 40s 3s/step - loss: 0.9736 - acc: 0.6776 - val_loss: 1.1394 - val_acc: 0.6714\n",
            "Epoch 12/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8471 - acc: 0.7265\n",
            "Epoch 12: val_acc did not improve from 0.67143\n",
            "16/16 [==============================] - 45s 3s/step - loss: 0.8471 - acc: 0.7265 - val_loss: 1.4624 - val_acc: 0.6143\n",
            "Epoch 13/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9149 - acc: 0.6918\n",
            "Epoch 13: val_acc improved from 0.67143 to 0.72857, saving model to percobaan170_noImgPro/model\\vgg_16_170-saved-model-13-acc-0.73.hdf5\n",
            "16/16 [==============================] - 40s 3s/step - loss: 0.9149 - acc: 0.6918 - val_loss: 0.7524 - val_acc: 0.7286\n",
            "Epoch 14/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9840 - acc: 0.6898\n",
            "Epoch 14: val_acc did not improve from 0.72857\n",
            "16/16 [==============================] - 45s 3s/step - loss: 0.9840 - acc: 0.6898 - val_loss: 1.3810 - val_acc: 0.6000\n",
            "Epoch 15/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9467 - acc: 0.7041\n",
            "Epoch 15: val_acc improved from 0.72857 to 0.74286, saving model to percobaan170_noImgPro/model\\vgg_16_170-saved-model-15-acc-0.74.hdf5\n",
            "16/16 [==============================] - 45s 3s/step - loss: 0.9467 - acc: 0.7041 - val_loss: 1.1194 - val_acc: 0.7429\n",
            "Epoch 16/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7539 - acc: 0.7490\n",
            "Epoch 16: val_acc did not improve from 0.74286\n",
            "16/16 [==============================] - 39s 3s/step - loss: 0.7539 - acc: 0.7490 - val_loss: 1.0396 - val_acc: 0.7357\n",
            "Epoch 17/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8695 - acc: 0.7224\n",
            "Epoch 17: val_acc did not improve from 0.74286\n",
            "16/16 [==============================] - 45s 3s/step - loss: 0.8695 - acc: 0.7224 - val_loss: 1.1561 - val_acc: 0.6929\n",
            "Epoch 18/63\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7293 - acc: 0.7653\n",
            "Epoch 18: val_acc did not improve from 0.74286\n",
            "16/16 [==============================] - 45s 3s/step - loss: 0.7293 - acc: 0.7653 - val_loss: 1.4580 - val_acc: 0.6857\n",
            "\n",
            "\n",
            "Model Accuracy 0.6571428571428571\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_57148\\3902733085.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.77      1.00      0.87        10\n",
            "       10000       1.00      0.50      0.67        10\n",
            "      100000       0.88      0.70      0.78        10\n",
            "        2000       0.80      0.80      0.80        10\n",
            "       20000       0.00      0.00      0.00        10\n",
            "        5000       0.38      1.00      0.56        10\n",
            "       50000       0.75      0.60      0.67        10\n",
            "\n",
            "    accuracy                           0.66        70\n",
            "   macro avg       0.65      0.66      0.62        70\n",
            "weighted avg       0.65      0.66      0.62        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 171 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 57\n",
            "learning rate: 0.0643415463943495\n",
            "batch size: 32\n",
            "dropout rate: 0.6972232656911934\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 3.9176 - acc: 0.2286\n",
            "Epoch 1: val_acc improved from -inf to 0.21429, saving model to percobaan171_noImgPro/model\\vgg_16_171-saved-model-01-acc-0.21.hdf5\n",
            "16/16 [==============================] - 41s 3s/step - loss: 3.9176 - acc: 0.2286 - val_loss: 10.1638 - val_acc: 0.2143\n",
            "Epoch 2/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.5368 - acc: 0.3286\n",
            "Epoch 2: val_acc improved from 0.21429 to 0.30000, saving model to percobaan171_noImgPro/model\\vgg_16_171-saved-model-02-acc-0.30.hdf5\n",
            "16/16 [==============================] - 39s 2s/step - loss: 2.5368 - acc: 0.3286 - val_loss: 2.4498 - val_acc: 0.3000\n",
            "Epoch 3/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.7059 - acc: 0.4020\n",
            "Epoch 3: val_acc did not improve from 0.30000\n",
            "16/16 [==============================] - 45s 3s/step - loss: 1.7059 - acc: 0.4020 - val_loss: 4.0815 - val_acc: 0.1643\n",
            "Epoch 4/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.6152 - acc: 0.4531\n",
            "Epoch 4: val_acc did not improve from 0.30000\n",
            "16/16 [==============================] - 39s 2s/step - loss: 1.6152 - acc: 0.4531 - val_loss: 2.3664 - val_acc: 0.2429\n",
            "Epoch 5/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3212 - acc: 0.5429\n",
            "Epoch 5: val_acc did not improve from 0.30000\n",
            "16/16 [==============================] - 45s 3s/step - loss: 1.3212 - acc: 0.5429 - val_loss: 4.4760 - val_acc: 0.1714\n",
            "Epoch 6/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3154 - acc: 0.5408\n",
            "Epoch 6: val_acc did not improve from 0.30000\n",
            "16/16 [==============================] - 39s 2s/step - loss: 1.3154 - acc: 0.5408 - val_loss: 4.0081 - val_acc: 0.1929\n",
            "Epoch 7/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2137 - acc: 0.5551\n",
            "Epoch 7: val_acc improved from 0.30000 to 0.31429, saving model to percobaan171_noImgPro/model\\vgg_16_171-saved-model-07-acc-0.31.hdf5\n",
            "16/16 [==============================] - 45s 3s/step - loss: 1.2137 - acc: 0.5551 - val_loss: 1.8227 - val_acc: 0.3143\n",
            "Epoch 8/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0010 - acc: 0.6694\n",
            "Epoch 8: val_acc did not improve from 0.31429\n",
            "16/16 [==============================] - 44s 3s/step - loss: 1.0010 - acc: 0.6694 - val_loss: 2.4146 - val_acc: 0.2571\n",
            "Epoch 9/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0549 - acc: 0.6429\n",
            "Epoch 9: val_acc improved from 0.31429 to 0.43571, saving model to percobaan171_noImgPro/model\\vgg_16_171-saved-model-09-acc-0.44.hdf5\n",
            "16/16 [==============================] - 40s 3s/step - loss: 1.0549 - acc: 0.6429 - val_loss: 1.5549 - val_acc: 0.4357\n",
            "Epoch 10/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0265 - acc: 0.6592\n",
            "Epoch 10: val_acc improved from 0.43571 to 0.45000, saving model to percobaan171_noImgPro/model\\vgg_16_171-saved-model-10-acc-0.45.hdf5\n",
            "16/16 [==============================] - 44s 3s/step - loss: 1.0265 - acc: 0.6592 - val_loss: 1.6036 - val_acc: 0.4500\n",
            "Epoch 11/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0795 - acc: 0.6531\n",
            "Epoch 11: val_acc did not improve from 0.45000\n",
            "16/16 [==============================] - 40s 2s/step - loss: 1.0795 - acc: 0.6531 - val_loss: 1.6618 - val_acc: 0.4143\n",
            "Epoch 12/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1257 - acc: 0.6653\n",
            "Epoch 12: val_acc improved from 0.45000 to 0.55000, saving model to percobaan171_noImgPro/model\\vgg_16_171-saved-model-12-acc-0.55.hdf5\n",
            "16/16 [==============================] - 44s 3s/step - loss: 1.1257 - acc: 0.6653 - val_loss: 1.3653 - val_acc: 0.5500\n",
            "Epoch 13/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1152 - acc: 0.6469\n",
            "Epoch 13: val_acc improved from 0.55000 to 0.77143, saving model to percobaan171_noImgPro/model\\vgg_16_171-saved-model-13-acc-0.77.hdf5\n",
            "16/16 [==============================] - 39s 2s/step - loss: 1.1152 - acc: 0.6469 - val_loss: 0.7091 - val_acc: 0.7714\n",
            "Epoch 14/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0430 - acc: 0.6592\n",
            "Epoch 14: val_acc did not improve from 0.77143\n",
            "16/16 [==============================] - 44s 3s/step - loss: 1.0430 - acc: 0.6592 - val_loss: 1.6116 - val_acc: 0.5857\n",
            "Epoch 15/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0665 - acc: 0.6633\n",
            "Epoch 15: val_acc did not improve from 0.77143\n",
            "16/16 [==============================] - 44s 3s/step - loss: 1.0665 - acc: 0.6633 - val_loss: 1.9177 - val_acc: 0.5500\n",
            "Epoch 16/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0429 - acc: 0.6551\n",
            "Epoch 16: val_acc did not improve from 0.77143\n",
            "16/16 [==============================] - 39s 2s/step - loss: 1.0429 - acc: 0.6551 - val_loss: 1.6135 - val_acc: 0.5643\n",
            "Epoch 17/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8087 - acc: 0.7143\n",
            "Epoch 17: val_acc did not improve from 0.77143\n",
            "16/16 [==============================] - 44s 3s/step - loss: 0.8087 - acc: 0.7143 - val_loss: 1.1444 - val_acc: 0.7143\n",
            "Epoch 18/57\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0360 - acc: 0.7367\n",
            "Epoch 18: val_acc did not improve from 0.77143\n",
            "16/16 [==============================] - 39s 2s/step - loss: 1.0360 - acc: 0.7367 - val_loss: 1.3608 - val_acc: 0.6571\n",
            "\n",
            "\n",
            "Model Accuracy 0.5428571428571428\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.78      0.70      0.74        10\n",
            "       10000       0.80      0.40      0.53        10\n",
            "      100000       1.00      0.40      0.57        10\n",
            "        2000       0.60      0.30      0.40        10\n",
            "       20000       0.75      0.60      0.67        10\n",
            "        5000       0.29      1.00      0.44        10\n",
            "       50000       1.00      0.40      0.57        10\n",
            "\n",
            "    accuracy                           0.54        70\n",
            "   macro avg       0.74      0.54      0.56        70\n",
            "weighted avg       0.74      0.54      0.56        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 172 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 61\n",
            "learning rate: 0.05456418129045296\n",
            "batch size: 32\n",
            "dropout rate: 0.794188348194432\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_57148\\3902733085.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 4.1433 - acc: 0.2286\n",
            "Epoch 1: val_acc improved from -inf to 0.14286, saving model to percobaan172_noImgPro/model\\vgg_16_172-saved-model-01-acc-0.14.hdf5\n",
            "16/16 [==============================] - 46s 3s/step - loss: 4.1433 - acc: 0.2286 - val_loss: 6.6944 - val_acc: 0.1429\n",
            "Epoch 2/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 3.2669 - acc: 0.2898\n",
            "Epoch 2: val_acc improved from 0.14286 to 0.22143, saving model to percobaan172_noImgPro/model\\vgg_16_172-saved-model-02-acc-0.22.hdf5\n",
            "16/16 [==============================] - 39s 2s/step - loss: 3.2669 - acc: 0.2898 - val_loss: 6.5569 - val_acc: 0.2214\n",
            "Epoch 3/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.4490 - acc: 0.2959\n",
            "Epoch 3: val_acc improved from 0.22143 to 0.22857, saving model to percobaan172_noImgPro/model\\vgg_16_172-saved-model-03-acc-0.23.hdf5\n",
            "16/16 [==============================] - 45s 3s/step - loss: 2.4490 - acc: 0.2959 - val_loss: 2.5225 - val_acc: 0.2286\n",
            "Epoch 4/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.8738 - acc: 0.3347\n",
            "Epoch 4: val_acc did not improve from 0.22857\n",
            "16/16 [==============================] - 39s 3s/step - loss: 1.8738 - acc: 0.3347 - val_loss: 2.1166 - val_acc: 0.1929\n",
            "Epoch 5/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.6582 - acc: 0.3837\n",
            "Epoch 5: val_acc did not improve from 0.22857\n",
            "16/16 [==============================] - 44s 3s/step - loss: 1.6582 - acc: 0.3837 - val_loss: 1.6742 - val_acc: 0.2214\n",
            "Epoch 6/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.5233 - acc: 0.4061\n",
            "Epoch 6: val_acc improved from 0.22857 to 0.35000, saving model to percobaan172_noImgPro/model\\vgg_16_172-saved-model-06-acc-0.35.hdf5\n",
            "16/16 [==============================] - 45s 3s/step - loss: 1.5233 - acc: 0.4061 - val_loss: 1.4943 - val_acc: 0.3500\n",
            "Epoch 7/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.4919 - acc: 0.4551\n",
            "Epoch 7: val_acc did not improve from 0.35000\n",
            "16/16 [==============================] - 39s 2s/step - loss: 1.4919 - acc: 0.4551 - val_loss: 1.5885 - val_acc: 0.3000\n",
            "Epoch 8/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.4634 - acc: 0.4837\n",
            "Epoch 8: val_acc improved from 0.35000 to 0.52857, saving model to percobaan172_noImgPro/model\\vgg_16_172-saved-model-08-acc-0.53.hdf5\n",
            "16/16 [==============================] - 45s 3s/step - loss: 1.4634 - acc: 0.4837 - val_loss: 1.2623 - val_acc: 0.5286\n",
            "Epoch 9/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3912 - acc: 0.4837\n",
            "Epoch 9: val_acc improved from 0.52857 to 0.62143, saving model to percobaan172_noImgPro/model\\vgg_16_172-saved-model-09-acc-0.62.hdf5\n",
            "16/16 [==============================] - 44s 3s/step - loss: 1.3912 - acc: 0.4837 - val_loss: 1.0872 - val_acc: 0.6214\n",
            "Epoch 10/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3855 - acc: 0.5102\n",
            "Epoch 10: val_acc did not improve from 0.62143\n",
            "16/16 [==============================] - 39s 3s/step - loss: 1.3855 - acc: 0.5102 - val_loss: 1.0680 - val_acc: 0.5929\n",
            "Epoch 11/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3363 - acc: 0.5265\n",
            "Epoch 11: val_acc improved from 0.62143 to 0.66429, saving model to percobaan172_noImgPro/model\\vgg_16_172-saved-model-11-acc-0.66.hdf5\n",
            "16/16 [==============================] - 45s 3s/step - loss: 1.3363 - acc: 0.5265 - val_loss: 1.0095 - val_acc: 0.6643\n",
            "Epoch 12/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2552 - acc: 0.5449\n",
            "Epoch 12: val_acc improved from 0.66429 to 0.67143, saving model to percobaan172_noImgPro/model\\vgg_16_172-saved-model-12-acc-0.67.hdf5\n",
            "16/16 [==============================] - 39s 2s/step - loss: 1.2552 - acc: 0.5449 - val_loss: 0.9809 - val_acc: 0.6714\n",
            "Epoch 13/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3206 - acc: 0.5490\n",
            "Epoch 13: val_acc improved from 0.67143 to 0.68571, saving model to percobaan172_noImgPro/model\\vgg_16_172-saved-model-13-acc-0.69.hdf5\n",
            "16/16 [==============================] - 44s 3s/step - loss: 1.3206 - acc: 0.5490 - val_loss: 0.9559 - val_acc: 0.6857\n",
            "Epoch 14/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2184 - acc: 0.5510\n",
            "Epoch 14: val_acc did not improve from 0.68571\n",
            "16/16 [==============================] - 43s 3s/step - loss: 1.2184 - acc: 0.5510 - val_loss: 1.0306 - val_acc: 0.6857\n",
            "Epoch 15/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2300 - acc: 0.5735\n",
            "Epoch 15: val_acc improved from 0.68571 to 0.74286, saving model to percobaan172_noImgPro/model\\vgg_16_172-saved-model-15-acc-0.74.hdf5\n",
            "16/16 [==============================] - 40s 2s/step - loss: 1.2300 - acc: 0.5735 - val_loss: 0.8427 - val_acc: 0.7429\n",
            "Epoch 16/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1511 - acc: 0.6245\n",
            "Epoch 16: val_acc did not improve from 0.74286\n",
            "16/16 [==============================] - 45s 3s/step - loss: 1.1511 - acc: 0.6245 - val_loss: 0.8369 - val_acc: 0.7071\n",
            "Epoch 17/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2250 - acc: 0.5776\n",
            "Epoch 17: val_acc did not improve from 0.74286\n",
            "16/16 [==============================] - 39s 2s/step - loss: 1.2250 - acc: 0.5776 - val_loss: 0.8659 - val_acc: 0.7357\n",
            "Epoch 18/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1586 - acc: 0.6041\n",
            "Epoch 18: val_acc improved from 0.74286 to 0.77143, saving model to percobaan172_noImgPro/model\\vgg_16_172-saved-model-18-acc-0.77.hdf5\n",
            "16/16 [==============================] - 44s 3s/step - loss: 1.1586 - acc: 0.6041 - val_loss: 0.7518 - val_acc: 0.7714\n",
            "Epoch 19/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2113 - acc: 0.6163\n",
            "Epoch 19: val_acc improved from 0.77143 to 0.77857, saving model to percobaan172_noImgPro/model\\vgg_16_172-saved-model-19-acc-0.78.hdf5\n",
            "16/16 [==============================] - 39s 2s/step - loss: 1.2113 - acc: 0.6163 - val_loss: 0.6709 - val_acc: 0.7786\n",
            "Epoch 20/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1523 - acc: 0.6367\n",
            "Epoch 20: val_acc did not improve from 0.77857\n",
            "16/16 [==============================] - 44s 2s/step - loss: 1.1523 - acc: 0.6367 - val_loss: 0.9691 - val_acc: 0.7143\n",
            "Epoch 21/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0238 - acc: 0.6510\n",
            "Epoch 21: val_acc did not improve from 0.77857\n",
            "16/16 [==============================] - 44s 3s/step - loss: 1.0238 - acc: 0.6510 - val_loss: 0.6777 - val_acc: 0.7714\n",
            "Epoch 22/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1938 - acc: 0.6163\n",
            "Epoch 22: val_acc did not improve from 0.77857\n",
            "16/16 [==============================] - 39s 2s/step - loss: 1.1938 - acc: 0.6163 - val_loss: 0.9208 - val_acc: 0.7571\n",
            "Epoch 23/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1796 - acc: 0.6449\n",
            "Epoch 23: val_acc did not improve from 0.77857\n",
            "16/16 [==============================] - 44s 3s/step - loss: 1.1796 - acc: 0.6449 - val_loss: 1.1965 - val_acc: 0.7000\n",
            "Epoch 24/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1879 - acc: 0.6408\n",
            "Epoch 24: val_acc did not improve from 0.77857\n",
            "16/16 [==============================] - 39s 2s/step - loss: 1.1879 - acc: 0.6408 - val_loss: 0.9856 - val_acc: 0.7214\n",
            "\n",
            "\n",
            "Model Accuracy 0.6714285714285714\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.56      1.00      0.71        10\n",
            "       10000       0.86      0.60      0.71        10\n",
            "      100000       1.00      0.40      0.57        10\n",
            "        2000       0.80      0.80      0.80        10\n",
            "       20000       0.75      0.60      0.67        10\n",
            "        5000       0.47      0.90      0.62        10\n",
            "       50000       1.00      0.40      0.57        10\n",
            "\n",
            "    accuracy                           0.67        70\n",
            "   macro avg       0.78      0.67      0.66        70\n",
            "weighted avg       0.78      0.67      0.66        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 173 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 61\n",
            "learning rate: 0.05327411242859223\n",
            "batch size: 64\n",
            "dropout rate: 0.5561835407646608\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_57148\\3902733085.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/61\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.5627 - acc: 0.3265\n",
            "Epoch 1: val_acc improved from -inf to 0.14286, saving model to percobaan173_noImgPro/model\\vgg_16_173-saved-model-01-acc-0.14.hdf5\n",
            "8/8 [==============================] - 47s 5s/step - loss: 2.5627 - acc: 0.3265 - val_loss: 12.2817 - val_acc: 0.1429\n",
            "Epoch 2/61\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5901 - acc: 0.5082\n",
            "Epoch 2: val_acc improved from 0.14286 to 0.34286, saving model to percobaan173_noImgPro/model\\vgg_16_173-saved-model-02-acc-0.34.hdf5\n",
            "8/8 [==============================] - 40s 5s/step - loss: 1.5901 - acc: 0.5082 - val_loss: 3.9982 - val_acc: 0.3429\n",
            "Epoch 3/61\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0801 - acc: 0.6367\n",
            "Epoch 3: val_acc improved from 0.34286 to 0.49286, saving model to percobaan173_noImgPro/model\\vgg_16_173-saved-model-03-acc-0.49.hdf5\n",
            "8/8 [==============================] - 47s 6s/step - loss: 1.0801 - acc: 0.6367 - val_loss: 2.6668 - val_acc: 0.4929\n",
            "Epoch 4/61\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9881 - acc: 0.6755\n",
            "Epoch 4: val_acc did not improve from 0.49286\n",
            "8/8 [==============================] - 40s 5s/step - loss: 0.9881 - acc: 0.6755 - val_loss: 2.8815 - val_acc: 0.3500\n",
            "Epoch 5/61\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8380 - acc: 0.7265\n",
            "Epoch 5: val_acc did not improve from 0.49286\n",
            "8/8 [==============================] - 48s 5s/step - loss: 0.8380 - acc: 0.7265 - val_loss: 4.4591 - val_acc: 0.1857\n",
            "Epoch 6/61\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6598 - acc: 0.7816\n",
            "Epoch 6: val_acc did not improve from 0.49286\n",
            "8/8 [==============================] - 45s 6s/step - loss: 0.6598 - acc: 0.7816 - val_loss: 4.2116 - val_acc: 0.2214\n",
            "Epoch 7/61\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5828 - acc: 0.7939\n",
            "Epoch 7: val_acc did not improve from 0.49286\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.5828 - acc: 0.7939 - val_loss: 3.5794 - val_acc: 0.3500\n",
            "Epoch 8/61\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4425 - acc: 0.8306\n",
            "Epoch 8: val_acc did not improve from 0.49286\n",
            "8/8 [==============================] - 46s 5s/step - loss: 0.4425 - acc: 0.8306 - val_loss: 2.9656 - val_acc: 0.2500\n",
            "\n",
            "\n",
            "Model Accuracy 0.18571428571428572\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_57148\\3902733085.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.10      0.18        10\n",
            "       10000       0.50      0.10      0.17        10\n",
            "      100000       1.00      0.10      0.18        10\n",
            "        2000       0.00      0.00      0.00        10\n",
            "       20000       0.00      0.00      0.00        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       0.15      1.00      0.27        10\n",
            "\n",
            "    accuracy                           0.19        70\n",
            "   macro avg       0.38      0.19      0.11        70\n",
            "weighted avg       0.38      0.19      0.11        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 174 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 64\n",
            "learning rate: 0.06768303141523284\n",
            "batch size: 64\n",
            "dropout rate: 0.5921609271702973\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/64\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.8466 - acc: 0.3020\n",
            "Epoch 1: val_acc improved from -inf to 0.20714, saving model to percobaan174_noImgPro/model\\vgg_16_174-saved-model-01-acc-0.21.hdf5\n",
            "8/8 [==============================] - 40s 5s/step - loss: 2.8466 - acc: 0.3020 - val_loss: 7.8413 - val_acc: 0.2071\n",
            "Epoch 2/64\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8268 - acc: 0.4347\n",
            "Epoch 2: val_acc improved from 0.20714 to 0.39286, saving model to percobaan174_noImgPro/model\\vgg_16_174-saved-model-02-acc-0.39.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 1.8268 - acc: 0.4347 - val_loss: 5.8105 - val_acc: 0.3929\n",
            "Epoch 3/64\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3773 - acc: 0.5755\n",
            "Epoch 3: val_acc did not improve from 0.39286\n",
            "8/8 [==============================] - 45s 5s/step - loss: 1.3773 - acc: 0.5755 - val_loss: 6.1211 - val_acc: 0.3214\n",
            "Epoch 4/64\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1121 - acc: 0.5980\n",
            "Epoch 4: val_acc did not improve from 0.39286\n",
            "8/8 [==============================] - 42s 6s/step - loss: 1.1121 - acc: 0.5980 - val_loss: 4.8528 - val_acc: 0.3286\n",
            "Epoch 5/64\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0748 - acc: 0.6571\n",
            "Epoch 5: val_acc did not improve from 0.39286\n",
            "8/8 [==============================] - 41s 5s/step - loss: 1.0748 - acc: 0.6571 - val_loss: 3.4400 - val_acc: 0.3357\n",
            "Epoch 6/64\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7752 - acc: 0.7367\n",
            "Epoch 6: val_acc did not improve from 0.39286\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.7752 - acc: 0.7367 - val_loss: 6.8836 - val_acc: 0.1643\n",
            "Epoch 7/64\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7291 - acc: 0.7367\n",
            "Epoch 7: val_acc did not improve from 0.39286\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.7291 - acc: 0.7367 - val_loss: 6.6424 - val_acc: 0.2143\n",
            "Epoch 8/64\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7207 - acc: 0.7490\n",
            "Epoch 8: val_acc did not improve from 0.39286\n",
            "8/8 [==============================] - 46s 6s/step - loss: 0.7207 - acc: 0.7490 - val_loss: 5.1318 - val_acc: 0.2143\n",
            "Epoch 9/64\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6549 - acc: 0.7673\n",
            "Epoch 9: val_acc did not improve from 0.39286\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.6549 - acc: 0.7673 - val_loss: 2.9060 - val_acc: 0.2429\n",
            "Epoch 10/64\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5960 - acc: 0.7878\n",
            "Epoch 10: val_acc improved from 0.39286 to 0.57857, saving model to percobaan174_noImgPro/model\\vgg_16_174-saved-model-10-acc-0.58.hdf5\n",
            "8/8 [==============================] - 45s 5s/step - loss: 0.5960 - acc: 0.7878 - val_loss: 1.6158 - val_acc: 0.5786\n",
            "Epoch 11/64\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5585 - acc: 0.8041\n",
            "Epoch 11: val_acc did not improve from 0.57857\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.5585 - acc: 0.8041 - val_loss: 1.3312 - val_acc: 0.5786\n",
            "Epoch 12/64\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5688 - acc: 0.8102\n",
            "Epoch 12: val_acc did not improve from 0.57857\n",
            "8/8 [==============================] - 44s 5s/step - loss: 0.5688 - acc: 0.8102 - val_loss: 1.8074 - val_acc: 0.4786\n",
            "Epoch 13/64\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7020 - acc: 0.7918\n",
            "Epoch 13: val_acc did not improve from 0.57857\n",
            "8/8 [==============================] - 43s 6s/step - loss: 0.7020 - acc: 0.7918 - val_loss: 1.3729 - val_acc: 0.5643\n",
            "Epoch 14/64\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5904 - acc: 0.8061\n",
            "Epoch 14: val_acc improved from 0.57857 to 0.65714, saving model to percobaan174_noImgPro/model\\vgg_16_174-saved-model-14-acc-0.66.hdf5\n",
            "8/8 [==============================] - 40s 5s/step - loss: 0.5904 - acc: 0.8061 - val_loss: 1.1326 - val_acc: 0.6571\n",
            "Epoch 15/64\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5750 - acc: 0.8020\n",
            "Epoch 15: val_acc improved from 0.65714 to 0.67857, saving model to percobaan174_noImgPro/model\\vgg_16_174-saved-model-15-acc-0.68.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.5750 - acc: 0.8020 - val_loss: 0.9023 - val_acc: 0.6786\n",
            "Epoch 16/64\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4725 - acc: 0.8367\n",
            "Epoch 16: val_acc did not improve from 0.67857\n",
            "8/8 [==============================] - 45s 6s/step - loss: 0.4725 - acc: 0.8367 - val_loss: 0.9541 - val_acc: 0.6429\n",
            "Epoch 17/64\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5195 - acc: 0.8408\n",
            "Epoch 17: val_acc improved from 0.67857 to 0.70000, saving model to percobaan174_noImgPro/model\\vgg_16_174-saved-model-17-acc-0.70.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.5195 - acc: 0.8408 - val_loss: 0.9012 - val_acc: 0.7000\n",
            "Epoch 18/64\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4324 - acc: 0.8571\n",
            "Epoch 18: val_acc did not improve from 0.70000\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.4324 - acc: 0.8571 - val_loss: 1.1827 - val_acc: 0.6500\n",
            "Epoch 19/64\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4726 - acc: 0.8449\n",
            "Epoch 19: val_acc did not improve from 0.70000\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.4726 - acc: 0.8449 - val_loss: 2.8643 - val_acc: 0.3643\n",
            "Epoch 20/64\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4290 - acc: 0.8612\n",
            "Epoch 20: val_acc did not improve from 0.70000\n",
            "8/8 [==============================] - 45s 6s/step - loss: 0.4290 - acc: 0.8612 - val_loss: 3.1730 - val_acc: 0.3500\n",
            "Epoch 21/64\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4581 - acc: 0.8571\n",
            "Epoch 21: val_acc did not improve from 0.70000\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.4581 - acc: 0.8571 - val_loss: 4.2417 - val_acc: 0.2214\n",
            "Epoch 22/64\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4028 - acc: 0.8755\n",
            "Epoch 22: val_acc did not improve from 0.70000\n",
            "8/8 [==============================] - 45s 6s/step - loss: 0.4028 - acc: 0.8755 - val_loss: 2.3200 - val_acc: 0.4643\n",
            "\n",
            "\n",
            "Model Accuracy 0.34285714285714286\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_57148\\3902733085.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.10      0.18        10\n",
            "       10000       1.00      0.40      0.57        10\n",
            "      100000       1.00      0.30      0.46        10\n",
            "        2000       0.45      0.50      0.48        10\n",
            "       20000       0.50      0.10      0.17        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       0.20      1.00      0.34        10\n",
            "\n",
            "    accuracy                           0.34        70\n",
            "   macro avg       0.59      0.34      0.31        70\n",
            "weighted avg       0.59      0.34      0.31        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 175 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 60\n",
            "learning rate: 0.056487248551922116\n",
            "batch size: 64\n",
            "dropout rate: 0.6712097698346025\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/60\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.9050 - acc: 0.2898\n",
            "Epoch 1: val_acc improved from -inf to 0.15000, saving model to percobaan175_noImgPro/model\\vgg_16_175-saved-model-01-acc-0.15.hdf5\n",
            "8/8 [==============================] - 40s 5s/step - loss: 2.9050 - acc: 0.2898 - val_loss: 16.4402 - val_acc: 0.1500\n",
            "Epoch 2/60\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.0388 - acc: 0.4102\n",
            "Epoch 2: val_acc improved from 0.15000 to 0.17143, saving model to percobaan175_noImgPro/model\\vgg_16_175-saved-model-02-acc-0.17.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 2.0388 - acc: 0.4102 - val_loss: 14.8262 - val_acc: 0.1714\n",
            "Epoch 3/60\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7081 - acc: 0.4878\n",
            "Epoch 3: val_acc improved from 0.17143 to 0.20714, saving model to percobaan175_noImgPro/model\\vgg_16_175-saved-model-03-acc-0.21.hdf5\n",
            "8/8 [==============================] - 44s 6s/step - loss: 1.7081 - acc: 0.4878 - val_loss: 8.6224 - val_acc: 0.2071\n",
            "Epoch 4/60\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4321 - acc: 0.5286\n",
            "Epoch 4: val_acc improved from 0.20714 to 0.22857, saving model to percobaan175_noImgPro/model\\vgg_16_175-saved-model-04-acc-0.23.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 1.4321 - acc: 0.5286 - val_loss: 5.9610 - val_acc: 0.2286\n",
            "Epoch 5/60\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1621 - acc: 0.5959\n",
            "Epoch 5: val_acc did not improve from 0.22857\n",
            "8/8 [==============================] - 44s 6s/step - loss: 1.1621 - acc: 0.5959 - val_loss: 4.1896 - val_acc: 0.2143\n",
            "Epoch 6/60\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0760 - acc: 0.6347\n",
            "Epoch 6: val_acc did not improve from 0.22857\n",
            "8/8 [==============================] - 38s 5s/step - loss: 1.0760 - acc: 0.6347 - val_loss: 5.4259 - val_acc: 0.1857\n",
            "Epoch 7/60\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8207 - acc: 0.6898\n",
            "Epoch 7: val_acc did not improve from 0.22857\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.8207 - acc: 0.6898 - val_loss: 4.7099 - val_acc: 0.1857\n",
            "Epoch 8/60\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7679 - acc: 0.7061\n",
            "Epoch 8: val_acc improved from 0.22857 to 0.35714, saving model to percobaan175_noImgPro/model\\vgg_16_175-saved-model-08-acc-0.36.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.7679 - acc: 0.7061 - val_loss: 2.7652 - val_acc: 0.3571\n",
            "Epoch 9/60\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6699 - acc: 0.7673\n",
            "Epoch 9: val_acc improved from 0.35714 to 0.41429, saving model to percobaan175_noImgPro/model\\vgg_16_175-saved-model-09-acc-0.41.hdf5\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.6699 - acc: 0.7673 - val_loss: 2.7841 - val_acc: 0.4143\n",
            "Epoch 10/60\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8396 - acc: 0.7163\n",
            "Epoch 10: val_acc improved from 0.41429 to 0.42857, saving model to percobaan175_noImgPro/model\\vgg_16_175-saved-model-10-acc-0.43.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.8396 - acc: 0.7163 - val_loss: 2.5387 - val_acc: 0.4286\n",
            "Epoch 11/60\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6275 - acc: 0.7837\n",
            "Epoch 11: val_acc did not improve from 0.42857\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.6275 - acc: 0.7837 - val_loss: 2.5998 - val_acc: 0.4071\n",
            "Epoch 12/60\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5376 - acc: 0.8061\n",
            "Epoch 12: val_acc improved from 0.42857 to 0.49286, saving model to percobaan175_noImgPro/model\\vgg_16_175-saved-model-12-acc-0.49.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.5376 - acc: 0.8061 - val_loss: 1.6738 - val_acc: 0.4929\n",
            "Epoch 13/60\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5706 - acc: 0.8184\n",
            "Epoch 13: val_acc improved from 0.49286 to 0.50000, saving model to percobaan175_noImgPro/model\\vgg_16_175-saved-model-13-acc-0.50.hdf5\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.5706 - acc: 0.8184 - val_loss: 1.8169 - val_acc: 0.5000\n",
            "Epoch 14/60\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5232 - acc: 0.8286\n",
            "Epoch 14: val_acc improved from 0.50000 to 0.55714, saving model to percobaan175_noImgPro/model\\vgg_16_175-saved-model-14-acc-0.56.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.5232 - acc: 0.8286 - val_loss: 1.3550 - val_acc: 0.5571\n",
            "Epoch 15/60\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6258 - acc: 0.7857\n",
            "Epoch 15: val_acc did not improve from 0.55714\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.6258 - acc: 0.7857 - val_loss: 1.5373 - val_acc: 0.5357\n",
            "Epoch 16/60\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5375 - acc: 0.8224\n",
            "Epoch 16: val_acc improved from 0.55714 to 0.61429, saving model to percobaan175_noImgPro/model\\vgg_16_175-saved-model-16-acc-0.61.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.5375 - acc: 0.8224 - val_loss: 1.2352 - val_acc: 0.6143\n",
            "Epoch 17/60\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6150 - acc: 0.7653\n",
            "Epoch 17: val_acc improved from 0.61429 to 0.65000, saving model to percobaan175_noImgPro/model\\vgg_16_175-saved-model-17-acc-0.65.hdf5\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.6150 - acc: 0.7653 - val_loss: 1.0753 - val_acc: 0.6500\n",
            "Epoch 18/60\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5338 - acc: 0.8122\n",
            "Epoch 18: val_acc improved from 0.65000 to 0.73571, saving model to percobaan175_noImgPro/model\\vgg_16_175-saved-model-18-acc-0.74.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.5338 - acc: 0.8122 - val_loss: 0.8416 - val_acc: 0.7357\n",
            "Epoch 19/60\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5384 - acc: 0.8122\n",
            "Epoch 19: val_acc did not improve from 0.73571\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.5384 - acc: 0.8122 - val_loss: 1.4112 - val_acc: 0.5786\n",
            "Epoch 20/60\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5226 - acc: 0.8265\n",
            "Epoch 20: val_acc did not improve from 0.73571\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.5226 - acc: 0.8265 - val_loss: 1.3142 - val_acc: 0.6071\n",
            "Epoch 21/60\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4367 - acc: 0.8571\n",
            "Epoch 21: val_acc did not improve from 0.73571\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.4367 - acc: 0.8571 - val_loss: 1.1714 - val_acc: 0.6929\n",
            "Epoch 22/60\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4288 - acc: 0.8571\n",
            "Epoch 22: val_acc did not improve from 0.73571\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.4288 - acc: 0.8571 - val_loss: 1.3180 - val_acc: 0.6571\n",
            "Epoch 23/60\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4122 - acc: 0.8714\n",
            "Epoch 23: val_acc did not improve from 0.73571\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.4122 - acc: 0.8714 - val_loss: 0.9850 - val_acc: 0.6857\n",
            "\n",
            "\n",
            "Model Accuracy 0.6\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.20      0.33        10\n",
            "       10000       1.00      0.80      0.89        10\n",
            "      100000       1.00      0.20      0.33        10\n",
            "        2000       0.78      0.70      0.74        10\n",
            "       20000       1.00      0.40      0.57        10\n",
            "        5000       0.45      0.90      0.60        10\n",
            "       50000       0.40      1.00      0.57        10\n",
            "\n",
            "    accuracy                           0.60        70\n",
            "   macro avg       0.80      0.60      0.58        70\n",
            "weighted avg       0.80      0.60      0.58        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 176 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 63\n",
            "learning rate: 0.06166803432745274\n",
            "batch size: 64\n",
            "dropout rate: 0.7450838038175333\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_57148\\3902733085.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 3.4995 - acc: 0.2204\n",
            "Epoch 1: val_acc improved from -inf to 0.19286, saving model to percobaan176_noImgPro/model\\vgg_16_176-saved-model-01-acc-0.19.hdf5\n",
            "8/8 [==============================] - 40s 5s/step - loss: 3.4995 - acc: 0.2204 - val_loss: 12.1367 - val_acc: 0.1929\n",
            "Epoch 2/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 3.0034 - acc: 0.3020\n",
            "Epoch 2: val_acc did not improve from 0.19286\n",
            "8/8 [==============================] - 38s 5s/step - loss: 3.0034 - acc: 0.3020 - val_loss: 9.5723 - val_acc: 0.1429\n",
            "Epoch 3/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.0171 - acc: 0.4163\n",
            "Epoch 3: val_acc did not improve from 0.19286\n",
            "8/8 [==============================] - 44s 6s/step - loss: 2.0171 - acc: 0.4163 - val_loss: 5.8642 - val_acc: 0.1786\n",
            "Epoch 4/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6194 - acc: 0.4551\n",
            "Epoch 4: val_acc did not improve from 0.19286\n",
            "8/8 [==============================] - 38s 5s/step - loss: 1.6194 - acc: 0.4551 - val_loss: 5.2638 - val_acc: 0.1857\n",
            "Epoch 5/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.2689 - acc: 0.5449\n",
            "Epoch 5: val_acc improved from 0.19286 to 0.24286, saving model to percobaan176_noImgPro/model\\vgg_16_176-saved-model-05-acc-0.24.hdf5\n",
            "8/8 [==============================] - 44s 6s/step - loss: 1.2689 - acc: 0.5449 - val_loss: 4.3398 - val_acc: 0.2429\n",
            "Epoch 6/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.2476 - acc: 0.5469\n",
            "Epoch 6: val_acc did not improve from 0.24286\n",
            "8/8 [==============================] - 39s 5s/step - loss: 1.2476 - acc: 0.5469 - val_loss: 4.2401 - val_acc: 0.1429\n",
            "Epoch 7/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1638 - acc: 0.5612\n",
            "Epoch 7: val_acc improved from 0.24286 to 0.25714, saving model to percobaan176_noImgPro/model\\vgg_16_176-saved-model-07-acc-0.26.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 1.1638 - acc: 0.5612 - val_loss: 2.7513 - val_acc: 0.2571\n",
            "Epoch 8/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0155 - acc: 0.6592\n",
            "Epoch 8: val_acc improved from 0.25714 to 0.35000, saving model to percobaan176_noImgPro/model\\vgg_16_176-saved-model-08-acc-0.35.hdf5\n",
            "8/8 [==============================] - 44s 6s/step - loss: 1.0155 - acc: 0.6592 - val_loss: 2.1192 - val_acc: 0.3500\n",
            "Epoch 9/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9405 - acc: 0.6714\n",
            "Epoch 9: val_acc did not improve from 0.35000\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.9405 - acc: 0.6714 - val_loss: 2.0144 - val_acc: 0.2571\n",
            "Epoch 10/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9144 - acc: 0.7082\n",
            "Epoch 10: val_acc improved from 0.35000 to 0.37143, saving model to percobaan176_noImgPro/model\\vgg_16_176-saved-model-10-acc-0.37.hdf5\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.9144 - acc: 0.7082 - val_loss: 1.7101 - val_acc: 0.3714\n",
            "Epoch 11/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9332 - acc: 0.6714\n",
            "Epoch 11: val_acc improved from 0.37143 to 0.40714, saving model to percobaan176_noImgPro/model\\vgg_16_176-saved-model-11-acc-0.41.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.9332 - acc: 0.6714 - val_loss: 1.7626 - val_acc: 0.4071\n",
            "Epoch 12/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8793 - acc: 0.6816\n",
            "Epoch 12: val_acc did not improve from 0.40714\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.8793 - acc: 0.6816 - val_loss: 2.0188 - val_acc: 0.2929\n",
            "Epoch 13/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8552 - acc: 0.6980\n",
            "Epoch 13: val_acc improved from 0.40714 to 0.59286, saving model to percobaan176_noImgPro/model\\vgg_16_176-saved-model-13-acc-0.59.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.8552 - acc: 0.6980 - val_loss: 1.1532 - val_acc: 0.5929\n",
            "Epoch 14/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7505 - acc: 0.7510\n",
            "Epoch 14: val_acc improved from 0.59286 to 0.60714, saving model to percobaan176_noImgPro/model\\vgg_16_176-saved-model-14-acc-0.61.hdf5\n",
            "8/8 [==============================] - 45s 6s/step - loss: 0.7505 - acc: 0.7510 - val_loss: 1.1740 - val_acc: 0.6071\n",
            "Epoch 15/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7301 - acc: 0.7408\n",
            "Epoch 15: val_acc did not improve from 0.60714\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.7301 - acc: 0.7408 - val_loss: 1.2871 - val_acc: 0.4857\n",
            "Epoch 16/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8080 - acc: 0.7000\n",
            "Epoch 16: val_acc did not improve from 0.60714\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.8080 - acc: 0.7000 - val_loss: 1.2498 - val_acc: 0.5286\n",
            "Epoch 17/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7489 - acc: 0.7265\n",
            "Epoch 17: val_acc did not improve from 0.60714\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.7489 - acc: 0.7265 - val_loss: 1.2493 - val_acc: 0.5714\n",
            "Epoch 18/63\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7584 - acc: 0.7469\n",
            "Epoch 18: val_acc did not improve from 0.60714\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.7584 - acc: 0.7469 - val_loss: 1.4817 - val_acc: 0.4786\n",
            "\n",
            "\n",
            "Model Accuracy 0.4142857142857143\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_57148\\3902733085.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.20      0.33        10\n",
            "       10000       0.56      0.90      0.69        10\n",
            "      100000       1.00      0.10      0.18        10\n",
            "        2000       0.67      0.20      0.31        10\n",
            "       20000       0.00      0.00      0.00        10\n",
            "        5000       0.45      0.50      0.48        10\n",
            "       50000       0.27      1.00      0.43        10\n",
            "\n",
            "    accuracy                           0.41        70\n",
            "   macro avg       0.56      0.41      0.35        70\n",
            "weighted avg       0.56      0.41      0.35        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 177 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 58\n",
            "learning rate: 0.05663843796445758\n",
            "batch size: 128\n",
            "dropout rate: 0.5176627733075307\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.7680 - acc: 0.2980\n",
            "Epoch 1: val_acc improved from -inf to 0.14286, saving model to percobaan177_noImgPro/model\\vgg_16_177-saved-model-01-acc-0.14.hdf5\n",
            "4/4 [==============================] - 41s 11s/step - loss: 2.7680 - acc: 0.2980 - val_loss: 17.1991 - val_acc: 0.1429\n",
            "Epoch 2/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.8798 - acc: 0.4633\n",
            "Epoch 2: val_acc improved from 0.14286 to 0.22857, saving model to percobaan177_noImgPro/model\\vgg_16_177-saved-model-02-acc-0.23.hdf5\n",
            "4/4 [==============================] - 39s 11s/step - loss: 1.8798 - acc: 0.4633 - val_loss: 9.5210 - val_acc: 0.2286\n",
            "Epoch 3/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1487 - acc: 0.6347\n",
            "Epoch 3: val_acc did not improve from 0.22857\n",
            "4/4 [==============================] - 44s 12s/step - loss: 1.1487 - acc: 0.6347 - val_loss: 8.2137 - val_acc: 0.2214\n",
            "Epoch 4/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8865 - acc: 0.7163\n",
            "Epoch 4: val_acc improved from 0.22857 to 0.28571, saving model to percobaan177_noImgPro/model\\vgg_16_177-saved-model-04-acc-0.29.hdf5\n",
            "4/4 [==============================] - 38s 11s/step - loss: 0.8865 - acc: 0.7163 - val_loss: 3.6131 - val_acc: 0.2857\n",
            "Epoch 5/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7882 - acc: 0.7224\n",
            "Epoch 5: val_acc improved from 0.28571 to 0.37857, saving model to percobaan177_noImgPro/model\\vgg_16_177-saved-model-05-acc-0.38.hdf5\n",
            "4/4 [==============================] - 44s 13s/step - loss: 0.7882 - acc: 0.7224 - val_loss: 3.0890 - val_acc: 0.3786\n",
            "Epoch 6/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6685 - acc: 0.7714\n",
            "Epoch 6: val_acc did not improve from 0.37857\n",
            "4/4 [==============================] - 38s 11s/step - loss: 0.6685 - acc: 0.7714 - val_loss: 2.8500 - val_acc: 0.3571\n",
            "Epoch 7/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5176 - acc: 0.8204\n",
            "Epoch 7: val_acc did not improve from 0.37857\n",
            "4/4 [==============================] - 43s 13s/step - loss: 0.5176 - acc: 0.8204 - val_loss: 3.0417 - val_acc: 0.3143\n",
            "Epoch 8/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4339 - acc: 0.8571\n",
            "Epoch 8: val_acc did not improve from 0.37857\n",
            "4/4 [==============================] - 38s 11s/step - loss: 0.4339 - acc: 0.8571 - val_loss: 3.0423 - val_acc: 0.3071\n",
            "Epoch 9/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4239 - acc: 0.8571\n",
            "Epoch 9: val_acc did not improve from 0.37857\n",
            "4/4 [==============================] - 45s 11s/step - loss: 0.4239 - acc: 0.8571 - val_loss: 2.5628 - val_acc: 0.3429\n",
            "Epoch 10/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3975 - acc: 0.8633\n",
            "Epoch 10: val_acc improved from 0.37857 to 0.45000, saving model to percobaan177_noImgPro/model\\vgg_16_177-saved-model-10-acc-0.45.hdf5\n",
            "4/4 [==============================] - 39s 11s/step - loss: 0.3975 - acc: 0.8633 - val_loss: 1.8784 - val_acc: 0.4500\n",
            "Epoch 11/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4181 - acc: 0.8429\n",
            "Epoch 11: val_acc improved from 0.45000 to 0.47857, saving model to percobaan177_noImgPro/model\\vgg_16_177-saved-model-11-acc-0.48.hdf5\n",
            "4/4 [==============================] - 44s 11s/step - loss: 0.4181 - acc: 0.8429 - val_loss: 1.9677 - val_acc: 0.4786\n",
            "Epoch 12/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4096 - acc: 0.8653\n",
            "Epoch 12: val_acc did not improve from 0.47857\n",
            "4/4 [==============================] - 39s 11s/step - loss: 0.4096 - acc: 0.8653 - val_loss: 2.7686 - val_acc: 0.3929\n",
            "Epoch 13/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3347 - acc: 0.8878\n",
            "Epoch 13: val_acc did not improve from 0.47857\n",
            "4/4 [==============================] - 44s 11s/step - loss: 0.3347 - acc: 0.8878 - val_loss: 2.1904 - val_acc: 0.4571\n",
            "Epoch 14/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3490 - acc: 0.8796\n",
            "Epoch 14: val_acc improved from 0.47857 to 0.55000, saving model to percobaan177_noImgPro/model\\vgg_16_177-saved-model-14-acc-0.55.hdf5\n",
            "4/4 [==============================] - 38s 11s/step - loss: 0.3490 - acc: 0.8796 - val_loss: 1.4049 - val_acc: 0.5500\n",
            "Epoch 15/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2263 - acc: 0.9122\n",
            "Epoch 15: val_acc improved from 0.55000 to 0.56429, saving model to percobaan177_noImgPro/model\\vgg_16_177-saved-model-15-acc-0.56.hdf5\n",
            "4/4 [==============================] - 44s 11s/step - loss: 0.2263 - acc: 0.9122 - val_loss: 1.3442 - val_acc: 0.5643\n",
            "Epoch 16/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2755 - acc: 0.8980\n",
            "Epoch 16: val_acc improved from 0.56429 to 0.59286, saving model to percobaan177_noImgPro/model\\vgg_16_177-saved-model-16-acc-0.59.hdf5\n",
            "4/4 [==============================] - 39s 11s/step - loss: 0.2755 - acc: 0.8980 - val_loss: 1.2373 - val_acc: 0.5929\n",
            "Epoch 17/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2685 - acc: 0.9020\n",
            "Epoch 17: val_acc did not improve from 0.59286\n",
            "4/4 [==============================] - 44s 11s/step - loss: 0.2685 - acc: 0.9020 - val_loss: 1.3305 - val_acc: 0.5714\n",
            "Epoch 18/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2069 - acc: 0.9204\n",
            "Epoch 18: val_acc did not improve from 0.59286\n",
            "4/4 [==============================] - 44s 12s/step - loss: 0.2069 - acc: 0.9204 - val_loss: 1.5202 - val_acc: 0.5429\n",
            "Epoch 19/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1682 - acc: 0.9347\n",
            "Epoch 19: val_acc did not improve from 0.59286\n",
            "4/4 [==============================] - 39s 11s/step - loss: 0.1682 - acc: 0.9347 - val_loss: 1.4741 - val_acc: 0.5571\n",
            "Epoch 20/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2696 - acc: 0.9082\n",
            "Epoch 20: val_acc did not improve from 0.59286\n",
            "4/4 [==============================] - 44s 13s/step - loss: 0.2696 - acc: 0.9082 - val_loss: 2.0208 - val_acc: 0.5571\n",
            "Epoch 21/58\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2423 - acc: 0.8959\n",
            "Epoch 21: val_acc did not improve from 0.59286\n",
            "4/4 [==============================] - 44s 12s/step - loss: 0.2423 - acc: 0.8959 - val_loss: 2.2159 - val_acc: 0.4571\n",
            "\n",
            "\n",
            "Model Accuracy 0.44285714285714284\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.37      1.00      0.54        10\n",
            "       10000       1.00      0.20      0.33        10\n",
            "      100000       1.00      0.20      0.33        10\n",
            "        2000       1.00      0.20      0.33        10\n",
            "       20000       0.35      0.70      0.47        10\n",
            "        5000       1.00      0.10      0.18        10\n",
            "       50000       0.44      0.70      0.54        10\n",
            "\n",
            "    accuracy                           0.44        70\n",
            "   macro avg       0.74      0.44      0.39        70\n",
            "weighted avg       0.74      0.44      0.39        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 178 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 57\n",
            "learning rate: 0.06432417642677618\n",
            "batch size: 128\n",
            "dropout rate: 0.6126037423684957\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_57148\\3902733085.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/57\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.9565 - acc: 0.2735\n",
            "Epoch 1: val_acc improved from -inf to 0.14286, saving model to percobaan178_noImgPro/model\\vgg_16_178-saved-model-01-acc-0.14.hdf5\n",
            "4/4 [==============================] - 56s 16s/step - loss: 2.9565 - acc: 0.2735 - val_loss: 19.9779 - val_acc: 0.1429\n",
            "Epoch 2/57\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.8290 - acc: 0.4673\n",
            "Epoch 2: val_acc improved from 0.14286 to 0.23571, saving model to percobaan178_noImgPro/model\\vgg_16_178-saved-model-02-acc-0.24.hdf5\n",
            "4/4 [==============================] - 68s 17s/step - loss: 1.8290 - acc: 0.4673 - val_loss: 8.6898 - val_acc: 0.2357\n",
            "Epoch 3/57\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.4758 - acc: 0.5204\n",
            "Epoch 3: val_acc did not improve from 0.23571\n",
            "4/4 [==============================] - 62s 16s/step - loss: 1.4758 - acc: 0.5204 - val_loss: 11.6813 - val_acc: 0.1429\n",
            "Epoch 4/57\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1279 - acc: 0.6184 \n",
            "Epoch 4: val_acc did not improve from 0.23571\n",
            "4/4 [==============================] - 58s 16s/step - loss: 1.1279 - acc: 0.6184 - val_loss: 6.9579 - val_acc: 0.2000\n",
            "Epoch 5/57\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1267 - acc: 0.6429 \n",
            "Epoch 5: val_acc did not improve from 0.23571\n",
            "4/4 [==============================] - 67s 17s/step - loss: 1.1267 - acc: 0.6429 - val_loss: 5.2400 - val_acc: 0.1929\n",
            "Epoch 6/57\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7318 - acc: 0.7286\n",
            "Epoch 6: val_acc did not improve from 0.23571\n",
            "4/4 [==============================] - 55s 13s/step - loss: 0.7318 - acc: 0.7286 - val_loss: 5.6029 - val_acc: 0.1857\n",
            "Epoch 7/57\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7484 - acc: 0.7245\n",
            "Epoch 7: val_acc did not improve from 0.23571\n",
            "4/4 [==============================] - 58s 15s/step - loss: 0.7484 - acc: 0.7245 - val_loss: 5.5955 - val_acc: 0.1929\n",
            "Epoch 8/57\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6556 - acc: 0.7592 \n",
            "Epoch 8: val_acc did not improve from 0.23571\n",
            "4/4 [==============================] - 63s 17s/step - loss: 0.6556 - acc: 0.7592 - val_loss: 4.4467 - val_acc: 0.2071\n",
            "Epoch 9/57\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6221 - acc: 0.7490\n",
            "Epoch 9: val_acc did not improve from 0.23571\n",
            "4/4 [==============================] - 66s 17s/step - loss: 0.6221 - acc: 0.7490 - val_loss: 3.7597 - val_acc: 0.2286\n",
            "Epoch 10/57\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5801 - acc: 0.7939 \n",
            "Epoch 10: val_acc improved from 0.23571 to 0.29286, saving model to percobaan178_noImgPro/model\\vgg_16_178-saved-model-10-acc-0.29.hdf5\n",
            "4/4 [==============================] - 61s 17s/step - loss: 0.5801 - acc: 0.7939 - val_loss: 2.8055 - val_acc: 0.2929\n",
            "Epoch 11/57\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5403 - acc: 0.8102\n",
            "Epoch 11: val_acc improved from 0.29286 to 0.40714, saving model to percobaan178_noImgPro/model\\vgg_16_178-saved-model-11-acc-0.41.hdf5\n",
            "4/4 [==============================] - 67s 17s/step - loss: 0.5403 - acc: 0.8102 - val_loss: 2.4338 - val_acc: 0.4071\n",
            "Epoch 12/57\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4715 - acc: 0.8286 \n",
            "Epoch 12: val_acc improved from 0.40714 to 0.45714, saving model to percobaan178_noImgPro/model\\vgg_16_178-saved-model-12-acc-0.46.hdf5\n",
            "4/4 [==============================] - 61s 17s/step - loss: 0.4715 - acc: 0.8286 - val_loss: 2.8582 - val_acc: 0.4571\n",
            "Epoch 13/57\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4225 - acc: 0.8551 \n",
            "Epoch 13: val_acc improved from 0.45714 to 0.52143, saving model to percobaan178_noImgPro/model\\vgg_16_178-saved-model-13-acc-0.52.hdf5\n",
            "4/4 [==============================] - 65s 17s/step - loss: 0.4225 - acc: 0.8551 - val_loss: 2.5054 - val_acc: 0.5214\n",
            "Epoch 14/57\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3650 - acc: 0.8776\n",
            "Epoch 14: val_acc improved from 0.52143 to 0.59286, saving model to percobaan178_noImgPro/model\\vgg_16_178-saved-model-14-acc-0.59.hdf5\n",
            "4/4 [==============================] - 53s 13s/step - loss: 0.3650 - acc: 0.8776 - val_loss: 2.0056 - val_acc: 0.5929\n",
            "Epoch 15/57\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3270 - acc: 0.8633\n",
            "Epoch 15: val_acc did not improve from 0.59286\n",
            "4/4 [==============================] - 65s 17s/step - loss: 0.3270 - acc: 0.8633 - val_loss: 1.7972 - val_acc: 0.5786\n",
            "Epoch 16/57\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3288 - acc: 0.8959 \n",
            "Epoch 16: val_acc did not improve from 0.59286\n",
            "4/4 [==============================] - 61s 17s/step - loss: 0.3288 - acc: 0.8959 - val_loss: 1.6595 - val_acc: 0.5500\n",
            "Epoch 17/57\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3784 - acc: 0.8878 \n",
            "Epoch 17: val_acc did not improve from 0.59286\n",
            "4/4 [==============================] - 66s 17s/step - loss: 0.3784 - acc: 0.8878 - val_loss: 1.7447 - val_acc: 0.5714\n",
            "Epoch 18/57\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3298 - acc: 0.8837 \n",
            "Epoch 18: val_acc did not improve from 0.59286\n",
            "4/4 [==============================] - 57s 17s/step - loss: 0.3298 - acc: 0.8837 - val_loss: 1.9290 - val_acc: 0.5643\n",
            "Epoch 19/57\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3660 - acc: 0.8837\n",
            "Epoch 19: val_acc did not improve from 0.59286\n",
            "4/4 [==============================] - 50s 12s/step - loss: 0.3660 - acc: 0.8837 - val_loss: 1.6142 - val_acc: 0.5857\n",
            "Epoch 20/57\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3433 - acc: 0.8857\n",
            "Epoch 20: val_acc did not improve from 0.59286\n",
            "4/4 [==============================] - 61s 15s/step - loss: 0.3433 - acc: 0.8857 - val_loss: 1.5113 - val_acc: 0.5857\n",
            "Epoch 21/57\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2833 - acc: 0.8898 \n",
            "Epoch 21: val_acc improved from 0.59286 to 0.62857, saving model to percobaan178_noImgPro/model\\vgg_16_178-saved-model-21-acc-0.63.hdf5\n",
            "4/4 [==============================] - 66s 17s/step - loss: 0.2833 - acc: 0.8898 - val_loss: 1.4440 - val_acc: 0.6286\n",
            "Epoch 22/57\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3276 - acc: 0.8959 \n",
            "Epoch 22: val_acc improved from 0.62857 to 0.66429, saving model to percobaan178_noImgPro/model\\vgg_16_178-saved-model-22-acc-0.66.hdf5\n",
            "4/4 [==============================] - 61s 17s/step - loss: 0.3276 - acc: 0.8959 - val_loss: 1.1633 - val_acc: 0.6643\n",
            "Epoch 23/57\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2675 - acc: 0.9061 \n",
            "Epoch 23: val_acc did not improve from 0.66429\n",
            "4/4 [==============================] - 61s 17s/step - loss: 0.2675 - acc: 0.9061 - val_loss: 1.6033 - val_acc: 0.5714\n",
            "Epoch 24/57\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2926 - acc: 0.8878\n",
            "Epoch 24: val_acc did not improve from 0.66429\n",
            "4/4 [==============================] - 61s 15s/step - loss: 0.2926 - acc: 0.8878 - val_loss: 1.7099 - val_acc: 0.5929\n",
            "Epoch 25/57\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3030 - acc: 0.8837\n",
            "Epoch 25: val_acc did not improve from 0.66429\n",
            "4/4 [==============================] - 66s 17s/step - loss: 0.3030 - acc: 0.8837 - val_loss: 1.6654 - val_acc: 0.6286\n",
            "Epoch 26/57\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3147 - acc: 0.8939 \n",
            "Epoch 26: val_acc did not improve from 0.66429\n",
            "4/4 [==============================] - 61s 18s/step - loss: 0.3147 - acc: 0.8939 - val_loss: 1.7811 - val_acc: 0.6071\n",
            "Epoch 27/57\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3441 - acc: 0.8776\n",
            "Epoch 27: val_acc did not improve from 0.66429\n",
            "4/4 [==============================] - 57s 14s/step - loss: 0.3441 - acc: 0.8776 - val_loss: 1.5839 - val_acc: 0.6000\n",
            "\n",
            "\n",
            "Model Accuracy 0.44285714285714284\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_57148\\3902733085.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.30      0.46        10\n",
            "       10000       0.33      1.00      0.50        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.67      0.20      0.31        10\n",
            "       20000       0.56      0.50      0.53        10\n",
            "        5000       0.80      0.40      0.53        10\n",
            "       50000       0.35      0.70      0.47        10\n",
            "\n",
            "    accuracy                           0.44        70\n",
            "   macro avg       0.53      0.44      0.40        70\n",
            "weighted avg       0.53      0.44      0.40        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 179 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 60\n",
            "learning rate: 0.07024575766414658\n",
            "batch size: 128\n",
            "dropout rate: 0.6682938138340236\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 3.1924 - acc: 0.2224\n",
            "Epoch 1: val_acc improved from -inf to 0.14286, saving model to percobaan179_noImgPro/model\\vgg_16_179-saved-model-01-acc-0.14.hdf5\n",
            "4/4 [==============================] - 50s 12s/step - loss: 3.1924 - acc: 0.2224 - val_loss: 29.2328 - val_acc: 0.1429\n",
            "Epoch 2/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.2592 - acc: 0.3714\n",
            "Epoch 2: val_acc improved from 0.14286 to 0.19286, saving model to percobaan179_noImgPro/model\\vgg_16_179-saved-model-02-acc-0.19.hdf5\n",
            "4/4 [==============================] - 51s 15s/step - loss: 2.2592 - acc: 0.3714 - val_loss: 10.5717 - val_acc: 0.1929\n",
            "Epoch 3/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.7454 - acc: 0.4694\n",
            "Epoch 3: val_acc did not improve from 0.19286\n",
            "4/4 [==============================] - 41s 11s/step - loss: 1.7454 - acc: 0.4694 - val_loss: 11.2099 - val_acc: 0.1429\n",
            "Epoch 4/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.3363 - acc: 0.5571\n",
            "Epoch 4: val_acc did not improve from 0.19286\n",
            "4/4 [==============================] - 49s 12s/step - loss: 1.3363 - acc: 0.5571 - val_loss: 9.4366 - val_acc: 0.1429\n",
            "Epoch 5/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.3008 - acc: 0.5694\n",
            "Epoch 5: val_acc did not improve from 0.19286\n",
            "4/4 [==============================] - 49s 12s/step - loss: 1.3008 - acc: 0.5694 - val_loss: 5.8670 - val_acc: 0.1786\n",
            "Epoch 6/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1443 - acc: 0.5796\n",
            "Epoch 6: val_acc improved from 0.19286 to 0.22857, saving model to percobaan179_noImgPro/model\\vgg_16_179-saved-model-06-acc-0.23.hdf5\n",
            "4/4 [==============================] - 54s 13s/step - loss: 1.1443 - acc: 0.5796 - val_loss: 4.7407 - val_acc: 0.2286\n",
            "Epoch 7/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9130 - acc: 0.6714\n",
            "Epoch 7: val_acc improved from 0.22857 to 0.25000, saving model to percobaan179_noImgPro/model\\vgg_16_179-saved-model-07-acc-0.25.hdf5\n",
            "4/4 [==============================] - 52s 14s/step - loss: 0.9130 - acc: 0.6714 - val_loss: 4.5654 - val_acc: 0.2500\n",
            "Epoch 8/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9769 - acc: 0.6469\n",
            "Epoch 8: val_acc did not improve from 0.25000\n",
            "4/4 [==============================] - 45s 13s/step - loss: 0.9769 - acc: 0.6469 - val_loss: 4.4948 - val_acc: 0.2071\n",
            "Epoch 9/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8396 - acc: 0.7000\n",
            "Epoch 9: val_acc did not improve from 0.25000\n",
            "4/4 [==============================] - 54s 14s/step - loss: 0.8396 - acc: 0.7000 - val_loss: 3.8635 - val_acc: 0.2500\n",
            "Epoch 10/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7089 - acc: 0.7449\n",
            "Epoch 10: val_acc improved from 0.25000 to 0.25714, saving model to percobaan179_noImgPro/model\\vgg_16_179-saved-model-10-acc-0.26.hdf5\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.7089 - acc: 0.7449 - val_loss: 3.5617 - val_acc: 0.2571\n",
            "Epoch 11/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6914 - acc: 0.7633\n",
            "Epoch 11: val_acc did not improve from 0.25714\n",
            "4/4 [==============================] - 48s 14s/step - loss: 0.6914 - acc: 0.7633 - val_loss: 3.5310 - val_acc: 0.2571\n",
            "Epoch 12/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7134 - acc: 0.7510\n",
            "Epoch 12: val_acc improved from 0.25714 to 0.31429, saving model to percobaan179_noImgPro/model\\vgg_16_179-saved-model-12-acc-0.31.hdf5\n",
            "4/4 [==============================] - 48s 13s/step - loss: 0.7134 - acc: 0.7510 - val_loss: 2.9604 - val_acc: 0.3143\n",
            "Epoch 13/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6258 - acc: 0.7776\n",
            "Epoch 13: val_acc improved from 0.31429 to 0.32857, saving model to percobaan179_noImgPro/model\\vgg_16_179-saved-model-13-acc-0.33.hdf5\n",
            "4/4 [==============================] - 46s 13s/step - loss: 0.6258 - acc: 0.7776 - val_loss: 2.6347 - val_acc: 0.3286\n",
            "Epoch 14/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5368 - acc: 0.7939\n",
            "Epoch 14: val_acc improved from 0.32857 to 0.42143, saving model to percobaan179_noImgPro/model\\vgg_16_179-saved-model-14-acc-0.42.hdf5\n",
            "4/4 [==============================] - 52s 14s/step - loss: 0.5368 - acc: 0.7939 - val_loss: 2.3518 - val_acc: 0.4214\n",
            "Epoch 15/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5654 - acc: 0.8041\n",
            "Epoch 15: val_acc did not improve from 0.42143\n",
            "4/4 [==============================] - 51s 14s/step - loss: 0.5654 - acc: 0.8041 - val_loss: 2.5772 - val_acc: 0.4143\n",
            "Epoch 16/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5708 - acc: 0.8000\n",
            "Epoch 16: val_acc did not improve from 0.42143\n",
            "4/4 [==============================] - 40s 11s/step - loss: 0.5708 - acc: 0.8000 - val_loss: 2.4629 - val_acc: 0.4143\n",
            "Epoch 17/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4892 - acc: 0.8327\n",
            "Epoch 17: val_acc improved from 0.42143 to 0.51429, saving model to percobaan179_noImgPro/model\\vgg_16_179-saved-model-17-acc-0.51.hdf5\n",
            "4/4 [==============================] - 49s 12s/step - loss: 0.4892 - acc: 0.8327 - val_loss: 1.9550 - val_acc: 0.5143\n",
            "Epoch 18/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4585 - acc: 0.8286\n",
            "Epoch 18: val_acc improved from 0.51429 to 0.53571, saving model to percobaan179_noImgPro/model\\vgg_16_179-saved-model-18-acc-0.54.hdf5\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.4585 - acc: 0.8286 - val_loss: 1.7710 - val_acc: 0.5357\n",
            "Epoch 19/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4233 - acc: 0.8429\n",
            "Epoch 19: val_acc improved from 0.53571 to 0.54286, saving model to percobaan179_noImgPro/model\\vgg_16_179-saved-model-19-acc-0.54.hdf5\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.4233 - acc: 0.8429 - val_loss: 1.5588 - val_acc: 0.5429\n",
            "Epoch 20/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4351 - acc: 0.8673\n",
            "Epoch 20: val_acc did not improve from 0.54286\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.4351 - acc: 0.8673 - val_loss: 1.8818 - val_acc: 0.4643\n",
            "Epoch 21/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5393 - acc: 0.8061\n",
            "Epoch 21: val_acc did not improve from 0.54286\n",
            "4/4 [==============================] - 49s 12s/step - loss: 0.5393 - acc: 0.8061 - val_loss: 1.7043 - val_acc: 0.5286\n",
            "Epoch 22/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4505 - acc: 0.8286\n",
            "Epoch 22: val_acc did not improve from 0.54286\n",
            "4/4 [==============================] - 48s 13s/step - loss: 0.4505 - acc: 0.8286 - val_loss: 1.6308 - val_acc: 0.5429\n",
            "Epoch 23/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4220 - acc: 0.8531\n",
            "Epoch 23: val_acc did not improve from 0.54286\n",
            "4/4 [==============================] - 46s 14s/step - loss: 0.4220 - acc: 0.8531 - val_loss: 2.1958 - val_acc: 0.4571\n",
            "Epoch 24/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4060 - acc: 0.8592\n",
            "Epoch 24: val_acc did not improve from 0.54286\n",
            "4/4 [==============================] - 49s 12s/step - loss: 0.4060 - acc: 0.8592 - val_loss: 3.1434 - val_acc: 0.2643\n",
            "\n",
            "\n",
            "Model Accuracy 0.21428571428571427\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_57148\\3902733085.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.10      0.18        10\n",
            "       10000       1.00      0.30      0.46        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       1.00      0.10      0.18        10\n",
            "       20000       0.15      1.00      0.27        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       0.00      0.00      0.00        10\n",
            "\n",
            "    accuracy                           0.21        70\n",
            "   macro avg       0.45      0.21      0.16        70\n",
            "weighted avg       0.45      0.21      0.16        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 180 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 64\n",
            "learning rate: 0.053614915664819775\n",
            "batch size: 128\n",
            "dropout rate: 0.7822639042235293\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 3.2948 - acc: 0.2204\n",
            "Epoch 1: val_acc improved from -inf to 0.22857, saving model to percobaan180_noImgPro/model\\vgg_16_180-saved-model-01-acc-0.23.hdf5\n",
            "4/4 [==============================] - 41s 11s/step - loss: 3.2948 - acc: 0.2204 - val_loss: 5.5103 - val_acc: 0.2286\n",
            "Epoch 2/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.6412 - acc: 0.2857\n",
            "Epoch 2: val_acc did not improve from 0.22857\n",
            "4/4 [==============================] - 44s 11s/step - loss: 2.6412 - acc: 0.2857 - val_loss: 13.6797 - val_acc: 0.1500\n",
            "Epoch 3/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.1917 - acc: 0.3633\n",
            "Epoch 3: val_acc did not improve from 0.22857\n",
            "4/4 [==============================] - 39s 11s/step - loss: 2.1917 - acc: 0.3633 - val_loss: 8.8308 - val_acc: 0.2214\n",
            "Epoch 4/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.7809 - acc: 0.4265\n",
            "Epoch 4: val_acc did not improve from 0.22857\n",
            "4/4 [==============================] - 45s 11s/step - loss: 1.7809 - acc: 0.4265 - val_loss: 7.0541 - val_acc: 0.2000\n",
            "Epoch 5/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.5324 - acc: 0.4347\n",
            "Epoch 5: val_acc improved from 0.22857 to 0.25000, saving model to percobaan180_noImgPro/model\\vgg_16_180-saved-model-05-acc-0.25.hdf5\n",
            "4/4 [==============================] - 39s 11s/step - loss: 1.5324 - acc: 0.4347 - val_loss: 4.5913 - val_acc: 0.2500\n",
            "Epoch 6/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.4820 - acc: 0.4837\n",
            "Epoch 6: val_acc did not improve from 0.25000\n",
            "4/4 [==============================] - 48s 12s/step - loss: 1.4820 - acc: 0.4837 - val_loss: 3.6043 - val_acc: 0.2500\n",
            "Epoch 7/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.3061 - acc: 0.5184\n",
            "Epoch 7: val_acc improved from 0.25000 to 0.26429, saving model to percobaan180_noImgPro/model\\vgg_16_180-saved-model-07-acc-0.26.hdf5\n",
            "4/4 [==============================] - 41s 12s/step - loss: 1.3061 - acc: 0.5184 - val_loss: 2.4537 - val_acc: 0.2643\n",
            "Epoch 8/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.3306 - acc: 0.5490\n",
            "Epoch 8: val_acc did not improve from 0.26429\n",
            "4/4 [==============================] - 49s 12s/step - loss: 1.3306 - acc: 0.5490 - val_loss: 2.1504 - val_acc: 0.2357\n",
            "Epoch 9/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0814 - acc: 0.5796\n",
            "Epoch 9: val_acc improved from 0.26429 to 0.28571, saving model to percobaan180_noImgPro/model\\vgg_16_180-saved-model-09-acc-0.29.hdf5\n",
            "4/4 [==============================] - 50s 12s/step - loss: 1.0814 - acc: 0.5796 - val_loss: 1.9017 - val_acc: 0.2857\n",
            "Epoch 10/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0467 - acc: 0.5980\n",
            "Epoch 10: val_acc improved from 0.28571 to 0.32143, saving model to percobaan180_noImgPro/model\\vgg_16_180-saved-model-10-acc-0.32.hdf5\n",
            "4/4 [==============================] - 46s 11s/step - loss: 1.0467 - acc: 0.5980 - val_loss: 1.8567 - val_acc: 0.3214\n",
            "Epoch 11/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0401 - acc: 0.6449\n",
            "Epoch 11: val_acc did not improve from 0.32143\n",
            "4/4 [==============================] - 38s 11s/step - loss: 1.0401 - acc: 0.6449 - val_loss: 2.3005 - val_acc: 0.2357\n",
            "Epoch 12/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9042 - acc: 0.6714\n",
            "Epoch 12: val_acc did not improve from 0.32143\n",
            "4/4 [==============================] - 45s 11s/step - loss: 0.9042 - acc: 0.6714 - val_loss: 2.5545 - val_acc: 0.2429\n",
            "Epoch 13/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9024 - acc: 0.7020\n",
            "Epoch 13: val_acc improved from 0.32143 to 0.37857, saving model to percobaan180_noImgPro/model\\vgg_16_180-saved-model-13-acc-0.38.hdf5\n",
            "4/4 [==============================] - 38s 11s/step - loss: 0.9024 - acc: 0.7020 - val_loss: 2.1549 - val_acc: 0.3786\n",
            "Epoch 14/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7937 - acc: 0.7163\n",
            "Epoch 14: val_acc improved from 0.37857 to 0.39286, saving model to percobaan180_noImgPro/model\\vgg_16_180-saved-model-14-acc-0.39.hdf5\n",
            "4/4 [==============================] - 44s 11s/step - loss: 0.7937 - acc: 0.7163 - val_loss: 1.8979 - val_acc: 0.3929\n",
            "Epoch 15/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7831 - acc: 0.7000\n",
            "Epoch 15: val_acc did not improve from 0.39286\n",
            "4/4 [==============================] - 45s 11s/step - loss: 0.7831 - acc: 0.7000 - val_loss: 2.0201 - val_acc: 0.3857\n",
            "\n",
            "\n",
            "Model Accuracy 0.2714285714285714\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_57148\\3902733085.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.40      0.57        10\n",
            "       10000       0.50      0.20      0.29        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.00      0.00      0.00        10\n",
            "       20000       0.17      0.90      0.29        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       0.44      0.40      0.42        10\n",
            "\n",
            "    accuracy                           0.27        70\n",
            "   macro avg       0.30      0.27      0.22        70\n",
            "weighted avg       0.30      0.27      0.22        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 181 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 58\n",
            "learning rate: 0.09952692676447965\n",
            "batch size: 32\n",
            "dropout rate: 0.5375480463188825\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 3.5325 - acc: 0.3000\n",
            "Epoch 1: val_acc improved from -inf to 0.14286, saving model to percobaan181_noImgPro/model\\vgg_16_181-saved-model-01-acc-0.14.hdf5\n",
            "16/16 [==============================] - 40s 2s/step - loss: 3.5325 - acc: 0.3000 - val_loss: 12.4380 - val_acc: 0.1429\n",
            "Epoch 2/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.5126 - acc: 0.3531\n",
            "Epoch 2: val_acc improved from 0.14286 to 0.16429, saving model to percobaan181_noImgPro/model\\vgg_16_181-saved-model-02-acc-0.16.hdf5\n",
            "16/16 [==============================] - 45s 3s/step - loss: 2.5126 - acc: 0.3531 - val_loss: 4.6431 - val_acc: 0.1643\n",
            "Epoch 3/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.9314 - acc: 0.4245\n",
            "Epoch 3: val_acc improved from 0.16429 to 0.35714, saving model to percobaan181_noImgPro/model\\vgg_16_181-saved-model-03-acc-0.36.hdf5\n",
            "16/16 [==============================] - 44s 3s/step - loss: 1.9314 - acc: 0.4245 - val_loss: 1.9886 - val_acc: 0.3571\n",
            "Epoch 4/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.5846 - acc: 0.5184\n",
            "Epoch 4: val_acc did not improve from 0.35714\n",
            "16/16 [==============================] - 44s 3s/step - loss: 1.5846 - acc: 0.5184 - val_loss: 4.2650 - val_acc: 0.1643\n",
            "Epoch 5/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2009 - acc: 0.5959\n",
            "Epoch 5: val_acc improved from 0.35714 to 0.37857, saving model to percobaan181_noImgPro/model\\vgg_16_181-saved-model-05-acc-0.38.hdf5\n",
            "16/16 [==============================] - 45s 3s/step - loss: 1.2009 - acc: 0.5959 - val_loss: 2.1881 - val_acc: 0.3786\n",
            "Epoch 6/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2824 - acc: 0.5939\n",
            "Epoch 6: val_acc improved from 0.37857 to 0.57857, saving model to percobaan181_noImgPro/model\\vgg_16_181-saved-model-06-acc-0.58.hdf5\n",
            "16/16 [==============================] - 39s 2s/step - loss: 1.2824 - acc: 0.5939 - val_loss: 1.2229 - val_acc: 0.5786\n",
            "Epoch 7/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.5764 - acc: 0.5551\n",
            "Epoch 7: val_acc did not improve from 0.57857\n",
            "16/16 [==============================] - 45s 3s/step - loss: 1.5764 - acc: 0.5551 - val_loss: 1.9832 - val_acc: 0.4214\n",
            "Epoch 8/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2719 - acc: 0.6224\n",
            "Epoch 8: val_acc did not improve from 0.57857\n",
            "16/16 [==============================] - 44s 3s/step - loss: 1.2719 - acc: 0.6224 - val_loss: 2.1102 - val_acc: 0.4286\n",
            "Epoch 9/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9819 - acc: 0.7143\n",
            "Epoch 9: val_acc improved from 0.57857 to 0.64286, saving model to percobaan181_noImgPro/model\\vgg_16_181-saved-model-09-acc-0.64.hdf5\n",
            "16/16 [==============================] - 44s 3s/step - loss: 0.9819 - acc: 0.7143 - val_loss: 1.7725 - val_acc: 0.6429\n",
            "Epoch 10/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1143 - acc: 0.6898\n",
            "Epoch 10: val_acc did not improve from 0.64286\n",
            "16/16 [==============================] - 45s 3s/step - loss: 1.1143 - acc: 0.6898 - val_loss: 3.5302 - val_acc: 0.3643\n",
            "Epoch 11/58\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0536 - acc: 0.7041\n",
            "Epoch 11: val_acc did not improve from 0.64286\n",
            "16/16 [==============================] - 45s 3s/step - loss: 1.0536 - acc: 0.7041 - val_loss: 2.0148 - val_acc: 0.5500\n",
            "\n",
            "\n",
            "Model Accuracy 0.5285714285714286\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_57148\\2095710237.py:11: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
            "  plt.figure(figsize=(7,7))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_57148\\3902733085.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.30      0.46        10\n",
            "       10000       0.80      0.40      0.53        10\n",
            "      100000       0.88      0.70      0.78        10\n",
            "        2000       0.34      1.00      0.51        10\n",
            "       20000       0.00      0.00      0.00        10\n",
            "        5000       0.42      0.80      0.55        10\n",
            "       50000       0.83      0.50      0.62        10\n",
            "\n",
            "    accuracy                           0.53        70\n",
            "   macro avg       0.61      0.53      0.49        70\n",
            "weighted avg       0.61      0.53      0.49        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 182 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 64\n",
            "learning rate: 0.09193259745962626\n",
            "batch size: 32\n",
            "dropout rate: 0.5834423368272322\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/64\n",
            "16/16 [==============================] - ETA: 0s - loss: 3.8203 - acc: 0.2918\n",
            "Epoch 1: val_acc improved from -inf to 0.25714, saving model to percobaan182_noImgPro/model\\vgg_16_182-saved-model-01-acc-0.26.hdf5\n",
            "16/16 [==============================] - 40s 3s/step - loss: 3.8203 - acc: 0.2918 - val_loss: 5.0917 - val_acc: 0.2571\n",
            "Epoch 2/64\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.6573 - acc: 0.3816\n",
            "Epoch 2: val_acc did not improve from 0.25714\n",
            "16/16 [==============================] - 44s 3s/step - loss: 2.6573 - acc: 0.3816 - val_loss: 3.7044 - val_acc: 0.1714\n",
            "Epoch 3/64\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.7077 - acc: 0.4633\n",
            "Epoch 3: val_acc improved from 0.25714 to 0.40714, saving model to percobaan182_noImgPro/model\\vgg_16_182-saved-model-03-acc-0.41.hdf5\n",
            "16/16 [==============================] - 39s 2s/step - loss: 1.7077 - acc: 0.4633 - val_loss: 1.7950 - val_acc: 0.4071\n",
            "Epoch 4/64\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.5905 - acc: 0.4959\n",
            "Epoch 4: val_acc improved from 0.40714 to 0.51429, saving model to percobaan182_noImgPro/model\\vgg_16_182-saved-model-04-acc-0.51.hdf5\n",
            "16/16 [==============================] - 44s 3s/step - loss: 1.5905 - acc: 0.4959 - val_loss: 1.3372 - val_acc: 0.5143\n",
            "Epoch 5/64\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3572 - acc: 0.5612\n",
            "Epoch 5: val_acc did not improve from 0.51429\n",
            "16/16 [==============================] - 44s 3s/step - loss: 1.3572 - acc: 0.5612 - val_loss: 2.4072 - val_acc: 0.4429\n",
            "Epoch 6/64\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1698 - acc: 0.6388\n",
            "Epoch 6: val_acc did not improve from 0.51429\n",
            "16/16 [==============================] - 41s 3s/step - loss: 1.1698 - acc: 0.6388 - val_loss: 1.6305 - val_acc: 0.5071\n",
            "Epoch 7/64\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0555 - acc: 0.6571\n",
            "Epoch 7: val_acc did not improve from 0.51429\n",
            "16/16 [==============================] - 43s 2s/step - loss: 1.0555 - acc: 0.6571 - val_loss: 1.8561 - val_acc: 0.4500\n",
            "Epoch 8/64\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0450 - acc: 0.6531\n",
            "Epoch 8: val_acc improved from 0.51429 to 0.69286, saving model to percobaan182_noImgPro/model\\vgg_16_182-saved-model-08-acc-0.69.hdf5\n",
            "16/16 [==============================] - 44s 3s/step - loss: 1.0450 - acc: 0.6531 - val_loss: 0.9860 - val_acc: 0.6929\n",
            "Epoch 9/64\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0337 - acc: 0.6531\n",
            "Epoch 9: val_acc did not improve from 0.69286\n",
            "16/16 [==============================] - 39s 2s/step - loss: 1.0337 - acc: 0.6531 - val_loss: 1.5813 - val_acc: 0.5143\n",
            "Epoch 10/64\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0099 - acc: 0.6878\n",
            "Epoch 10: val_acc did not improve from 0.69286\n",
            "16/16 [==============================] - 44s 3s/step - loss: 1.0099 - acc: 0.6878 - val_loss: 2.5659 - val_acc: 0.4929\n",
            "Epoch 11/64\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1702 - acc: 0.6918\n",
            "Epoch 11: val_acc did not improve from 0.69286\n",
            "16/16 [==============================] - 39s 2s/step - loss: 1.1702 - acc: 0.6918 - val_loss: 1.7932 - val_acc: 0.5643\n",
            "Epoch 12/64\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3215 - acc: 0.6653\n",
            "Epoch 12: val_acc did not improve from 0.69286\n",
            "16/16 [==============================] - 44s 3s/step - loss: 1.3215 - acc: 0.6653 - val_loss: 4.9976 - val_acc: 0.2786\n",
            "Epoch 13/64\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3770 - acc: 0.6408\n",
            "Epoch 13: val_acc did not improve from 0.69286\n",
            "16/16 [==============================] - 39s 3s/step - loss: 1.3770 - acc: 0.6408 - val_loss: 2.5767 - val_acc: 0.6071\n",
            "\n",
            "\n",
            "Model Accuracy 0.5428571428571428\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_57148\\3902733085.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.47      0.90      0.62        10\n",
            "       10000       0.42      1.00      0.59        10\n",
            "      100000       1.00      0.50      0.67        10\n",
            "        2000       0.00      0.00      0.00        10\n",
            "       20000       0.50      0.70      0.58        10\n",
            "        5000       0.75      0.30      0.43        10\n",
            "       50000       1.00      0.40      0.57        10\n",
            "\n",
            "    accuracy                           0.54        70\n",
            "   macro avg       0.59      0.54      0.49        70\n",
            "weighted avg       0.59      0.54      0.49        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 183 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 61\n",
            "learning rate: 0.09225142690123946\n",
            "batch size: 32\n",
            "dropout rate: 0.7057671620550943\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 5.2936 - acc: 0.2163\n",
            "Epoch 1: val_acc improved from -inf to 0.16429, saving model to percobaan183_noImgPro/model\\vgg_16_183-saved-model-01-acc-0.16.hdf5\n",
            "16/16 [==============================] - 45s 3s/step - loss: 5.2936 - acc: 0.2163 - val_loss: 10.1152 - val_acc: 0.1643\n",
            "Epoch 2/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 3.7229 - acc: 0.2531\n",
            "Epoch 2: val_acc improved from 0.16429 to 0.22857, saving model to percobaan183_noImgPro/model\\vgg_16_183-saved-model-02-acc-0.23.hdf5\n",
            "16/16 [==============================] - 39s 2s/step - loss: 3.7229 - acc: 0.2531 - val_loss: 3.0911 - val_acc: 0.2286\n",
            "Epoch 3/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.1872 - acc: 0.3286\n",
            "Epoch 3: val_acc improved from 0.22857 to 0.45000, saving model to percobaan183_noImgPro/model\\vgg_16_183-saved-model-03-acc-0.45.hdf5\n",
            "16/16 [==============================] - 45s 3s/step - loss: 2.1872 - acc: 0.3286 - val_loss: 1.5781 - val_acc: 0.4500\n",
            "Epoch 4/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.8994 - acc: 0.3653\n",
            "Epoch 4: val_acc did not improve from 0.45000\n",
            "16/16 [==============================] - 39s 2s/step - loss: 1.8994 - acc: 0.3653 - val_loss: 1.8887 - val_acc: 0.3786\n",
            "Epoch 5/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.6814 - acc: 0.4327\n",
            "Epoch 5: val_acc did not improve from 0.45000\n",
            "16/16 [==============================] - 45s 3s/step - loss: 1.6814 - acc: 0.4327 - val_loss: 1.4267 - val_acc: 0.4429\n",
            "Epoch 6/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.5691 - acc: 0.4653\n",
            "Epoch 6: val_acc did not improve from 0.45000\n",
            "16/16 [==============================] - 44s 3s/step - loss: 1.5691 - acc: 0.4653 - val_loss: 1.9892 - val_acc: 0.2786\n",
            "Epoch 7/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.4159 - acc: 0.5102\n",
            "Epoch 7: val_acc did not improve from 0.45000\n",
            "16/16 [==============================] - 38s 2s/step - loss: 1.4159 - acc: 0.5102 - val_loss: 2.1967 - val_acc: 0.2929\n",
            "Epoch 8/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.6608 - acc: 0.4857\n",
            "Epoch 8: val_acc did not improve from 0.45000\n",
            "16/16 [==============================] - 44s 3s/step - loss: 1.6608 - acc: 0.4857 - val_loss: 1.5753 - val_acc: 0.3929\n",
            "Epoch 9/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.4602 - acc: 0.5102\n",
            "Epoch 9: val_acc improved from 0.45000 to 0.67143, saving model to percobaan183_noImgPro/model\\vgg_16_183-saved-model-09-acc-0.67.hdf5\n",
            "16/16 [==============================] - 39s 2s/step - loss: 1.4602 - acc: 0.5102 - val_loss: 0.9707 - val_acc: 0.6714\n",
            "Epoch 10/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3597 - acc: 0.5531\n",
            "Epoch 10: val_acc did not improve from 0.67143\n",
            "16/16 [==============================] - 45s 3s/step - loss: 1.3597 - acc: 0.5531 - val_loss: 1.0321 - val_acc: 0.6429\n",
            "Epoch 11/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3987 - acc: 0.5469\n",
            "Epoch 11: val_acc did not improve from 0.67143\n",
            "16/16 [==============================] - 39s 2s/step - loss: 1.3987 - acc: 0.5469 - val_loss: 0.9951 - val_acc: 0.6071\n",
            "Epoch 12/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3129 - acc: 0.5816\n",
            "Epoch 12: val_acc improved from 0.67143 to 0.72857, saving model to percobaan183_noImgPro/model\\vgg_16_183-saved-model-12-acc-0.73.hdf5\n",
            "16/16 [==============================] - 38s 2s/step - loss: 1.3129 - acc: 0.5816 - val_loss: 0.8838 - val_acc: 0.7286\n",
            "Epoch 13/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.5289 - acc: 0.5204\n",
            "Epoch 13: val_acc did not improve from 0.72857\n",
            "16/16 [==============================] - 45s 3s/step - loss: 1.5289 - acc: 0.5204 - val_loss: 1.1084 - val_acc: 0.6500\n",
            "Epoch 14/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.4721 - acc: 0.5796\n",
            "Epoch 14: val_acc improved from 0.72857 to 0.76429, saving model to percobaan183_noImgPro/model\\vgg_16_183-saved-model-14-acc-0.76.hdf5\n",
            "16/16 [==============================] - 39s 2s/step - loss: 1.4721 - acc: 0.5796 - val_loss: 0.8254 - val_acc: 0.7643\n",
            "Epoch 15/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3437 - acc: 0.5612\n",
            "Epoch 15: val_acc improved from 0.76429 to 0.79286, saving model to percobaan183_noImgPro/model\\vgg_16_183-saved-model-15-acc-0.79.hdf5\n",
            "16/16 [==============================] - 44s 3s/step - loss: 1.3437 - acc: 0.5612 - val_loss: 0.7306 - val_acc: 0.7929\n",
            "Epoch 16/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.2880 - acc: 0.6184\n",
            "Epoch 16: val_acc did not improve from 0.79286\n",
            "16/16 [==============================] - 39s 2s/step - loss: 1.2880 - acc: 0.6184 - val_loss: 0.8761 - val_acc: 0.6929\n",
            "Epoch 17/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.4281 - acc: 0.5898\n",
            "Epoch 17: val_acc did not improve from 0.79286\n",
            "16/16 [==============================] - 39s 2s/step - loss: 1.4281 - acc: 0.5898 - val_loss: 1.1285 - val_acc: 0.6214\n",
            "Epoch 18/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.5353 - acc: 0.5878\n",
            "Epoch 18: val_acc did not improve from 0.79286\n",
            "16/16 [==============================] - 45s 3s/step - loss: 1.5353 - acc: 0.5878 - val_loss: 1.3632 - val_acc: 0.6071\n",
            "Epoch 19/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3405 - acc: 0.5980\n",
            "Epoch 19: val_acc did not improve from 0.79286\n",
            "16/16 [==============================] - 38s 2s/step - loss: 1.3405 - acc: 0.5980 - val_loss: 1.0543 - val_acc: 0.7000\n",
            "Epoch 20/61\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3066 - acc: 0.6449\n",
            "Epoch 20: val_acc did not improve from 0.79286\n",
            "16/16 [==============================] - 44s 3s/step - loss: 1.3066 - acc: 0.6449 - val_loss: 0.9593 - val_acc: 0.7714\n",
            "\n",
            "\n",
            "Model Accuracy 0.6571428571428571\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.45      1.00      0.62        10\n",
            "       10000       0.55      0.60      0.57        10\n",
            "      100000       0.77      1.00      0.87        10\n",
            "        2000       1.00      0.40      0.57        10\n",
            "       20000       1.00      0.20      0.33        10\n",
            "        5000       0.80      0.40      0.53        10\n",
            "       50000       0.77      1.00      0.87        10\n",
            "\n",
            "    accuracy                           0.66        70\n",
            "   macro avg       0.76      0.66      0.62        70\n",
            "weighted avg       0.76      0.66      0.62        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 184 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 59\n",
            "learning rate: 0.08658644654143674\n",
            "batch size: 32\n",
            "dropout rate: 0.726183385614934\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_57148\\3902733085.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/59\n",
            "16/16 [==============================] - ETA: 0s - loss: 4.3477 - acc: 0.2306\n",
            "Epoch 1: val_acc improved from -inf to 0.17143, saving model to percobaan184_noImgPro/model\\vgg_16_184-saved-model-01-acc-0.17.hdf5\n",
            "16/16 [==============================] - 42s 3s/step - loss: 4.3477 - acc: 0.2306 - val_loss: 7.1786 - val_acc: 0.1714\n",
            "Epoch 2/59\n",
            "16/16 [==============================] - ETA: 0s - loss: 3.3358 - acc: 0.2592\n",
            "Epoch 2: val_acc improved from 0.17143 to 0.24286, saving model to percobaan184_noImgPro/model\\vgg_16_184-saved-model-02-acc-0.24.hdf5\n",
            "16/16 [==============================] - 41s 3s/step - loss: 3.3358 - acc: 0.2592 - val_loss: 3.8339 - val_acc: 0.2429\n",
            "Epoch 3/59\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.3106 - acc: 0.2959\n",
            "Epoch 3: val_acc improved from 0.24286 to 0.39286, saving model to percobaan184_noImgPro/model\\vgg_16_184-saved-model-03-acc-0.39.hdf5\n",
            "16/16 [==============================] - 47s 3s/step - loss: 2.3106 - acc: 0.2959 - val_loss: 1.6620 - val_acc: 0.3929\n",
            "Epoch 4/59\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.8850 - acc: 0.3469\n",
            "Epoch 4: val_acc did not improve from 0.39286\n",
            "16/16 [==============================] - 40s 3s/step - loss: 1.8850 - acc: 0.3469 - val_loss: 2.3971 - val_acc: 0.2286\n",
            "Epoch 5/59\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.6797 - acc: 0.4367\n",
            "Epoch 5: val_acc did not improve from 0.39286\n",
            "16/16 [==============================] - 47s 3s/step - loss: 1.6797 - acc: 0.4367 - val_loss: 2.3987 - val_acc: 0.3571\n",
            "Epoch 6/59\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.6351 - acc: 0.4510\n",
            "Epoch 6: val_acc improved from 0.39286 to 0.47857, saving model to percobaan184_noImgPro/model\\vgg_16_184-saved-model-06-acc-0.48.hdf5\n",
            "16/16 [==============================] - 40s 3s/step - loss: 1.6351 - acc: 0.4510 - val_loss: 1.8137 - val_acc: 0.4786\n",
            "Epoch 7/59\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.4826 - acc: 0.4694\n",
            "Epoch 7: val_acc did not improve from 0.47857\n",
            "16/16 [==============================] - 48s 3s/step - loss: 1.4826 - acc: 0.4694 - val_loss: 1.6267 - val_acc: 0.4500\n",
            "Epoch 8/59\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.5624 - acc: 0.5020\n",
            "Epoch 8: val_acc did not improve from 0.47857\n",
            "16/16 [==============================] - 41s 3s/step - loss: 1.5624 - acc: 0.5020 - val_loss: 2.5833 - val_acc: 0.2857\n",
            "Epoch 9/59\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.4881 - acc: 0.5122\n",
            "Epoch 9: val_acc did not improve from 0.47857\n",
            "16/16 [==============================] - 48s 3s/step - loss: 1.4881 - acc: 0.5122 - val_loss: 2.4514 - val_acc: 0.2929\n",
            "Epoch 10/59\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.4697 - acc: 0.5347\n",
            "Epoch 10: val_acc did not improve from 0.47857\n",
            "16/16 [==============================] - 40s 3s/step - loss: 1.4697 - acc: 0.5347 - val_loss: 1.7032 - val_acc: 0.4500\n",
            "Epoch 11/59\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.4579 - acc: 0.5510\n",
            "Epoch 11: val_acc improved from 0.47857 to 0.60000, saving model to percobaan184_noImgPro/model\\vgg_16_184-saved-model-11-acc-0.60.hdf5\n",
            "16/16 [==============================] - 48s 3s/step - loss: 1.4579 - acc: 0.5510 - val_loss: 1.4966 - val_acc: 0.6000\n",
            "Epoch 12/59\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.4690 - acc: 0.5490\n",
            "Epoch 12: val_acc did not improve from 0.60000\n",
            "16/16 [==============================] - 40s 3s/step - loss: 1.4690 - acc: 0.5490 - val_loss: 2.1055 - val_acc: 0.4429\n",
            "Epoch 13/59\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.4371 - acc: 0.5918\n",
            "Epoch 13: val_acc did not improve from 0.60000\n",
            "16/16 [==============================] - 47s 3s/step - loss: 1.4371 - acc: 0.5918 - val_loss: 3.0266 - val_acc: 0.4214\n",
            "Epoch 14/59\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.5632 - acc: 0.5551\n",
            "Epoch 14: val_acc did not improve from 0.60000\n",
            "16/16 [==============================] - 40s 3s/step - loss: 1.5632 - acc: 0.5551 - val_loss: 2.7579 - val_acc: 0.4286\n",
            "Epoch 15/59\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.8635 - acc: 0.5163\n",
            "Epoch 15: val_acc did not improve from 0.60000\n",
            "16/16 [==============================] - 47s 3s/step - loss: 1.8635 - acc: 0.5163 - val_loss: 1.7194 - val_acc: 0.5500\n",
            "Epoch 16/59\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.7451 - acc: 0.5122\n",
            "Epoch 16: val_acc did not improve from 0.60000\n",
            "16/16 [==============================] - 40s 3s/step - loss: 1.7451 - acc: 0.5122 - val_loss: 2.5548 - val_acc: 0.4143\n",
            "\n",
            "\n",
            "Model Accuracy 0.37142857142857144\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_57148\\3902733085.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.00      0.00      0.00        10\n",
            "       10000       0.00      0.00      0.00        10\n",
            "      100000       0.88      0.70      0.78        10\n",
            "        2000       0.36      0.80      0.50        10\n",
            "       20000       0.24      0.90      0.38        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       1.00      0.20      0.33        10\n",
            "\n",
            "    accuracy                           0.37        70\n",
            "   macro avg       0.35      0.37      0.28        70\n",
            "weighted avg       0.35      0.37      0.28        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 185 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 59\n",
            "learning rate: 0.07734945974226162\n",
            "batch size: 64\n",
            "dropout rate: 0.5188873335448414\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/59\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.8043 - acc: 0.3347\n",
            "Epoch 1: val_acc improved from -inf to 0.22143, saving model to percobaan185_noImgPro/model\\vgg_16_185-saved-model-01-acc-0.22.hdf5\n",
            "8/8 [==============================] - 44s 5s/step - loss: 2.8043 - acc: 0.3347 - val_loss: 6.9647 - val_acc: 0.2214\n",
            "Epoch 2/59\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8052 - acc: 0.5163\n",
            "Epoch 2: val_acc improved from 0.22143 to 0.23571, saving model to percobaan185_noImgPro/model\\vgg_16_185-saved-model-02-acc-0.24.hdf5\n",
            "8/8 [==============================] - 41s 5s/step - loss: 1.8052 - acc: 0.5163 - val_loss: 5.3182 - val_acc: 0.2357\n",
            "Epoch 3/59\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4091 - acc: 0.5449\n",
            "Epoch 3: val_acc improved from 0.23571 to 0.25714, saving model to percobaan185_noImgPro/model\\vgg_16_185-saved-model-03-acc-0.26.hdf5\n",
            "8/8 [==============================] - 41s 5s/step - loss: 1.4091 - acc: 0.5449 - val_loss: 3.3040 - val_acc: 0.2571\n",
            "Epoch 4/59\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0076 - acc: 0.6878\n",
            "Epoch 4: val_acc did not improve from 0.25714\n",
            "8/8 [==============================] - 45s 6s/step - loss: 1.0076 - acc: 0.6878 - val_loss: 5.0168 - val_acc: 0.2286\n",
            "Epoch 5/59\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8949 - acc: 0.6959\n",
            "Epoch 5: val_acc improved from 0.25714 to 0.32857, saving model to percobaan185_noImgPro/model\\vgg_16_185-saved-model-05-acc-0.33.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.8949 - acc: 0.6959 - val_loss: 2.8156 - val_acc: 0.3286\n",
            "Epoch 6/59\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7673 - acc: 0.7122\n",
            "Epoch 6: val_acc improved from 0.32857 to 0.50000, saving model to percobaan185_noImgPro/model\\vgg_16_185-saved-model-06-acc-0.50.hdf5\n",
            "8/8 [==============================] - 47s 6s/step - loss: 0.7673 - acc: 0.7122 - val_loss: 1.5325 - val_acc: 0.5000\n",
            "Epoch 7/59\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5880 - acc: 0.8122\n",
            "Epoch 7: val_acc improved from 0.50000 to 0.59286, saving model to percobaan185_noImgPro/model\\vgg_16_185-saved-model-07-acc-0.59.hdf5\n",
            "8/8 [==============================] - 40s 5s/step - loss: 0.5880 - acc: 0.8122 - val_loss: 1.1673 - val_acc: 0.5929\n",
            "Epoch 8/59\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5325 - acc: 0.8122\n",
            "Epoch 8: val_acc improved from 0.59286 to 0.69286, saving model to percobaan185_noImgPro/model\\vgg_16_185-saved-model-08-acc-0.69.hdf5\n",
            "8/8 [==============================] - 48s 6s/step - loss: 0.5325 - acc: 0.8122 - val_loss: 1.0214 - val_acc: 0.6929\n",
            "Epoch 9/59\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5816 - acc: 0.8102\n",
            "Epoch 9: val_acc did not improve from 0.69286\n",
            "8/8 [==============================] - 40s 5s/step - loss: 0.5816 - acc: 0.8102 - val_loss: 0.9685 - val_acc: 0.6714\n",
            "Epoch 10/59\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5550 - acc: 0.8204\n",
            "Epoch 10: val_acc did not improve from 0.69286\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.5550 - acc: 0.8204 - val_loss: 1.8559 - val_acc: 0.5429\n",
            "Epoch 11/59\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5510 - acc: 0.8082\n",
            "Epoch 11: val_acc did not improve from 0.69286\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.5510 - acc: 0.8082 - val_loss: 1.1754 - val_acc: 0.5929\n",
            "Epoch 12/59\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5391 - acc: 0.8408\n",
            "Epoch 12: val_acc did not improve from 0.69286\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.5391 - acc: 0.8408 - val_loss: 1.1306 - val_acc: 0.6571\n",
            "Epoch 13/59\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4628 - acc: 0.8510\n",
            "Epoch 13: val_acc did not improve from 0.69286\n",
            "8/8 [==============================] - 46s 6s/step - loss: 0.4628 - acc: 0.8510 - val_loss: 0.9531 - val_acc: 0.6714\n",
            "Epoch 14/59\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4863 - acc: 0.8469\n",
            "Epoch 14: val_acc did not improve from 0.69286\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.4863 - acc: 0.8469 - val_loss: 1.5074 - val_acc: 0.5143\n",
            "Epoch 15/59\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5241 - acc: 0.8306\n",
            "Epoch 15: val_acc did not improve from 0.69286\n",
            "8/8 [==============================] - 43s 6s/step - loss: 0.5241 - acc: 0.8306 - val_loss: 0.9217 - val_acc: 0.6929\n",
            "Epoch 16/59\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4947 - acc: 0.8429\n",
            "Epoch 16: val_acc improved from 0.69286 to 0.79286, saving model to percobaan185_noImgPro/model\\vgg_16_185-saved-model-16-acc-0.79.hdf5\n",
            "8/8 [==============================] - 46s 5s/step - loss: 0.4947 - acc: 0.8429 - val_loss: 0.7911 - val_acc: 0.7929\n",
            "Epoch 17/59\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5159 - acc: 0.8633\n",
            "Epoch 17: val_acc did not improve from 0.79286\n",
            "8/8 [==============================] - 41s 5s/step - loss: 0.5159 - acc: 0.8633 - val_loss: 1.9748 - val_acc: 0.5500\n",
            "Epoch 18/59\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5621 - acc: 0.8408\n",
            "Epoch 18: val_acc did not improve from 0.79286\n",
            "8/8 [==============================] - 47s 6s/step - loss: 0.5621 - acc: 0.8408 - val_loss: 2.0360 - val_acc: 0.5357\n",
            "Epoch 19/59\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4205 - acc: 0.8469\n",
            "Epoch 19: val_acc did not improve from 0.79286\n",
            "8/8 [==============================] - 48s 6s/step - loss: 0.4205 - acc: 0.8469 - val_loss: 2.2264 - val_acc: 0.5143\n",
            "Epoch 20/59\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5056 - acc: 0.8510\n",
            "Epoch 20: val_acc did not improve from 0.79286\n",
            "8/8 [==============================] - 48s 6s/step - loss: 0.5056 - acc: 0.8510 - val_loss: 2.2797 - val_acc: 0.5571\n",
            "Epoch 21/59\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4039 - acc: 0.8735\n",
            "Epoch 21: val_acc did not improve from 0.79286\n",
            "8/8 [==============================] - 46s 6s/step - loss: 0.4039 - acc: 0.8735 - val_loss: 2.5227 - val_acc: 0.4571\n",
            "\n",
            "\n",
            "Model Accuracy 0.37142857142857144\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_57148\\3902733085.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.86      0.60      0.71        10\n",
            "       10000       1.00      0.20      0.33        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.67      0.20      0.31        10\n",
            "       20000       0.00      0.00      0.00        10\n",
            "        5000       0.20      1.00      0.33        10\n",
            "       50000       0.75      0.60      0.67        10\n",
            "\n",
            "    accuracy                           0.37        70\n",
            "   macro avg       0.50      0.37      0.34        70\n",
            "weighted avg       0.50      0.37      0.34        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 186 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 64\n",
            "learning rate: 0.07947062888733505\n",
            "batch size: 64\n",
            "dropout rate: 0.5905997755879455\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/64\n",
            "8/8 [==============================] - ETA: 0s - loss: 3.0785 - acc: 0.2755\n",
            "Epoch 1: val_acc improved from -inf to 0.14286, saving model to percobaan186_noImgPro/model\\vgg_16_186-saved-model-01-acc-0.14.hdf5\n",
            "8/8 [==============================] - 49s 6s/step - loss: 3.0785 - acc: 0.2755 - val_loss: 26.3816 - val_acc: 0.1429\n",
            "Epoch 2/64\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.0513 - acc: 0.4429\n",
            "Epoch 2: val_acc improved from 0.14286 to 0.17857, saving model to percobaan186_noImgPro/model\\vgg_16_186-saved-model-02-acc-0.18.hdf5\n",
            "8/8 [==============================] - 32s 4s/step - loss: 2.0513 - acc: 0.4429 - val_loss: 5.2053 - val_acc: 0.1786\n",
            "Epoch 3/64\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7128 - acc: 0.4776\n",
            "Epoch 3: val_acc improved from 0.17857 to 0.27143, saving model to percobaan186_noImgPro/model\\vgg_16_186-saved-model-03-acc-0.27.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 1.7128 - acc: 0.4776 - val_loss: 3.7429 - val_acc: 0.2714\n",
            "Epoch 4/64\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.2479 - acc: 0.5755\n",
            "Epoch 4: val_acc did not improve from 0.27143\n",
            "8/8 [==============================] - 40s 5s/step - loss: 1.2479 - acc: 0.5755 - val_loss: 5.1326 - val_acc: 0.2643\n",
            "Epoch 5/64\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1286 - acc: 0.6204\n",
            "Epoch 5: val_acc did not improve from 0.27143\n",
            "8/8 [==============================] - 41s 5s/step - loss: 1.1286 - acc: 0.6204 - val_loss: 4.0900 - val_acc: 0.2000\n",
            "Epoch 6/64\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8750 - acc: 0.6796\n",
            "Epoch 6: val_acc improved from 0.27143 to 0.27857, saving model to percobaan186_noImgPro/model\\vgg_16_186-saved-model-06-acc-0.28.hdf5\n",
            "8/8 [==============================] - 47s 6s/step - loss: 0.8750 - acc: 0.6796 - val_loss: 3.8684 - val_acc: 0.2786\n",
            "Epoch 7/64\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7744 - acc: 0.7306\n",
            "Epoch 7: val_acc did not improve from 0.27857\n",
            "8/8 [==============================] - 47s 6s/step - loss: 0.7744 - acc: 0.7306 - val_loss: 5.4790 - val_acc: 0.1500\n",
            "Epoch 8/64\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7688 - acc: 0.7510\n",
            "Epoch 8: val_acc did not improve from 0.27857\n",
            "8/8 [==============================] - 46s 6s/step - loss: 0.7688 - acc: 0.7510 - val_loss: 6.9767 - val_acc: 0.1429\n",
            "\n",
            "\n",
            "Model Accuracy 0.14285714285714285\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_57148\\3902733085.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.00      0.00      0.00        10\n",
            "       10000       0.00      0.00      0.00        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.00      0.00      0.00        10\n",
            "       20000       0.00      0.00      0.00        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       0.14      1.00      0.25        10\n",
            "\n",
            "    accuracy                           0.14        70\n",
            "   macro avg       0.02      0.14      0.04        70\n",
            "weighted avg       0.02      0.14      0.04        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 187 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 57\n",
            "learning rate: 0.0894503303369099\n",
            "batch size: 64\n",
            "dropout rate: 0.6501938003311495\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 3.6928 - acc: 0.2367\n",
            "Epoch 1: val_acc improved from -inf to 0.17143, saving model to percobaan187_noImgPro/model\\vgg_16_187-saved-model-01-acc-0.17.hdf5\n",
            "8/8 [==============================] - 48s 6s/step - loss: 3.6928 - acc: 0.2367 - val_loss: 18.7736 - val_acc: 0.1714\n",
            "Epoch 2/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.5136 - acc: 0.3592\n",
            "Epoch 2: val_acc improved from 0.17143 to 0.20714, saving model to percobaan187_noImgPro/model\\vgg_16_187-saved-model-02-acc-0.21.hdf5\n",
            "8/8 [==============================] - 46s 6s/step - loss: 2.5136 - acc: 0.3592 - val_loss: 5.9064 - val_acc: 0.2071\n",
            "Epoch 3/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8854 - acc: 0.3776\n",
            "Epoch 3: val_acc improved from 0.20714 to 0.30714, saving model to percobaan187_noImgPro/model\\vgg_16_187-saved-model-03-acc-0.31.hdf5\n",
            "8/8 [==============================] - 33s 4s/step - loss: 1.8854 - acc: 0.3776 - val_loss: 5.1328 - val_acc: 0.3071\n",
            "Epoch 4/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5432 - acc: 0.4673\n",
            "Epoch 4: val_acc improved from 0.30714 to 0.32857, saving model to percobaan187_noImgPro/model\\vgg_16_187-saved-model-04-acc-0.33.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 1.5432 - acc: 0.4673 - val_loss: 3.9524 - val_acc: 0.3286\n",
            "Epoch 5/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.2740 - acc: 0.5408\n",
            "Epoch 5: val_acc did not improve from 0.32857\n",
            "8/8 [==============================] - 38s 5s/step - loss: 1.2740 - acc: 0.5408 - val_loss: 3.3950 - val_acc: 0.3071\n",
            "Epoch 6/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.2283 - acc: 0.5551\n",
            "Epoch 6: val_acc did not improve from 0.32857\n",
            "8/8 [==============================] - 38s 5s/step - loss: 1.2283 - acc: 0.5551 - val_loss: 4.2000 - val_acc: 0.2286\n",
            "Epoch 7/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.2250 - acc: 0.6020\n",
            "Epoch 7: val_acc did not improve from 0.32857\n",
            "8/8 [==============================] - 38s 5s/step - loss: 1.2250 - acc: 0.6020 - val_loss: 4.0342 - val_acc: 0.2786\n",
            "Epoch 8/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0691 - acc: 0.6388\n",
            "Epoch 8: val_acc improved from 0.32857 to 0.36429, saving model to percobaan187_noImgPro/model\\vgg_16_187-saved-model-08-acc-0.36.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 1.0691 - acc: 0.6388 - val_loss: 3.1173 - val_acc: 0.3643\n",
            "Epoch 9/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0078 - acc: 0.6531\n",
            "Epoch 9: val_acc improved from 0.36429 to 0.53571, saving model to percobaan187_noImgPro/model\\vgg_16_187-saved-model-09-acc-0.54.hdf5\n",
            "8/8 [==============================] - 45s 6s/step - loss: 1.0078 - acc: 0.6531 - val_loss: 2.1172 - val_acc: 0.5357\n",
            "Epoch 10/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9222 - acc: 0.7061\n",
            "Epoch 10: val_acc improved from 0.53571 to 0.55000, saving model to percobaan187_noImgPro/model\\vgg_16_187-saved-model-10-acc-0.55.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.9222 - acc: 0.7061 - val_loss: 2.4374 - val_acc: 0.5500\n",
            "Epoch 11/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8300 - acc: 0.7020\n",
            "Epoch 11: val_acc did not improve from 0.55000\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.8300 - acc: 0.7020 - val_loss: 2.2472 - val_acc: 0.5214\n",
            "Epoch 12/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8900 - acc: 0.7041\n",
            "Epoch 12: val_acc did not improve from 0.55000\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.8900 - acc: 0.7041 - val_loss: 1.7958 - val_acc: 0.5357\n",
            "Epoch 13/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7856 - acc: 0.7347\n",
            "Epoch 13: val_acc improved from 0.55000 to 0.60714, saving model to percobaan187_noImgPro/model\\vgg_16_187-saved-model-13-acc-0.61.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.7856 - acc: 0.7347 - val_loss: 1.3632 - val_acc: 0.6071\n",
            "Epoch 14/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7229 - acc: 0.7531\n",
            "Epoch 14: val_acc did not improve from 0.60714\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.7229 - acc: 0.7531 - val_loss: 1.3810 - val_acc: 0.5929\n",
            "Epoch 15/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6051 - acc: 0.7939\n",
            "Epoch 15: val_acc did not improve from 0.60714\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.6051 - acc: 0.7939 - val_loss: 1.5645 - val_acc: 0.5071\n",
            "Epoch 16/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7569 - acc: 0.7429\n",
            "Epoch 16: val_acc improved from 0.60714 to 0.61429, saving model to percobaan187_noImgPro/model\\vgg_16_187-saved-model-16-acc-0.61.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.7569 - acc: 0.7429 - val_loss: 1.4217 - val_acc: 0.6143\n",
            "Epoch 17/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6509 - acc: 0.7796\n",
            "Epoch 17: val_acc did not improve from 0.61429\n",
            "8/8 [==============================] - 43s 6s/step - loss: 0.6509 - acc: 0.7796 - val_loss: 1.7477 - val_acc: 0.5286\n",
            "Epoch 18/57\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6747 - acc: 0.7837\n",
            "Epoch 18: val_acc did not improve from 0.61429\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.6747 - acc: 0.7837 - val_loss: 1.7476 - val_acc: 0.5429\n",
            "\n",
            "\n",
            "Model Accuracy 0.4857142857142857\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_57148\\3902733085.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.40      0.57        10\n",
            "       10000       1.00      0.30      0.46        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       1.00      0.10      0.18        10\n",
            "       20000       0.33      1.00      0.50        10\n",
            "        5000       0.39      0.90      0.55        10\n",
            "       50000       0.78      0.70      0.74        10\n",
            "\n",
            "    accuracy                           0.49        70\n",
            "   macro avg       0.64      0.49      0.43        70\n",
            "weighted avg       0.64      0.49      0.43        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 188 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 64\n",
            "learning rate: 0.09482506445713337\n",
            "batch size: 64\n",
            "dropout rate: 0.7737785634714955\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/64\n",
            "8/8 [==============================] - ETA: 0s - loss: 4.6297 - acc: 0.1673\n",
            "Epoch 1: val_acc improved from -inf to 0.20000, saving model to percobaan188_noImgPro/model\\vgg_16_188-saved-model-01-acc-0.20.hdf5\n",
            "8/8 [==============================] - 40s 5s/step - loss: 4.6297 - acc: 0.1673 - val_loss: 16.0731 - val_acc: 0.2000\n",
            "Epoch 2/64\n",
            "8/8 [==============================] - ETA: 0s - loss: 3.3683 - acc: 0.2816\n",
            "Epoch 2: val_acc improved from 0.20000 to 0.22143, saving model to percobaan188_noImgPro/model\\vgg_16_188-saved-model-02-acc-0.22.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 3.3683 - acc: 0.2816 - val_loss: 6.1877 - val_acc: 0.2214\n",
            "Epoch 3/64\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.3614 - acc: 0.3163\n",
            "Epoch 3: val_acc did not improve from 0.22143\n",
            "8/8 [==============================] - 44s 6s/step - loss: 2.3614 - acc: 0.3163 - val_loss: 5.0973 - val_acc: 0.1857\n",
            "Epoch 4/64\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.0934 - acc: 0.2898\n",
            "Epoch 4: val_acc improved from 0.22143 to 0.27143, saving model to percobaan188_noImgPro/model\\vgg_16_188-saved-model-04-acc-0.27.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 2.0934 - acc: 0.2898 - val_loss: 3.1099 - val_acc: 0.2714\n",
            "Epoch 5/64\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8483 - acc: 0.3265\n",
            "Epoch 5: val_acc did not improve from 0.27143\n",
            "8/8 [==============================] - 44s 6s/step - loss: 1.8483 - acc: 0.3265 - val_loss: 2.7258 - val_acc: 0.2214\n",
            "Epoch 6/64\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8121 - acc: 0.3286\n",
            "Epoch 6: val_acc did not improve from 0.27143\n",
            "8/8 [==============================] - 38s 5s/step - loss: 1.8121 - acc: 0.3286 - val_loss: 4.2210 - val_acc: 0.1857\n",
            "Epoch 7/64\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6906 - acc: 0.3898\n",
            "Epoch 7: val_acc did not improve from 0.27143\n",
            "8/8 [==============================] - 44s 6s/step - loss: 1.6906 - acc: 0.3898 - val_loss: 5.5053 - val_acc: 0.1714\n",
            "Epoch 8/64\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6935 - acc: 0.3959\n",
            "Epoch 8: val_acc did not improve from 0.27143\n",
            "8/8 [==============================] - 38s 5s/step - loss: 1.6935 - acc: 0.3959 - val_loss: 3.4771 - val_acc: 0.2643\n",
            "Epoch 9/64\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4998 - acc: 0.4714\n",
            "Epoch 9: val_acc did not improve from 0.27143\n",
            "8/8 [==============================] - 44s 6s/step - loss: 1.4998 - acc: 0.4714 - val_loss: 5.4880 - val_acc: 0.1786\n",
            "Epoch 10/64\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4262 - acc: 0.4694\n",
            "Epoch 10: val_acc did not improve from 0.27143\n",
            "8/8 [==============================] - 38s 5s/step - loss: 1.4262 - acc: 0.4694 - val_loss: 3.9649 - val_acc: 0.2429\n",
            "\n",
            "\n",
            "Model Accuracy 0.24285714285714285\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_57148\\3902733085.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.21      1.00      0.35        10\n",
            "       10000       0.00      0.00      0.00        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.00      0.00      0.00        10\n",
            "       20000       0.30      0.70      0.42        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       0.00      0.00      0.00        10\n",
            "\n",
            "    accuracy                           0.24        70\n",
            "   macro avg       0.07      0.24      0.11        70\n",
            "weighted avg       0.07      0.24      0.11        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 189 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 64\n",
            "learning rate: 0.09189516139642909\n",
            "batch size: 128\n",
            "dropout rate: 0.5686150804911808\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 3.2826 - acc: 0.2449\n",
            "Epoch 1: val_acc improved from -inf to 0.17857, saving model to percobaan189_noImgPro/model\\vgg_16_189-saved-model-01-acc-0.18.hdf5\n",
            "4/4 [==============================] - 40s 11s/step - loss: 3.2826 - acc: 0.2449 - val_loss: 13.7073 - val_acc: 0.1786\n",
            "Epoch 2/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.2536 - acc: 0.3918\n",
            "Epoch 2: val_acc improved from 0.17857 to 0.19286, saving model to percobaan189_noImgPro/model\\vgg_16_189-saved-model-02-acc-0.19.hdf5\n",
            "4/4 [==============================] - 40s 11s/step - loss: 2.2536 - acc: 0.3918 - val_loss: 12.7059 - val_acc: 0.1929\n",
            "Epoch 3/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.7115 - acc: 0.4714\n",
            "Epoch 3: val_acc improved from 0.19286 to 0.20714, saving model to percobaan189_noImgPro/model\\vgg_16_189-saved-model-03-acc-0.21.hdf5\n",
            "4/4 [==============================] - 44s 12s/step - loss: 1.7115 - acc: 0.4714 - val_loss: 9.5238 - val_acc: 0.2071\n",
            "Epoch 4/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2304 - acc: 0.5571\n",
            "Epoch 4: val_acc improved from 0.20714 to 0.28571, saving model to percobaan189_noImgPro/model\\vgg_16_189-saved-model-04-acc-0.29.hdf5\n",
            "4/4 [==============================] - 39s 11s/step - loss: 1.2304 - acc: 0.5571 - val_loss: 5.8044 - val_acc: 0.2857\n",
            "Epoch 5/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0643 - acc: 0.6245\n",
            "Epoch 5: val_acc did not improve from 0.28571\n",
            "4/4 [==============================] - 44s 12s/step - loss: 1.0643 - acc: 0.6245 - val_loss: 8.9124 - val_acc: 0.1857\n",
            "Epoch 6/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9259 - acc: 0.6776\n",
            "Epoch 6: val_acc did not improve from 0.28571\n",
            "4/4 [==============================] - 38s 10s/step - loss: 0.9259 - acc: 0.6776 - val_loss: 10.4105 - val_acc: 0.1714\n",
            "Epoch 7/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9180 - acc: 0.6735\n",
            "Epoch 7: val_acc did not improve from 0.28571\n",
            "4/4 [==============================] - 39s 11s/step - loss: 0.9180 - acc: 0.6735 - val_loss: 9.4278 - val_acc: 0.1714\n",
            "Epoch 8/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7340 - acc: 0.7490\n",
            "Epoch 8: val_acc did not improve from 0.28571\n",
            "4/4 [==============================] - 44s 11s/step - loss: 0.7340 - acc: 0.7490 - val_loss: 6.9897 - val_acc: 0.1929\n",
            "Epoch 9/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6303 - acc: 0.7755\n",
            "Epoch 9: val_acc did not improve from 0.28571\n",
            "4/4 [==============================] - 39s 11s/step - loss: 0.6303 - acc: 0.7755 - val_loss: 5.7896 - val_acc: 0.2000\n",
            "Epoch 10/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6287 - acc: 0.7776\n",
            "Epoch 10: val_acc did not improve from 0.28571\n",
            "4/4 [==============================] - 41s 12s/step - loss: 0.6287 - acc: 0.7776 - val_loss: 4.2354 - val_acc: 0.2286\n",
            "Epoch 11/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6655 - acc: 0.7694\n",
            "Epoch 11: val_acc did not improve from 0.28571\n",
            "4/4 [==============================] - 41s 11s/step - loss: 0.6655 - acc: 0.7694 - val_loss: 3.0202 - val_acc: 0.2714\n",
            "Epoch 12/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5028 - acc: 0.8122\n",
            "Epoch 12: val_acc improved from 0.28571 to 0.48571, saving model to percobaan189_noImgPro/model\\vgg_16_189-saved-model-12-acc-0.49.hdf5\n",
            "4/4 [==============================] - 38s 10s/step - loss: 0.5028 - acc: 0.8122 - val_loss: 2.2784 - val_acc: 0.4857\n",
            "Epoch 13/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4837 - acc: 0.8367\n",
            "Epoch 13: val_acc did not improve from 0.48571\n",
            "4/4 [==============================] - 44s 11s/step - loss: 0.4837 - acc: 0.8367 - val_loss: 2.7559 - val_acc: 0.4214\n",
            "Epoch 14/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4740 - acc: 0.8490\n",
            "Epoch 14: val_acc did not improve from 0.48571\n",
            "4/4 [==============================] - 38s 10s/step - loss: 0.4740 - acc: 0.8490 - val_loss: 2.4312 - val_acc: 0.4714\n",
            "Epoch 15/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3608 - acc: 0.8735\n",
            "Epoch 15: val_acc improved from 0.48571 to 0.50714, saving model to percobaan189_noImgPro/model\\vgg_16_189-saved-model-15-acc-0.51.hdf5\n",
            "4/4 [==============================] - 44s 13s/step - loss: 0.3608 - acc: 0.8735 - val_loss: 2.1849 - val_acc: 0.5071\n",
            "Epoch 16/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4182 - acc: 0.8429\n",
            "Epoch 16: val_acc did not improve from 0.50714\n",
            "4/4 [==============================] - 38s 11s/step - loss: 0.4182 - acc: 0.8429 - val_loss: 2.5329 - val_acc: 0.4500\n",
            "Epoch 17/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3521 - acc: 0.8592\n",
            "Epoch 17: val_acc did not improve from 0.50714\n",
            "4/4 [==============================] - 38s 11s/step - loss: 0.3521 - acc: 0.8592 - val_loss: 2.7699 - val_acc: 0.4429\n",
            "Epoch 18/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4050 - acc: 0.8735\n",
            "Epoch 18: val_acc did not improve from 0.50714\n",
            "4/4 [==============================] - 44s 11s/step - loss: 0.4050 - acc: 0.8735 - val_loss: 2.7951 - val_acc: 0.4500\n",
            "Epoch 19/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3815 - acc: 0.8714\n",
            "Epoch 19: val_acc improved from 0.50714 to 0.52143, saving model to percobaan189_noImgPro/model\\vgg_16_189-saved-model-19-acc-0.52.hdf5\n",
            "4/4 [==============================] - 40s 11s/step - loss: 0.3815 - acc: 0.8714 - val_loss: 2.0366 - val_acc: 0.5214\n",
            "Epoch 20/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3574 - acc: 0.8776\n",
            "Epoch 20: val_acc did not improve from 0.52143\n",
            "4/4 [==============================] - 45s 11s/step - loss: 0.3574 - acc: 0.8776 - val_loss: 2.6046 - val_acc: 0.3429\n",
            "Epoch 21/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4075 - acc: 0.8551\n",
            "Epoch 21: val_acc did not improve from 0.52143\n",
            "4/4 [==============================] - 37s 10s/step - loss: 0.4075 - acc: 0.8551 - val_loss: 1.9563 - val_acc: 0.4214\n",
            "Epoch 22/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2933 - acc: 0.9041\n",
            "Epoch 22: val_acc improved from 0.52143 to 0.67143, saving model to percobaan189_noImgPro/model\\vgg_16_189-saved-model-22-acc-0.67.hdf5\n",
            "4/4 [==============================] - 44s 11s/step - loss: 0.2933 - acc: 0.9041 - val_loss: 1.0230 - val_acc: 0.6714\n",
            "Epoch 23/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3718 - acc: 0.8612\n",
            "Epoch 23: val_acc did not improve from 0.67143\n",
            "4/4 [==============================] - 38s 11s/step - loss: 0.3718 - acc: 0.8612 - val_loss: 1.3955 - val_acc: 0.5857\n",
            "Epoch 24/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2980 - acc: 0.9102\n",
            "Epoch 24: val_acc did not improve from 0.67143\n",
            "4/4 [==============================] - 44s 11s/step - loss: 0.2980 - acc: 0.9102 - val_loss: 1.4772 - val_acc: 0.5929\n",
            "Epoch 25/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3353 - acc: 0.8816\n",
            "Epoch 25: val_acc did not improve from 0.67143\n",
            "4/4 [==============================] - 38s 11s/step - loss: 0.3353 - acc: 0.8816 - val_loss: 1.3983 - val_acc: 0.6429\n",
            "Epoch 26/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3975 - acc: 0.8816\n",
            "Epoch 26: val_acc did not improve from 0.67143\n",
            "4/4 [==============================] - 43s 11s/step - loss: 0.3975 - acc: 0.8816 - val_loss: 2.3077 - val_acc: 0.4500\n",
            "Epoch 27/64\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2772 - acc: 0.9082\n",
            "Epoch 27: val_acc did not improve from 0.67143\n",
            "4/4 [==============================] - 39s 11s/step - loss: 0.2772 - acc: 0.9082 - val_loss: 2.7280 - val_acc: 0.4643\n",
            "\n",
            "\n",
            "Model Accuracy 0.2857142857142857\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_57148\\3902733085.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.10      0.18        10\n",
            "       10000       0.00      0.00      0.00        10\n",
            "      100000       0.71      0.50      0.59        10\n",
            "        2000       0.00      0.00      0.00        10\n",
            "       20000       0.50      0.40      0.44        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       0.19      1.00      0.32        10\n",
            "\n",
            "    accuracy                           0.29        70\n",
            "   macro avg       0.34      0.29      0.22        70\n",
            "weighted avg       0.34      0.29      0.22        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 190 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 60\n",
            "learning rate: 0.08676559624484512\n",
            "batch size: 128\n",
            "dropout rate: 0.580570129460604\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.8939 - acc: 0.2592\n",
            "Epoch 1: val_acc improved from -inf to 0.15000, saving model to percobaan190_noImgPro/model\\vgg_16_190-saved-model-01-acc-0.15.hdf5\n",
            "4/4 [==============================] - 45s 12s/step - loss: 2.8939 - acc: 0.2592 - val_loss: 12.8292 - val_acc: 0.1500\n",
            "Epoch 2/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.9857 - acc: 0.4163\n",
            "Epoch 2: val_acc improved from 0.15000 to 0.24286, saving model to percobaan190_noImgPro/model\\vgg_16_190-saved-model-02-acc-0.24.hdf5\n",
            "4/4 [==============================] - 60s 15s/step - loss: 1.9857 - acc: 0.4163 - val_loss: 10.0815 - val_acc: 0.2429\n",
            "Epoch 3/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.5156 - acc: 0.5429\n",
            "Epoch 3: val_acc did not improve from 0.24286\n",
            "4/4 [==============================] - 61s 15s/step - loss: 1.5156 - acc: 0.5429 - val_loss: 6.3591 - val_acc: 0.1714\n",
            "Epoch 4/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2106 - acc: 0.6082\n",
            "Epoch 4: val_acc did not improve from 0.24286\n",
            "4/4 [==============================] - 54s 13s/step - loss: 1.2106 - acc: 0.6082 - val_loss: 4.4769 - val_acc: 0.2214\n",
            "Epoch 5/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9662 - acc: 0.6735\n",
            "Epoch 5: val_acc improved from 0.24286 to 0.25000, saving model to percobaan190_noImgPro/model\\vgg_16_190-saved-model-05-acc-0.25.hdf5\n",
            "4/4 [==============================] - 60s 15s/step - loss: 0.9662 - acc: 0.6735 - val_loss: 4.5898 - val_acc: 0.2500\n",
            "Epoch 6/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8989 - acc: 0.6980\n",
            "Epoch 6: val_acc improved from 0.25000 to 0.25714, saving model to percobaan190_noImgPro/model\\vgg_16_190-saved-model-06-acc-0.26.hdf5\n",
            "4/4 [==============================] - 60s 15s/step - loss: 0.8989 - acc: 0.6980 - val_loss: 3.9128 - val_acc: 0.2571\n",
            "Epoch 7/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7807 - acc: 0.7286\n",
            "Epoch 7: val_acc did not improve from 0.25714\n",
            "4/4 [==============================] - 61s 15s/step - loss: 0.7807 - acc: 0.7286 - val_loss: 3.9161 - val_acc: 0.2214\n",
            "Epoch 8/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6875 - acc: 0.7367\n",
            "Epoch 8: val_acc did not improve from 0.25714\n",
            "4/4 [==============================] - 60s 15s/step - loss: 0.6875 - acc: 0.7367 - val_loss: 5.9185 - val_acc: 0.1500\n",
            "Epoch 9/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7023 - acc: 0.7612\n",
            "Epoch 9: val_acc did not improve from 0.25714\n",
            "4/4 [==============================] - 66s 17s/step - loss: 0.7023 - acc: 0.7612 - val_loss: 5.4384 - val_acc: 0.1857\n",
            "Epoch 10/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6008 - acc: 0.8061 \n",
            "Epoch 10: val_acc improved from 0.25714 to 0.32143, saving model to percobaan190_noImgPro/model\\vgg_16_190-saved-model-10-acc-0.32.hdf5\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6008 - acc: 0.8061 - val_loss: 4.4138 - val_acc: 0.3214\n",
            "Epoch 11/60\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5728 - acc: 0.7898\n",
            "Epoch 11: val_acc improved from 0.32143 to 0.35000, saving model to percobaan190_noImgPro/model\\vgg_16_190-saved-model-11-acc-0.35.hdf5\n",
            "4/4 [==============================] - 49s 12s/step - loss: 0.5728 - acc: 0.7898 - val_loss: 4.1326 - val_acc: 0.3500\n",
            "\n",
            "\n",
            "Model Accuracy 0.22857142857142856\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_57148\\3902733085.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.00      0.00      0.00        10\n",
            "       10000       0.17      1.00      0.29        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.00      0.00      0.00        10\n",
            "       20000       0.44      0.40      0.42        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       1.00      0.20      0.33        10\n",
            "\n",
            "    accuracy                           0.23        70\n",
            "   macro avg       0.23      0.23      0.15        70\n",
            "weighted avg       0.23      0.23      0.15        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 191 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 59\n",
            "learning rate: 0.08158571203931907\n",
            "batch size: 128\n",
            "dropout rate: 0.6839418105731678\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/59\n",
            "4/4 [==============================] - ETA: 0s - loss: 3.2216 - acc: 0.2122\n",
            "Epoch 1: val_acc improved from -inf to 0.23571, saving model to percobaan191_noImgPro/model\\vgg_16_191-saved-model-01-acc-0.24.hdf5\n",
            "4/4 [==============================] - 43s 11s/step - loss: 3.2216 - acc: 0.2122 - val_loss: 9.0379 - val_acc: 0.2357\n",
            "Epoch 2/59\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.3771 - acc: 0.3592\n",
            "Epoch 2: val_acc did not improve from 0.23571\n",
            "4/4 [==============================] - 39s 11s/step - loss: 2.3771 - acc: 0.3592 - val_loss: 8.1600 - val_acc: 0.1786\n",
            "Epoch 3/59\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mCanceled future for execute_request message before replies were done"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "#start: 11 Juni 5:27 PM\n",
        "j = 160\n",
        "for i in range (j,len(parameter)):\n",
        "#for i in range (0,10): #aslinya in range len(parameter) tapi kalau mau coba per sedikit2 ya gini deh\n",
        "  vgg_epoch = (parameter[i][0])\n",
        "  learning_rate = (parameter[i][1])\n",
        "  batch_size = (parameter[i][2])\n",
        "  dropout_rate = (parameter[i][3])\n",
        "  i=i+1\n",
        "  savePercobaan(i)\n",
        "  print(\"Percobaan ke-\",i,\"↓\")\n",
        "  print(\"HYPERPARAMETER\".center(100,\"─\"))\n",
        "  print(\"vgg epoch:\",vgg_epoch)\n",
        "  print(\"learning rate:\",learning_rate)\n",
        "  print(\"batch size:\",batch_size)\n",
        "  print(\"dropout rate:\",dropout_rate)\n",
        "  print(\"\".center(100,\"─\"))\n",
        "  vgg16_training(i, vgg_epoch, learning_rate, batch_size, dropout_rate)\n",
        "  new_row = {'Epoch': vgg_epoch, 'Learning Rate': learning_rate, 'Batch Size': batch_size, 'Dropout Rate': dropout_rate, 'Accuracy': arr_accuracy16[-1]}\n",
        "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n",
        "  hasilTabel.index = hasilTabel.index + (j+1)\n",
        "  hasilTabel.to_excel(\"hasilTabel.xlsx\")\n",
        "  print(\"\".center(100,\"─\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percobaan ke- 191 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 62\n",
            "learning rate: 0.09512085165074452\n",
            "batch size: 128\n",
            "dropout rate: 0.708637177375642\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/62\n",
            "4/4 [==============================] - ETA: 0s - loss: 3.5617 - acc: 0.2245\n",
            "Epoch 1: val_acc improved from -inf to 0.17143, saving model to percobaan191_noImgPro/model\\vgg_16_191-saved-model-01-acc-0.17.hdf5\n",
            "4/4 [==============================] - 35s 9s/step - loss: 3.5617 - acc: 0.2245 - val_loss: 8.1506 - val_acc: 0.1714\n",
            "Epoch 2/62\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.9923 - acc: 0.2959\n",
            "Epoch 2: val_acc did not improve from 0.17143\n",
            "4/4 [==============================] - 32s 8s/step - loss: 2.9923 - acc: 0.2959 - val_loss: 12.2875 - val_acc: 0.1500\n",
            "Epoch 3/62\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.1389 - acc: 0.3816\n",
            "Epoch 3: val_acc improved from 0.17143 to 0.17857, saving model to percobaan191_noImgPro/model\\vgg_16_191-saved-model-03-acc-0.18.hdf5\n",
            "4/4 [==============================] - 32s 9s/step - loss: 2.1389 - acc: 0.3816 - val_loss: 7.1610 - val_acc: 0.1786\n",
            "Epoch 4/62\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.7099 - acc: 0.4061\n",
            "Epoch 4: val_acc did not improve from 0.17857\n",
            "4/4 [==============================] - 32s 9s/step - loss: 1.7099 - acc: 0.4061 - val_loss: 6.2652 - val_acc: 0.1429\n",
            "Epoch 5/62\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.4924 - acc: 0.4367\n",
            "Epoch 5: val_acc did not improve from 0.17857\n",
            "4/4 [==============================] - 40s 12s/step - loss: 1.4924 - acc: 0.4367 - val_loss: 5.9538 - val_acc: 0.1571\n",
            "Epoch 6/62\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.4668 - acc: 0.4490\n",
            "Epoch 6: val_acc did not improve from 0.17857\n",
            "4/4 [==============================] - 42s 10s/step - loss: 1.4668 - acc: 0.4490 - val_loss: 6.9478 - val_acc: 0.1714\n",
            "Epoch 7/62\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.3853 - acc: 0.4837\n",
            "Epoch 7: val_acc improved from 0.17857 to 0.18571, saving model to percobaan191_noImgPro/model\\vgg_16_191-saved-model-07-acc-0.19.hdf5\n",
            "4/4 [==============================] - 39s 9s/step - loss: 1.3853 - acc: 0.4837 - val_loss: 6.3080 - val_acc: 0.1857\n",
            "Epoch 8/62\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2006 - acc: 0.5653\n",
            "Epoch 8: val_acc did not improve from 0.18571\n",
            "4/4 [==============================] - 38s 9s/step - loss: 1.2006 - acc: 0.5653 - val_loss: 6.7129 - val_acc: 0.1857\n",
            "Epoch 9/62\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1960 - acc: 0.5980\n",
            "Epoch 9: val_acc did not improve from 0.18571\n",
            "4/4 [==============================] - 38s 9s/step - loss: 1.1960 - acc: 0.5980 - val_loss: 4.9044 - val_acc: 0.1786\n",
            "Epoch 10/62\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0540 - acc: 0.6469\n",
            "Epoch 10: val_acc improved from 0.18571 to 0.23571, saving model to percobaan191_noImgPro/model\\vgg_16_191-saved-model-10-acc-0.24.hdf5\n",
            "4/4 [==============================] - 44s 11s/step - loss: 1.0540 - acc: 0.6469 - val_loss: 3.4947 - val_acc: 0.2357\n",
            "Epoch 11/62\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1082 - acc: 0.6000\n",
            "Epoch 11: val_acc did not improve from 0.23571\n",
            "4/4 [==============================] - 39s 11s/step - loss: 1.1082 - acc: 0.6000 - val_loss: 3.9900 - val_acc: 0.1571\n",
            "Epoch 12/62\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9735 - acc: 0.6612\n",
            "Epoch 12: val_acc did not improve from 0.23571\n",
            "4/4 [==============================] - 40s 11s/step - loss: 0.9735 - acc: 0.6612 - val_loss: 3.7564 - val_acc: 0.1714\n",
            "Epoch 13/62\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8930 - acc: 0.7082\n",
            "Epoch 13: val_acc improved from 0.23571 to 0.30714, saving model to percobaan191_noImgPro/model\\vgg_16_191-saved-model-13-acc-0.31.hdf5\n",
            "4/4 [==============================] - 42s 12s/step - loss: 0.8930 - acc: 0.7082 - val_loss: 2.8558 - val_acc: 0.3071\n",
            "Epoch 14/62\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8245 - acc: 0.7143\n",
            "Epoch 14: val_acc improved from 0.30714 to 0.34286, saving model to percobaan191_noImgPro/model\\vgg_16_191-saved-model-14-acc-0.34.hdf5\n",
            "4/4 [==============================] - 47s 11s/step - loss: 0.8245 - acc: 0.7143 - val_loss: 2.5667 - val_acc: 0.3429\n",
            "Epoch 15/62\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8228 - acc: 0.7184\n",
            "Epoch 15: val_acc improved from 0.34286 to 0.37857, saving model to percobaan191_noImgPro/model\\vgg_16_191-saved-model-15-acc-0.38.hdf5\n",
            "4/4 [==============================] - 40s 11s/step - loss: 0.8228 - acc: 0.7184 - val_loss: 2.3228 - val_acc: 0.3786\n",
            "Epoch 16/62\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7729 - acc: 0.7286\n",
            "Epoch 16: val_acc did not improve from 0.37857\n",
            "4/4 [==============================] - 38s 11s/step - loss: 0.7729 - acc: 0.7286 - val_loss: 2.6580 - val_acc: 0.3000\n",
            "Epoch 17/62\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7439 - acc: 0.7449\n",
            "Epoch 17: val_acc did not improve from 0.37857\n",
            "4/4 [==============================] - 42s 10s/step - loss: 0.7439 - acc: 0.7449 - val_loss: 3.7458 - val_acc: 0.2500\n",
            "Epoch 18/62\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7526 - acc: 0.7265\n",
            "Epoch 18: val_acc did not improve from 0.37857\n",
            "4/4 [==============================] - 40s 10s/step - loss: 0.7526 - acc: 0.7265 - val_loss: 3.4944 - val_acc: 0.2643\n",
            "Epoch 19/62\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7172 - acc: 0.7571\n",
            "Epoch 19: val_acc did not improve from 0.37857\n",
            "4/4 [==============================] - 39s 11s/step - loss: 0.7172 - acc: 0.7571 - val_loss: 2.7111 - val_acc: 0.3714\n",
            "Epoch 20/62\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6435 - acc: 0.7673\n",
            "Epoch 20: val_acc improved from 0.37857 to 0.43571, saving model to percobaan191_noImgPro/model\\vgg_16_191-saved-model-20-acc-0.44.hdf5\n",
            "4/4 [==============================] - 38s 11s/step - loss: 0.6435 - acc: 0.7673 - val_loss: 2.2704 - val_acc: 0.4357\n",
            "Epoch 21/62\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6682 - acc: 0.7633\n",
            "Epoch 21: val_acc improved from 0.43571 to 0.52857, saving model to percobaan191_noImgPro/model\\vgg_16_191-saved-model-21-acc-0.53.hdf5\n",
            "4/4 [==============================] - 45s 11s/step - loss: 0.6682 - acc: 0.7633 - val_loss: 1.9002 - val_acc: 0.5286\n",
            "Epoch 22/62\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6354 - acc: 0.7837\n",
            "Epoch 22: val_acc did not improve from 0.52857\n",
            "4/4 [==============================] - 38s 11s/step - loss: 0.6354 - acc: 0.7837 - val_loss: 2.1357 - val_acc: 0.4714\n",
            "Epoch 23/62\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5219 - acc: 0.8347\n",
            "Epoch 23: val_acc did not improve from 0.52857\n",
            "4/4 [==============================] - 38s 11s/step - loss: 0.5219 - acc: 0.8347 - val_loss: 2.2899 - val_acc: 0.3857\n",
            "Epoch 24/62\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5377 - acc: 0.8143\n",
            "Epoch 24: val_acc improved from 0.52857 to 0.57143, saving model to percobaan191_noImgPro/model\\vgg_16_191-saved-model-24-acc-0.57.hdf5\n",
            "4/4 [==============================] - 38s 10s/step - loss: 0.5377 - acc: 0.8143 - val_loss: 1.2374 - val_acc: 0.5714\n",
            "Epoch 25/62\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5728 - acc: 0.8041\n",
            "Epoch 25: val_acc did not improve from 0.57143\n",
            "4/4 [==============================] - 44s 13s/step - loss: 0.5728 - acc: 0.8041 - val_loss: 1.8941 - val_acc: 0.5000\n",
            "Epoch 26/62\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5744 - acc: 0.8061\n",
            "Epoch 26: val_acc did not improve from 0.57143\n",
            "4/4 [==============================] - 38s 11s/step - loss: 0.5744 - acc: 0.8061 - val_loss: 1.9788 - val_acc: 0.4643\n",
            "Epoch 27/62\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5866 - acc: 0.7959\n",
            "Epoch 27: val_acc did not improve from 0.57143\n",
            "4/4 [==============================] - 38s 11s/step - loss: 0.5866 - acc: 0.7959 - val_loss: 1.7292 - val_acc: 0.5571\n",
            "Epoch 28/62\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5700 - acc: 0.8061\n",
            "Epoch 28: val_acc improved from 0.57143 to 0.60000, saving model to percobaan191_noImgPro/model\\vgg_16_191-saved-model-28-acc-0.60.hdf5\n",
            "4/4 [==============================] - 39s 11s/step - loss: 0.5700 - acc: 0.8061 - val_loss: 1.5196 - val_acc: 0.6000\n",
            "Epoch 29/62\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5968 - acc: 0.8041\n",
            "Epoch 29: val_acc improved from 0.60000 to 0.61429, saving model to percobaan191_noImgPro/model\\vgg_16_191-saved-model-29-acc-0.61.hdf5\n",
            "4/4 [==============================] - 38s 11s/step - loss: 0.5968 - acc: 0.8041 - val_loss: 1.6089 - val_acc: 0.6143\n",
            "\n",
            "\n",
            "Model Accuracy 0.5142857142857142\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_54864\\894696303.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.62      1.00      0.77        10\n",
            "       10000       0.78      0.70      0.74        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.80      0.40      0.53        10\n",
            "       20000       1.00      0.40      0.57        10\n",
            "        5000       0.50      0.10      0.17        10\n",
            "       50000       0.29      1.00      0.45        10\n",
            "\n",
            "    accuracy                           0.51        70\n",
            "   macro avg       0.57      0.51      0.46        70\n",
            "weighted avg       0.57      0.51      0.46        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Percobaan ke- 192 ↓\n",
            "───────────────────────────────────────────HYPERPARAMETER───────────────────────────────────────────\n",
            "vgg epoch: 57\n",
            "learning rate: 0.09549074082597434\n",
            "batch size: 128\n",
            "dropout rate: 0.7585384009036407\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/57\n",
            "4/4 [==============================] - ETA: 0s - loss: 3.7805 - acc: 0.2184\n",
            "Epoch 1: val_acc improved from -inf to 0.20000, saving model to percobaan192_noImgPro/model\\vgg_16_192-saved-model-01-acc-0.20.hdf5\n",
            "4/4 [==============================] - 40s 11s/step - loss: 3.7805 - acc: 0.2184 - val_loss: 16.5820 - val_acc: 0.2000\n",
            "Epoch 2/57\n",
            "4/4 [==============================] - ETA: 0s - loss: 3.1077 - acc: 0.2898\n",
            "Epoch 2: val_acc improved from 0.20000 to 0.22143, saving model to percobaan192_noImgPro/model\\vgg_16_192-saved-model-02-acc-0.22.hdf5\n",
            "4/4 [==============================] - 38s 10s/step - loss: 3.1077 - acc: 0.2898 - val_loss: 9.0899 - val_acc: 0.2214\n",
            "Epoch 3/57\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.3668 - acc: 0.3673\n",
            "Epoch 3: val_acc did not improve from 0.22143\n",
            "4/4 [==============================] - 38s 11s/step - loss: 2.3668 - acc: 0.3673 - val_loss: 10.6231 - val_acc: 0.1429\n",
            "Epoch 4/57\n",
            "4/4 [==============================] - ETA: 0s - loss: 2.1430 - acc: 0.3694\n",
            "Epoch 4: val_acc did not improve from 0.22143\n",
            "4/4 [==============================] - 38s 10s/step - loss: 2.1430 - acc: 0.3694 - val_loss: 6.8621 - val_acc: 0.1714\n",
            "Epoch 5/57\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.8511 - acc: 0.3531\n",
            "Epoch 5: val_acc did not improve from 0.22143\n",
            "4/4 [==============================] - 38s 11s/step - loss: 1.8511 - acc: 0.3531 - val_loss: 5.2276 - val_acc: 0.1786\n",
            "Epoch 6/57\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.7260 - acc: 0.4082\n",
            "Epoch 6: val_acc did not improve from 0.22143\n",
            "4/4 [==============================] - 37s 8s/step - loss: 1.7260 - acc: 0.4082 - val_loss: 5.5371 - val_acc: 0.1500\n",
            "Epoch 7/57\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.5454 - acc: 0.4020\n",
            "Epoch 7: val_acc did not improve from 0.22143\n",
            "4/4 [==============================] - 44s 10s/step - loss: 1.5454 - acc: 0.4020 - val_loss: 5.0258 - val_acc: 0.1929\n",
            "Epoch 8/57\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.4848 - acc: 0.4694\n",
            "Epoch 8: val_acc did not improve from 0.22143\n",
            "4/4 [==============================] - 38s 11s/step - loss: 1.4848 - acc: 0.4694 - val_loss: 5.2551 - val_acc: 0.1857\n",
            "Epoch 9/57\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2839 - acc: 0.5163\n",
            "Epoch 9: val_acc improved from 0.22143 to 0.25714, saving model to percobaan192_noImgPro/model\\vgg_16_192-saved-model-09-acc-0.26.hdf5\n",
            "4/4 [==============================] - 38s 11s/step - loss: 1.2839 - acc: 0.5163 - val_loss: 5.2039 - val_acc: 0.2571\n",
            "Epoch 10/57\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2558 - acc: 0.5347\n",
            "Epoch 10: val_acc did not improve from 0.25714\n",
            "4/4 [==============================] - 38s 11s/step - loss: 1.2558 - acc: 0.5347 - val_loss: 5.4195 - val_acc: 0.2214\n",
            "Epoch 11/57\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1952 - acc: 0.5653\n",
            "Epoch 11: val_acc did not improve from 0.25714\n",
            "4/4 [==============================] - 38s 9s/step - loss: 1.1952 - acc: 0.5653 - val_loss: 6.1205 - val_acc: 0.2429\n",
            "Epoch 12/57\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1028 - acc: 0.5980\n",
            "Epoch 12: val_acc did not improve from 0.25714\n",
            "4/4 [==============================] - 43s 10s/step - loss: 1.1028 - acc: 0.5980 - val_loss: 6.4733 - val_acc: 0.1857\n",
            "\n",
            "\n",
            "Model Accuracy 0.17142857142857143\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\ardin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_54864\\894696303.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.00      0.00      0.00        10\n",
            "       10000       0.00      0.00      0.00        10\n",
            "      100000       0.00      0.00      0.00        10\n",
            "        2000       0.00      0.00      0.00        10\n",
            "       20000       0.16      1.00      0.27        10\n",
            "        5000       0.00      0.00      0.00        10\n",
            "       50000       0.29      0.20      0.24        10\n",
            "\n",
            "    accuracy                           0.17        70\n",
            "   macro avg       0.06      0.17      0.07        70\n",
            "weighted avg       0.06      0.17      0.07        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 700x700 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 700x700 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#start: 12 Juni 12:36 AM\n",
        "j = 190\n",
        "for i in range (j,len(parameter)):\n",
        "#for i in range (0,10): #aslinya in range len(parameter) tapi kalau mau coba per sedikit2 ya gini deh\n",
        "  vgg_epoch = (parameter[i][0])\n",
        "  learning_rate = (parameter[i][1])\n",
        "  batch_size = (parameter[i][2])\n",
        "  dropout_rate = (parameter[i][3])\n",
        "  i=i+1\n",
        "  savePercobaan(i)\n",
        "  print(\"Percobaan ke-\",i,\"↓\")\n",
        "  print(\"HYPERPARAMETER\".center(100,\"─\"))\n",
        "  print(\"vgg epoch:\",vgg_epoch)\n",
        "  print(\"learning rate:\",learning_rate)\n",
        "  print(\"batch size:\",batch_size)\n",
        "  print(\"dropout rate:\",dropout_rate)\n",
        "  print(\"\".center(100,\"─\"))\n",
        "  vgg16_training(i, vgg_epoch, learning_rate, batch_size, dropout_rate)\n",
        "  new_row = {'Epoch': vgg_epoch, 'Learning Rate': learning_rate, 'Batch Size': batch_size, 'Dropout Rate': dropout_rate, 'Accuracy': arr_accuracy16[-1]}\n",
        "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n",
        "  hasilTabel.index = hasilTabel.index + (j+1)\n",
        "  hasilTabel.to_excel(\"hasilTabel.xlsx\")\n",
        "  print(\"\".center(100,\"─\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeQt8oqamD0x",
        "outputId": "562efe07-fde7-4af4-c2ad-eb32e7382fbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Percobaan  Epoch  Learning Rate  Batch Size  Dropout Rate  Accuracy\n",
            "0          1     34       0.013475          32      0.533236  0.300000\n",
            "1          2     38       0.008827          32      0.624940  0.571429\n",
            "2          3     35       0.012391          32      0.704752  0.171429\n",
            "3          4     32       0.001534          32      0.769208  0.571429\n",
            "4          5     35       0.023369          64      0.516714  0.142857\n"
          ]
        }
      ],
      "source": [
        "result = pd.read_excel(\"hasilTabel.xlsx\")\n",
        "print(result)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SryQgnt_9utH"
      },
      "source": [
        "#### **<font color='Pink'>Testing</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "inv_map_classes = {0: '1000', 1: '10000', 2: '100000', 3: '2000', 4: '20000', 5: '5000', 6: '50000'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "rfTvl2VoZVm_",
        "outputId": "686d5b4e-3b00-4d6a-8ab6-90f3fdaea5d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 294ms/step\n",
            "1/1 [==============================] - 0s 105ms/step\n",
            "Prediksi: 100000 | Probabilitas: 0.975997\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "path = r\"D:\\UNAIR\\Semester_8\\Skripsi\\deteksi_nominal_vending_machine\\datasetUang/100000/100k_b_2016_15.png\"\n",
        "img = cv2.resize(cv2.imread(path),(242,130))\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "#img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "#img = cv2.imread(path)\n",
        "img_normalized = img/255\n",
        "\n",
        "model = load_model(\"percobaan148_noImgPro/vgg16-model148.h5\")\n",
        "\n",
        "vgg16_image_prediction = np.argmax(model.predict(np.array([img_normalized])))\n",
        "prob = np.amax(model.predict(np.array([img_normalized])))\n",
        "plt.imshow(img)\n",
        "plt.axis(\"off\")\n",
        "print(\"Prediksi:\",inv_map_classes[vgg16_image_prediction],\"| Probabilitas:\",prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#Revisi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1392\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Copying files: 700 files [00:06, 101.92 files/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "172\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Copying files: 700 files [00:01, 541.42 files/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "198\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Copying files: 700 files [00:01, 559.61 files/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "751\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Copying files: 700 files [00:01, 657.31 files/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1401\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Copying files: 700 files [00:01, 611.13 files/s]\n"
          ]
        }
      ],
      "source": [
        "import splitfolders\n",
        "dataset=\"datasetAbu\"\n",
        "for i in range(0,5):\n",
        "    seed = random.randint(0,1500)\n",
        "    print(seed)\n",
        "    i=i+1\n",
        "    splitfolders.ratio(dataset, output=\"datasetSplit\"+str(i), seed=seed, ratio=(0.7, 0.2, 0.1)) #70% : 10% : 20%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 490 images belonging to 7 classes.\n",
            "Found 70 images belonging to 7 classes.\n",
            "Found 140 images belonging to 7 classes.\n",
            "Percobaan ke- 1 ↓\n",
            "───────────────────────────────────────HYPERPARAMETER VGG-16────────────────────────────────────────\n",
            "vgg epoch: 48\n",
            "learning rate: 0.001789042\n",
            "batch size: 64\n",
            "dropout rate: 0.617462768\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.6178 - acc: 0.2837\n",
            "Epoch 1: val_acc improved from -inf to 0.29286, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-01-acc-0.29.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 2.6178 - acc: 0.2837 - val_loss: 2.0056 - val_acc: 0.2929\n",
            "Epoch 2/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4761 - acc: 0.5224\n",
            "Epoch 2: val_acc did not improve from 0.29286\n",
            "8/8 [==============================] - 33s 4s/step - loss: 1.4761 - acc: 0.5224 - val_loss: 1.9059 - val_acc: 0.2929\n",
            "Epoch 3/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1456 - acc: 0.6347\n",
            "Epoch 3: val_acc improved from 0.29286 to 0.32857, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-03-acc-0.33.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 1.1456 - acc: 0.6347 - val_loss: 1.7947 - val_acc: 0.3286\n",
            "Epoch 4/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7468 - acc: 0.7469\n",
            "Epoch 4: val_acc did not improve from 0.32857\n",
            "8/8 [==============================] - 45s 5s/step - loss: 0.7468 - acc: 0.7469 - val_loss: 1.7278 - val_acc: 0.3071\n",
            "Epoch 5/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6914 - acc: 0.7837\n",
            "Epoch 5: val_acc improved from 0.32857 to 0.40000, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-05-acc-0.40.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.6914 - acc: 0.7837 - val_loss: 1.6226 - val_acc: 0.4000\n",
            "Epoch 6/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5298 - acc: 0.8327\n",
            "Epoch 6: val_acc improved from 0.40000 to 0.45000, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-06-acc-0.45.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.5298 - acc: 0.8327 - val_loss: 1.5252 - val_acc: 0.4500\n",
            "Epoch 7/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4754 - acc: 0.8367\n",
            "Epoch 7: val_acc improved from 0.45000 to 0.50714, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-07-acc-0.51.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.4754 - acc: 0.8367 - val_loss: 1.3988 - val_acc: 0.5071\n",
            "Epoch 8/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4107 - acc: 0.8571\n",
            "Epoch 8: val_acc improved from 0.50714 to 0.55714, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-08-acc-0.56.hdf5\n",
            "8/8 [==============================] - 34s 4s/step - loss: 0.4107 - acc: 0.8571 - val_loss: 1.3037 - val_acc: 0.5571\n",
            "Epoch 9/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3671 - acc: 0.8796\n",
            "Epoch 9: val_acc improved from 0.55714 to 0.61429, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-09-acc-0.61.hdf5\n",
            "8/8 [==============================] - 39s 4s/step - loss: 0.3671 - acc: 0.8796 - val_loss: 1.2050 - val_acc: 0.6143\n",
            "Epoch 10/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2836 - acc: 0.9163\n",
            "Epoch 10: val_acc improved from 0.61429 to 0.64286, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-10-acc-0.64.hdf5\n",
            "8/8 [==============================] - 38s 4s/step - loss: 0.2836 - acc: 0.9163 - val_loss: 1.1100 - val_acc: 0.6429\n",
            "Epoch 11/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3033 - acc: 0.8918\n",
            "Epoch 11: val_acc improved from 0.64286 to 0.67857, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-11-acc-0.68.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.3033 - acc: 0.8918 - val_loss: 1.0046 - val_acc: 0.6786\n",
            "Epoch 12/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2957 - acc: 0.9000\n",
            "Epoch 12: val_acc improved from 0.67857 to 0.71429, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-12-acc-0.71.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.2957 - acc: 0.9000 - val_loss: 0.9317 - val_acc: 0.7143\n",
            "Epoch 13/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2582 - acc: 0.9204\n",
            "Epoch 13: val_acc improved from 0.71429 to 0.74286, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-13-acc-0.74.hdf5\n",
            "8/8 [==============================] - 44s 5s/step - loss: 0.2582 - acc: 0.9204 - val_loss: 0.8551 - val_acc: 0.7429\n",
            "Epoch 14/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2276 - acc: 0.9306\n",
            "Epoch 14: val_acc improved from 0.74286 to 0.75714, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-14-acc-0.76.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.2276 - acc: 0.9306 - val_loss: 0.7773 - val_acc: 0.7571\n",
            "Epoch 15/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1788 - acc: 0.9408\n",
            "Epoch 15: val_acc improved from 0.75714 to 0.78571, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-15-acc-0.79.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.1788 - acc: 0.9408 - val_loss: 0.7007 - val_acc: 0.7857\n",
            "Epoch 16/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2048 - acc: 0.9347\n",
            "Epoch 16: val_acc improved from 0.78571 to 0.82857, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-16-acc-0.83.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.2048 - acc: 0.9347 - val_loss: 0.6195 - val_acc: 0.8286\n",
            "Epoch 17/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1910 - acc: 0.9265\n",
            "Epoch 17: val_acc improved from 0.82857 to 0.85714, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-17-acc-0.86.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.1910 - acc: 0.9265 - val_loss: 0.5319 - val_acc: 0.8571\n",
            "Epoch 18/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1788 - acc: 0.9429\n",
            "Epoch 18: val_acc did not improve from 0.85714\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.1788 - acc: 0.9429 - val_loss: 0.4726 - val_acc: 0.8571\n",
            "Epoch 19/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1655 - acc: 0.9510\n",
            "Epoch 19: val_acc improved from 0.85714 to 0.87143, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-19-acc-0.87.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.1655 - acc: 0.9510 - val_loss: 0.4347 - val_acc: 0.8714\n",
            "Epoch 20/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1451 - acc: 0.9592\n",
            "Epoch 20: val_acc improved from 0.87143 to 0.87857, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-20-acc-0.88.hdf5\n",
            "8/8 [==============================] - 45s 5s/step - loss: 0.1451 - acc: 0.9592 - val_loss: 0.4005 - val_acc: 0.8786\n",
            "Epoch 21/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1314 - acc: 0.9592\n",
            "Epoch 21: val_acc improved from 0.87857 to 0.88571, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-21-acc-0.89.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.1314 - acc: 0.9592 - val_loss: 0.3700 - val_acc: 0.8857\n",
            "Epoch 22/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1447 - acc: 0.9592\n",
            "Epoch 22: val_acc improved from 0.88571 to 0.89286, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-22-acc-0.89.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.1447 - acc: 0.9592 - val_loss: 0.3398 - val_acc: 0.8929\n",
            "Epoch 23/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1475 - acc: 0.9571\n",
            "Epoch 23: val_acc improved from 0.89286 to 0.90714, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-23-acc-0.91.hdf5\n",
            "8/8 [==============================] - 45s 6s/step - loss: 0.1475 - acc: 0.9571 - val_loss: 0.3080 - val_acc: 0.9071\n",
            "Epoch 24/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1344 - acc: 0.9531\n",
            "Epoch 24: val_acc did not improve from 0.90714\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.1344 - acc: 0.9531 - val_loss: 0.2753 - val_acc: 0.9071\n",
            "Epoch 25/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1201 - acc: 0.9592\n",
            "Epoch 25: val_acc improved from 0.90714 to 0.92143, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-25-acc-0.92.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.1201 - acc: 0.9592 - val_loss: 0.2433 - val_acc: 0.9214\n",
            "Epoch 26/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1314 - acc: 0.9531\n",
            "Epoch 26: val_acc improved from 0.92143 to 0.94286, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-26-acc-0.94.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.1314 - acc: 0.9531 - val_loss: 0.2215 - val_acc: 0.9429\n",
            "Epoch 27/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1173 - acc: 0.9673\n",
            "Epoch 27: val_acc did not improve from 0.94286\n",
            "8/8 [==============================] - 45s 5s/step - loss: 0.1173 - acc: 0.9673 - val_loss: 0.2082 - val_acc: 0.9429\n",
            "Epoch 28/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1054 - acc: 0.9796\n",
            "Epoch 28: val_acc improved from 0.94286 to 0.95000, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-28-acc-0.95.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.1054 - acc: 0.9796 - val_loss: 0.1951 - val_acc: 0.9500\n",
            "Epoch 29/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1014 - acc: 0.9694\n",
            "Epoch 29: val_acc did not improve from 0.95000\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.1014 - acc: 0.9694 - val_loss: 0.1886 - val_acc: 0.9500\n",
            "Epoch 30/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1097 - acc: 0.9673\n",
            "Epoch 30: val_acc did not improve from 0.95000\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.1097 - acc: 0.9673 - val_loss: 0.1784 - val_acc: 0.9429\n",
            "Epoch 31/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1405 - acc: 0.9510\n",
            "Epoch 31: val_acc did not improve from 0.95000\n",
            "8/8 [==============================] - 45s 6s/step - loss: 0.1405 - acc: 0.9510 - val_loss: 0.1722 - val_acc: 0.9429\n",
            "Epoch 32/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1295 - acc: 0.9612\n",
            "Epoch 32: val_acc did not improve from 0.95000\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.1295 - acc: 0.9612 - val_loss: 0.1607 - val_acc: 0.9500\n",
            "Epoch 33/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0998 - acc: 0.9735\n",
            "Epoch 33: val_acc improved from 0.95000 to 0.96429, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-33-acc-0.96.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.0998 - acc: 0.9735 - val_loss: 0.1479 - val_acc: 0.9643\n",
            "Epoch 34/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1045 - acc: 0.9653\n",
            "Epoch 34: val_acc improved from 0.96429 to 0.97143, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-34-acc-0.97.hdf5\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.1045 - acc: 0.9653 - val_loss: 0.1393 - val_acc: 0.9714\n",
            "Epoch 35/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0815 - acc: 0.9796\n",
            "Epoch 35: val_acc did not improve from 0.97143\n",
            "8/8 [==============================] - 40s 5s/step - loss: 0.0815 - acc: 0.9796 - val_loss: 0.1396 - val_acc: 0.9500\n",
            "Epoch 36/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0890 - acc: 0.9673\n",
            "Epoch 36: val_acc did not improve from 0.97143\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.0890 - acc: 0.9673 - val_loss: 0.1356 - val_acc: 0.9500\n",
            "Epoch 37/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1002 - acc: 0.9694\n",
            "Epoch 37: val_acc did not improve from 0.97143\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.1002 - acc: 0.9694 - val_loss: 0.1246 - val_acc: 0.9500\n",
            "Epoch 38/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0870 - acc: 0.9776\n",
            "Epoch 38: val_acc did not improve from 0.97143\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.0870 - acc: 0.9776 - val_loss: 0.1170 - val_acc: 0.9571\n",
            "Epoch 39/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0658 - acc: 0.9857\n",
            "Epoch 39: val_acc did not improve from 0.97143\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.0658 - acc: 0.9857 - val_loss: 0.1142 - val_acc: 0.9643\n",
            "Epoch 40/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0708 - acc: 0.9816\n",
            "Epoch 40: val_acc improved from 0.97143 to 0.97857, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-40-acc-0.98.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.0708 - acc: 0.9816 - val_loss: 0.1116 - val_acc: 0.9786\n",
            "Epoch 41/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0701 - acc: 0.9776\n",
            "Epoch 41: val_acc did not improve from 0.97857\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.0701 - acc: 0.9776 - val_loss: 0.1128 - val_acc: 0.9786\n",
            "Epoch 42/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0859 - acc: 0.9776\n",
            "Epoch 42: val_acc did not improve from 0.97857\n",
            "8/8 [==============================] - 45s 5s/step - loss: 0.0859 - acc: 0.9776 - val_loss: 0.1157 - val_acc: 0.9643\n",
            "Epoch 43/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0877 - acc: 0.9694\n",
            "Epoch 43: val_acc did not improve from 0.97857\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.0877 - acc: 0.9694 - val_loss: 0.1232 - val_acc: 0.9714\n",
            "Epoch 44/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0622 - acc: 0.9857\n",
            "Epoch 44: val_acc did not improve from 0.97857\n",
            "8/8 [==============================] - 45s 6s/step - loss: 0.0622 - acc: 0.9857 - val_loss: 0.1234 - val_acc: 0.9714\n",
            "Epoch 45/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0568 - acc: 0.9816\n",
            "Epoch 45: val_acc did not improve from 0.97857\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.0568 - acc: 0.9816 - val_loss: 0.1177 - val_acc: 0.9714\n",
            "\n",
            "\n",
            "Model Accuracy 0.8285714285714286\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.90      0.95        10\n",
            "       10000       0.67      0.80      0.73        10\n",
            "      100000       1.00      0.60      0.75        10\n",
            "        2000       0.83      1.00      0.91        10\n",
            "       20000       0.91      1.00      0.95        10\n",
            "        5000       0.70      0.70      0.70        10\n",
            "       50000       0.80      0.80      0.80        10\n",
            "\n",
            "    accuracy                           0.83        70\n",
            "   macro avg       0.84      0.83      0.83        70\n",
            "weighted avg       0.84      0.83      0.83        70\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_19668\\1083539539.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Found 490 images belonging to 7 classes.\n",
            "Found 70 images belonging to 7 classes.\n",
            "Found 140 images belonging to 7 classes.\n",
            "Percobaan ke- 2 ↓\n",
            "───────────────────────────────────────HYPERPARAMETER VGG-16────────────────────────────────────────\n",
            "vgg epoch: 48\n",
            "learning rate: 0.001789042\n",
            "batch size: 64\n",
            "dropout rate: 0.617462768\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.8154 - acc: 0.2265\n",
            "Epoch 1: val_acc improved from -inf to 0.32857, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-01-acc-0.33.hdf5\n",
            "8/8 [==============================] - 42s 5s/step - loss: 2.8154 - acc: 0.2265 - val_loss: 2.1719 - val_acc: 0.3286\n",
            "Epoch 2/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4989 - acc: 0.5286\n",
            "Epoch 2: val_acc improved from 0.32857 to 0.37143, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-02-acc-0.37.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 1.4989 - acc: 0.5286 - val_loss: 1.9748 - val_acc: 0.3714\n",
            "Epoch 3/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.1262 - acc: 0.6143\n",
            "Epoch 3: val_acc improved from 0.37143 to 0.45000, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-03-acc-0.45.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 1.1262 - acc: 0.6143 - val_loss: 1.7986 - val_acc: 0.4500\n",
            "Epoch 4/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8150 - acc: 0.7224\n",
            "Epoch 4: val_acc improved from 0.45000 to 0.49286, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-04-acc-0.49.hdf5\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.8150 - acc: 0.7224 - val_loss: 1.5736 - val_acc: 0.4929\n",
            "Epoch 5/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6304 - acc: 0.7776\n",
            "Epoch 5: val_acc improved from 0.49286 to 0.58571, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-05-acc-0.59.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.6304 - acc: 0.7776 - val_loss: 1.3657 - val_acc: 0.5857\n",
            "Epoch 6/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6224 - acc: 0.8000\n",
            "Epoch 6: val_acc improved from 0.58571 to 0.60714, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-06-acc-0.61.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.6224 - acc: 0.8000 - val_loss: 1.2123 - val_acc: 0.6071\n",
            "Epoch 7/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5350 - acc: 0.8143\n",
            "Epoch 7: val_acc did not improve from 0.60714\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.5350 - acc: 0.8143 - val_loss: 1.1096 - val_acc: 0.6000\n",
            "Epoch 8/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4711 - acc: 0.8265\n",
            "Epoch 8: val_acc improved from 0.60714 to 0.64286, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-08-acc-0.64.hdf5\n",
            "8/8 [==============================] - 44s 5s/step - loss: 0.4711 - acc: 0.8265 - val_loss: 1.0012 - val_acc: 0.6429\n",
            "Epoch 9/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3630 - acc: 0.8735\n",
            "Epoch 9: val_acc improved from 0.64286 to 0.70714, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-09-acc-0.71.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.3630 - acc: 0.8735 - val_loss: 0.9054 - val_acc: 0.7071\n",
            "Epoch 10/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2896 - acc: 0.9102\n",
            "Epoch 10: val_acc improved from 0.70714 to 0.79286, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-10-acc-0.79.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.2896 - acc: 0.9102 - val_loss: 0.7775 - val_acc: 0.7929\n",
            "Epoch 11/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2790 - acc: 0.9082\n",
            "Epoch 11: val_acc improved from 0.79286 to 0.81429, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-11-acc-0.81.hdf5\n",
            "8/8 [==============================] - 44s 5s/step - loss: 0.2790 - acc: 0.9082 - val_loss: 0.6781 - val_acc: 0.8143\n",
            "Epoch 12/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2643 - acc: 0.9204\n",
            "Epoch 12: val_acc improved from 0.81429 to 0.82143, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-12-acc-0.82.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.2643 - acc: 0.9204 - val_loss: 0.6220 - val_acc: 0.8214\n",
            "Epoch 13/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3106 - acc: 0.9122\n",
            "Epoch 13: val_acc improved from 0.82143 to 0.85000, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-13-acc-0.85.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.3106 - acc: 0.9122 - val_loss: 0.5598 - val_acc: 0.8500\n",
            "Epoch 14/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2195 - acc: 0.9245\n",
            "Epoch 14: val_acc did not improve from 0.85000\n",
            "8/8 [==============================] - 45s 5s/step - loss: 0.2195 - acc: 0.9245 - val_loss: 0.5352 - val_acc: 0.8429\n",
            "Epoch 15/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2121 - acc: 0.9347\n",
            "Epoch 15: val_acc improved from 0.85000 to 0.86429, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-15-acc-0.86.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.2121 - acc: 0.9347 - val_loss: 0.4890 - val_acc: 0.8643\n",
            "Epoch 16/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2147 - acc: 0.9388\n",
            "Epoch 16: val_acc improved from 0.86429 to 0.88571, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-16-acc-0.89.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.2147 - acc: 0.9388 - val_loss: 0.4406 - val_acc: 0.8857\n",
            "Epoch 17/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1655 - acc: 0.9469\n",
            "Epoch 17: val_acc improved from 0.88571 to 0.90714, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-17-acc-0.91.hdf5\n",
            "8/8 [==============================] - 45s 6s/step - loss: 0.1655 - acc: 0.9469 - val_loss: 0.4002 - val_acc: 0.9071\n",
            "Epoch 18/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1887 - acc: 0.9347\n",
            "Epoch 18: val_acc improved from 0.90714 to 0.92857, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-18-acc-0.93.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.1887 - acc: 0.9347 - val_loss: 0.3797 - val_acc: 0.9286\n",
            "Epoch 19/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1530 - acc: 0.9531\n",
            "Epoch 19: val_acc did not improve from 0.92857\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.1530 - acc: 0.9531 - val_loss: 0.3817 - val_acc: 0.9000\n",
            "Epoch 20/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1547 - acc: 0.9469\n",
            "Epoch 20: val_acc did not improve from 0.92857\n",
            "8/8 [==============================] - 45s 6s/step - loss: 0.1547 - acc: 0.9469 - val_loss: 0.3565 - val_acc: 0.9286\n",
            "Epoch 21/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1555 - acc: 0.9490\n",
            "Epoch 21: val_acc improved from 0.92857 to 0.95000, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-21-acc-0.95.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.1555 - acc: 0.9490 - val_loss: 0.3189 - val_acc: 0.9500\n",
            "Epoch 22/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1311 - acc: 0.9571\n",
            "Epoch 22: val_acc improved from 0.95000 to 0.95714, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-22-acc-0.96.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.1311 - acc: 0.9571 - val_loss: 0.2899 - val_acc: 0.9571\n",
            "Epoch 23/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1259 - acc: 0.9592\n",
            "Epoch 23: val_acc did not improve from 0.95714\n",
            "8/8 [==============================] - 40s 5s/step - loss: 0.1259 - acc: 0.9592 - val_loss: 0.2624 - val_acc: 0.9571\n",
            "Epoch 24/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1009 - acc: 0.9633\n",
            "Epoch 24: val_acc did not improve from 0.95714\n",
            "8/8 [==============================] - 42s 5s/step - loss: 0.1009 - acc: 0.9633 - val_loss: 0.2417 - val_acc: 0.9571\n",
            "Epoch 25/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0850 - acc: 0.9857\n",
            "Epoch 25: val_acc did not improve from 0.95714\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.0850 - acc: 0.9857 - val_loss: 0.2274 - val_acc: 0.9571\n",
            "Epoch 26/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1140 - acc: 0.9714\n",
            "Epoch 26: val_acc improved from 0.95714 to 0.96429, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-26-acc-0.96.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.1140 - acc: 0.9714 - val_loss: 0.2112 - val_acc: 0.9643\n",
            "Epoch 27/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1309 - acc: 0.9633\n",
            "Epoch 27: val_acc did not improve from 0.96429\n",
            "8/8 [==============================] - 45s 6s/step - loss: 0.1309 - acc: 0.9633 - val_loss: 0.1942 - val_acc: 0.9571\n",
            "Epoch 28/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1179 - acc: 0.9673\n",
            "Epoch 28: val_acc did not improve from 0.96429\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.1179 - acc: 0.9673 - val_loss: 0.1741 - val_acc: 0.9643\n",
            "Epoch 29/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0928 - acc: 0.9673\n",
            "Epoch 29: val_acc did not improve from 0.96429\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.0928 - acc: 0.9673 - val_loss: 0.1689 - val_acc: 0.9643\n",
            "Epoch 30/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1127 - acc: 0.9673\n",
            "Epoch 30: val_acc did not improve from 0.96429\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.1127 - acc: 0.9673 - val_loss: 0.1763 - val_acc: 0.9571\n",
            "Epoch 31/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1042 - acc: 0.9694\n",
            "Epoch 31: val_acc did not improve from 0.96429\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.1042 - acc: 0.9694 - val_loss: 0.1857 - val_acc: 0.9571\n",
            "Epoch 32/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1028 - acc: 0.9653\n",
            "Epoch 32: val_acc did not improve from 0.96429\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.1028 - acc: 0.9653 - val_loss: 0.1866 - val_acc: 0.9500\n",
            "Epoch 33/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1014 - acc: 0.9714\n",
            "Epoch 33: val_acc did not improve from 0.96429\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.1014 - acc: 0.9714 - val_loss: 0.1593 - val_acc: 0.9500\n",
            "Epoch 34/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0761 - acc: 0.9857\n",
            "Epoch 34: val_acc did not improve from 0.96429\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.0761 - acc: 0.9857 - val_loss: 0.1471 - val_acc: 0.9571\n",
            "Epoch 35/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0756 - acc: 0.9796\n",
            "Epoch 35: val_acc did not improve from 0.96429\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.0756 - acc: 0.9796 - val_loss: 0.1470 - val_acc: 0.9571\n",
            "Epoch 36/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0862 - acc: 0.9857\n",
            "Epoch 36: val_acc did not improve from 0.96429\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.0862 - acc: 0.9857 - val_loss: 0.1384 - val_acc: 0.9571\n",
            "Epoch 37/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0931 - acc: 0.9714\n",
            "Epoch 37: val_acc did not improve from 0.96429\n",
            "8/8 [==============================] - 44s 5s/step - loss: 0.0931 - acc: 0.9714 - val_loss: 0.1397 - val_acc: 0.9571\n",
            "Epoch 38/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0935 - acc: 0.9714\n",
            "Epoch 38: val_acc did not improve from 0.96429\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.0935 - acc: 0.9714 - val_loss: 0.1437 - val_acc: 0.9500\n",
            "Epoch 39/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0757 - acc: 0.9755\n",
            "Epoch 39: val_acc did not improve from 0.96429\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.0757 - acc: 0.9755 - val_loss: 0.1440 - val_acc: 0.9500\n",
            "Epoch 40/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0731 - acc: 0.9796\n",
            "Epoch 40: val_acc did not improve from 0.96429\n",
            "8/8 [==============================] - 44s 5s/step - loss: 0.0731 - acc: 0.9796 - val_loss: 0.1361 - val_acc: 0.9571\n",
            "Epoch 41/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0846 - acc: 0.9714\n",
            "Epoch 41: val_acc improved from 0.96429 to 0.97143, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-41-acc-0.97.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.0846 - acc: 0.9714 - val_loss: 0.1269 - val_acc: 0.9714\n",
            "Epoch 42/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0673 - acc: 0.9776\n",
            "Epoch 42: val_acc did not improve from 0.97143\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.0673 - acc: 0.9776 - val_loss: 0.1298 - val_acc: 0.9643\n",
            "Epoch 43/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0618 - acc: 0.9857\n",
            "Epoch 43: val_acc did not improve from 0.97143\n",
            "8/8 [==============================] - 44s 5s/step - loss: 0.0618 - acc: 0.9857 - val_loss: 0.1316 - val_acc: 0.9643\n",
            "Epoch 44/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0693 - acc: 0.9694\n",
            "Epoch 44: val_acc did not improve from 0.97143\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.0693 - acc: 0.9694 - val_loss: 0.1357 - val_acc: 0.9643\n",
            "Epoch 45/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0877 - acc: 0.9755\n",
            "Epoch 45: val_acc did not improve from 0.97143\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.0877 - acc: 0.9755 - val_loss: 0.1402 - val_acc: 0.9571\n",
            "Epoch 46/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0562 - acc: 0.9837\n",
            "Epoch 46: val_acc did not improve from 0.97143\n",
            "8/8 [==============================] - 44s 5s/step - loss: 0.0562 - acc: 0.9837 - val_loss: 0.1376 - val_acc: 0.9571\n",
            "\n",
            "\n",
            "Model Accuracy 0.6857142857142857\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.88      0.70      0.78        10\n",
            "       10000       0.43      0.60      0.50        10\n",
            "      100000       0.62      0.50      0.56        10\n",
            "        2000       0.50      0.90      0.64        10\n",
            "       20000       1.00      0.90      0.95        10\n",
            "        5000       1.00      0.50      0.67        10\n",
            "       50000       0.88      0.70      0.78        10\n",
            "\n",
            "    accuracy                           0.69        70\n",
            "   macro avg       0.76      0.69      0.70        70\n",
            "weighted avg       0.76      0.69      0.70        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Found 490 images belonging to 7 classes.\n",
            "Found 70 images belonging to 7 classes.\n",
            "Found 140 images belonging to 7 classes.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_19668\\1083539539.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percobaan ke- 3 ↓\n",
            "───────────────────────────────────────HYPERPARAMETER VGG-16────────────────────────────────────────\n",
            "vgg epoch: 48\n",
            "learning rate: 0.001789042\n",
            "batch size: 64\n",
            "dropout rate: 0.617462768\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.6044 - acc: 0.2653\n",
            "Epoch 1: val_acc improved from -inf to 0.35000, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-01-acc-0.35.hdf5\n",
            "8/8 [==============================] - 42s 5s/step - loss: 2.6044 - acc: 0.2653 - val_loss: 1.9698 - val_acc: 0.3500\n",
            "Epoch 2/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4322 - acc: 0.5265\n",
            "Epoch 2: val_acc improved from 0.35000 to 0.47143, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-02-acc-0.47.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 1.4322 - acc: 0.5265 - val_loss: 1.7580 - val_acc: 0.4714\n",
            "Epoch 3/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9726 - acc: 0.6612\n",
            "Epoch 3: val_acc improved from 0.47143 to 0.55000, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-03-acc-0.55.hdf5\n",
            "8/8 [==============================] - 41s 5s/step - loss: 0.9726 - acc: 0.6612 - val_loss: 1.4911 - val_acc: 0.5500\n",
            "Epoch 4/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7462 - acc: 0.7388\n",
            "Epoch 4: val_acc improved from 0.55000 to 0.56429, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-04-acc-0.56.hdf5\n",
            "8/8 [==============================] - 42s 5s/step - loss: 0.7462 - acc: 0.7388 - val_loss: 1.3869 - val_acc: 0.5643\n",
            "Epoch 5/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6343 - acc: 0.7776\n",
            "Epoch 5: val_acc improved from 0.56429 to 0.61429, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-05-acc-0.61.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.6343 - acc: 0.7776 - val_loss: 1.2412 - val_acc: 0.6143\n",
            "Epoch 6/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4892 - acc: 0.8265\n",
            "Epoch 6: val_acc improved from 0.61429 to 0.70000, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-06-acc-0.70.hdf5\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.4892 - acc: 0.8265 - val_loss: 1.1171 - val_acc: 0.7000\n",
            "Epoch 7/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4338 - acc: 0.8653\n",
            "Epoch 7: val_acc improved from 0.70000 to 0.70714, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-07-acc-0.71.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.4338 - acc: 0.8653 - val_loss: 1.0483 - val_acc: 0.7071\n",
            "Epoch 8/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3276 - acc: 0.8898\n",
            "Epoch 8: val_acc improved from 0.70714 to 0.73571, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-08-acc-0.74.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.3276 - acc: 0.8898 - val_loss: 0.9779 - val_acc: 0.7357\n",
            "Epoch 9/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2990 - acc: 0.8939\n",
            "Epoch 9: val_acc did not improve from 0.73571\n",
            "8/8 [==============================] - 44s 5s/step - loss: 0.2990 - acc: 0.8939 - val_loss: 0.9501 - val_acc: 0.7143\n",
            "Epoch 10/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2679 - acc: 0.9122\n",
            "Epoch 10: val_acc improved from 0.73571 to 0.74286, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-10-acc-0.74.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.2679 - acc: 0.9122 - val_loss: 0.8750 - val_acc: 0.7429\n",
            "Epoch 11/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2474 - acc: 0.9204\n",
            "Epoch 11: val_acc improved from 0.74286 to 0.76429, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-11-acc-0.76.hdf5\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.2474 - acc: 0.9204 - val_loss: 0.7979 - val_acc: 0.7643\n",
            "Epoch 12/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2554 - acc: 0.9082\n",
            "Epoch 12: val_acc improved from 0.76429 to 0.81429, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-12-acc-0.81.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.2554 - acc: 0.9082 - val_loss: 0.7086 - val_acc: 0.8143\n",
            "Epoch 13/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1769 - acc: 0.9449\n",
            "Epoch 13: val_acc improved from 0.81429 to 0.85000, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-13-acc-0.85.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.1769 - acc: 0.9449 - val_loss: 0.6333 - val_acc: 0.8500\n",
            "Epoch 14/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2292 - acc: 0.9224\n",
            "Epoch 14: val_acc improved from 0.85000 to 0.85714, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-14-acc-0.86.hdf5\n",
            "8/8 [==============================] - 45s 6s/step - loss: 0.2292 - acc: 0.9224 - val_loss: 0.5741 - val_acc: 0.8571\n",
            "Epoch 15/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1895 - acc: 0.9388\n",
            "Epoch 15: val_acc improved from 0.85714 to 0.87857, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-15-acc-0.88.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.1895 - acc: 0.9388 - val_loss: 0.5259 - val_acc: 0.8786\n",
            "Epoch 16/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1610 - acc: 0.9510\n",
            "Epoch 16: val_acc did not improve from 0.87857\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.1610 - acc: 0.9510 - val_loss: 0.4842 - val_acc: 0.8786\n",
            "Epoch 17/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1630 - acc: 0.9510\n",
            "Epoch 17: val_acc improved from 0.87857 to 0.88571, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-17-acc-0.89.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.1630 - acc: 0.9510 - val_loss: 0.4515 - val_acc: 0.8857\n",
            "Epoch 18/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1353 - acc: 0.9531\n",
            "Epoch 18: val_acc improved from 0.88571 to 0.89286, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-18-acc-0.89.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.1353 - acc: 0.9531 - val_loss: 0.4083 - val_acc: 0.8929\n",
            "Epoch 19/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1289 - acc: 0.9673\n",
            "Epoch 19: val_acc improved from 0.89286 to 0.91429, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-19-acc-0.91.hdf5\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.1289 - acc: 0.9673 - val_loss: 0.3670 - val_acc: 0.9143\n",
            "Epoch 20/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1567 - acc: 0.9388\n",
            "Epoch 20: val_acc improved from 0.91429 to 0.92143, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-20-acc-0.92.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.1567 - acc: 0.9388 - val_loss: 0.3335 - val_acc: 0.9214\n",
            "Epoch 21/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1589 - acc: 0.9510\n",
            "Epoch 21: val_acc improved from 0.92143 to 0.93571, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-21-acc-0.94.hdf5\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.1589 - acc: 0.9510 - val_loss: 0.3062 - val_acc: 0.9357\n",
            "Epoch 22/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1186 - acc: 0.9653\n",
            "Epoch 22: val_acc improved from 0.93571 to 0.94286, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-22-acc-0.94.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.1186 - acc: 0.9653 - val_loss: 0.2843 - val_acc: 0.9429\n",
            "Epoch 23/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1317 - acc: 0.9551\n",
            "Epoch 23: val_acc did not improve from 0.94286\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.1317 - acc: 0.9551 - val_loss: 0.2633 - val_acc: 0.9429\n",
            "Epoch 24/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1307 - acc: 0.9592\n",
            "Epoch 24: val_acc did not improve from 0.94286\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.1307 - acc: 0.9592 - val_loss: 0.2544 - val_acc: 0.9357\n",
            "Epoch 25/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1092 - acc: 0.9673\n",
            "Epoch 25: val_acc did not improve from 0.94286\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.1092 - acc: 0.9673 - val_loss: 0.2434 - val_acc: 0.9286\n",
            "Epoch 26/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1262 - acc: 0.9571\n",
            "Epoch 26: val_acc did not improve from 0.94286\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.1262 - acc: 0.9571 - val_loss: 0.2341 - val_acc: 0.9286\n",
            "Epoch 27/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1122 - acc: 0.9633\n",
            "Epoch 27: val_acc did not improve from 0.94286\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.1122 - acc: 0.9633 - val_loss: 0.2249 - val_acc: 0.9429\n",
            "Epoch 28/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0926 - acc: 0.9673\n",
            "Epoch 28: val_acc did not improve from 0.94286\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.0926 - acc: 0.9673 - val_loss: 0.2152 - val_acc: 0.9143\n",
            "Epoch 29/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1110 - acc: 0.9673\n",
            "Epoch 29: val_acc did not improve from 0.94286\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.1110 - acc: 0.9673 - val_loss: 0.2103 - val_acc: 0.9071\n",
            "Epoch 30/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0908 - acc: 0.9735\n",
            "Epoch 30: val_acc did not improve from 0.94286\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.0908 - acc: 0.9735 - val_loss: 0.2087 - val_acc: 0.9214\n",
            "Epoch 31/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1129 - acc: 0.9633\n",
            "Epoch 31: val_acc did not improve from 0.94286\n",
            "8/8 [==============================] - 44s 5s/step - loss: 0.1129 - acc: 0.9633 - val_loss: 0.2072 - val_acc: 0.9214\n",
            "Epoch 32/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0890 - acc: 0.9735\n",
            "Epoch 32: val_acc did not improve from 0.94286\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.0890 - acc: 0.9735 - val_loss: 0.2080 - val_acc: 0.9286\n",
            "Epoch 33/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0865 - acc: 0.9796\n",
            "Epoch 33: val_acc did not improve from 0.94286\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.0865 - acc: 0.9796 - val_loss: 0.2084 - val_acc: 0.9214\n",
            "Epoch 34/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0961 - acc: 0.9633\n",
            "Epoch 34: val_acc did not improve from 0.94286\n",
            "8/8 [==============================] - 43s 5s/step - loss: 0.0961 - acc: 0.9633 - val_loss: 0.1963 - val_acc: 0.9214\n",
            "Epoch 35/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0685 - acc: 0.9755\n",
            "Epoch 35: val_acc did not improve from 0.94286\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.0685 - acc: 0.9755 - val_loss: 0.1883 - val_acc: 0.9214\n",
            "Epoch 36/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0697 - acc: 0.9857\n",
            "Epoch 36: val_acc did not improve from 0.94286\n",
            "8/8 [==============================] - 40s 5s/step - loss: 0.0697 - acc: 0.9857 - val_loss: 0.1867 - val_acc: 0.9214\n",
            "Epoch 37/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0684 - acc: 0.9837\n",
            "Epoch 37: val_acc did not improve from 0.94286\n",
            "8/8 [==============================] - 42s 5s/step - loss: 0.0684 - acc: 0.9837 - val_loss: 0.1851 - val_acc: 0.9214\n",
            "Epoch 38/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0675 - acc: 0.9776\n",
            "Epoch 38: val_acc did not improve from 0.94286\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.0675 - acc: 0.9776 - val_loss: 0.1866 - val_acc: 0.9214\n",
            "Epoch 39/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0453 - acc: 0.9918\n",
            "Epoch 39: val_acc did not improve from 0.94286\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.0453 - acc: 0.9918 - val_loss: 0.1843 - val_acc: 0.9214\n",
            "Epoch 40/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0621 - acc: 0.9776\n",
            "Epoch 40: val_acc did not improve from 0.94286\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.0621 - acc: 0.9776 - val_loss: 0.1887 - val_acc: 0.9143\n",
            "Epoch 41/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0745 - acc: 0.9776\n",
            "Epoch 41: val_acc did not improve from 0.94286\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.0745 - acc: 0.9776 - val_loss: 0.1859 - val_acc: 0.9143\n",
            "Epoch 42/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0593 - acc: 0.9857\n",
            "Epoch 42: val_acc did not improve from 0.94286\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.0593 - acc: 0.9857 - val_loss: 0.1749 - val_acc: 0.9286\n",
            "Epoch 43/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0540 - acc: 0.9816\n",
            "Epoch 43: val_acc did not improve from 0.94286\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.0540 - acc: 0.9816 - val_loss: 0.1750 - val_acc: 0.9214\n",
            "Epoch 44/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0721 - acc: 0.9776\n",
            "Epoch 44: val_acc did not improve from 0.94286\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.0721 - acc: 0.9776 - val_loss: 0.1721 - val_acc: 0.9214\n",
            "Epoch 45/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0513 - acc: 0.9878\n",
            "Epoch 45: val_acc did not improve from 0.94286\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.0513 - acc: 0.9878 - val_loss: 0.1803 - val_acc: 0.9286\n",
            "Epoch 46/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0476 - acc: 0.9878\n",
            "Epoch 46: val_acc did not improve from 0.94286\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.0476 - acc: 0.9878 - val_loss: 0.1807 - val_acc: 0.9286\n",
            "Epoch 47/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0522 - acc: 0.9878\n",
            "Epoch 47: val_acc did not improve from 0.94286\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.0522 - acc: 0.9878 - val_loss: 0.1794 - val_acc: 0.9357\n",
            "Epoch 48/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0466 - acc: 0.9898\n",
            "Epoch 48: val_acc did not improve from 0.94286\n",
            "8/8 [==============================] - 44s 5s/step - loss: 0.0466 - acc: 0.9898 - val_loss: 0.1778 - val_acc: 0.9429\n",
            "\n",
            "\n",
            "Model Accuracy 0.6714285714285714\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.73      0.80      0.76        10\n",
            "       10000       0.47      0.70      0.56        10\n",
            "      100000       0.83      0.50      0.62        10\n",
            "        2000       0.67      0.80      0.73        10\n",
            "       20000       0.73      0.80      0.76        10\n",
            "        5000       0.60      0.60      0.60        10\n",
            "       50000       1.00      0.50      0.67        10\n",
            "\n",
            "    accuracy                           0.67        70\n",
            "   macro avg       0.72      0.67      0.67        70\n",
            "weighted avg       0.72      0.67      0.67        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Found 490 images belonging to 7 classes.\n",
            "Found 70 images belonging to 7 classes.\n",
            "Found 140 images belonging to 7 classes.\n",
            "Percobaan ke- 4 ↓\n",
            "───────────────────────────────────────HYPERPARAMETER VGG-16────────────────────────────────────────\n",
            "vgg epoch: 48\n",
            "learning rate: 0.001789042\n",
            "batch size: 64\n",
            "dropout rate: 0.617462768\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_19668\\1083539539.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.8436 - acc: 0.2184\n",
            "Epoch 1: val_acc improved from -inf to 0.18571, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-01-acc-0.19.hdf5\n",
            "8/8 [==============================] - 42s 5s/step - loss: 2.8436 - acc: 0.2184 - val_loss: 1.8745 - val_acc: 0.1857\n",
            "Epoch 2/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6348 - acc: 0.4837\n",
            "Epoch 2: val_acc improved from 0.18571 to 0.25714, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-02-acc-0.26.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 1.6348 - acc: 0.4837 - val_loss: 1.7520 - val_acc: 0.2571\n",
            "Epoch 3/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0781 - acc: 0.6388\n",
            "Epoch 3: val_acc improved from 0.25714 to 0.35000, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-03-acc-0.35.hdf5\n",
            "8/8 [==============================] - 43s 6s/step - loss: 1.0781 - acc: 0.6388 - val_loss: 1.6647 - val_acc: 0.3500\n",
            "Epoch 4/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7580 - acc: 0.7551\n",
            "Epoch 4: val_acc improved from 0.35000 to 0.42857, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-04-acc-0.43.hdf5\n",
            "8/8 [==============================] - 40s 5s/step - loss: 0.7580 - acc: 0.7551 - val_loss: 1.4891 - val_acc: 0.4286\n",
            "Epoch 5/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.5980 - acc: 0.7918\n",
            "Epoch 5: val_acc improved from 0.42857 to 0.53571, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-05-acc-0.54.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.5980 - acc: 0.7918 - val_loss: 1.3777 - val_acc: 0.5357\n",
            "Epoch 6/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4915 - acc: 0.8327\n",
            "Epoch 6: val_acc improved from 0.53571 to 0.55714, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-06-acc-0.56.hdf5\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.4915 - acc: 0.8327 - val_loss: 1.3044 - val_acc: 0.5571\n",
            "Epoch 7/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4480 - acc: 0.8571\n",
            "Epoch 7: val_acc improved from 0.55714 to 0.56429, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-07-acc-0.56.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.4480 - acc: 0.8571 - val_loss: 1.2501 - val_acc: 0.5643\n",
            "Epoch 8/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3717 - acc: 0.8755\n",
            "Epoch 8: val_acc improved from 0.56429 to 0.63571, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-08-acc-0.64.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.3717 - acc: 0.8755 - val_loss: 1.1645 - val_acc: 0.6357\n",
            "Epoch 9/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3285 - acc: 0.9041\n",
            "Epoch 9: val_acc improved from 0.63571 to 0.67143, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-09-acc-0.67.hdf5\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.3285 - acc: 0.9041 - val_loss: 1.0893 - val_acc: 0.6714\n",
            "Epoch 10/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3204 - acc: 0.8980\n",
            "Epoch 10: val_acc improved from 0.67143 to 0.71429, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-10-acc-0.71.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.3204 - acc: 0.8980 - val_loss: 1.0024 - val_acc: 0.7143\n",
            "Epoch 11/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2317 - acc: 0.9306\n",
            "Epoch 11: val_acc improved from 0.71429 to 0.72143, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-11-acc-0.72.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.2317 - acc: 0.9306 - val_loss: 0.9231 - val_acc: 0.7214\n",
            "Epoch 12/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2179 - acc: 0.9367\n",
            "Epoch 12: val_acc improved from 0.72143 to 0.72857, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-12-acc-0.73.hdf5\n",
            "8/8 [==============================] - 45s 5s/step - loss: 0.2179 - acc: 0.9367 - val_loss: 0.8795 - val_acc: 0.7286\n",
            "Epoch 13/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2698 - acc: 0.9204\n",
            "Epoch 13: val_acc improved from 0.72857 to 0.75714, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-13-acc-0.76.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.2698 - acc: 0.9204 - val_loss: 0.8370 - val_acc: 0.7571\n",
            "Epoch 14/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1980 - acc: 0.9388\n",
            "Epoch 14: val_acc improved from 0.75714 to 0.77857, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-14-acc-0.78.hdf5\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.1980 - acc: 0.9388 - val_loss: 0.7834 - val_acc: 0.7786\n",
            "Epoch 15/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1610 - acc: 0.9510\n",
            "Epoch 15: val_acc improved from 0.77857 to 0.79286, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-15-acc-0.79.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.1610 - acc: 0.9510 - val_loss: 0.7219 - val_acc: 0.7929\n",
            "Epoch 16/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1617 - acc: 0.9551\n",
            "Epoch 16: val_acc improved from 0.79286 to 0.81429, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-16-acc-0.81.hdf5\n",
            "8/8 [==============================] - 40s 5s/step - loss: 0.1617 - acc: 0.9551 - val_loss: 0.6695 - val_acc: 0.8143\n",
            "Epoch 17/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1629 - acc: 0.9469\n",
            "Epoch 17: val_acc improved from 0.81429 to 0.82857, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-17-acc-0.83.hdf5\n",
            "8/8 [==============================] - 43s 5s/step - loss: 0.1629 - acc: 0.9469 - val_loss: 0.6292 - val_acc: 0.8286\n",
            "Epoch 18/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1574 - acc: 0.9429\n",
            "Epoch 18: val_acc did not improve from 0.82857\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.1574 - acc: 0.9429 - val_loss: 0.5923 - val_acc: 0.8286\n",
            "Epoch 19/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1356 - acc: 0.9612\n",
            "Epoch 19: val_acc did not improve from 0.82857\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.1356 - acc: 0.9612 - val_loss: 0.5604 - val_acc: 0.8286\n",
            "Epoch 20/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1356 - acc: 0.9694\n",
            "Epoch 20: val_acc improved from 0.82857 to 0.87143, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-20-acc-0.87.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.1356 - acc: 0.9694 - val_loss: 0.5166 - val_acc: 0.8714\n",
            "Epoch 21/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1604 - acc: 0.9449\n",
            "Epoch 21: val_acc did not improve from 0.87143\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.1604 - acc: 0.9449 - val_loss: 0.4955 - val_acc: 0.8714\n",
            "Epoch 22/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1142 - acc: 0.9694\n",
            "Epoch 22: val_acc improved from 0.87143 to 0.87857, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-22-acc-0.88.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.1142 - acc: 0.9694 - val_loss: 0.4725 - val_acc: 0.8786\n",
            "Epoch 23/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1204 - acc: 0.9571\n",
            "Epoch 23: val_acc improved from 0.87857 to 0.88571, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-23-acc-0.89.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.1204 - acc: 0.9571 - val_loss: 0.4516 - val_acc: 0.8857\n",
            "Epoch 24/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1126 - acc: 0.9612\n",
            "Epoch 24: val_acc did not improve from 0.88571\n",
            "8/8 [==============================] - 45s 5s/step - loss: 0.1126 - acc: 0.9612 - val_loss: 0.4378 - val_acc: 0.8857\n",
            "Epoch 25/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1062 - acc: 0.9653\n",
            "Epoch 25: val_acc did not improve from 0.88571\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.1062 - acc: 0.9653 - val_loss: 0.4341 - val_acc: 0.8857\n",
            "Epoch 26/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0949 - acc: 0.9673\n",
            "Epoch 26: val_acc did not improve from 0.88571\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.0949 - acc: 0.9673 - val_loss: 0.4287 - val_acc: 0.8857\n",
            "Epoch 27/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0998 - acc: 0.9755\n",
            "Epoch 27: val_acc did not improve from 0.88571\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.0998 - acc: 0.9755 - val_loss: 0.4193 - val_acc: 0.8786\n",
            "Epoch 28/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0886 - acc: 0.9755\n",
            "Epoch 28: val_acc did not improve from 0.88571\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.0886 - acc: 0.9755 - val_loss: 0.4093 - val_acc: 0.8857\n",
            "Epoch 29/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0685 - acc: 0.9878\n",
            "Epoch 29: val_acc did not improve from 0.88571\n",
            "8/8 [==============================] - 44s 5s/step - loss: 0.0685 - acc: 0.9878 - val_loss: 0.4059 - val_acc: 0.8857\n",
            "Epoch 30/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0876 - acc: 0.9816\n",
            "Epoch 30: val_acc improved from 0.88571 to 0.90000, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-30-acc-0.90.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.0876 - acc: 0.9816 - val_loss: 0.3900 - val_acc: 0.9000\n",
            "Epoch 31/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0658 - acc: 0.9837\n",
            "Epoch 31: val_acc did not improve from 0.90000\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.0658 - acc: 0.9837 - val_loss: 0.3862 - val_acc: 0.8857\n",
            "Epoch 32/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0834 - acc: 0.9755\n",
            "Epoch 32: val_acc did not improve from 0.90000\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.0834 - acc: 0.9755 - val_loss: 0.3970 - val_acc: 0.8786\n",
            "Epoch 33/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0572 - acc: 0.9898\n",
            "Epoch 33: val_acc did not improve from 0.90000\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.0572 - acc: 0.9898 - val_loss: 0.4076 - val_acc: 0.8786\n",
            "Epoch 34/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0630 - acc: 0.9816\n",
            "Epoch 34: val_acc did not improve from 0.90000\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.0630 - acc: 0.9816 - val_loss: 0.4016 - val_acc: 0.8857\n",
            "Epoch 35/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0745 - acc: 0.9796\n",
            "Epoch 35: val_acc did not improve from 0.90000\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.0745 - acc: 0.9796 - val_loss: 0.4021 - val_acc: 0.8929\n",
            "Epoch 36/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0658 - acc: 0.9857\n",
            "Epoch 36: val_acc did not improve from 0.90000\n",
            "8/8 [==============================] - 45s 6s/step - loss: 0.0658 - acc: 0.9857 - val_loss: 0.4022 - val_acc: 0.8857\n",
            "\n",
            "\n",
            "Model Accuracy 0.7714285714285715\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.67      1.00      0.80        10\n",
            "       10000       0.56      1.00      0.71        10\n",
            "      100000       0.80      0.40      0.53        10\n",
            "        2000       1.00      0.60      0.75        10\n",
            "       20000       0.90      0.90      0.90        10\n",
            "        5000       0.88      0.70      0.78        10\n",
            "       50000       1.00      0.80      0.89        10\n",
            "\n",
            "    accuracy                           0.77        70\n",
            "   macro avg       0.83      0.77      0.77        70\n",
            "weighted avg       0.83      0.77      0.77        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Found 490 images belonging to 7 classes.\n",
            "Found 70 images belonging to 7 classes.\n",
            "Found 140 images belonging to 7 classes.\n",
            "Percobaan ke- 5 ↓\n",
            "───────────────────────────────────────HYPERPARAMETER VGG-16────────────────────────────────────────\n",
            "vgg epoch: 48\n",
            "learning rate: 0.001789042\n",
            "batch size: 64\n",
            "dropout rate: 0.617462768\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_19668\\1083539539.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.8126 - acc: 0.2510\n",
            "Epoch 1: val_acc improved from -inf to 0.20714, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-01-acc-0.21.hdf5\n",
            "8/8 [==============================] - 40s 5s/step - loss: 2.8126 - acc: 0.2510 - val_loss: 2.1026 - val_acc: 0.2071\n",
            "Epoch 2/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5578 - acc: 0.4755\n",
            "Epoch 2: val_acc improved from 0.20714 to 0.24286, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-02-acc-0.24.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 1.5578 - acc: 0.4755 - val_loss: 1.9412 - val_acc: 0.2429\n",
            "Epoch 3/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0075 - acc: 0.6367\n",
            "Epoch 3: val_acc improved from 0.24286 to 0.27143, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-03-acc-0.27.hdf5\n",
            "8/8 [==============================] - 45s 6s/step - loss: 1.0075 - acc: 0.6367 - val_loss: 1.7806 - val_acc: 0.2714\n",
            "Epoch 4/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8233 - acc: 0.7102\n",
            "Epoch 4: val_acc improved from 0.27143 to 0.32857, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-04-acc-0.33.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.8233 - acc: 0.7102 - val_loss: 1.6490 - val_acc: 0.3286\n",
            "Epoch 5/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6340 - acc: 0.7694\n",
            "Epoch 5: val_acc improved from 0.32857 to 0.37857, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-05-acc-0.38.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.6340 - acc: 0.7694 - val_loss: 1.6066 - val_acc: 0.3786\n",
            "Epoch 6/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4517 - acc: 0.8367\n",
            "Epoch 6: val_acc improved from 0.37857 to 0.42143, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-06-acc-0.42.hdf5\n",
            "8/8 [==============================] - 45s 6s/step - loss: 0.4517 - acc: 0.8367 - val_loss: 1.5213 - val_acc: 0.4214\n",
            "Epoch 7/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4532 - acc: 0.8653\n",
            "Epoch 7: val_acc improved from 0.42143 to 0.45714, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-07-acc-0.46.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.4532 - acc: 0.8653 - val_loss: 1.4087 - val_acc: 0.4571\n",
            "Epoch 8/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.4157 - acc: 0.8653\n",
            "Epoch 8: val_acc improved from 0.45714 to 0.52857, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-08-acc-0.53.hdf5\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.4157 - acc: 0.8653 - val_loss: 1.2913 - val_acc: 0.5286\n",
            "Epoch 9/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.3568 - acc: 0.8796\n",
            "Epoch 9: val_acc improved from 0.52857 to 0.57857, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-09-acc-0.58.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.3568 - acc: 0.8796 - val_loss: 1.1879 - val_acc: 0.5786\n",
            "Epoch 10/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2962 - acc: 0.8918\n",
            "Epoch 10: val_acc improved from 0.57857 to 0.63571, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-10-acc-0.64.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.2962 - acc: 0.8918 - val_loss: 1.1057 - val_acc: 0.6357\n",
            "Epoch 11/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2561 - acc: 0.9224\n",
            "Epoch 11: val_acc improved from 0.63571 to 0.70714, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-11-acc-0.71.hdf5\n",
            "8/8 [==============================] - 45s 5s/step - loss: 0.2561 - acc: 0.9224 - val_loss: 0.9722 - val_acc: 0.7071\n",
            "Epoch 12/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2875 - acc: 0.8980\n",
            "Epoch 12: val_acc improved from 0.70714 to 0.74286, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-12-acc-0.74.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.2875 - acc: 0.8980 - val_loss: 0.8602 - val_acc: 0.7429\n",
            "Epoch 13/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2288 - acc: 0.9265\n",
            "Epoch 13: val_acc improved from 0.74286 to 0.77857, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-13-acc-0.78.hdf5\n",
            "8/8 [==============================] - 44s 5s/step - loss: 0.2288 - acc: 0.9265 - val_loss: 0.7813 - val_acc: 0.7786\n",
            "Epoch 14/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2172 - acc: 0.9327\n",
            "Epoch 14: val_acc improved from 0.77857 to 0.82143, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-14-acc-0.82.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.2172 - acc: 0.9327 - val_loss: 0.7195 - val_acc: 0.8214\n",
            "Epoch 15/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.2250 - acc: 0.9306\n",
            "Epoch 15: val_acc improved from 0.82143 to 0.82857, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-15-acc-0.83.hdf5\n",
            "8/8 [==============================] - 43s 6s/step - loss: 0.2250 - acc: 0.9306 - val_loss: 0.6597 - val_acc: 0.8286\n",
            "Epoch 16/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1821 - acc: 0.9429\n",
            "Epoch 16: val_acc improved from 0.82857 to 0.84286, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-16-acc-0.84.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.1821 - acc: 0.9429 - val_loss: 0.6028 - val_acc: 0.8429\n",
            "Epoch 17/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1689 - acc: 0.9571\n",
            "Epoch 17: val_acc improved from 0.84286 to 0.87143, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-17-acc-0.87.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.1689 - acc: 0.9571 - val_loss: 0.5566 - val_acc: 0.8714\n",
            "Epoch 18/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1685 - acc: 0.9429\n",
            "Epoch 18: val_acc improved from 0.87143 to 0.87857, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-18-acc-0.88.hdf5\n",
            "8/8 [==============================] - 45s 5s/step - loss: 0.1685 - acc: 0.9429 - val_loss: 0.5172 - val_acc: 0.8786\n",
            "Epoch 19/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1431 - acc: 0.9551\n",
            "Epoch 19: val_acc improved from 0.87857 to 0.88571, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-19-acc-0.89.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.1431 - acc: 0.9551 - val_loss: 0.4759 - val_acc: 0.8857\n",
            "Epoch 20/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1250 - acc: 0.9612\n",
            "Epoch 20: val_acc improved from 0.88571 to 0.90000, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-20-acc-0.90.hdf5\n",
            "8/8 [==============================] - 45s 6s/step - loss: 0.1250 - acc: 0.9612 - val_loss: 0.4351 - val_acc: 0.9000\n",
            "Epoch 21/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1593 - acc: 0.9490\n",
            "Epoch 21: val_acc improved from 0.90000 to 0.92143, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-21-acc-0.92.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.1593 - acc: 0.9490 - val_loss: 0.3905 - val_acc: 0.9214\n",
            "Epoch 22/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1146 - acc: 0.9694\n",
            "Epoch 22: val_acc improved from 0.92143 to 0.92857, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-22-acc-0.93.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.1146 - acc: 0.9694 - val_loss: 0.3579 - val_acc: 0.9286\n",
            "Epoch 23/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1409 - acc: 0.9612\n",
            "Epoch 23: val_acc did not improve from 0.92857\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.1409 - acc: 0.9612 - val_loss: 0.3352 - val_acc: 0.9286\n",
            "Epoch 24/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1218 - acc: 0.9755\n",
            "Epoch 24: val_acc did not improve from 0.92857\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.1218 - acc: 0.9755 - val_loss: 0.3123 - val_acc: 0.9214\n",
            "Epoch 25/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1185 - acc: 0.9592\n",
            "Epoch 25: val_acc did not improve from 0.92857\n",
            "8/8 [==============================] - 45s 6s/step - loss: 0.1185 - acc: 0.9592 - val_loss: 0.2922 - val_acc: 0.9286\n",
            "Epoch 26/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1097 - acc: 0.9694\n",
            "Epoch 26: val_acc improved from 0.92857 to 0.93571, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-26-acc-0.94.hdf5\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.1097 - acc: 0.9694 - val_loss: 0.2700 - val_acc: 0.9357\n",
            "Epoch 27/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0903 - acc: 0.9673\n",
            "Epoch 27: val_acc did not improve from 0.93571\n",
            "8/8 [==============================] - 45s 6s/step - loss: 0.0903 - acc: 0.9673 - val_loss: 0.2576 - val_acc: 0.9286\n",
            "Epoch 28/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1207 - acc: 0.9633\n",
            "Epoch 28: val_acc improved from 0.93571 to 0.94286, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-28-acc-0.94.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.1207 - acc: 0.9633 - val_loss: 0.2408 - val_acc: 0.9429\n",
            "Epoch 29/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0888 - acc: 0.9755\n",
            "Epoch 29: val_acc did not improve from 0.94286\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.0888 - acc: 0.9755 - val_loss: 0.2300 - val_acc: 0.9429\n",
            "Epoch 30/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0994 - acc: 0.9714\n",
            "Epoch 30: val_acc improved from 0.94286 to 0.95000, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-30-acc-0.95.hdf5\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.0994 - acc: 0.9714 - val_loss: 0.2267 - val_acc: 0.9500\n",
            "Epoch 31/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0900 - acc: 0.9735\n",
            "Epoch 31: val_acc improved from 0.95000 to 0.95714, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-31-acc-0.96.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.0900 - acc: 0.9735 - val_loss: 0.2232 - val_acc: 0.9571\n",
            "Epoch 32/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0849 - acc: 0.9755\n",
            "Epoch 32: val_acc did not improve from 0.95714\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.0849 - acc: 0.9755 - val_loss: 0.2182 - val_acc: 0.9500\n",
            "Epoch 33/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0925 - acc: 0.9694\n",
            "Epoch 33: val_acc did not improve from 0.95714\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.0925 - acc: 0.9694 - val_loss: 0.2069 - val_acc: 0.9500\n",
            "Epoch 34/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0899 - acc: 0.9694\n",
            "Epoch 34: val_acc did not improve from 0.95714\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.0899 - acc: 0.9694 - val_loss: 0.1899 - val_acc: 0.9571\n",
            "Epoch 35/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0832 - acc: 0.9735\n",
            "Epoch 35: val_acc did not improve from 0.95714\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.0832 - acc: 0.9735 - val_loss: 0.1847 - val_acc: 0.9571\n",
            "Epoch 36/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0709 - acc: 0.9796\n",
            "Epoch 36: val_acc did not improve from 0.95714\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.0709 - acc: 0.9796 - val_loss: 0.1839 - val_acc: 0.9571\n",
            "Epoch 37/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0531 - acc: 0.9898\n",
            "Epoch 37: val_acc did not improve from 0.95714\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.0531 - acc: 0.9898 - val_loss: 0.1863 - val_acc: 0.9500\n",
            "Epoch 38/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0862 - acc: 0.9796\n",
            "Epoch 38: val_acc did not improve from 0.95714\n",
            "8/8 [==============================] - 43s 6s/step - loss: 0.0862 - acc: 0.9796 - val_loss: 0.1875 - val_acc: 0.9429\n",
            "Epoch 39/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0698 - acc: 0.9755\n",
            "Epoch 39: val_acc did not improve from 0.95714\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.0698 - acc: 0.9755 - val_loss: 0.1840 - val_acc: 0.9357\n",
            "Epoch 40/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0436 - acc: 0.9918\n",
            "Epoch 40: val_acc did not improve from 0.95714\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.0436 - acc: 0.9918 - val_loss: 0.1754 - val_acc: 0.9500\n",
            "Epoch 41/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0693 - acc: 0.9796\n",
            "Epoch 41: val_acc did not improve from 0.95714\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.0693 - acc: 0.9796 - val_loss: 0.1684 - val_acc: 0.9571\n",
            "Epoch 42/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0676 - acc: 0.9878\n",
            "Epoch 42: val_acc did not improve from 0.95714\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.0676 - acc: 0.9878 - val_loss: 0.1709 - val_acc: 0.9500\n",
            "Epoch 43/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0763 - acc: 0.9776\n",
            "Epoch 43: val_acc did not improve from 0.95714\n",
            "8/8 [==============================] - 45s 5s/step - loss: 0.0763 - acc: 0.9776 - val_loss: 0.1763 - val_acc: 0.9500\n",
            "Epoch 44/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0726 - acc: 0.9816\n",
            "Epoch 44: val_acc did not improve from 0.95714\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.0726 - acc: 0.9816 - val_loss: 0.1924 - val_acc: 0.9429\n",
            "Epoch 45/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0579 - acc: 0.9796\n",
            "Epoch 45: val_acc did not improve from 0.95714\n",
            "8/8 [==============================] - 44s 6s/step - loss: 0.0579 - acc: 0.9796 - val_loss: 0.1943 - val_acc: 0.9500\n",
            "Epoch 46/48\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1059 - acc: 0.9714\n",
            "Epoch 46: val_acc improved from 0.95714 to 0.96429, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-46-acc-0.96.hdf5\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.1059 - acc: 0.9714 - val_loss: 0.1706 - val_acc: 0.9643\n",
            "\n",
            "\n",
            "Model Accuracy 0.6714285714285714\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.70      0.70      0.70        10\n",
            "       10000       0.56      0.90      0.69        10\n",
            "      100000       0.67      0.40      0.50        10\n",
            "        2000       0.64      0.70      0.67        10\n",
            "       20000       0.89      0.80      0.84        10\n",
            "        5000       0.60      0.60      0.60        10\n",
            "       50000       0.75      0.60      0.67        10\n",
            "\n",
            "    accuracy                           0.67        70\n",
            "   macro avg       0.69      0.67      0.67        70\n",
            "weighted avg       0.69      0.67      0.67        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_19668\\1083539539.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 700x700 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 700x700 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 700x700 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 700x700 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 700x700 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "for i in range (0,5):\n",
        "#for i in range (0,10): #aslinya in range len(parameter) tapi kalau mau coba per sedikit2 ya gini deh\n",
        "  vgg_epoch = 48\n",
        "  learning_rate = 0.001789042\n",
        "  batch_size = 64\n",
        "  dropout_rate = 0.617462768\n",
        "  i=i+1\n",
        "  dataset = \"datasetSplit\"+str(i)\n",
        "  IMAGE_SIZE = (130, 242, 3)\n",
        "  train_pred_test_folders = os.listdir(dataset)\n",
        "  train_path = dataset+'/train'\n",
        "  test_path = dataset+'/test'\n",
        "  val_path = dataset+'/val'\n",
        "\n",
        "  #normalisasi\n",
        "  train_datagen = ImageDataGenerator(rescale = 1.0/255.,shear_range=0.2,zoom_range=0.2)\n",
        "  train_generator16 = train_datagen.flow_from_directory(train_path,\n",
        "                                                    batch_size=32,\n",
        "                                                    shuffle=True,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    target_size=(130, 242))\n",
        "\n",
        "  validation_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
        "\n",
        "  test_datagen = ImageDataGenerator(rescale = 1.0/255.,shear_range=0.2,zoom_range=0.2)\n",
        "  test_generator16 = test_datagen.flow_from_directory(test_path, target_size=(130, 242),\n",
        "      batch_size=1,\n",
        "      shuffle=True,\n",
        "      class_mode='categorical')\n",
        "\n",
        "  validation_generator16 = validation_datagen.flow_from_directory(val_path, shuffle=True, batch_size=1, class_mode='categorical', target_size=(130, 242))\n",
        "\n",
        "  savePercobaan(i)\n",
        "  print(\"Percobaan ke-\",i,\"↓\")\n",
        "  print(\"HYPERPARAMETER VGG-16\".center(100,\"─\"))\n",
        "  print(\"vgg epoch:\",vgg_epoch)\n",
        "  print(\"learning rate:\",learning_rate)\n",
        "  print(\"batch size:\",batch_size)\n",
        "  print(\"dropout rate:\",dropout_rate)\n",
        "  print(\"\".center(100,\"─\"))\n",
        "  vgg16_training(i, vgg_epoch, learning_rate, batch_size, dropout_rate)\n",
        "  new_row = {'Epoch': vgg_epoch, 'Learning Rate': learning_rate, 'Batch Size': batch_size, 'Dropout Rate': dropout_rate, 'Accuracy': arr_accuracy16[-1]}\n",
        "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n",
        "  hasilTabel.index = hasilTabel.index + (i+1)\n",
        "  hasilTabel.to_excel(\"hasilTabelRevisi.xlsx\")\n",
        "  print(\"\".center(100,\"─\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 490 images belonging to 7 classes.\n",
            "Found 70 images belonging to 7 classes.\n",
            "Found 140 images belonging to 7 classes.\n",
            "Percobaan ke- 1 ↓\n",
            "───────────────────────────────────────HYPERPARAMETER VGG-16────────────────────────────────────────\n",
            "vgg epoch: 45\n",
            "learning rate: 0.00433602899725914\n",
            "batch size: 32\n",
            "dropout rate: 0.638916709600142\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.8249 - acc: 0.2551\n",
            "Epoch 1: val_acc improved from -inf to 0.30000, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-01-acc-0.30.hdf5\n",
            "16/16 [==============================] - 60s 4s/step - loss: 2.8249 - acc: 0.2551 - val_loss: 2.1478 - val_acc: 0.3000\n",
            "Epoch 2/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.5919 - acc: 0.4776\n",
            "Epoch 2: val_acc improved from 0.30000 to 0.41429, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-02-acc-0.41.hdf5\n",
            "16/16 [==============================] - 63s 4s/step - loss: 1.5919 - acc: 0.4776 - val_loss: 1.6516 - val_acc: 0.4143\n",
            "Epoch 3/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0721 - acc: 0.6204\n",
            "Epoch 3: val_acc improved from 0.41429 to 0.46429, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-03-acc-0.46.hdf5\n",
            "16/16 [==============================] - 86s 5s/step - loss: 1.0721 - acc: 0.6204 - val_loss: 1.5215 - val_acc: 0.4643\n",
            "Epoch 4/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9652 - acc: 0.6959\n",
            "Epoch 4: val_acc improved from 0.46429 to 0.53571, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-04-acc-0.54.hdf5\n",
            "16/16 [==============================] - 66s 4s/step - loss: 0.9652 - acc: 0.6959 - val_loss: 1.3431 - val_acc: 0.5357\n",
            "Epoch 5/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7921 - acc: 0.7347\n",
            "Epoch 5: val_acc improved from 0.53571 to 0.55000, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-05-acc-0.55.hdf5\n",
            "16/16 [==============================] - 71s 5s/step - loss: 0.7921 - acc: 0.7347 - val_loss: 1.2509 - val_acc: 0.5500\n",
            "Epoch 6/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6632 - acc: 0.7592\n",
            "Epoch 6: val_acc improved from 0.55000 to 0.60000, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-06-acc-0.60.hdf5\n",
            "16/16 [==============================] - 68s 4s/step - loss: 0.6632 - acc: 0.7592 - val_loss: 1.1379 - val_acc: 0.6000\n",
            "Epoch 7/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6024 - acc: 0.8061\n",
            "Epoch 7: val_acc improved from 0.60000 to 0.65000, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-07-acc-0.65.hdf5\n",
            "16/16 [==============================] - 72s 4s/step - loss: 0.6024 - acc: 0.8061 - val_loss: 1.0408 - val_acc: 0.6500\n",
            "Epoch 8/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5780 - acc: 0.7878\n",
            "Epoch 8: val_acc improved from 0.65000 to 0.72857, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-08-acc-0.73.hdf5\n",
            "16/16 [==============================] - 68s 4s/step - loss: 0.5780 - acc: 0.7878 - val_loss: 0.9454 - val_acc: 0.7286\n",
            "Epoch 9/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4776 - acc: 0.8347\n",
            "Epoch 9: val_acc improved from 0.72857 to 0.76429, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-09-acc-0.76.hdf5\n",
            "16/16 [==============================] - 74s 5s/step - loss: 0.4776 - acc: 0.8347 - val_loss: 0.8456 - val_acc: 0.7643\n",
            "Epoch 10/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4855 - acc: 0.8286\n",
            "Epoch 10: val_acc did not improve from 0.76429\n",
            "16/16 [==============================] - 76s 5s/step - loss: 0.4855 - acc: 0.8286 - val_loss: 0.7969 - val_acc: 0.7143\n",
            "Epoch 11/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4494 - acc: 0.8388\n",
            "Epoch 11: val_acc improved from 0.76429 to 0.78571, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-11-acc-0.79.hdf5\n",
            "16/16 [==============================] - 71s 5s/step - loss: 0.4494 - acc: 0.8388 - val_loss: 0.7079 - val_acc: 0.7857\n",
            "Epoch 12/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3920 - acc: 0.8816\n",
            "Epoch 12: val_acc improved from 0.78571 to 0.81429, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-12-acc-0.81.hdf5\n",
            "16/16 [==============================] - 73s 5s/step - loss: 0.3920 - acc: 0.8816 - val_loss: 0.6367 - val_acc: 0.8143\n",
            "Epoch 13/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3732 - acc: 0.8735\n",
            "Epoch 13: val_acc improved from 0.81429 to 0.83571, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-13-acc-0.84.hdf5\n",
            "16/16 [==============================] - 66s 4s/step - loss: 0.3732 - acc: 0.8735 - val_loss: 0.5828 - val_acc: 0.8357\n",
            "Epoch 14/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3665 - acc: 0.8714\n",
            "Epoch 14: val_acc improved from 0.83571 to 0.87857, saving model to percobaan1_noImgPro/model\\vgg_16_1-saved-model-14-acc-0.88.hdf5\n",
            "16/16 [==============================] - 72s 4s/step - loss: 0.3665 - acc: 0.8714 - val_loss: 0.5511 - val_acc: 0.8786\n",
            "Epoch 15/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3255 - acc: 0.8878\n",
            "Epoch 15: val_acc did not improve from 0.87857\n",
            "16/16 [==============================] - 76s 5s/step - loss: 0.3255 - acc: 0.8878 - val_loss: 0.5293 - val_acc: 0.8500\n",
            "Epoch 16/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3375 - acc: 0.8959\n",
            "Epoch 16: val_acc did not improve from 0.87857\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.3375 - acc: 0.8959 - val_loss: 0.5486 - val_acc: 0.8214\n",
            "Epoch 17/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2856 - acc: 0.9020\n",
            "Epoch 17: val_acc did not improve from 0.87857\n",
            "16/16 [==============================] - 67s 4s/step - loss: 0.2856 - acc: 0.9020 - val_loss: 0.5026 - val_acc: 0.8500\n",
            "Epoch 18/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3317 - acc: 0.8816\n",
            "Epoch 18: val_acc did not improve from 0.87857\n",
            "16/16 [==============================] - 72s 5s/step - loss: 0.3317 - acc: 0.8816 - val_loss: 0.5442 - val_acc: 0.8429\n",
            "Epoch 19/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3150 - acc: 0.8857\n",
            "Epoch 19: val_acc did not improve from 0.87857\n",
            "16/16 [==============================] - 65s 4s/step - loss: 0.3150 - acc: 0.8857 - val_loss: 0.5173 - val_acc: 0.8357\n",
            "Epoch 20/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2682 - acc: 0.9102\n",
            "Epoch 20: val_acc did not improve from 0.87857\n",
            "16/16 [==============================] - 73s 5s/step - loss: 0.2682 - acc: 0.9102 - val_loss: 0.4592 - val_acc: 0.8500\n",
            "Epoch 21/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2705 - acc: 0.9061\n",
            "Epoch 21: val_acc did not improve from 0.87857\n",
            "16/16 [==============================] - 76s 5s/step - loss: 0.2705 - acc: 0.9061 - val_loss: 0.4108 - val_acc: 0.8643\n",
            "Epoch 22/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2728 - acc: 0.8980\n",
            "Epoch 22: val_acc did not improve from 0.87857\n",
            "16/16 [==============================] - 70s 4s/step - loss: 0.2728 - acc: 0.8980 - val_loss: 0.4399 - val_acc: 0.8786\n",
            "Epoch 23/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2321 - acc: 0.9163\n",
            "Epoch 23: val_acc did not improve from 0.87857\n",
            "16/16 [==============================] - 73s 5s/step - loss: 0.2321 - acc: 0.9163 - val_loss: 0.4493 - val_acc: 0.8571\n",
            "Epoch 24/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2368 - acc: 0.9204\n",
            "Epoch 24: val_acc did not improve from 0.87857\n",
            "16/16 [==============================] - 72s 5s/step - loss: 0.2368 - acc: 0.9204 - val_loss: 0.4466 - val_acc: 0.8571\n",
            "Epoch 25/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2076 - acc: 0.9327\n",
            "Epoch 25: val_acc did not improve from 0.87857\n",
            "16/16 [==============================] - 66s 4s/step - loss: 0.2076 - acc: 0.9327 - val_loss: 0.4376 - val_acc: 0.8714\n",
            "Epoch 26/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2797 - acc: 0.9102\n",
            "Epoch 26: val_acc did not improve from 0.87857\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2797 - acc: 0.9102 - val_loss: 0.4694 - val_acc: 0.8357\n",
            "\n",
            "\n",
            "Model Accuracy 0.9142857142857143\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.83      1.00      0.91        10\n",
            "       10000       1.00      0.70      0.82        10\n",
            "      100000       1.00      0.90      0.95        10\n",
            "        2000       0.83      1.00      0.91        10\n",
            "       20000       1.00      0.90      0.95        10\n",
            "        5000       0.82      0.90      0.86        10\n",
            "       50000       1.00      1.00      1.00        10\n",
            "\n",
            "    accuracy                           0.91        70\n",
            "   macro avg       0.93      0.91      0.91        70\n",
            "weighted avg       0.93      0.91      0.91        70\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_19668\\777585943.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Found 490 images belonging to 7 classes.\n",
            "Found 70 images belonging to 7 classes.\n",
            "Found 140 images belonging to 7 classes.\n",
            "Percobaan ke- 2 ↓\n",
            "───────────────────────────────────────HYPERPARAMETER VGG-16────────────────────────────────────────\n",
            "vgg epoch: 45\n",
            "learning rate: 0.00433602899725914\n",
            "batch size: 32\n",
            "dropout rate: 0.638916709600142\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.6523 - acc: 0.2755\n",
            "Epoch 1: val_acc improved from -inf to 0.31429, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-01-acc-0.31.hdf5\n",
            "16/16 [==============================] - 174s 11s/step - loss: 2.6523 - acc: 0.2755 - val_loss: 1.9749 - val_acc: 0.3143\n",
            "Epoch 2/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.4835 - acc: 0.4796\n",
            "Epoch 2: val_acc did not improve from 0.31429\n",
            "16/16 [==============================] - 155s 10s/step - loss: 1.4835 - acc: 0.4796 - val_loss: 1.8993 - val_acc: 0.2214\n",
            "Epoch 3/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9822 - acc: 0.6551\n",
            "Epoch 3: val_acc did not improve from 0.31429\n",
            "16/16 [==============================] - 131s 8s/step - loss: 0.9822 - acc: 0.6551 - val_loss: 1.6841 - val_acc: 0.2714\n",
            "Epoch 4/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8305 - acc: 0.7102\n",
            "Epoch 4: val_acc improved from 0.31429 to 0.46429, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-04-acc-0.46.hdf5\n",
            "16/16 [==============================] - 157s 10s/step - loss: 0.8305 - acc: 0.7102 - val_loss: 1.3361 - val_acc: 0.4643\n",
            "Epoch 5/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6601 - acc: 0.7653\n",
            "Epoch 5: val_acc improved from 0.46429 to 0.59286, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-05-acc-0.59.hdf5\n",
            "16/16 [==============================] - 142s 9s/step - loss: 0.6601 - acc: 0.7653 - val_loss: 1.0975 - val_acc: 0.5929\n",
            "Epoch 6/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6428 - acc: 0.7694\n",
            "Epoch 6: val_acc improved from 0.59286 to 0.67857, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-06-acc-0.68.hdf5\n",
            "16/16 [==============================] - 157s 10s/step - loss: 0.6428 - acc: 0.7694 - val_loss: 0.9697 - val_acc: 0.6786\n",
            "Epoch 7/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5567 - acc: 0.7939\n",
            "Epoch 7: val_acc improved from 0.67857 to 0.75000, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-07-acc-0.75.hdf5\n",
            "16/16 [==============================] - 151s 10s/step - loss: 0.5567 - acc: 0.7939 - val_loss: 0.8404 - val_acc: 0.7500\n",
            "Epoch 8/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5124 - acc: 0.8204\n",
            "Epoch 8: val_acc did not improve from 0.75000\n",
            "16/16 [==============================] - 153s 10s/step - loss: 0.5124 - acc: 0.8204 - val_loss: 0.7755 - val_acc: 0.7357\n",
            "Epoch 9/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4763 - acc: 0.8245\n",
            "Epoch 9: val_acc did not improve from 0.75000\n",
            "16/16 [==============================] - 158s 10s/step - loss: 0.4763 - acc: 0.8245 - val_loss: 0.7344 - val_acc: 0.7429\n",
            "Epoch 10/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4789 - acc: 0.8265\n",
            "Epoch 10: val_acc improved from 0.75000 to 0.77143, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-10-acc-0.77.hdf5\n",
            "16/16 [==============================] - 157s 10s/step - loss: 0.4789 - acc: 0.8265 - val_loss: 0.6530 - val_acc: 0.7714\n",
            "Epoch 11/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4069 - acc: 0.8571\n",
            "Epoch 11: val_acc improved from 0.77143 to 0.77857, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-11-acc-0.78.hdf5\n",
            "16/16 [==============================] - 153s 10s/step - loss: 0.4069 - acc: 0.8571 - val_loss: 0.6214 - val_acc: 0.7786\n",
            "Epoch 12/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4095 - acc: 0.8612\n",
            "Epoch 12: val_acc improved from 0.77857 to 0.81429, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-12-acc-0.81.hdf5\n",
            "16/16 [==============================] - 152s 9s/step - loss: 0.4095 - acc: 0.8612 - val_loss: 0.5616 - val_acc: 0.8143\n",
            "Epoch 13/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3900 - acc: 0.8714\n",
            "Epoch 13: val_acc did not improve from 0.81429\n",
            "16/16 [==============================] - 155s 10s/step - loss: 0.3900 - acc: 0.8714 - val_loss: 0.5676 - val_acc: 0.8071\n",
            "Epoch 14/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3329 - acc: 0.8878\n",
            "Epoch 14: val_acc improved from 0.81429 to 0.84286, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-14-acc-0.84.hdf5\n",
            "16/16 [==============================] - 151s 10s/step - loss: 0.3329 - acc: 0.8878 - val_loss: 0.5179 - val_acc: 0.8429\n",
            "Epoch 15/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3883 - acc: 0.8755\n",
            "Epoch 15: val_acc did not improve from 0.84286\n",
            "16/16 [==============================] - 157s 10s/step - loss: 0.3883 - acc: 0.8755 - val_loss: 0.5164 - val_acc: 0.8286\n",
            "Epoch 16/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3041 - acc: 0.8918\n",
            "Epoch 16: val_acc did not improve from 0.84286\n",
            "16/16 [==============================] - 153s 10s/step - loss: 0.3041 - acc: 0.8918 - val_loss: 0.4879 - val_acc: 0.8214\n",
            "Epoch 17/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3312 - acc: 0.8898\n",
            "Epoch 17: val_acc did not improve from 0.84286\n",
            "16/16 [==============================] - 139s 9s/step - loss: 0.3312 - acc: 0.8898 - val_loss: 0.4741 - val_acc: 0.8429\n",
            "Epoch 18/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3566 - acc: 0.8898\n",
            "Epoch 18: val_acc improved from 0.84286 to 0.85714, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-18-acc-0.86.hdf5\n",
            "16/16 [==============================] - 131s 8s/step - loss: 0.3566 - acc: 0.8898 - val_loss: 0.4440 - val_acc: 0.8571\n",
            "Epoch 19/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3231 - acc: 0.8878\n",
            "Epoch 19: val_acc improved from 0.85714 to 0.89286, saving model to percobaan2_noImgPro/model\\vgg_16_2-saved-model-19-acc-0.89.hdf5\n",
            "16/16 [==============================] - 148s 9s/step - loss: 0.3231 - acc: 0.8878 - val_loss: 0.4083 - val_acc: 0.8929\n",
            "Epoch 20/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3027 - acc: 0.9000\n",
            "Epoch 20: val_acc did not improve from 0.89286\n",
            "16/16 [==============================] - 153s 9s/step - loss: 0.3027 - acc: 0.9000 - val_loss: 0.4315 - val_acc: 0.8786\n",
            "Epoch 21/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2884 - acc: 0.8898\n",
            "Epoch 21: val_acc did not improve from 0.89286\n",
            "16/16 [==============================] - 145s 9s/step - loss: 0.2884 - acc: 0.8898 - val_loss: 0.4499 - val_acc: 0.8571\n",
            "Epoch 22/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2653 - acc: 0.9061\n",
            "Epoch 22: val_acc did not improve from 0.89286\n",
            "16/16 [==============================] - 149s 9s/step - loss: 0.2653 - acc: 0.9061 - val_loss: 0.4179 - val_acc: 0.8500\n",
            "Epoch 23/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3304 - acc: 0.8714\n",
            "Epoch 23: val_acc did not improve from 0.89286\n",
            "16/16 [==============================] - 144s 9s/step - loss: 0.3304 - acc: 0.8714 - val_loss: 0.4563 - val_acc: 0.8643\n",
            "Epoch 24/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2848 - acc: 0.8837\n",
            "Epoch 24: val_acc did not improve from 0.89286\n",
            "16/16 [==============================] - 144s 9s/step - loss: 0.2848 - acc: 0.8837 - val_loss: 0.4606 - val_acc: 0.8571\n",
            "\n",
            "\n",
            "Model Accuracy 0.7857142857142857\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.90      0.90      0.90        10\n",
            "       10000       0.88      0.70      0.78        10\n",
            "      100000       1.00      0.90      0.95        10\n",
            "        2000       0.56      0.90      0.69        10\n",
            "       20000       1.00      0.60      0.75        10\n",
            "        5000       0.58      0.70      0.64        10\n",
            "       50000       0.89      0.80      0.84        10\n",
            "\n",
            "    accuracy                           0.79        70\n",
            "   macro avg       0.83      0.79      0.79        70\n",
            "weighted avg       0.83      0.79      0.79        70\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_19668\\777585943.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Found 490 images belonging to 7 classes.\n",
            "Found 70 images belonging to 7 classes.\n",
            "Found 140 images belonging to 7 classes.\n",
            "Percobaan ke- 3 ↓\n",
            "───────────────────────────────────────HYPERPARAMETER VGG-16────────────────────────────────────────\n",
            "vgg epoch: 45\n",
            "learning rate: 0.00433602899725914\n",
            "batch size: 32\n",
            "dropout rate: 0.638916709600142\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.6156 - acc: 0.2980\n",
            "Epoch 1: val_acc improved from -inf to 0.15000, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-01-acc-0.15.hdf5\n",
            "16/16 [==============================] - 116s 7s/step - loss: 2.6156 - acc: 0.2980 - val_loss: 2.7004 - val_acc: 0.1500\n",
            "Epoch 2/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.4781 - acc: 0.5102\n",
            "Epoch 2: val_acc improved from 0.15000 to 0.16429, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-02-acc-0.16.hdf5\n",
            "16/16 [==============================] - 97s 6s/step - loss: 1.4781 - acc: 0.5102 - val_loss: 2.0742 - val_acc: 0.1643\n",
            "Epoch 3/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0996 - acc: 0.6122\n",
            "Epoch 3: val_acc improved from 0.16429 to 0.25000, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-03-acc-0.25.hdf5\n",
            "16/16 [==============================] - 92s 6s/step - loss: 1.0996 - acc: 0.6122 - val_loss: 1.9402 - val_acc: 0.2500\n",
            "Epoch 4/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9913 - acc: 0.6714\n",
            "Epoch 4: val_acc improved from 0.25000 to 0.46429, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-04-acc-0.46.hdf5\n",
            "16/16 [==============================] - 89s 6s/step - loss: 0.9913 - acc: 0.6714 - val_loss: 1.3534 - val_acc: 0.4643\n",
            "Epoch 5/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7202 - acc: 0.7571\n",
            "Epoch 5: val_acc improved from 0.46429 to 0.51429, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-05-acc-0.51.hdf5\n",
            "16/16 [==============================] - 86s 5s/step - loss: 0.7202 - acc: 0.7571 - val_loss: 1.2636 - val_acc: 0.5143\n",
            "Epoch 6/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6446 - acc: 0.7653\n",
            "Epoch 6: val_acc did not improve from 0.51429\n",
            "16/16 [==============================] - 89s 6s/step - loss: 0.6446 - acc: 0.7653 - val_loss: 1.1342 - val_acc: 0.5143\n",
            "Epoch 7/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6110 - acc: 0.7878\n",
            "Epoch 7: val_acc improved from 0.51429 to 0.66429, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-07-acc-0.66.hdf5\n",
            "16/16 [==============================] - 88s 6s/step - loss: 0.6110 - acc: 0.7878 - val_loss: 0.9575 - val_acc: 0.6643\n",
            "Epoch 8/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5214 - acc: 0.8286\n",
            "Epoch 8: val_acc improved from 0.66429 to 0.77143, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-08-acc-0.77.hdf5\n",
            "16/16 [==============================] - 90s 6s/step - loss: 0.5214 - acc: 0.8286 - val_loss: 0.7644 - val_acc: 0.7714\n",
            "Epoch 9/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5146 - acc: 0.8163\n",
            "Epoch 9: val_acc improved from 0.77143 to 0.80714, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-09-acc-0.81.hdf5\n",
            "16/16 [==============================] - 92s 6s/step - loss: 0.5146 - acc: 0.8163 - val_loss: 0.6876 - val_acc: 0.8071\n",
            "Epoch 10/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3849 - acc: 0.8673\n",
            "Epoch 10: val_acc improved from 0.80714 to 0.85000, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-10-acc-0.85.hdf5\n",
            "16/16 [==============================] - 102s 6s/step - loss: 0.3849 - acc: 0.8673 - val_loss: 0.5890 - val_acc: 0.8500\n",
            "Epoch 11/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4774 - acc: 0.8265\n",
            "Epoch 11: val_acc did not improve from 0.85000\n",
            "16/16 [==============================] - 83s 5s/step - loss: 0.4774 - acc: 0.8265 - val_loss: 0.5609 - val_acc: 0.8429\n",
            "Epoch 12/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3551 - acc: 0.8837\n",
            "Epoch 12: val_acc improved from 0.85000 to 0.85714, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-12-acc-0.86.hdf5\n",
            "16/16 [==============================] - 86s 6s/step - loss: 0.3551 - acc: 0.8837 - val_loss: 0.5171 - val_acc: 0.8571\n",
            "Epoch 13/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3433 - acc: 0.8755\n",
            "Epoch 13: val_acc improved from 0.85714 to 0.87143, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-13-acc-0.87.hdf5\n",
            "16/16 [==============================] - 89s 6s/step - loss: 0.3433 - acc: 0.8755 - val_loss: 0.4858 - val_acc: 0.8714\n",
            "Epoch 14/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3734 - acc: 0.8571\n",
            "Epoch 14: val_acc improved from 0.87143 to 0.87857, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-14-acc-0.88.hdf5\n",
            "16/16 [==============================] - 87s 5s/step - loss: 0.3734 - acc: 0.8571 - val_loss: 0.4464 - val_acc: 0.8786\n",
            "Epoch 15/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3407 - acc: 0.8776\n",
            "Epoch 15: val_acc did not improve from 0.87857\n",
            "16/16 [==============================] - 92s 6s/step - loss: 0.3407 - acc: 0.8776 - val_loss: 0.4208 - val_acc: 0.8786\n",
            "Epoch 16/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3507 - acc: 0.8653\n",
            "Epoch 16: val_acc improved from 0.87857 to 0.88571, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-16-acc-0.89.hdf5\n",
            "16/16 [==============================] - 69s 4s/step - loss: 0.3507 - acc: 0.8653 - val_loss: 0.3714 - val_acc: 0.8857\n",
            "Epoch 17/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3536 - acc: 0.8714\n",
            "Epoch 17: val_acc did not improve from 0.88571\n",
            "16/16 [==============================] - 85s 5s/step - loss: 0.3536 - acc: 0.8714 - val_loss: 0.3628 - val_acc: 0.8857\n",
            "Epoch 18/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2950 - acc: 0.9020\n",
            "Epoch 18: val_acc improved from 0.88571 to 0.89286, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-18-acc-0.89.hdf5\n",
            "16/16 [==============================] - 90s 6s/step - loss: 0.2950 - acc: 0.9020 - val_loss: 0.3572 - val_acc: 0.8929\n",
            "Epoch 19/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3235 - acc: 0.8980\n",
            "Epoch 19: val_acc did not improve from 0.89286\n",
            "16/16 [==============================] - 82s 5s/step - loss: 0.3235 - acc: 0.8980 - val_loss: 0.3660 - val_acc: 0.8714\n",
            "Epoch 20/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2979 - acc: 0.8837\n",
            "Epoch 20: val_acc did not improve from 0.89286\n",
            "16/16 [==============================] - 92s 6s/step - loss: 0.2979 - acc: 0.8837 - val_loss: 0.3765 - val_acc: 0.8714\n",
            "Epoch 21/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3550 - acc: 0.8837\n",
            "Epoch 21: val_acc did not improve from 0.89286\n",
            "16/16 [==============================] - 88s 6s/step - loss: 0.3550 - acc: 0.8837 - val_loss: 0.3967 - val_acc: 0.8929\n",
            "Epoch 22/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2807 - acc: 0.9041\n",
            "Epoch 22: val_acc did not improve from 0.89286\n",
            "16/16 [==============================] - 88s 6s/step - loss: 0.2807 - acc: 0.9041 - val_loss: 0.4438 - val_acc: 0.8857\n",
            "Epoch 23/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3336 - acc: 0.8898\n",
            "Epoch 23: val_acc improved from 0.89286 to 0.90714, saving model to percobaan3_noImgPro/model\\vgg_16_3-saved-model-23-acc-0.91.hdf5\n",
            "16/16 [==============================] - 93s 6s/step - loss: 0.3336 - acc: 0.8898 - val_loss: 0.3775 - val_acc: 0.9071\n",
            "\n",
            "\n",
            "Model Accuracy 0.8142857142857143\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      0.90      0.95        10\n",
            "       10000       0.83      1.00      0.91        10\n",
            "      100000       1.00      0.70      0.82        10\n",
            "        2000       0.64      0.90      0.75        10\n",
            "       20000       0.83      0.50      0.62        10\n",
            "        5000       0.73      0.80      0.76        10\n",
            "       50000       0.82      0.90      0.86        10\n",
            "\n",
            "    accuracy                           0.81        70\n",
            "   macro avg       0.84      0.81      0.81        70\n",
            "weighted avg       0.84      0.81      0.81        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_19668\\777585943.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 490 images belonging to 7 classes.\n",
            "Found 70 images belonging to 7 classes.\n",
            "Found 140 images belonging to 7 classes.\n",
            "Percobaan ke- 4 ↓\n",
            "───────────────────────────────────────HYPERPARAMETER VGG-16────────────────────────────────────────\n",
            "vgg epoch: 45\n",
            "learning rate: 0.00433602899725914\n",
            "batch size: 32\n",
            "dropout rate: 0.638916709600142\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.6608 - acc: 0.2918\n",
            "Epoch 1: val_acc improved from -inf to 0.17857, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-01-acc-0.18.hdf5\n",
            "16/16 [==============================] - 88s 5s/step - loss: 2.6608 - acc: 0.2918 - val_loss: 2.0798 - val_acc: 0.1786\n",
            "Epoch 2/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.6306 - acc: 0.4816\n",
            "Epoch 2: val_acc improved from 0.17857 to 0.26429, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-02-acc-0.26.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 1.6306 - acc: 0.4816 - val_loss: 1.8097 - val_acc: 0.2643\n",
            "Epoch 3/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1164 - acc: 0.6122\n",
            "Epoch 3: val_acc improved from 0.26429 to 0.39286, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-03-acc-0.39.hdf5\n",
            "16/16 [==============================] - 82s 5s/step - loss: 1.1164 - acc: 0.6122 - val_loss: 1.5735 - val_acc: 0.3929\n",
            "Epoch 4/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9313 - acc: 0.6490\n",
            "Epoch 4: val_acc improved from 0.39286 to 0.42143, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-04-acc-0.42.hdf5\n",
            "16/16 [==============================] - 71s 5s/step - loss: 0.9313 - acc: 0.6490 - val_loss: 1.3967 - val_acc: 0.4214\n",
            "Epoch 5/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.8260 - acc: 0.7245\n",
            "Epoch 5: val_acc improved from 0.42143 to 0.62857, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-05-acc-0.63.hdf5\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.8260 - acc: 0.7245 - val_loss: 1.0889 - val_acc: 0.6286\n",
            "Epoch 6/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6904 - acc: 0.7531\n",
            "Epoch 6: val_acc improved from 0.62857 to 0.64286, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-06-acc-0.64.hdf5\n",
            "16/16 [==============================] - 74s 5s/step - loss: 0.6904 - acc: 0.7531 - val_loss: 1.0814 - val_acc: 0.6429\n",
            "Epoch 7/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6515 - acc: 0.7694\n",
            "Epoch 7: val_acc improved from 0.64286 to 0.67857, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-07-acc-0.68.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.6515 - acc: 0.7694 - val_loss: 1.0008 - val_acc: 0.6786\n",
            "Epoch 8/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5896 - acc: 0.8082\n",
            "Epoch 8: val_acc did not improve from 0.67857\n",
            "16/16 [==============================] - 82s 5s/step - loss: 0.5896 - acc: 0.8082 - val_loss: 0.9119 - val_acc: 0.6714\n",
            "Epoch 9/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5954 - acc: 0.8000\n",
            "Epoch 9: val_acc improved from 0.67857 to 0.74286, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-09-acc-0.74.hdf5\n",
            "16/16 [==============================] - 73s 5s/step - loss: 0.5954 - acc: 0.8000 - val_loss: 0.7746 - val_acc: 0.7429\n",
            "Epoch 10/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4985 - acc: 0.8306\n",
            "Epoch 10: val_acc improved from 0.74286 to 0.76429, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-10-acc-0.76.hdf5\n",
            "16/16 [==============================] - 72s 5s/step - loss: 0.4985 - acc: 0.8306 - val_loss: 0.6827 - val_acc: 0.7643\n",
            "Epoch 11/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3754 - acc: 0.8694\n",
            "Epoch 11: val_acc improved from 0.76429 to 0.85000, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-11-acc-0.85.hdf5\n",
            "16/16 [==============================] - 79s 5s/step - loss: 0.3754 - acc: 0.8694 - val_loss: 0.5650 - val_acc: 0.8500\n",
            "Epoch 12/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4293 - acc: 0.8408\n",
            "Epoch 12: val_acc did not improve from 0.85000\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.4293 - acc: 0.8408 - val_loss: 0.5208 - val_acc: 0.8357\n",
            "Epoch 13/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3307 - acc: 0.8857\n",
            "Epoch 13: val_acc did not improve from 0.85000\n",
            "16/16 [==============================] - 82s 5s/step - loss: 0.3307 - acc: 0.8857 - val_loss: 0.5397 - val_acc: 0.8214\n",
            "Epoch 14/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3888 - acc: 0.8633\n",
            "Epoch 14: val_acc improved from 0.85000 to 0.87143, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-14-acc-0.87.hdf5\n",
            "16/16 [==============================] - 72s 5s/step - loss: 0.3888 - acc: 0.8633 - val_loss: 0.4659 - val_acc: 0.8714\n",
            "Epoch 15/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3570 - acc: 0.8878\n",
            "Epoch 15: val_acc improved from 0.87143 to 0.92857, saving model to percobaan4_noImgPro/model\\vgg_16_4-saved-model-15-acc-0.93.hdf5\n",
            "16/16 [==============================] - 73s 5s/step - loss: 0.3570 - acc: 0.8878 - val_loss: 0.4352 - val_acc: 0.9286\n",
            "Epoch 16/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3490 - acc: 0.9000\n",
            "Epoch 16: val_acc did not improve from 0.92857\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.3490 - acc: 0.9000 - val_loss: 0.4632 - val_acc: 0.8857\n",
            "Epoch 17/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3454 - acc: 0.8755\n",
            "Epoch 17: val_acc did not improve from 0.92857\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.3454 - acc: 0.8755 - val_loss: 0.4063 - val_acc: 0.9071\n",
            "Epoch 18/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3124 - acc: 0.9000\n",
            "Epoch 18: val_acc did not improve from 0.92857\n",
            "16/16 [==============================] - 84s 5s/step - loss: 0.3124 - acc: 0.9000 - val_loss: 0.3692 - val_acc: 0.8857\n",
            "Epoch 19/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2972 - acc: 0.8959\n",
            "Epoch 19: val_acc did not improve from 0.92857\n",
            "16/16 [==============================] - 74s 5s/step - loss: 0.2972 - acc: 0.8959 - val_loss: 0.4046 - val_acc: 0.8857\n",
            "Epoch 20/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3203 - acc: 0.8837\n",
            "Epoch 20: val_acc did not improve from 0.92857\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.3203 - acc: 0.8837 - val_loss: 0.3759 - val_acc: 0.9000\n",
            "Epoch 21/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2743 - acc: 0.9122\n",
            "Epoch 21: val_acc did not improve from 0.92857\n",
            "16/16 [==============================] - 71s 5s/step - loss: 0.2743 - acc: 0.9122 - val_loss: 0.4064 - val_acc: 0.9143\n",
            "Epoch 22/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2210 - acc: 0.9327\n",
            "Epoch 22: val_acc did not improve from 0.92857\n",
            "16/16 [==============================] - 82s 5s/step - loss: 0.2210 - acc: 0.9327 - val_loss: 0.3738 - val_acc: 0.9143\n",
            "Epoch 23/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2958 - acc: 0.8959\n",
            "Epoch 23: val_acc did not improve from 0.92857\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2958 - acc: 0.8959 - val_loss: 0.3763 - val_acc: 0.8929\n",
            "\n",
            "\n",
            "Model Accuracy 0.9285714285714286\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       1.00      1.00      1.00        10\n",
            "       10000       1.00      0.80      0.89        10\n",
            "      100000       1.00      1.00      1.00        10\n",
            "        2000       1.00      0.80      0.89        10\n",
            "       20000       0.90      0.90      0.90        10\n",
            "        5000       0.77      1.00      0.87        10\n",
            "       50000       0.91      1.00      0.95        10\n",
            "\n",
            "    accuracy                           0.93        70\n",
            "   macro avg       0.94      0.93      0.93        70\n",
            "weighted avg       0.94      0.93      0.93        70\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_19668\\777585943.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 490 images belonging to 7 classes.\n",
            "Found 70 images belonging to 7 classes.\n",
            "Found 140 images belonging to 7 classes.\n",
            "Percobaan ke- 5 ↓\n",
            "───────────────────────────────────────HYPERPARAMETER VGG-16────────────────────────────────────────\n",
            "vgg epoch: 45\n",
            "learning rate: 0.00433602899725914\n",
            "batch size: 32\n",
            "dropout rate: 0.638916709600142\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Epoch 1/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.6782 - acc: 0.2857\n",
            "Epoch 1: val_acc improved from -inf to 0.30714, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-01-acc-0.31.hdf5\n",
            "16/16 [==============================] - 87s 5s/step - loss: 2.6782 - acc: 0.2857 - val_loss: 2.3737 - val_acc: 0.3071\n",
            "Epoch 2/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.6128 - acc: 0.4735\n",
            "Epoch 2: val_acc did not improve from 0.30714\n",
            "16/16 [==============================] - 77s 4s/step - loss: 1.6128 - acc: 0.4735 - val_loss: 2.3714 - val_acc: 0.1786\n",
            "Epoch 3/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1282 - acc: 0.6204\n",
            "Epoch 3: val_acc did not improve from 0.30714\n",
            "16/16 [==============================] - 72s 5s/step - loss: 1.1282 - acc: 0.6204 - val_loss: 2.1953 - val_acc: 0.2071\n",
            "Epoch 4/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9439 - acc: 0.6898\n",
            "Epoch 4: val_acc improved from 0.30714 to 0.39286, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-04-acc-0.39.hdf5\n",
            "16/16 [==============================] - 83s 5s/step - loss: 0.9439 - acc: 0.6898 - val_loss: 1.4986 - val_acc: 0.3929\n",
            "Epoch 5/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7617 - acc: 0.7429\n",
            "Epoch 5: val_acc improved from 0.39286 to 0.48571, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-05-acc-0.49.hdf5\n",
            "16/16 [==============================] - 56s 4s/step - loss: 0.7617 - acc: 0.7429 - val_loss: 1.2663 - val_acc: 0.4857\n",
            "Epoch 6/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7224 - acc: 0.7592\n",
            "Epoch 6: val_acc improved from 0.48571 to 0.63571, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-06-acc-0.64.hdf5\n",
            "16/16 [==============================] - 71s 5s/step - loss: 0.7224 - acc: 0.7592 - val_loss: 1.0316 - val_acc: 0.6357\n",
            "Epoch 7/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6035 - acc: 0.7898\n",
            "Epoch 7: val_acc improved from 0.63571 to 0.71429, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-07-acc-0.71.hdf5\n",
            "16/16 [==============================] - 79s 5s/step - loss: 0.6035 - acc: 0.7898 - val_loss: 0.9338 - val_acc: 0.7143\n",
            "Epoch 8/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5174 - acc: 0.8163\n",
            "Epoch 8: val_acc improved from 0.71429 to 0.79286, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-08-acc-0.79.hdf5\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.5174 - acc: 0.8163 - val_loss: 0.7756 - val_acc: 0.7929\n",
            "Epoch 9/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5553 - acc: 0.8020\n",
            "Epoch 9: val_acc improved from 0.79286 to 0.81429, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-09-acc-0.81.hdf5\n",
            "16/16 [==============================] - 71s 4s/step - loss: 0.5553 - acc: 0.8020 - val_loss: 0.7005 - val_acc: 0.8143\n",
            "Epoch 10/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4701 - acc: 0.8490\n",
            "Epoch 10: val_acc improved from 0.81429 to 0.84286, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-10-acc-0.84.hdf5\n",
            "16/16 [==============================] - 76s 5s/step - loss: 0.4701 - acc: 0.8490 - val_loss: 0.5973 - val_acc: 0.8429\n",
            "Epoch 11/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4531 - acc: 0.8510\n",
            "Epoch 11: val_acc did not improve from 0.84286\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.4531 - acc: 0.8510 - val_loss: 0.5513 - val_acc: 0.8429\n",
            "Epoch 12/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4360 - acc: 0.8367\n",
            "Epoch 12: val_acc improved from 0.84286 to 0.86429, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-12-acc-0.86.hdf5\n",
            "16/16 [==============================] - 82s 5s/step - loss: 0.4360 - acc: 0.8367 - val_loss: 0.5135 - val_acc: 0.8643\n",
            "Epoch 13/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4104 - acc: 0.8449\n",
            "Epoch 13: val_acc did not improve from 0.86429\n",
            "16/16 [==============================] - 73s 5s/step - loss: 0.4104 - acc: 0.8449 - val_loss: 0.4361 - val_acc: 0.8643\n",
            "Epoch 14/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3673 - acc: 0.8714\n",
            "Epoch 14: val_acc improved from 0.86429 to 0.89286, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-14-acc-0.89.hdf5\n",
            "16/16 [==============================] - 71s 5s/step - loss: 0.3673 - acc: 0.8714 - val_loss: 0.3908 - val_acc: 0.8929\n",
            "Epoch 15/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3664 - acc: 0.8776\n",
            "Epoch 15: val_acc did not improve from 0.89286\n",
            "16/16 [==============================] - 76s 4s/step - loss: 0.3664 - acc: 0.8776 - val_loss: 0.3767 - val_acc: 0.8786\n",
            "Epoch 16/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3707 - acc: 0.8673\n",
            "Epoch 16: val_acc improved from 0.89286 to 0.90714, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-16-acc-0.91.hdf5\n",
            "16/16 [==============================] - 83s 5s/step - loss: 0.3707 - acc: 0.8673 - val_loss: 0.3550 - val_acc: 0.9071\n",
            "Epoch 17/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4533 - acc: 0.8347\n",
            "Epoch 17: val_acc did not improve from 0.90714\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.4533 - acc: 0.8347 - val_loss: 0.3451 - val_acc: 0.9000\n",
            "Epoch 18/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3789 - acc: 0.8857\n",
            "Epoch 18: val_acc did not improve from 0.90714\n",
            "16/16 [==============================] - 80s 5s/step - loss: 0.3789 - acc: 0.8857 - val_loss: 0.3222 - val_acc: 0.9071\n",
            "Epoch 19/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3078 - acc: 0.8980\n",
            "Epoch 19: val_acc did not improve from 0.90714\n",
            "16/16 [==============================] - 69s 4s/step - loss: 0.3078 - acc: 0.8980 - val_loss: 0.3400 - val_acc: 0.8857\n",
            "Epoch 20/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3357 - acc: 0.8673\n",
            "Epoch 20: val_acc improved from 0.90714 to 0.91429, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-20-acc-0.91.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.3357 - acc: 0.8673 - val_loss: 0.3241 - val_acc: 0.9143\n",
            "Epoch 21/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2696 - acc: 0.9143\n",
            "Epoch 21: val_acc improved from 0.91429 to 0.94286, saving model to percobaan5_noImgPro/model\\vgg_16_5-saved-model-21-acc-0.94.hdf5\n",
            "16/16 [==============================] - 76s 5s/step - loss: 0.2696 - acc: 0.9143 - val_loss: 0.2522 - val_acc: 0.9429\n",
            "Epoch 22/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2912 - acc: 0.9020\n",
            "Epoch 22: val_acc did not improve from 0.94286\n",
            "16/16 [==============================] - 82s 5s/step - loss: 0.2912 - acc: 0.9020 - val_loss: 0.2767 - val_acc: 0.9143\n",
            "Epoch 23/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3099 - acc: 0.8898\n",
            "Epoch 23: val_acc did not improve from 0.94286\n",
            "16/16 [==============================] - 76s 5s/step - loss: 0.3099 - acc: 0.8898 - val_loss: 0.3066 - val_acc: 0.9214\n",
            "Epoch 24/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2963 - acc: 0.8878\n",
            "Epoch 24: val_acc did not improve from 0.94286\n",
            "16/16 [==============================] - 76s 4s/step - loss: 0.2963 - acc: 0.8878 - val_loss: 0.2953 - val_acc: 0.9143\n",
            "Epoch 25/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3128 - acc: 0.9041\n",
            "Epoch 25: val_acc did not improve from 0.94286\n",
            "16/16 [==============================] - 71s 4s/step - loss: 0.3128 - acc: 0.9041 - val_loss: 0.3070 - val_acc: 0.9071\n",
            "Epoch 26/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2604 - acc: 0.9245\n",
            "Epoch 26: val_acc did not improve from 0.94286\n",
            "16/16 [==============================] - 81s 5s/step - loss: 0.2604 - acc: 0.9245 - val_loss: 0.2500 - val_acc: 0.9286\n",
            "Epoch 27/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2715 - acc: 0.9082\n",
            "Epoch 27: val_acc did not improve from 0.94286\n",
            "16/16 [==============================] - 75s 5s/step - loss: 0.2715 - acc: 0.9082 - val_loss: 0.2298 - val_acc: 0.9214\n",
            "Epoch 28/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2278 - acc: 0.9163\n",
            "Epoch 28: val_acc did not improve from 0.94286\n",
            "16/16 [==============================] - 81s 5s/step - loss: 0.2278 - acc: 0.9163 - val_loss: 0.2193 - val_acc: 0.9214\n",
            "Epoch 29/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2062 - acc: 0.9286\n",
            "Epoch 29: val_acc did not improve from 0.94286\n",
            "16/16 [==============================] - 70s 4s/step - loss: 0.2062 - acc: 0.9286 - val_loss: 0.2072 - val_acc: 0.9286\n",
            "Epoch 30/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2231 - acc: 0.9143\n",
            "Epoch 30: val_acc did not improve from 0.94286\n",
            "16/16 [==============================] - 76s 4s/step - loss: 0.2231 - acc: 0.9143 - val_loss: 0.2024 - val_acc: 0.9357\n",
            "Epoch 31/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2671 - acc: 0.9204\n",
            "Epoch 31: val_acc did not improve from 0.94286\n",
            "16/16 [==============================] - 81s 5s/step - loss: 0.2671 - acc: 0.9204 - val_loss: 0.2189 - val_acc: 0.9357\n",
            "Epoch 32/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2757 - acc: 0.8959\n",
            "Epoch 32: val_acc did not improve from 0.94286\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2757 - acc: 0.8959 - val_loss: 0.2425 - val_acc: 0.9143\n",
            "Epoch 33/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2497 - acc: 0.9204\n",
            "Epoch 33: val_acc did not improve from 0.94286\n",
            "16/16 [==============================] - 81s 5s/step - loss: 0.2497 - acc: 0.9204 - val_loss: 0.2262 - val_acc: 0.9071\n",
            "Epoch 34/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2425 - acc: 0.9143\n",
            "Epoch 34: val_acc did not improve from 0.94286\n",
            "16/16 [==============================] - 70s 4s/step - loss: 0.2425 - acc: 0.9143 - val_loss: 0.2230 - val_acc: 0.9357\n",
            "Epoch 35/45\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2786 - acc: 0.8959\n",
            "Epoch 35: val_acc did not improve from 0.94286\n",
            "16/16 [==============================] - 71s 4s/step - loss: 0.2786 - acc: 0.8959 - val_loss: 0.2486 - val_acc: 0.9071\n",
            "\n",
            "\n",
            "Model Accuracy 0.8428571428571429\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1000       0.73      0.80      0.76        10\n",
            "       10000       0.86      0.60      0.71        10\n",
            "      100000       1.00      0.90      0.95        10\n",
            "        2000       0.64      0.90      0.75        10\n",
            "       20000       1.00      0.80      0.89        10\n",
            "        5000       0.90      0.90      0.90        10\n",
            "       50000       0.91      1.00      0.95        10\n",
            "\n",
            "    accuracy                           0.84        70\n",
            "   macro avg       0.86      0.84      0.84        70\n",
            "weighted avg       0.86      0.84      0.84        70\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ardin\\AppData\\Local\\Temp\\ipykernel_19668\\777585943.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 700x700 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 700x700 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 700x700 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 700x700 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 700x700 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "for i in range (0,5):\n",
        "#for i in range (0,10): #aslinya in range len(parameter) tapi kalau mau coba per sedikit2 ya gini deh\n",
        "  vgg_epoch = 45\n",
        "  learning_rate = 0.00433602899725914\n",
        "  batch_size = 32\n",
        "  dropout_rate = 0.638916709600142\n",
        "  i=i+1\n",
        "  dataset = \"datasetSplit\"+str(i)\n",
        "  IMAGE_SIZE = (130, 242, 3)\n",
        "  train_pred_test_folders = os.listdir(dataset)\n",
        "  train_path = dataset+'/train'\n",
        "  test_path = dataset+'/test'\n",
        "  val_path = dataset+'/val'\n",
        "\n",
        "  #normalisasi\n",
        "  train_datagen = ImageDataGenerator(rescale = 1.0/255.,shear_range=0.2,zoom_range=0.2)\n",
        "  train_generator16 = train_datagen.flow_from_directory(train_path,\n",
        "                                                    batch_size=32,\n",
        "                                                    shuffle=True,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    target_size=(130, 242))\n",
        "\n",
        "  validation_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
        "\n",
        "  test_datagen = ImageDataGenerator(rescale = 1.0/255.,shear_range=0.2,zoom_range=0.2)\n",
        "  test_generator16 = test_datagen.flow_from_directory(test_path, target_size=(130, 242),\n",
        "      batch_size=1,\n",
        "      shuffle=True,\n",
        "      class_mode='categorical')\n",
        "\n",
        "  validation_generator16 = validation_datagen.flow_from_directory(val_path, shuffle=True, batch_size=1, class_mode='categorical', target_size=(130, 242))\n",
        "\n",
        "  savePercobaan(i)\n",
        "  print(\"Percobaan ke-\",i,\"↓\")\n",
        "  print(\"HYPERPARAMETER VGG-16\".center(100,\"─\"))\n",
        "  print(\"vgg epoch:\",vgg_epoch)\n",
        "  print(\"learning rate:\",learning_rate)\n",
        "  print(\"batch size:\",batch_size)\n",
        "  print(\"dropout rate:\",dropout_rate)\n",
        "  print(\"\".center(100,\"─\"))\n",
        "  vgg16_training(i, vgg_epoch, learning_rate, batch_size, dropout_rate)\n",
        "  new_row = {'Epoch': vgg_epoch, 'Learning Rate': learning_rate, 'Batch Size': batch_size, 'Dropout Rate': dropout_rate, 'Accuracy': arr_accuracy16[-1]}\n",
        "  hasilTabel = hasilTabel.append(new_row, ignore_index=True)\n",
        "  hasilTabel.index = hasilTabel.index + (i+1)\n",
        "  hasilTabel.to_excel(\"hasilTabelRevisi.xlsx\")\n",
        "  print(\"\".center(100,\"─\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Copying files: 700 files [00:01, 607.62 files/s]\n",
            "Copying files: 700 files [00:01, 638.14 files/s]\n",
            "Copying files: 700 files [00:01, 626.90 files/s]\n",
            "Copying files: 700 files [00:01, 652.18 files/s]\n",
            "Copying files: 700 files [00:00, 700.51 files/s]\n",
            "Copying files: 700 files [00:00, 703.48 files/s]\n",
            "Copying files: 700 files [00:01, 695.56 files/s]\n",
            "Copying files: 700 files [00:01, 657.38 files/s]\n",
            "Copying files: 700 files [00:01, 643.42 files/s]\n",
            "Copying files: 700 files [00:00, 704.97 files/s]\n"
          ]
        }
      ],
      "source": [
        "import splitfolders\n",
        "dataset=\"datasetAbu\"\n",
        "seed = [946, 521, 811, 358, 333, 1471, 25, 955, 1492, 467]\n",
        "for i in range(0,10):\n",
        "    splitfolders.ratio(dataset, output=\"datasetSplit\"+str(i+1), seed=seed[i], ratio=(0.7, 0.2, 0.1)) #70% : 10% : 20%\n",
        "    i=i+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import splitfolders\n",
        "dataset=\"datasetAbu\"\n",
        "seed = [946, 521, 811, 358, 333, 1471, 25, 955, 1492, 467, 300, 1221, 495, 782, 305, 302, 639, 740, 110, 125, 488, 728, 1444, 872, 819, 346, 1315, 855, 382, 1159, 1281, 537, 1354, 108, 377, 226, 170, 196, 1254, 951, 932, 737, 373, 1330, 562, 8, 546, 1111, 1037, 10]\n",
        "for i in range(6,50):\n",
        "    splitfolders.ratio(dataset, output=\"datasetSplit\"+str(i+1), seed=seed[i], ratio=(0.7, 0.2, 0.1)) #70% : 10% : 20%\n",
        "    i=i+1"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
