{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RbAFc0gCE1Yf"
      },
      "source": [
        "> ### **OPTIMAL DATA RANGE**\n",
        "---\n",
        "*   ClipLimit: 2-3\n",
        "*   Learning rate: 0.0001 < lr < 0.1\n",
        "*   Batch size: 32, 64, 128\n",
        "*   Dropout rate: 0,5 - 0,8\n",
        "*   Weight: auto"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GS2cutmMFf7k"
      },
      "source": [
        "> ### **STRUCTURE**\n",
        "---\n",
        "\n",
        "*   Optimizer: Adam\n",
        "*   Activation function: ReLu (training), Softmax (final)\n",
        "*   Pooling: _Max Pooling_\n",
        "*   Kernel size: 130x242\n",
        "*   Training/testing/validation: 70/10/20\n",
        "*   Epoch: 30-65\n",
        "*   Class: 7\n",
        "*   Weight: ImageNet\n",
        "*   Loss: Cross-Entropy"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RiQq7ALDHNRD"
      },
      "source": [
        " ## **DATA PREPARATION**\n",
        "---\n",
        "menyiapkan data (termasuk penerapan image enhancement)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install -r \"Rupiah-PCR-Using-Image-Processing-and-CNN\\requirements.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rzc4-JxOI9Jj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing, neighbors\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izpw8VI-I9lt",
        "outputId": "9b0ba66a-3bef-4e3f-92cf-89f1426a0490"
      },
      "outputs": [],
      "source": [
        "dataset = r\"Rupiah-PCR-Using-Image-Processing-and-CNN\\datasetUang\"\n",
        "\n",
        "kelas = os.listdir(path)\n",
        "print(\"Classes list = \",kelas,\"\\n\\nNumber of classes = \", len(kelas))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdSJFwNsKYPU",
        "outputId": "01eda199-75c1-48c0-d593-8fb193175023"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Copying files: 700 files [00:10, 63.86 files/s]\n"
          ]
        }
      ],
      "source": [
        "import splitfolders\n",
        "splitfolders.ratio(dataset, output=\"datasetSplit\", seed=1307, ratio=(0.7, 0.2, 0.1)) #70% : 10% : 20%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvw2D5W_LIuC",
        "outputId": "c9c4ce5e-8677-4860-d9b6-c9978b5941cd"
      },
      "outputs": [],
      "source": [
        "dataset = \"datasetSplit\"\n",
        "#daftar_file(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ToC7O1guLVMc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from keras.utils import plot_model\n",
        "from sklearn.metrics import classification_report\n",
        "from collections import Counter\n",
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "\n",
        "from keras import Model, layers\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.layers import GlobalMaxPooling2D, GlobalAveragePooling2D, Dropout, Dense, Input, Conv2D, MaxPooling2D, Flatten,MaxPooling3D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "25wCmnRGLWAB"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = (130, 242, 3)\n",
        "dataset=\"datasetSplit\"\n",
        "train_pred_test_folders = os.listdir(dataset)\n",
        "train_path = dataset+'/train'\n",
        "test_path = dataset+'/test'\n",
        "val_path = dataset+'/val'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "FiEY_6rHLYKz",
        "outputId": "9d4609ad-b9a0-4390-929a-2c655aa760b6"
      },
      "outputs": [],
      "source": [
        "quantity_train = {} \n",
        "quantity_test = {}\n",
        "quantity_val = {}\n",
        "for folder in os.listdir(train_path):\n",
        "    quantity_train[folder] = len(os.listdir(train_path+'/'+folder))\n",
        "\n",
        "for folder in os.listdir(test_path):\n",
        "    quantity_test[folder] = len(os.listdir(test_path+'/'+folder))\n",
        "\n",
        "for folder in os.listdir(val_path):\n",
        "    quantity_val[folder] = len(os.listdir(val_path+'/'+folder))\n",
        "\n",
        "quantity_train = pd.DataFrame(list(quantity_train.items()), index=range(0,len(quantity_train)), columns=['class','count'])\n",
        "quantity_test = pd.DataFrame(list(quantity_test.items()), index=range(0,len(quantity_test)), columns=['class','count'])\n",
        "quantity_val = pd.DataFrame(list(quantity_val.items()), index=range(0,len(quantity_val)), columns=['class','count'])\n",
        "\n",
        "figure, ax = plt.subplots(1,2,figsize=(20,5))\n",
        "sns.barplot(x='class',y='count',data=quantity_train,ax=ax[0])\n",
        "sns.barplot(x='class',y='count',data=quantity_test,ax=ax[1])\n",
        "\n",
        "print(\"Number of training set:\", sum(quantity_train['count'].values))\n",
        "print(\"Number of testing set:\",sum(quantity_test['count'].values))\n",
        "print(\"Number of prediction set:\",sum(quantity_val['count'].values))\n",
        "print(\"Total:\",sum(quantity_train['count'].values)+sum(quantity_test['count'].values)+sum(quantity_val['count'].values))\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MGtlhk8QLaZh"
      },
      "outputs": [],
      "source": [
        "def save_history(i, history, model_name):\n",
        "    #convert the history.history dict to a pandas DataFrame:     \n",
        "    hist_df = pd.DataFrame(history.history) \n",
        "\n",
        "    # save ke json \n",
        "    hist_json_file = 'CNN_Model'+str(i)+'_noImgPro/'+model_name+'_history.json' \n",
        "    with open(hist_json_file, mode='w') as f:\n",
        "        hist_df.to_json(f)\n",
        "\n",
        "    # or save ke csv \n",
        "    hist_csv_file = 'CNN_Model'+str(i)+'_noImgPro/'+model_name+'_history.csv'\n",
        "    with open(hist_csv_file, mode='w') as f:\n",
        "        hist_df.to_csv(f)\n",
        "        \n",
        "def plot_accuracy_from_history(history, isinception=False):\n",
        "  try:\n",
        "    color = sns.color_palette()\n",
        "    if(isinception == False):\n",
        "        acc = history.history['acc']\n",
        "        val_acc = history.history['val_acc']\n",
        "    else:\n",
        "        acc = history.history['accuracy']\n",
        "        val_acc = history.history['val_accuracy']\n",
        "    \n",
        "\n",
        "    epochs = range(len(acc))\n",
        "\n",
        "    sns.lineplot(epochs, acc, label='Training Accuracy')\n",
        "    sns.lineplot(epochs, val_acc,label='Validation Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.legend()\n",
        "    plt.figure()\n",
        "    plt.show()\n",
        "  except TypeError:\n",
        "    pass\n",
        "    \n",
        "def plot_loss_from_history(history):\n",
        "  try:\n",
        "    color = sns.color_palette()\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    \n",
        "    epochs = range(len(loss))\n",
        "    \n",
        "    sns.lineplot(epochs, loss,label='Training Loss')\n",
        "    sns.lineplot(epochs, val_loss, label='Validation Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.figure()\n",
        "    plt.show()\n",
        "  except TypeError:\n",
        "    pass\n",
        "    \n",
        "def do_history_stuff(i, history, history_file_name, isinception=False):\n",
        "    save_history(i, history, history_file_name)\n",
        "    plot_accuracy_from_history(history, isinception)\n",
        "    plot_loss_from_history(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ie_x1Pw9LlHe"
      },
      "outputs": [],
      "source": [
        "def show_few_images(number_of_examples=2, predict_using_model=None):\n",
        "    figure1, ax1 = plt.subplots(number_of_examples,len(os.listdir(train_path)), figsize=(20,4*number_of_examples))\n",
        "    ax1 = ax1.reshape(-1)\n",
        "    axoff_fun = np.vectorize(lambda ax:ax.axis('off'))\n",
        "    axoff_fun(ax1)\n",
        "    axs = 0\n",
        "    for i, folder in enumerate(os.listdir(train_path)):\n",
        "        image_ids = os.listdir(os.path.join(train_path,folder))\n",
        "        for j in [random.randrange(0, len(image_ids)) for i in range(0,number_of_examples)]:\n",
        "            display = plt.imread(os.path.join(train_path,folder,image_ids[j]))\n",
        "            plt.axis('off')\n",
        "            ax1[axs].imshow(display)\n",
        "            title = 'True:'+folder\n",
        "            if(predict_using_model):\n",
        "                predicted_classname = inv_map_classes[np.argmax(vgg16_final_model.predict(np.array([display])))]\n",
        "                title = title+'\\nPredict :'+predicted_classname\n",
        "            ax1[axs].set_title(title)\n",
        "            axs=axs+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xCuQKBilLnS9"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "z8lwG1_kv0gx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "def saveCNN_Model(i):\n",
        "  try: \n",
        "    os.mkdir(\"CNN_Model\"+str(i)+\"_noImgPro\") \n",
        "  except OSError as error: \n",
        "    print(error)\n",
        "  saveModel(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4HbaR-kTv3TN"
      },
      "outputs": [],
      "source": [
        "def saveModel(i):\n",
        "  try: \n",
        "    os.mkdir(\"CNN_Model\"+str(i)+\"_noImgPro/model\") \n",
        "  except OSError as error: \n",
        "    print(error)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TQdkty4ZLt0M"
      },
      "source": [
        " ## **VGG-16**\n",
        "---\n",
        "Visual Geometry Group (16 layers)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jXvi5J4K3j9-"
      },
      "source": [
        "#### **<font color='Pink'>Data Generator</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgkzGvmbnDxg",
        "outputId": "bd49992d-14ec-4a71-81be-02045365a35c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 490 images belonging to 7 classes.\n",
            "Found 70 images belonging to 7 classes.\n",
            "Found 140 images belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "#normalisasi\n",
        "train_datagen = ImageDataGenerator(rescale = 1.0/255.,shear_range=0.2,zoom_range=0.2)\n",
        "train_generator16 = train_datagen.flow_from_directory(train_path,\n",
        "                                                    batch_size=32,\n",
        "                                                    shuffle=True,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    target_size=(130, 242))\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1.0/255.,shear_range=0.2,zoom_range=0.2)\n",
        "test_generator16 = test_datagen.flow_from_directory(test_path, target_size=(130, 242),\n",
        "    batch_size=1,\n",
        "    shuffle=True,\n",
        "    class_mode='categorical')\n",
        "\n",
        "validation_generator16 = validation_datagen.flow_from_directory(val_path, shuffle=True, batch_size=1, class_mode='categorical', target_size=(130, 242))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jr3pfWLTnF8_",
        "outputId": "a6b2bfd0-2659-44f6-8a42-f29101199cda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: '1000', 1: '10000', 2: '100000', 3: '2000', 4: '20000', 5: '5000', 6: '50000'}\n"
          ]
        }
      ],
      "source": [
        "inv_map_classes = {v: k for k, v in validation_generator16.class_indices.items()}\n",
        "#print(validation_generator16.class_indices)\n",
        "print(inv_map_classes)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aActKL9O3mnY"
      },
      "source": [
        "#### **<font color='Pink'>Hyperparameter</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "NjEEV1Mx385B"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "import random\n",
        "\n",
        "array = [['ep1','ep2','ep3','ep4'], ['lr1', 'lr2', 'lr3', 'lr4'], [32, 64, 128], ['dr1', 'dr2', 'dr3', 'dr4']]\n",
        "\n",
        "parameter = []\n",
        "lr_values = array[1][1:]  \n",
        "\n",
        "for _ in range(1):\n",
        "    updated_array = [array[0], ['lr1'] + lr_values, array[2], array[3]]\n",
        "    parameter.extend(list(itertools.product(*updated_array)))\n",
        "\n",
        "parameter = [\n",
        "    [\n",
        "        random.randint(30, 38) if val == 'ep1' else\n",
        "        random.randint(39, 47) if val == 'ep2' else\n",
        "        random.randint(48, 56) if val == 'ep3' else\n",
        "        random.randint(57, 65) if val == 'ep4' else\n",
        "\n",
        "        random.uniform(0.0001, 0.0250249) if val == 'lr1' else\n",
        "        random.uniform(0.025025, 0.050049) if val == 'lr2' else\n",
        "        random.uniform(0.05005, 0.0750749) if val == 'lr3' else\n",
        "        random.uniform(0.075075, 0.1) if val == 'lr4' else\n",
        "\n",
        "        random.uniform(0.5,0.5749) if val == 'dr1' else\n",
        "        random.uniform(0.575,0.649) if val == 'dr2' else\n",
        "        random.uniform(0.65,0.7249) if val == 'dr3' else\n",
        "        random.uniform(0.725,0.CNN_Model) if val == 'dr4' else\n",
        "\n",
        "        val\n",
        "        for val in combination\n",
        "    ]\n",
        "    for combination in parameter\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3r9T4AumF8JZ",
        "outputId": "f4f89d5d-c0c9-41c7-b0e3-743f28884496"
      },
      "outputs": [],
      "source": [
        "for combination in parameter:\n",
        "    print(combination)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HMKIsY1N6XTH"
      },
      "source": [
        "#### **<font color='Pink'>Model Training</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "oQwWy9EDvRfT"
      },
      "outputs": [],
      "source": [
        "from keras.layers import BatchNormalization\n",
        "def vgg16_training(i, vgg_epoch, learning_rate, batch_size, dropout_rate):\n",
        "  vgg16_model = VGG16(pooling='max', weights='imagenet', include_top=False, input_shape=(130,242,3), classes=7) #defaultnya AVERAGE POOLING\n",
        "  for layers in vgg16_model.layers:\n",
        "              layers.trainable=False\n",
        "\n",
        "  last_output_vgg16 = vgg16_model.layers[-1].output\n",
        "  vgg_16 = Flatten()(last_output_vgg16) #awalnya di bawah last output\n",
        "  vgg_16 = BatchNormalization()(vgg_16)\n",
        "  vgg_16 = Dense(128, activation = 'relu')(vgg_16)\n",
        "  vgg_16 = BatchNormalization()(vgg_16)\n",
        "  vgg_16 = Dropout(dropout_rate)(vgg_16)\n",
        "\n",
        "  #vgg_16 = Dense(64, activation = 'relu')(vgg_16)\n",
        "  #vgg_16 = Dropout(dropout_rate)(vgg_16)\n",
        "  vgg_16 = Dense(7, activation = 'softmax')(vgg_16)\n",
        "  vgg16_final_model = Model(vgg16_model.input, vgg_16)\n",
        "  \n",
        "  opt = Adam(learning_rate=learning_rate)\n",
        "  vgg16_final_model.compile(loss = 'categorical_crossentropy', optimizer= opt, metrics=['acc'])\n",
        "  #vgg16_final_model.summary()\n",
        "\n",
        "  #plot_model(model=vgg16_final_model, show_shapes=True)\n",
        "\n",
        "  train_generator16.batch_size = batch_size\n",
        "\n",
        "  vgg16_filepath = 'CNN_Model'+str(i)+'_noImgPro/model/vgg_16_'+str(i)+'-saved-model-{epoch:02d}-acc-{val_acc:.2f}.hdf5'\n",
        "  vgg16_checkpoint = tf.keras.callbacks.ModelCheckpoint(vgg16_filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "  vgg16_history = vgg16_final_model.fit(train_generator16, epochs = vgg_epoch, validation_data = validation_generator16,callbacks=[vgg16_checkpoint,early_stopping],verbose=1)\n",
        "\n",
        "  do_history_stuff(i, vgg16_history, 'vgg16_model')\n",
        "  save_vgg16(i, vgg16_final_model)\n",
        "\n",
        "  predictionTest(i, vgg16_final_model)\n",
        "\n",
        "  return(vgg16_final_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "uzyGkyI39Dbv"
      },
      "outputs": [],
      "source": [
        "def save_vgg16(i, vgg16_final_model):\n",
        "  vgg16_final_model.save(('CNN_Model'+str(i)+'_noImgPro/vgg16-model'+str(i)+'.h5'))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TIFMfEwf8HR8"
      },
      "source": [
        "#### **<font color='Pink'>Evaluation</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "siSMQNcU8oB-"
      },
      "outputs": [],
      "source": [
        "def acc_plot(vgg16_history):\n",
        "  plt.figure(figsize=(10, 8))\n",
        "  plt.plot(vgg16_history.history['acc'], label='train acc')\n",
        "  plt.plot(vgg16_history.history['val_acc'], label='val acc')\n",
        "  plt.legend()\n",
        "  plt.title('Accuracy')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "E7alj36o8w5T"
      },
      "outputs": [],
      "source": [
        "def loss_plot(vgg16_history):\n",
        "  plt.figure(figsize=(10, 8))\n",
        "  plt.plot(vgg16_history.history['loss'], label='train loss')\n",
        "  plt.plot(vgg16_history.history['val_loss'], label='val loss')\n",
        "  plt.legend()\n",
        "  plt.title('Loss')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "hoxqXW5381w9"
      },
      "outputs": [],
      "source": [
        "def predictionTest(i, vgg16_final_model):\n",
        "  true_value = []\n",
        "  vgg_pred = []\n",
        "  for folder in os.listdir(test_path):\n",
        "      test_image_ids = os.listdir(os.path.join(test_path,folder))\n",
        "      \n",
        "      for image_id in test_image_ids[:int(len(test_image_ids))]:\n",
        "          path = os.path.join(test_path,folder,image_id)\n",
        "          #print(path)\n",
        "          true_value.append(test_generator16.class_indices[folder])\n",
        "          img = cv2.resize(cv2.imread(path),(242,130))\n",
        "          img_normalized = img/255\n",
        "          #vgg\n",
        "          vgg16_image_prediction = np.argmax(vgg16_final_model.predict(np.array([img_normalized]), verbose = 0)) #verbose biar gak ngeprint\n",
        "          vgg_pred.append(vgg16_image_prediction)\n",
        "\n",
        "  print(\"\\n\")\n",
        "  clf_report(i, true_value, vgg_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "pJV_qqpT86bD"
      },
      "outputs": [],
      "source": [
        "arr_accuracy16 = []\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "#from mlxtend.plotting import plot_confusion_matrix\n",
        "def clf_report(k, true_value, model_pred):\n",
        "    classes = validation_generator16.class_indices.keys()\n",
        "    TP_count = [true_value[i] == model_pred[i] for i in range(len(true_value))]\n",
        "    model_accuracy = np.sum(TP_count)/len(TP_count)\n",
        "    print('Model Accuracy', model_accuracy)\n",
        "    arr_accuracy16.append(model_accuracy)\n",
        "    plt.figure(figsize=(7,7))\n",
        "    cm = confusion_matrix(true_value,model_pred)\n",
        "    plt.imshow(cm,interpolation='nearest',cmap=plt.cm.viridis)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    thresh = cm.max()*0.8\n",
        "    for i,j in itertools.product(range(cm.shape[0]),range(cm.shape[1])):\n",
        "        plt.text(j,i,cm[i,j],\n",
        "                horizontalalignment=\"center\",\n",
        "                color=\"black\" if cm[i,j] > thresh else \"white\")\n",
        "        pass\n",
        "    \n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    pass\n",
        "    \n",
        "    plt.savefig(\"CNN_Model\"+str(k)+\"_noImgPro/conf_matrix\"+str(k)+\".png\")\n",
        "    print(classification_report(true_value, model_pred, target_names = list(classes)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Empty DataFrame\n",
            "Columns: [Epoch, Learning Rate, Batch Size, Dropout Rate, Accuracy]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "resultTable = pd.DataFrame(columns=['Epoch', 'Learning Rate', 'Batch Size', 'Dropout Rate','Accuracy'])\n",
        "print(resultTable)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nr5k_MjPDmTN"
      },
      "source": [
        "#### **<font color='Pink'>Code Running</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "j = 0\n",
        "for i in range (j,len(parameter)):\n",
        "  vgg_epoch = (parameter[i][0])\n",
        "  learning_rate = (parameter[i][1])\n",
        "  batch_size = (parameter[i][2])\n",
        "  dropout_rate = (parameter[i][3])\n",
        "  i=i+1\n",
        "  saveCNN_Model(i)\n",
        "  print(\"CNN_Model\",i,\"↓\")\n",
        "  print(\"HYPERPARAMETER\".center(100,\"─\"))\n",
        "  print(\"vgg epoch:\",vgg_epoch)\n",
        "  print(\"learning rate:\",learning_rate)\n",
        "  print(\"batch size:\",batch_size)\n",
        "  print(\"dropout rate:\",dropout_rate)\n",
        "  print(\"\".center(100,\"─\"))\n",
        "  vgg16_training(i, vgg_epoch, learning_rate, batch_size, dropout_rate)\n",
        "  new_row = {'Epoch': vgg_epoch, 'Learning Rate': learning_rate, 'Batch Size': batch_size, 'Dropout Rate': dropout_rate, 'Accuracy': arr_accuracy16[-1]}\n",
        "  resultTable = resultTable.append(new_row, ignore_index=True)\n",
        "  resultTable.index = resultTable.index + (j+1)\n",
        "  resultTable.to_excel(\"resultTable.xlsx\")\n",
        "  print(\"\".center(100,\"─\"))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
